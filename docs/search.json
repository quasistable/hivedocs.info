[
  
    
    
    
    
    
    {
      "author"    : "inertia",
      "title"    : "Ruby Client for Hive: hive-ruby-1.0.0.pre.1",
      "category" : "tools, ruby",
      "url"      : "/tools/ruby/2020/05/07/ruby-client-for-hive-hive-ruby-1-0-0-pre-1.html",
      "date"     : "2020-05-07 01:16:18 -0700",
      "desc"     : "The hive-ruby gem was written from the ground.",
      "content"  : "hive-rubyhive-ruby the ruby api for hive blockchain.radiator vs. hive-rubythe hive-ruby gem was written from ground up by @inertia, who is also author of radiator. “i intend to continue work on radiator indefinitely. but in radiator-0.5, i refactor so that uses as its core. this means some features like serialization will become redundant. think it’s still useful do own because it reduces number requests.” - @inertia has internal failover logic can have delegated externally passes error responses caller handles and raises exceptions supports tx signing, does delegates database_api.get_transaction_hex, then deserializes verify all apis methods are hardcoded asks jsonrpc what available node (radiator-0.4.x) only appbase relies condenser_api not rely (wip) small list helper select ops (in addition build your transaction) complete implementation every op (yet) support json-rpc-batch requests getting startedthe compatible with 2.2.5 or later.install project(assuming installed computer, well rubygems)to install run shell:gem hive-ruby… add code:require 'hive'to a dependency project bundler, you line gemfile:gem 'hive-ruby', require: 'hive'examplesbroadcast voteparams = { voter: voter, author: author, permlink: permlink, weight: weight}hive::broadcast.vote(wif: wif, params: params) |result| puts resultendstreamingthe value passed block an object, keys: :type :value.stream hive::stream.newstream.operations |op| #{op.type}: #{op.value}endto start stream specific number, pass argument:stream hive::stream.newstream.operations(at_block_num: 9001) #{op.value}endyou grab related transaction id each operation:stream |op, trx_id, block_num| #{block_num} :: #{trx_id} certain operations:stream hive::stream.newstream.operations(types: :vote_operation) #{op.value}endor array [:comment_operation, :vote_operation]) (optionally) just operation(s) want arguments. semantic sugar when types take defaults.stream hive::stream.newstream.operations(:vote_operation) include virtual hive::stream.newstream.operations(include_virtual: true) #{op.value}endmultisigyou use multisignature broadcast operation.params [wif1, wif2], resultendin signing multiple wif private keys, possible export partially signed completed someone else.builder hive::transactionbuilder.new(wif: wif1)builder.put(vote: weight})trx builder.sign.to_jsonfile.open('trx.json', 'w') |f| f.write(trx)endthen send contents trx.json other party they privately sign transaction.trx open('trx.json').readbuilder wif2, trx: trx)api hive::condenserapi.newtrx builder.transactionapi.broadcast_transaction_synchronous(trx)get accountsapi hive::databaseapi.newapi.find_accounts(accounts: ['hiveio', 'alice']) result.accountsendreputation formatterrep hive::formatter.reputation(account.reputation)puts reptests clone client repository into directory choice: git &lt;a href=https://gitlab.syncad.com/hive/hive-ruby.git&gt;https://gitlab.syncad.com/hive/hive-ruby.git&lt;/a&gt; navigate new folder cd tests be invoked follows: bundle exec rake test static tests: test:static (broadcast simulated, actually used): test:broadcast threads (which quickly verifies thread safety): test:threads testnet actual broadcasts) test_node=&lt;a href=https://testnet-api.openhive.network&gt;https://testnet-api.openhive.network&lt;/a&gt; test:testnet part above execution: block_range, which streams blocks (using json-rpc-batch) stream:block_range if point any tests, instead letting suite pick default, set environment variable test_node, e.g.:$ testcontributionspatches welcome! contributors listed hive-ruby.gemspec file. please (rake test) before opening pull request make sure passing them. would contribute, don’t know on, check issues list.issueswhen find issues, report them!licensemit see: hive: hive-ruby-1.0.0.pre.1"
    } ,
  
    
    
    
    
    
    {
      "author"    : "gtg",
      "title"    : "Hive Pressure 2: How to Answer Hive Questions?",
      "category" : "news, devops, hivemind, nodes",
      "url"      : "/news/devops/hivemind/nodes/2020/05/04/hive-pressure-2-how-to-answer-hive-questions.html",
      "date"     : "2020-05-04 11:32:57 -0700",
      "desc"     : "",
      "content"  : "first, you need to learn how ask good questions, and here are some of the resources that will help do so:https://developers.hive.io/apidefinitions/https://hive.hivesigner.com/(kudos @inertia @good-karma)this set api calls is far from perfect, but for now it has be enough general purpose nodes.https://www.youtube.com/watch?v=vlw9lde3duithe big, slow, ugly.back in days, we used run a so-called “full node”, single steemd (yeah, haven’t renamed binary yet) node was built with low_memory_node=off clear_votes=off configured all plugins can get.it required lot ram, replayed ages, huge pain keep running.our code great running blockchain. it’s not equally efficient when answer complex questions.current architecturethe idea move workload requiring queries out our blockchain nodes. +----------+ | &lt;-----------------+ @ @@@@@@ ,@@@@@% hivemind @@@@ (@@@@@* +-------+ &lt;-------+ %@@@@@@ %@@@@@, +-----^----+ @@@@@@@@@@ redis ,@@@@@@@@@@@@ &lt;--+ +----v-----+ @@@@@@@@@@@@@@@&amp; +-v-+ @@@@@@@@@@@@@@@@@@ .@@@@@% &lt;-----&gt; ah @@@@@@@@@@@@@@@@@@@@@( +--&gt; j @@@@@@@@@@@@@@@@@@@@ &lt;-------&gt; u *@@@@@@@@@@@@@@@@ @@@@@@. nginx s @@@@@@@@@@@@@@ &amp;@@@@@. #@@@@@@@@@@ #@@@@@/ i @@@@@@@@ /@@@@@/ fat &lt;---+ @@@@@( .@@@@@&amp; +---+ @@ @@@@@&amp; sorry, lack gimp skillshivemindfor this use (hats off @roadscape) backed by postgresql. hive “consensus interpretation” layer blockchain, maintaining state social features such as post feeds, follows, communities. written python, synchronizes an sql database chain state, providing developers more flexible/extensible alternative raw hived api.fat nodealso, instead plugins, chose two nodes, one them “fat node” (low_memory_node=off clear_votes=off) on mira-enabled instance feed hivemind.please note have included market_history my configuration, simply because doesn’t require requires it, so make sure somewhere.ah nodeaccount history other setup. serves only account history, definitely heaviest plugin here, hence name.i’m using mira prefer pre-mira implementation had issues it. also, way too slow replay.jussiinstead service, three specialized ones, route incoming them.so get_account_history goes node, while get_followers hivemind.that’s what jussi does, also caches things.redisjussi uses in-memory data cache. very effectively take load even though most entries quickly expire, common questions “what’s head block?” 8 dapps asking latest block result 1 call 7 cache hits redis.nginxthat’s world facing component - your ssl termination, rate limiting, balancing, fancy stuff related serving clients.resourcesnow know components, let’s look at (in darkness) bind them.small stuffthere no specific needs here. traffic expect, need, they any reasonable server instance: usually bunch cores ram. different than comes resources. few gb ram hold data.big which non-mira setup, plenty shared_memory.bin file either tmpfs or buffer/cache especially during replay. machine 32gb work, would rather suggest 64gb these days. course, low latency storage ssd nvme must. 600gb setup mira, memory hungry, have, effective be. 16gb might go don’t try without fast nvme. 400gb itself simple script, postgresql backend, things needs. pretty much everything, long space fit data, currently 300gb. faster better performance. zero heroreference hardware configuration:intel(r) xeon(r) e-2274g cpu 4.00ghz64gb ecc, 2666mt/s2x 960gb (samsung pm983)when starting scratch, best get recent block_logi’m https://gtg.openhive.network/get/blockchain/how depends network server. average downloading speed around 30mb/s, should able less 3 hours. type replay time 15 hours 42 minutes 48 53 85 50 roughly 4 days 9 synced block. improved working that. developer-friendly, improve available calls, finally rid deprecated ones get_state, away wrapper condenser_api. that’s story occasion. see: pressure 2: questions? @gtg"
    } ,
  
    
    
    
    
    
    {
      "author"    : "good-karma",
      "title"    : "Interactive Hive API moved to Hivesigner",
      "category" : "news, swagger, api",
      "url"      : "/news/swagger/api/2020/04/29/interactive-hive-api-moved-to-hivesigner.html",
      "date"     : "2020-04-29 05:59:54 -0700",
      "desc"     : "Thank you everyone for your...",
      "content"  : "thank you everyone for your support on hivesigner proposal. we are almost in range of approved proposals. if haven’t voted, please consider approving proposal to help us make better. recent updatessome updates have missed developments related hivesigner: python client released thanks @emrebeyler his awesome job and contribution. voting witness! wiki updated, process unifying all documentation via github so that website can mirror guide developers. integrating oauth is quite simple but with proper it even new developers start developing blockchain/hive. earlier today, pushed release changes some links fixes few bugs dhive. chrome/brave extension update submitted review, should be available soon. effort onboarding more apps hive, introducing interactive hive api explorer visit https://hive.hivesigner.com try out directly browser. opensource, find or want contribute, feel free create pull request report issues githubit has search field relevant apis quickly, queries default values results fetched single click, i believe very convenient get started. check out!simply studying + api, building decentralized matter hours.buidl on!support vote hivedao: https://hivedao.com/proposal/88 peakd: https://peakd.com/proposals/88 hiveblog wallet: https://wallet.hive.blog/proposals discord: https://discord.gg/pnjn7wh roadmap thread see: moved by @good-karma"
    } ,
  
    
    
    
    
    
    {
      "author"    : "someguy123",
      "title"    : "How to set up a Hive Witness or Seed node (non-MIRA) / Upgrade from Steem-Docker to Hive-Docker",
      "category" : "howto, witness, docker, node",
      "url"      : "/howto/witness/docker/node/2020/04/27/how-to-set-up-a-hive-witness-or-seed-node-non-mira-upgrade-from-steem-docker-to-hive-docker.html",
      "date"     : "2020-04-27 12:30:21 -0700",
      "desc"     : "In this post you'll learn how to setup a Hive witness, or upgrade from Steem-docker",
      "content"  : "fresh installto become a witness without using mira, you’ll require server with at least 64gb of ram, 500gb disk (preferably ssd / nvme), and fast, reliable network.if you do not have which meets these requirements, can order one from privex (you even pay hive/hbd!)i personally use @privex for my own as top 20. while i am the ceo privex, there are many other customers, including witnesses who our servers their nodes, seed rpc nodes and/or projects.you’re free to any provider. don’t recommend trying run on your home internet, it’s likely enough witness.be aware that certain providers poor networks or hardware, may cause missed blocks, so be hopping around few until find that’s suitable node.if want learn more about what they do, check out article: hereshared memory noteright now, minimum ram requirement non-mira is due shared memory.this because hive stores information in file called “shared_memory.bin” used similar ram. this 58gb hf23, will continue grow overtime.as continues grow, need increase amount server. it better some room.install hive-docker dependenciesfirst, we install basic dependencies (assuming you’re ubuntu/debian).sudo apt updatesudo git curl wgetnext, (a line starting # comment, paste them)git clone &lt;a href=https://github.com/someguy123/hive-docker.git&gt;https://github.com/someguy123/hive-docker.git&lt;/a&gt;cd hive-docker# if don't already docker installation, you./run.sh install_dockerafter install_docker command has finished, recommended log back again (e.g. close ssh client re-connect) ensure shell correctly detects docker.then, download latest witness/seed image# downloads/updates low-memory image hive./run.sh installif witness, adjust configuration needed e.g. name, private key, logging config, turn off p2p-endpoint etc.if running seed, then worry just work skip signing key/config sectiongenerating keyfor witnesses, generate key first. remote wallet this.open public following command:./run.sh remote_walletnote: receive an error such “timeout” “invalid http status”. normal, usually load balancer having temporary problems.just times connects (you’ll see new»&gt; locked»&gt;)create pair witness.suggest_brain_key should get something this:{ brain_priv_key: gocart vincent photic iron outhit unglobe sicca lop taskit booster winded spry sackbut unice well rubelle, wif_priv_key: 5j1wn41bbss4l83n9n7p5nmmsvg9uawfvysnd363tvyhwpzu2e9, pub_key: stm7icekcr261f7cebcsmpe1rcw8hnr5pzykcfbuvqe5hsj41yewe}put keys notepad moment lose them.press ctrl-d exit wallet.setting up confignow, set name key. nano simple text editor linux) this.nano data/witness_node_data_dir/config.iniif change first lines disable seed.# endpoint p2p node listen onp2p-endpoint = 0.0.0.0:2001simply place (hash sign) start line. seed. example:# on#p2p-endpoint 0.0.0.0:2001now add settings. scroll down (use up/down arrows, page up/down) like this:# percent (0-99) must participating produce blocksrequired-participation 33# controlled by initwitness )# =# miner its [account,wif key] number threads proof mining# mining-threads wif miners# private-key uncomment (remove start) line, line.grab public/private saved earlier into (or app).then, below, witness’ quotes, “someguy123” front =, (without quotes) save time future, useful comment above (see example)example:# )witness someguy123# key: stm7icekcr261f7cebcsmpe1rcw8hnr5pzykcfbuvqe5hsj41yeweprivate-key 5j1wn41bbss4l83n9n7p5nmmsvg9uawfvysnd363tvyhwpzu2e9now nano) press ctrl-x, y when asks would save.environment settingsif comfortable linux, play settings consider setting .env file, readme informationotherwise, let’s continue. defaults generally fine most people.setting memory, swap settings, downloading blockchainat point have: installed hive-in-a-box (through run.sh command) downloaded container configurationyour almost ready. small things.you’ll size sudo logged root). 64 gigabytes (64g). please changes constantly.sudo ./run.sh shm_size 64gyou’ll also “swappiness”. tells linux how much (virtual disk. very slow). 1, means “don’t unless absolutely necessary”. helps prevent blocks excessive swapping despite plenty ram.# persist reboot, 'vm.swappiness=1' /etc/sysctl.confsudo sysctl -w vm.swappiness=1now you’ve configured server, block log, replays faster than download../run.sh dlblocksalmost ready!once done, ready replay steemd (the binary still hive) docker, begin replaying blockchain was create index, shared_memory file../run.sh replayyou status logs command../run.sh logsassuming did everything correctly, this:------------------------------------------------------ network------------------------------------------------------initminer stm8gc13uczbp44hzmlv6zpzgwvq8nt4kji8papspinq1bk153xtxchain id: 0000000000000000000000000000000000000000000000000000000000000000blockchain version: 0.23.0------------------------------------------------------2393837ms main.cpp:121 main ] backtrace segfault enabled.2393837ms chain_plugin.cpp:405 plugin_startup chain shared_file_size: 53687091200 bytes2393837ms chain_plugin.cpp:483 user request.2393837ms database.cpp:185 reindex reindexing blockchain2396435ms block_log.cpp:142 open nonempty2396435ms block_log.cpp:151 index database.cpp:193 blocks...please take hours depending speed cpu. cases 24 hours.you ctrl-c logs, leave watch replay.after replayedonce looks this, now go:1299055ms th_a application.cpp:507 handle_block got 14 transactions 12928269 pharesim -- latency: 55 ms1302427ms 18 12928270 xeldal 426 ms1305291ms 26 12928271 arhag 291 ms1308045ms 20 12928272 pfunk 45 ms1311092ms 23 12928273 bhuz 92 msgo profile: https://wallet.hive.blog/@yourusername/permissions https://peakd.com/@yourusername/permissions (for links, edit @yourusername part) click wallet, permissions. next “active key” “reveal”. button in. “show key”, reveal it. make sure begins “5”.copy key.now with:./run.sh walletset password, unlock same import active wallet.hive.blog peakd (not notepad):set_password hunter2unlock hunter2import_key 5somethingprivatekeyfinally, update/create network. replace stmxxxx wrote config there), yourname hive.update_witness https://hive.blog/witness-category/@yourname/my-witness-thread stmxxxxxxx {account_creation_fee:3.000 hive,maximum_block_size:65536,sbd_interest_rate:0} truecongratulations, working, getting votes producing blocksother informationyou /dev/shm (shared memory) across reboots. /etc/fstab, careful, mistakes system unbootable. (if try break server).simply bottom new damage file. “64g” whatever be.tmpfs tmpfs nodev,nosuid,size=64g 0 0see advanced options.upgrading steem-docker hive-dockerif existing convert installation below steps.updating repositoryuse set-url track repository. fetch updates, checkout master, pull update hive-docker.~/steem-docker $ origin href=https://github.com/someguy123/hive-docker.git&gt;https://github.com/someguy123/hive-docker.git&lt;/a&gt;~/steem-docker fetch~/steem-docker master~/steem-docker pullto always uses network, network=hive fileecho &gt;&gt; .envdownload hf23 were previously steem, state filesdelete files clean cleandownload block_log:./run.sh dlblocksnow slow part - replayingwhen upgrading steem hive, replay.to (this shutdown remove software, mode)./run.sh stop./run.sh command./run.sh logsnote: automatically updates realtime. ctrl-cif all well, v0.23.0 version read this):------------------------------------------------------ blocks...once replayed (may 3 hours), standard “got x y”.1668107ms p2p_plugin.cpp:210 54 25299003 cervantes 107 ms1671090ms 36 25299004 blocktrades 90 ms1674098ms 28 25299005 roelandp 98 msif re-enable :)you’re successfully upgraded 0.23.0 higher).for future releases, &amp;&amp; restart, but always, assume needed. test backup, before attempting update.to i’ve released haven’t made post yet, hub: https://hub.docker.com/r/someguy123/hive/tags/ gif avatar @stellabelledo i’m doing hive?vote me every vote counts.don’t forget follow this.are looking provider? company offers highly-reliable affordable dedicated virtual hbd, eos, monero, doge, ltc, btc!check website https://www.privex.iojoin discord at: https://invite.gg/privex see: (non-mira) upgrade @someguy123"
    } ,
  
    
    
    
    
    
    {
      "author"    : "engrave",
      "title"    : "Improvements for Condenser repository, Continuous Integration and Deployments",
      "category" : "howto, devops, docker",
      "url"      : "/howto/devops/docker/2020/04/19/improvements-for-condenser-repository-continuous-integration-and-deployments.html",
      "date"     : "2020-04-19 13:38:27 -0700",
      "desc"     : "I want to elaborate not onl...",
      "content"  : "i want to elaborate not only on introduced features but also my thought and reasoning so everyone can benefit introduce changes in their projects. this post will be long believe it might useful for the entire hivedevs community.the workflow is built top of gitlab ci/cd easily modified any other tool (i.e. circleci or jenkins).dockeri’ve started work by reviewing dockerfile. i’ve condenser image was a bit shocked:$ docker lscondenser latest 6d57c0c8a904 19 seconds ago 1.54gb1.54 gb simple frontend application? boy, it’s just too much. let’s do something with it.leaner imagelet’s start recognizing reason why big. you look into your dockerfile package.json search some common mistakes: using full-sized images rather than alpine versions installing dev dependencies production putting list copying useless files final imageyep, check every point here. make new dockerfile:from node:12.16.2 as developmentworkdir /var/appcopy yarn.lock ./run yarn install --non-interactive --frozen-lockfile --ignore-optionalcopy . .run mkdir tmp &amp;&amp; buildcmd [ yarn, run, ]### remove ##from development dependenciesrun --ignore-optional --production### build minified node:12.16.2-alpine productionworkdir /var/apparg source_commitenv source_commit ${source_commit}arg docker_tagenv docker_tag ${docker_tag}copy --from=dependencies /var/app/package.json /var/app/package.jsoncopy /var/app/config /var/app/configcopy /var/app/dist /var/app/distcopy /var/app/lib /var/app/libcopy /var/app/src /var/app/srccopy /var/app/tmp /var/app/tmpcopy /var/app/webpack /var/app/webpackcopy /var/app/node_modules /var/app/node_modulescopy /var/app/healthcheck.js /var/app/healthcheck.jshealthcheck --interval=30s --timeout=5s --start-period=30s --retries=5 cmd node /var/app/healthcheck.jscmd ]what has been improved: node.js version upgraded from 8.7 12.16.2 which lts at moment. always try framework versions, may include security fixes performance upgrades. good habit use specific up patch number. multistage used an optimal deployment. first, we stage dependency able compile react application. next, we’re removing --production switch during stage. after all, creating minimal smallest base available, necessary directories. healthcheck introduced, daemon manage containers automatic restarts if zero-downtime deployments explained later post. dynamic scaling capabilities swarm.also, file modified, worth its content here: like webpack, babel eslint moved proper called devdependencies could deps image. strict were sure produces exactly same semantic versioning popular, there no way package author does breaking increased. need update package, manually. have enough test coverage, run everything works fine.after all that done, size massively reduced:$ 58406d338e67 8 226mbthe compressed registry even smaller. much better, right? shame you, steemit!healthchecksimply speaking, running trying keep alive possible. system needs determine container actually alive. seem alive, app responding requests example? fortunately, integrated health mechanism docker-compose.yml. usually, create endpoint liveness checks. already one utilize easily.there lot examples curl check, go. should cross-platform implementation differs windows unix. write technology projects are written, node.js.const http = require(http);const options { host: localhost, port: 8080, path: '/.well-known/healthcheck.json', timeout: 5000};const request http.request(options, (res) =&gt; console.log(`status: ${res.statuscode}`); (res.statuscode == 200) process.exit(0); } else console.error(`error: process.exit(1); }});request.on('error', (err) console.error('error', err); process.exit(1);});request.end();when ready, instruct mechanism. add following line dockefile:healthcheck /var/app/healthcheck.jsmake exists inside working, inspect it:$ lscontainer id command created status ports names060166cf52ee hiveio/condenser:development docker-entrypoint.s… 5 minutes (healthy) 0.0.0.0:8080-&gt;8080/tcp mystifying_dhawanthere indicator column. is. please note startup process, indicate slightly different (starting), wait before making first check. because giving time our startup. start-period parameter.depending traffic/load, those parameters vary.pushing hubwe improved (smaller) image, push repository. doing manually waste cause human mistakes. best runner us bullet-proof manner.here job definition .gitlab-ci.yml additional code breakdown:variables: docker_image: hiveio/condenser.docker-job: &amp;docker-job image: docker:stable services: - docker:dind before_script: echo $hub_token | login -u $hub_username --password-stdinbuild-development: &lt;&lt;: *docker-job stage: variables: docker_tag: $docker_image:$ci_commit_short_sha docker_tag_main: $docker_image:development source_commit: $ci_commit_sha only: develop script: -t $docker_tag $docker_tag_main --build-arg $docker_tag_mainfirst, global variable docker_image reuse many places. case would change name, single place.hence multiple jobs defined file, advanced yaml syntax, includes hidden keys anchors. decrease duplicated easier read maintain. name starting dot considered key won’t directly executed. btw, quick temporarily disable without commenting it.by .docker-job: anchor extend job. *docker-job, populate services before_script properties automatically. move similar things.later on, local (job scoped) docker_tag_main evaluated hiveio/condenser:344e55ef 344e55efefd56e00b15eea6ccf8560a1107b9ff6 (or commit sha)it’s idea double tag track process. describe how specific, sha-tagged rollback them anytime click.finally, building arguments --build-arg:docker .if scroll section, notice arg env ${source_commit} means these injected environment variables containers. easy pass additional, build-level images. returned endpoint. instance source.$ &lt;a href=https://staging.condenser.engrave.dev/.well-known/healthcheck.json&gt;https://staging.condenser.engrave.dev/.well-known/healthcheck.json&lt;/a&gt;{status:ok,docker_tag:hiveio/condenser:344e55ef,source_commit:344e55efefd56e00b15eea6ccf8560a1107b9ff6}an important thing mention hub_token hub_username configured settings. prevent unauthorized users pushing malicious official registry, protected masked, they branches moderated logs, leak internal bad actor elevated permissions.merge requeststo improve process adding codebase, merge got brand jobs:the pipeline fired required merged. fails failing unit tests), main branch. enforce quality regression.eslintcode standardization important, especially open-source project maintained totally developers around world. statically analyzes quickly find potential problems organized specified rules. analysis when developing javascript applications. really stupid mistakes.eslint branch pushed repository:run-eslint: merge_requests ci:eslint allow_failure: true # changed false linter errors removedbecause codebase neglected, run-eslint allowed fail moment (allow_failure: true), indicated orange exclamation mark mr view pipelines list. “some” warnings right now cleaned soon, require merging proposed changes: ✖ 1208 (1187 errors, 21 warnings) 831 0 potentially fixable `--fix` option. error failed exit 1.unit testsextensive testing produce stable run-eslint, run-unit-tests request.run-unit-tests: ci:test coverage: /all files[^|]*|[^|]*s+([d.]+)/testing suit (jest) coverage report:this report parsed gitlab, files[^|]*|[^|]*s+([d.]+)/ configuration. display percentage view, allowing reviewers increasing not.i advise declining covered tests. omitted fixes, worse.also, repository settings must succeed setting checked default. more broken develop/production branches.review appsreview apps huge very feature. feature inspected visually reviewer click. special expose reviewers:review requires three request:build-review-app: $ci_registry_image:$ci_commit_short_sha $ci_job_token $ci_registry_user $ci_registry --password-stdin $docker_tagdeploy-review-app: *docker-remote-host-review deploy service_name: review_$ci_environment_slug docker_cert_path=$certs -h $review_host --tlsverify pull service rm $service_name || previous exist --with-registry-auth --network infrastructure --name review deployed environment: name: review/$ci_commit_ref_name url: href=https://&gt;https://&lt;/a&gt;$ci_environment_slug$app_review_subdomain on_stop: stop-review-app auto_stop_in: 1 week stop-review-app: when: manual stopped action: stopthe familiar parts difference overwriting before_script. you’re anchors, overwrite template freely what did here.because opened well known community (vel. actors), issue this, provided itself. private, accessible anyone else.echo --password-stdinwe ci_job_token, ci_registry_user ci_registry automatically configure them. also, secure log password being exposed logs.by default, connect unsecured, port. yet possible validate tls certificates external world way, runners machine. parameters: remote address makes identify itself send authentication swarm agents network reverse proxy docker_cert_path demon where certificatesdocker_cert_path=$certs $docker_tagthis under url ci_environment_slug, gitlab. guaranteed valid docker/kubernetes name.review instances removed closed opened. achieved triggered (when: manual).tracking deploymentsby images, redeploy moment, emergency, maintainers (docker specific)stagingdeploying staging quite deploying app. uses on-demand, updated image.with mode, ensure application highly available. agent take care restart spin (this important). built-in, native mode using.deploy-staging: *docker-remote-host-staging staging_condenser $staging_host --image --update-failure-action --update-order start-first href=https://&gt;https://&lt;/a&gt;$staging_domainjob “bad” pushing/deploying code. disabled.zero downtime deploymentsupdating swarm:docker_cert_path=$certs $service_namethere provided: existing case, nothing fails. passing parameter, instructing roll back state, kill current ones it. don’t want. start-first, first. healtcheck result becomes positive. gone wrong (healtcheck reason), end working old touched all.resources controlwith full control over example configuration environment. tweaks, also:version: 3.7services: condenser: hiveio/condenser:latest deploy: mode: replicated replicas: 2 resources: limits: cpus: 0.85 memory: 2024m restart_policy: condition: delay: 5s update_config: parallelism: 10s failure_action: order: rollback_config: networks: reverse-proxynetworks: reverse-proxy: external: reverse-proxyproductionit finished yet, advice (ci/cd ready). designed serve condenser.some (based documentation): cluster management engine: know container, ready swarm. software decentralized design: worker manager command. machines scaling: each service, declare number tasks run. scale down, adapts maintain desired state. multi-host networking: specify overlay services. assigns addresses initializes updates load balancing: balancer. internally, lets distribute between nodes. default: enforces mutual encryption communications option self-signed root custom ca. rolling updates: rollout apply nodes incrementally. delay deployment sets anything goes wrong, service. swarm, can’t coincidence! ;)i’m most within engrave (dblog.org) managing set 23 microservices almost 30 moment.my tips (and only) tests covering improving fewer bugs. visible damn see regression. quality. exact file. ^, two builds. changing major hub multi-stage builds leaner checks applications clean husky happens automatically.vote @engrave witness valuable see: improvements hive.blog, continuous integration"
    } ,
  
    
    
    
    
    
    {
      "author"    : "gtg",
      "title"    : "Hive Pressure #1: A New Hope",
      "category" : "news, devops, nodes",
      "url"      : "/news/devops/nodes/2020/04/19/hive-pressure-1-a-new-hope.html",
      "date"     : "2020-04-19 10:28:03 -0700",
      "desc"     : "",
      "content"  : "a long time ago, in block far, far away…no, wait, this is not the story you are looking for ;-)this part was going to be filled with retrospectives, origins of steem pressure series, stories about events that caused us fork from but would just waste time, and resource we can’t afford waste.tl;dr: no longer what knew it be. “no ned worry.” anonymous&lt;/sup&gt; our future hands.we hive now.paint hivetime update promo materials.https://www.youtube.com/watch?v=vlw9lde3duinew net, new nodessince many have upgraded their toys hive, at hf23, most used now compatible.seed nodesseed.openhive.network:2001 # gtgseed.roelandp.nl:2001 roelandphiveseed-se.privex.io:2001 privex (se)steemseed-fin.privex.io:2001 (fi)seed.liondani.com:2016 liondanihived.splinterlands.com:2001 aggroedseed.hivekings.com:2001 drakosnode.mahdiyari.info:2001 mahdiyarianyx.io:2001 anyxseed.buildteam.io:2001 thecryptodrivehive-seed.lukestokes.info:2001 lukestokes.mhthhive-seed.arcange.eu:2001 arcangeseed.chitty.me:2001 chittyapi nodeshttps://api.openhive.networkhttps://api.hive.bloghttps://anyx.iohttps://api.hivekings.comhttps://api.pharesim.mehttps://hived.hive-engine.comhttps://rpc.esteem.apphttps://hived.privex.iohttps://techcoderx.comdiyif want run your own node, here some quick tips can useful:seed nodeconfigure build with:cmake -dcmake_build_type=release -dlow_memory_node=on -dclear_votes=on -dskip_by_tx_id=off -dbuild_steem_testnet=off -denable_mira=off -dsteem_static_build=on ../hivedepending on needs resources, might use eitherenable_mira=off or enable_mira=on.config.ini seed node as simple that:plugin = witnessp2p-endpoint 0.0.0.0:2001this intended easily extend more useful by enabling webserver endpoint apis such block_api network_broadcast_api. however, if choose add plugin account_by_key market_history will replay.api nodeif you’ve read my series know i monolithic node. instead, jussi route specific methods specialized endpoints. account history (non-mira) fat (mira) hivemindplease note setup itself enough feed hivemind instance because lack plugin. an issue environment, i’m running both nodes, prefer plugins low memory where possible.account - reference configurationconfigure ../hivewe mira here, pre-mira implementation plugin: account_history_rocksdb.here’s config.ini file:log-appender {appender:stderr,stream:std_error}log-logger {name:default,level:info,appender:stderr}backtrace yesplugin p2p json_rpcplugin database_api condenser_apiplugin witnessplugin rcplugin market_historyplugin market_history_apiplugin account_history_rocksdbplugin account_history_apiplugin transaction_statusplugin transaction_status_apiplugin account_by_keyplugin account_by_key_apiplugin network_broadcast_api rc_apip2p-endpoint 0.0.0.0:2001p2p-seed-node gtg.openhive.network:2001transaction-status-block-depth 64000transaction-status-track-after-block 42000000webserver-http-endpoint 127.0.0.1:8091webserver-ws-endpoint 127.0.0.1:8090webserver-thread-pool-size 256fat -dlow_memory_node=off -dclear_votes=off -dskip_by_tx_id=on -denable_mira=on ../hivefor buildhere’s reputationplugin reputation_apiplugin block_apip2p-endpoint 0.0.0.0:32001p2p-seed-node gtg.openhive.network:2001webserver-http-endpoint 256storage needs:as always, make sure very fast storage. type storage ah 600 gb 400 300 next episode, write required hardware how takes nowadays scratch. see: #1: hope @gtg"
    } ,
  
    
    
    
    
    
    {
      "author"    : "yabapmatt",
      "title"    : "Hive Keychain Now Available on Chrome &amp; Brave!",
      "category" : "news, nodejs, keychain",
      "url"      : "/news/nodejs/keychain/2020/04/17/hive-keychain-now-available-on-chrome-and-brave.html",
      "date"     : "2020-04-17 08:50:54 -0700",
      "desc"     : "I am extremely happy to rep...",
      "content"  : "i am extremely happy to report that the hive keychain browser extension has finally been approved by google and is now available for everyone install on chrome brave browsers!you can use following link find in web store:https://chrome.google.com/webstore/detail/hive-keychain/jcacnejopjdphbnjgfaaobbfafkihpepwe encourage add a positive review store as will help ensure it remains listed future updates get timely fashion.it also firefox while here: https://addons.mozilla.org/en-us/firefox/addon/hive-keychain/@stoodkev did vast majority of development work with contributions from @arcange @quochuy, @nateaguila took care design graphics always.to see detailed update being done please @stoodkev’s recent post https://peakd.com/hive-139531/@stoodkev/hive-keychain-1-8-3hdf proposal updatethe existing funding end approximately one month at which time we expect launch new continue fund ongoing project. do not intend submit another steem plan extension, so going forward only come hive.we greatly appreciate support who backed proposal, hope community vote when initial expires.note: all rewards this go @steem.dao (the account) platform see: &amp; brave! @yabapmatt"
    } ,
  
    
    
    
    
    
    {
      "author"    : "emrebeyler",
      "title"    : "Hivesigner Python Client",
      "category" : "howto, python, hivesigner",
      "url"      : "/howto/python/hivesigner/2020/04/14/powering-up-2.html",
      "date"     : "2020-04-14 14:28:15 -0700",
      "desc"     : "hivesigner-python-client is...",
      "content"  : "hivesigner-python-client is a simple yet powerful library to interact with hivesigner. hivesigner single sign-on solution for hive based applications and it implements oauth2 the authorization logic.with this client; implementing authorization/authentication flow w/ oauth broadcasting supported operations blockchain user of your appare possible through hivesigner.| repository | documentation ||————————————————–|—————||github.com/emre/hivesigner-python-client| hivesigner-python-client.readthedocs.io |***installation$ (sudo) pip install hivesignermigrating from steemconnect-python-clientif you use steemconnect-python-client want switch version, only change need do updating imports.old way:from steemconnect.client import clientnew hivesigner.client client.also, resteem class changed as reblog. examples more details can be found at website.***note: being maintained by @good-karma since switch. there an ongoing proposal it’s maintenance while. if didn’t see yet, check out. see: python client @emrebeyler"
    } ,
  
    
    
    
    
    
    {
      "author"    : "lonelywolf",
      "title"    : "[Hive Patched] Upvoting By Payment In 4 Easy Steps - Basic Bot",
      "category" : "howdo, nodejs, bot",
      "url"      : "/howdo/nodejs/bot/2020/04/14/hive-patched-upvoting-by-payment-in-4-easy-steps-basic-bot.html",
      "date"     : "2020-04-14 13:14:21 -0700",
      "desc"     : "(Want to use the logo yours...",
      "content"  : "(want to use the logo yourself? no problem, check out post i made about my art design - hive logo)—repository:https://www.npmjs.com/package/steem-js-patched helpful tutorials: [hive patched] steemjs full tutorial all functions abilities[hive patched tutorial] vote, comment and follow in one of this is for hive, so it works steem hive!all examples results from old but still same hive!hello!today you’re going learn how create an upvoting bot with that calculate simply voting power by payment, note calculation a really simple calculation.load steem/hive package:const = require('steem-js-patched')to install package npm steem-js-patched --save repository abovefirst we will add user guest123 (or your account) code, this(guest123) global account developersconst acc_name 'guest123', // name acc_key '5jraypasxmx1l97zux7yuc5psb5eabf821kkagtbj7xcjfqcblg'; private wif keyyou want api work blockchainsteem.api.setoptions({ url: 'https://api.hive.blog' });so, first things first, get easiest hardest, firstly we’re transactions blockchainsteem.api.streamtransactions('head', function(err, result) { let type result.operations[0][0]; getting transaction data result.operations[0][1]; transaction}this function gets newest go through blockchain, such as new blogs, transfers etc.as already explained (new blogs/new transfer etc.) transaction, blog be author, permlink, content etc. transfer, memo, sender, receiver etc.now need if is, our account.if(type == 'transfer' &amp;&amp; data.to acc_name) checking reciever account}simple enough, type(transaction type) account.if memo url send it’s not normal transfers.var data.memo.split('/');if(memo[0] https:){ console.log(incoming request vote from: + data.from +, value: data.amount nn); sending console telling us come. streamvote(data.memo, data.amount);}else{ , requst.); console.log(memo: data.memo);}everything above!now, streamvote &amp; calcvoteweightfirstly, streamvote, called variables url, amountfunction streamvote(url, amount) {}now weight author const url.split('/'); spliting array memo[4].split('@')[1]; calcvoteweight(amount); value amountmemo urlauthor got example: ~~https://steemit.com/utopian-io/@lonelywolf/steem-bots—auto-follower-bot-steemjs–nodejs—-begginer-tutorial~~weight calculated after.now just stream blockchainsteem.broadcast.vote(acc_key, acc_name, memo[5], weight, starting process if(!!err) throw err; close program error details there console.log('voted succesfully, permalink: ' memo[5] ', author: weight: / 1000 '%.', err); //if succesfully sent information console});so have broadcast. function, says sends uses wif(private key), name, permlink(memo[5]) weight.if crash applicationif everything has done successfully info console. functioncreate variable amountpaid//this paid upvote can befunction calcvoteweight(amountpaid){}now token amountpaid.split(' '), tokentype token.pop(), //taking token(coin) [hive/hbd] tokenvalue token.shift(); taking only valueas easy be, splitting string spaces valuenow values set weight; (tokenvalue &gt;= 0.6){ higher than 0.6 (example: &gt;0.6$ hbd/ &gt;0.6 hive) 100; } else 0.25) 40; 0.1) 20; }else{ like it's lower 0.1 10; }first, or equal voteif amount 0.25 40% 20% 0.1(else) 10% votenow ratio between hbd, because doing manually hbdhiveratio 0.5; hbd 0.8 1.2, around 0.5 you 1.5 1 if( 'hive') return (weight * hbdhiveratio) regular }now coin calculating ratio,if we’ll vote.conclusionsimply, done, run script it, 0.01 (the on script) vote.if are any problems down below i’ll help you!if suggestions next tutorials appreciate suggestions, thanks!have great day! see: payment 4 steps basic @lonelywolf"
    } ,
  
    
    
    
    
    
    {
      "author"    : "good-karma",
      "title"    : "Devportal Hivesigner updates",
      "category" : "news, nodejs, hivesigner",
      "url"      : "/news/nodejs/hivesigner/2020/04/14/devportal-hivesigner-updates.html",
      "date"     : "2020-04-14 02:07:45 -0700",
      "desc"     : "Devportal updatesEarlier to...",
      "content"  : "devportal updatesearlier today, have made pull request to change and improve hivesigner related dev documentation javascript tutorial which has been merged into master already alive at hive devportal. information about http://developers.hive.io/services/#services-hivesigner js on how integrate your applications: http://developers.hive.io/tutorials-javascript/hivesigner.htmldocumentation is important part of any service tool, without it devs would hassle a lot, know use provided resources.i remember in 2016 when chain was launched, we had hard time developing apps, go through blockchain code find proper api calls parameters, secure way sign transactions etc. come long since then our documentations are better easier follow.we yet document implement lot pieces make easy understand for developers as well users. support proposal help us deliver those quicker!support vote using hivedao: https://hivedao.com/proposal/88 peakd: https://peakd.com/proposals/88 hiveblog wallet: https://wallet.hive.blog/proposals discord: https://discord.gg/pnjn7wh github roadmap thread see: updates by @good-karma"
    } ,
  
    
    
    
    
    
    {
      "author"    : "thecrazygm",
      "title"    : "Simple Transaction Monitor",
      "category" : "howto, stream, python",
      "url"      : "/howto/stream/python/2020/04/11/simple-transaction-monitor.html",
      "date"     : "2020-04-11 16:58:21 -0700",
      "desc"     : "Pretty straight forward mon...",
      "content"  : "pretty straight forward monitori’m back again with another simple python snippet of code to use in future projects. a lot projects begin as needing something monitor the chain and react accordingly. i thought about this decided best example show how it is teaching tool myself was transaction ops insert them into database if they were or from me.this basis listening for memos response sorts. (in case, put sqlite3 db) popular option listen comments op check mentioned (that may be project/lesson future)this requires both beem dataset will watch whatever account you set variable.#!/usr/bin/env python3import datasetfrom import steemfrom beem.blockchain blockchainwatch = thecrazygmhive steem(node='https://anyx.io')db dataset.connect('sqlite:///mydatabase.db')# system variablesblockchain blockchain(steem_instance=hive)stream blockchain.stream(opnames=['transfer'], raw_ops=false, threading=true, thread_num=4)table db[watch]# parse json data sql insertdef update_db(post): try: table.insert(dict(post)) db.commit() except exception e: print(f'[error: {e} moving on]') db.rollback()def monitor(): print([starting up...]) db.begin() # read live stream filter out only transfers post stream: post[to] == post[from] watch: print(f[transaction found {post['from']} {post['to']}]) update_db(post)if __name__ __main__: monitor()the can always up date at my github gist area file: monitor.pyif like what i’m doing consider following me, either here on buy me coffee.again, stay safe there people,michael garcia a.k.a. @thecrazygm see: by"
    } ,
  
    
    
    
    
    
    {
      "author"    : "lonelywolf",
      "title"    : "Quick Tip: Hive Scripting - In 3 easy steps",
      "category" : "howto, nodejs",
      "url"      : "/howto/nodejs/2020/04/10/quick-tip-hive-scripting-in-3-easy-steps.html",
      "date"     : "2020-04-10 16:38:45 -0700",
      "desc"     : "Hello, devs!my name is stav...",
      "content"  : "hello, devs!my name is stav aka lonelywolf,i’m a web developer, i worked with utopian-io for good amount of time back in the days, made lot useful tutorials mainly about steemjswhich what we’re going to talk today.so i’m not really familiar hive scripting, don’t have any idea how transfer some projects mine hivebut found out that one command can my steemjs projects.so, step 1install if you haven’tnpm install steem --savestep 2create your script, example:const = require('steem');steem.api.getaccounts(['lonelywolf'], function(err, res){ console.log(res, err)})this will give me all profile configuration and informationso now we want it api, right?step 3now, just need change api url,steem.api.setoptions({ url: 'https://api.hive.blog' })you use other node there hive.so i’ll get but as information(results at end post)hope useful, please leave an upvote comment down below are scripting blockchain[ { id: 495898, name: 'lonelywolf', owner: weight_threshold: 1, account_auths: [], key_auths: [array] }, active: posting: [array], memo_key: 'stm7rnp4djl3ztumsxsejuy7grc3aoh1ptvgfv4cuhfvsthwat4iw', json_metadata: '{profile:{name:therealwolf,about:realityhubs moderator -- fs developer,website:https://steemit.com/@lonelywolf,cover_image:https://cdn.steemitimages.com/dqmuxqc72fjzerakezlju7wfj89eju4ftugoxrnersc3gtc/steembanner.png,profile_image:https://cdn.steemitimages.com/dqmvsxtvsoeugvn9sjvcfmbqucpcvzcgor9gouu8nwg8quq/therealwolf_logo.png}}', posting_json_metadata: proxy: '', last_owner_update: '2018-10-13t14:13:21', last_account_update: '2019-08-08t11:40:00', created: '2017-12-14t15:13:15', mined: false, recovery_account: 'steem', last_account_recovery: '1970-01-01t00:00:00', reset_account: 'null', comment_count: 0, lifetime_vote_count: post_count: 865, can_vote: true, voting_manabar: current_mana: '161750492879', last_update_time: 1586559381 downvote_manabar: '43566594492', voting_power: 9281, balance: '0.001 hive', savings_balance: '0.000 sbd_balance: hbd', sbd_seconds: '52214760', sbd_seconds_last_update: '2020-04-07t23:19:45', sbd_last_interest_payment: '2020-03-23t20:43:36', savings_sbd_balance: savings_sbd_seconds: '0', savings_sbd_seconds_last_update: '2020-04-10t04:08:21', savings_sbd_last_interest_payment: savings_withdraw_requests: reward_sbd_balance: reward_steem_balance: reward_vesting_balance: '0.000000 vests', reward_vesting_steem: vesting_shares: '2984.805714 delegated_vesting_shares: '2982.828925 received_vesting_shares: '174264.401181 vesting_withdraw_rate: next_vesting_withdrawal: '1969-12-31t23:59:59', withdrawn: '60272175916', to_withdraw: withdraw_routes: curation_rewards: 6910, posting_rewards: 1207947, proxied_vsf_votes: [ 0 ], witnesses_voted_for: 3, last_post: '2020-04-10t23:12:00', last_root_post: '2020-04-10t19:32:24', last_vote_time: '2020-04-10t22:56:21', post_bandwidth: pending_claimed_accounts: vesting_balance: reputation: '16422564795330', transfer_history: market_history: post_history: vote_history: other_history: witness_votes: 'actifit', 'bdcommunity', 'emrebeyler' tags_usage: guest_bloggers: [] }] null see: quick tip: - 3 easy steps by @lonelywolf"
    } ,
  
    
    
    
    
    
    {
      "author"    : "holger80",
      "title"    : "Update for beem: beempy installer for windows and beempy as shell",
      "category" : "howto, beem, python, wallet",
      "url"      : "/howto/beem/python/wallet/2020/04/08/update-for-beem-beempy-installer-for-windows-and-beempy-as-shell.html",
      "date"     : "2020-04-08 07:26:15 -0700",
      "desc"     : "Repositoryhttps://github.co...",
      "content"  : "repositoryhttps://github.com/holgern/beem beem is a python library for steem and hive. the current version 0.22.14.there also discord channel beem: https://discord.gg/4hm592vthe newest can be installed by:pip install -u beemcheck that you are using hive nodes. following commandbeempy updatenodes --hiveupdates nodelist uses only after setting as default_chain, beempy used without switching to steem.the list of nodes checked withbeempy configandbeempy currentnodeshows currently connected node.upcoming changesthe next release will 0.23.0 blockchain then set new default. i rework countless steem_instance parameters replace them with more fitting name. create class which steem() conterpart.changelog versions 0.22.14 add click_shell turn into shell utility autocompletion added requirements installer on windows get_hive_nodes get_steem_nodes functions command resteem renamed reblog when in mode, walletinfo –unlock unlock wallet –lock it again get_blockchain_name steem, returns either or switch_blockchain switch between storage has now config “default_chain”, updatenode –hive switches use –steem nodesupload imagesthe url imageupload been fixed hive:beempy uploadimage -a holger80 .beempy_screencast.gifresults in:![](https://images.hive.blog/dqmx39y3dpzxurvvxrggmzsnxympekmcdce3xoutbafpodo/image)shell mode beempybeempy activated started any parameter:beempyyou an see here action:windows beempya automatically pushed section:https://github.com/holgern/beem/releases/tag/0.22.14after downloading installing beempysetup, icon shown start menu:when clicking it, terminal started.wallet unlocking modewhen unlocked withwalletinfo --unlockand locked --lockclosing program locks wallet.nodelists steemthe two functions:from beem.nodelist import nodelistnodelist = nodelist()print(nodelist.get_hive_nodes())print(nodelist.get_steem_nodes())this helps, sure always correct node.default_chain parameterthe chain stored default_chain. hive.beempy configreturns now:+-----------------+---------------------------------------------+| key | value |+-----------------+---------------------------------------------+| default_account || default_chain [ https://anyx.io, http://anyx.io, https://api.hivekings.com, https://api.hive.blog, https://api.openhive.network, https://techcoderx.com, https://rpc.esteem.app, https://hived.privex.io ] data_dir ...beembeem |+-----------------+---------------------------------------------+beempy updatenodeswill return nodes, steem.switching pythonthe object function booth blockchains.from steemstm steem()stm.switch_blockchain(steem)print(stm)stm.switch_blockchain(hive)print(stm)returns&lt;steem node=&lt;a href=https://steemd.minnowsupportproject.org&gt;https://steemd.minnowsupportproject.org&lt;/a&gt;, nobroadcast=false&gt;&lt;steem href=https://anyx.io&gt;https://anyx.io&lt;/a&gt;, nobroadcast=false&gt;switching --steemswitches blockchainandbeempy --hivewill blockchain.if like what do, consider casting vote me witness hivesigner peakd. see: update by @holger80"
    } ,
  
    
    
    
    
    
    {
      "author"    : "hiveio",
      "title"    : "Community Discussion and Updates: Hive Airdrop Exclusion List and Code Corrections, Core Developer Meetings",
      "category" : "news",
      "url"      : "/news/2020/04/06/community-discussion-updates-hive-airdrop-exclusion-core-developer-meetings.html",
      "date"     : "2020-04-06 14:48:21 -0700",
      "desc"     : "Read more about corrected airdrop code, appeal groups, and Hive core development meetings!",
      "content"  : "the buzz this week has been busy, busy. update will cover two important topics: airdrop corrections and appeals, hive core developer meetings. in last update, we discussed initial exclusion list, community feedback proposals, that an error had found in distribution code. over course of week, script reviewed depth by a number developers corrected, so before anything else: updated list compiled user accounts who be correctly dropped tokens via next upcoming hardfork. we’re including all public links to code post should you wish take closer look.the incorrectly excluded are as follows:these corrected automatically does not need make any vote.[ akiroq, balticbadger, dailychina, dailystats, dftba, double-u, edgarare1, electrodo, fadetoblack, freedompoint, friendlystranger, john371911, juancar347, kdtkaren, lichtblick, lifeskills-tv, lotusfleur, ricko66, rynow, scottcbusiness, seo-boss, sgbonus, spoke, steemchiller, steemflower, stimp1024, travelnepal, truce, tuckerjtruman, yanirauseche]the original was edge case arose from proxies were switched or cleared, where revoted way wasn’t accounted for. new results available here.what did these scripts do? what criteria? groups left for vote on?  reading understanding can tricky if it isn’t your forte. used pull is based on set criteria produces transparent reproducible data steem blockchain. included first block hardfork when distributed. was: voting 2 more sockpuppet witness accounts, proxied someone unvote unproxy announcement 1000 sp the remaining accurately still able use they see fit: blocked locked using chain interfaces, many already doing so. however, very passionate across range opinions whether appeal distribution. there main airdrop: those voter sockpuppets matched above voted sock puppets themselves criteria these have proposals made @hiveio account coming weeks leading up opportunity support secondary drop one, both, neither fit. encourage discussion among groups, ask consider carefully communicate openly respectfully each other, even may share same opinions!one most difficult things about moving towards decentralization deciding do what! today began looking at ways help stay organized get done. to end, morning marked developers’ meeting hive. live streaming approved time inaugural meeting, but recorded (you listen here- like subscribe channel future notifications). meetings streamed youtube other platforms forwards.these open anyone working development participate in, would listen. cases, likely technical probably won’t interesting everyone ecosystem (sorry, devs!) sure people abilities date, creating “what’s buzzing around repo” posts following day with summarize what’s covered easier understand. expect tomorrow!to finish today’s post, here few handy remind lot source work happening. involved, look might good fit! public, gitlab: https://gitlab.syncad.com/hive developer’s portal: https://developers.hive.io/ website: https://hive.io/ (links useful here, under continual development) one project sites browse projects ecosystem: https://hiveprojects.io/ explorers: https://hiveblocks.com/ https://hive-db.com/thanks another solid week! please spread info 🐝 see: updates: corrections,"
    } ,
  
    
    
    
    
    
    {
      "author"    : "holger80",
      "title"    : "Update for beem: huge performance improvements and bridge API support",
      "category" : "howto, beem, python, communities",
      "url"      : "/howto/beem/python/communities/2020/04/06/update-for-beem-huge-performance-improvements-and-bridge-api-support.html",
      "date"     : "2020-04-06 05:04:18 -0700",
      "desc"     : "Repositoryhttps://github.co...",
      "content"  : "repositoryhttps://github.com/holgern/beem beem is a python library for steem and hive. the current version 0.22.13.there also discord channel beem: https://discord.gg/4hm592vthe newest can be installed by:pip install -u beemcheck that you are using hive nodes. following commandbeempy updatenodes --hiveupdates nodelist uses only list of nodes checked withbeempy configandbeempy currentnodeshows currently connected node.changelog versions 0.22.13 hivesigner support added api link to steemconnect has been fixed change recovery account beempy node add get_notifications mark_notifications_as_read notifications bridge config storage improved get_default_config_storage, get_default_key_storage get_default_token_storage list_all_subscriptions get_account_posts reduce number performed calls on object creationperformance boost beemall integration tests finishing now in========== 469 passed, 27 skipped, 11 warnings in 1040.19s (0:17:20) ===========which an improvement 49% (version 0.22.12 needed 1551 seconds).this huge could accomplished by reducing when creating object. importing objects from beem, configstorage no longer created during import. read creation with get_default_config_storage. this speeds up modules stored parameter needed.these changes improves speed all commands.bridge apibeem supports parts api. more functions missing will follow.notificationsbeempy holger80prints table unread notifications.+---------------------+------+-------------------------------------------+| date | type message |+---------------------+------+-------------------------------------------+| 2020-04-06 10:15:57 vote @uwelang voted your post ($0.23) || 12:52:00 @steemcleaners ($2.45) |+---------------------+------+-------------------------------------------+they marked as -mbeempy -m holger80which broadcasts notify custom_json.list subscribtionsthe which returns cummunities subscript.get_account_poststhe function, used fetch posts shown feed account.get_ranked_postsa new class rankedposts was beem.comment receive ranked posts.change beempyit possible beempybeempy changerecovery -a holge80 recovery.accounthivesigner addedthe example shows how create login link:from beem.hivesigner import hivesignerhivesigner = hivesigner(client_id=rewarding.app, scope=login, get_refresh_token=false)hivesigner.get_login_url('https://rewarding.app/welcome')returns'&lt;a href=https://hivesigner.com/oauth2/authorize&gt;https://hivesigner.com/oauth2/authorize&lt;/a&gt;?client_id=rewarding.app&amp;redirect_uri=https%3a%2f%2frewarding.app%2fwelcome&amp;scope=login'the received token then check if user successfully entering its posting key script:try: hivesigner.set_access_token(access_token) name hivesigner.me()[name]except: print(wrong token)if like what i do, consider casting me witness or peakd. see: update performance improvements @holger80"
    } ,
  
    
    
    
    
    
    {
      "author"    : "beggars",
      "title"    : "Tutorial: Building A Dice Game Contract With Hive Stream (Part 2)",
      "category" : "howto, dapps, nodejs",
      "url"      : "/howto/dapps/nodejs/2020/04/06/tutorial-building-a-dice-game-contract-with-hive-stream-part-2.html",
      "date"     : "2020-04-06 04:00:21 -0700",
      "desc"     : "Elaborating on part one of our dice contract tutorial and beefing it up",
      "content"  : "if you missed part one here, we built a basic dice game contract which allows people to bet on an outcome and either win or lose. the tutorial left out some things that might want do in real deployment.install mongodbfor this tutorial, are going use mongodb as database behind it. we’ll be storing transactions outcomes database, so can ensure transfers not processed multiple times.while streamer keeps track of last block number json file sqlite what happens your node goes down gets edited deleted? it would result pain manually process.download community version installer from official website. choose appropriate for operating system follow instructions. should require very little input, just keep clicking next basically everything default.build adapternow, need write adapter will allow hive stream work with instead databases is configured out-of-the-box use. provided have installed (version 2+) new adapter’s functionality.an standard cases consists two mandatory methods loadstate savestate method called when starts start at finished. updates latest block.there however other lifecycle our more functional adapters. create initialisation, setup instances connections here. destroy stopped, naturally close here.the processoperation number, transaction id forth. it’s metadata used identify specific their data. processtransfer processcustomjson matching transfer custom operation matched contract. also information well payload helpful info.save following mongo.adapter.jsimport { adapterbase } 'hive-stream';import mongoclient, db 'mongodb';export class mongodbadapter extends client; db; mongo = uri: '', database: options: {} }; blocknumber; lastblocknumber; blockid; prevblockid; transactionid; constructor(uri, databasw, options usenewurlparser: true, useunifiedtopology: true }) super(); this.mongo.uri uri; this.mongo.database database; this.mongo.options options; async create() try this.client await mongoclient.connect(this.mongo.uri, this.mongo.options); this.db this.client.db(this.mongo.database); return true; catch (e) throw e; loadstate() const collection this.db.collection('params'); params collection.findone({}); (params) params; savestate(data) collection.replaceone({}, data, upsert: true}); processoperation(op, blocknumber, blockid, prevblockid, trxid, blocktime) this.blocknumber this.blockid this.prevblockid this.transactionid trxid; processtransfer(operation, payload, metadata) this.db.collection('transfers'); data id: this.transactionid, blockid: this.blockid, blocknumber: this.blocknumber, sender: metadata.sender, amount: metadata.amount, contractname: payload.name, contractaction: payload.action, contractpayload: payload.payload collection.insertone(data); processcustomjson(operation, this.db.collection('transactions'); issignedwithactivekey: metadata.issignedwithactivekey, destroy() this.client.close(); }}expanding contractnow support added via adapter, let’s modify code flag whether was (winnings sent loss memo sent). us replay worry about paying users who already received winnings times.above (verify) line code, access client connection.const this._instance['adapter']['db'];const db.collection('transfers');because contracts get instance, means property. downside here any doesn’t property, fail. case, know slightly tighter coupling fine.inside balance check refunds account than maximum bet, add sets status refundput inside statement: (balance &lt; max_bet) underneath transferhivetokens call.await collection.findoneandupdate({ }, $set: status: 'refund' });what doing querying based its id, then using $set property only add/update collection.next, statement (parsefloat(tokenswon) &gt; balance) same beneath call:await });underneath this._instance.transferhivetokens(account, sender, tokenswon, token_symbol, winningmemo); following:await 'win' });and now else '0.001', losingmemo);await 'loss' });finally, another amounttrim[0], amounttrim[1], `[refund] invalid params.`); user amount higher max, roll too high low.await });the final ends up looking like this:import utils seedrandom 'seedrandom';import bignumber 'bignumber.js';const contract_name 'hivedice';const 'beggars';const token_symbol 'hive';const house_edge 0.05;const min_bet 1;const max_bet 10;// random generatorconst rng (previousblockid, transactionid) =&gt; seedrandom(`${previousblockid}${blockid}${transactionid}`).double(); randomroll math.floor(random * 100) + 1; randomroll;};// valid betting currenciesconst valid_currencies ['hive'];class dicecontract _instancs; previousblockid; // runs every time register logic (creating etc) unregister run connections, state, etc current automatically exists updateblockinfo(blocknumber, previousblockid, info this.previousblockid /** helper getting balance. case make sure has enough money pay bets @returns */ getbalance() this._instance['client'].database.getaccounts([account]); (account?.[0]) (account[0].balance string).split(' '); balance[0]; parsefloat(amount); null; action matches @param param1 - sender roll(payload, destructure values payload; formatted 100 value first part, currency symbol second amounttrim amount.split(' parse numeric amountparsed parsefloat(amounttrim[0]); format 3 decimal places amountformatted parsefloat(amounttrim[0]).tofixed(3); trim space amountcurrency amounttrim[1].trim(); console.log(`roll: ${roll} parsed: ${amountparsed} formatted: ${amountformatted} currency: ${amountcurrency}`); blockchain this._instance.gettransaction(this.blocknumber, this.transactionid); call verifytransfer confirm happened verify this._instance.verifytransfer(transaction, 'beggars', amount); this.getbalance(); this._instance['adapter']['db']; db.collection('transfers'); server less max cancel refund send back sent, broke could fufill bet.`); }); return; (amountparsed &gt;= &amp;&amp; &lt;= validate ((roll 2 96) valid_currencies.includes(amountcurrency)) rng(this.previousblockid, calculate multiplier percentage bignumber(1).minus(house_edge).multipliedby(100).dividedby(roll); tokens won tokenswon bignumber(amountparsed).multipliedby(multiplier).tofixed(3, bignumber.round_down); shows they winningmemo `you ${tokenswon} ${token_symbol}. roll: ${random}, guess: ${roll}`; lose losingmemo lost afford, (random roll) losingmemo); parameters, amount.`); console.log(e); }}export default dicecontract();register itwe take bootstrapped app remains largely untouched, except pass configuration constructor.import './dice.contract';import './mongo.adapter';const streamer({ active_key: needed json_id: 'testdice' identifier payloads});streamer.registeradapter(new mongodbadapter('mongodb://127.0.0.1:27017', 'hivestream'));// contractstreamer.registercontract('hivedice', dicecontract);// watching blockchainstreamer.start();here screenshot modified refunded updated show all works intended.conclusionwhat did learn? learned how interfacing instance interact look by within actions them (in setting property).ps. ships package, don’t yourself, i process tutorial. enjoy. see: tutorial: building (part 2) @beggars"
    } ,
  
    
    
    
    
    
    {
      "author"    : "good-karma",
      "title"    : "SteemConnect notice",
      "category" : "news, hivesigner",
      "url"      : "/news/hivesigner/2020/04/05/steemconnect-notice.html",
      "date"     : "2020-04-05 12:07:21 -0700",
      "desc"     : "In this post we would like ...",
      "content"  : "in this post we would like to update everyone about discontinuation of steemconnect.it has been incredible few years serving all users and dapps on steem, but now that have migrated hive as hivesigner. it is time focus our effort making hivesigner the best authentication service, can be hive.sunset datewe are setting a date stop steemconnect services 1st june, 2020. kindly request dapp developers plan inform their changes.migration optionswe will actively improving encourage build hive. if for some reason you want stay please migrate other fork - example steemlogin. not any way connected with forks, always do your own research, audit security new forks.hivesigner developmentfor developers, visitors, redirecting homepage help them get started development adding faq more detailed documentation how integrate website, authenticate extension, sign transactions securely, etc. published roadmap proposal support continuous project. read here bringing secure social masses. vote github: ledgerconnect/hivesigner discord support: https://discord.gg/pnjn7wh email: hello@hivesigner.com see: notice by @good-karma"
    } ,
  
    
    
    
    
    
    {
      "author"    : "beggars",
      "title"    : "Tutorial: Building A Dice Game Contract With Hive Stream",
      "category" : "howto, dapps, nodejs",
      "url"      : "/howto/dapps/nodejs/2020/04/04/tutorial-building-a-dice-game-contract-with-hive-stream.html",
      "date"     : "2020-04-04 03:59:09 -0700",
      "desc"     : "Hot off the heels of announ...",
      "content"  : "hot off the heels of announcing some huge updates to hive stream which features ability write “smart” contracts, i promised a tutorial would be coming showing you how one and what could more fitting than writing contract for dice game?basing this that engine ships with as an example, i’ve created accepts roll value needs above server roll. by end tutorial, you’ll have understanding contracts are written (they’re just classes) can create your own smart dapps using them.if you’re kind person who wants see code, covered. code found here. it is in typescript but resembles javascript basically if not familiar. based engine, except they’re both fundamentally different pieced together.install packagein application, install hive-stream package running npm it’s published on npm. we also want seedrandom bignumber.js well since those used our code.npm bignumber.jswriting contractsave following dice.contract.js application.import { streamer, utils } from 'hive-stream';import 'seedrandom';import bignumber 'bignumber.js';const contract_name = 'hivedice';const account ''; // replace accountconst token_symbol 'hive';const house_edge 0.05;const min_bet 1;const max_bet 10;// random number generatorconst rng (previousblockid, blockid, transactionid) =&gt; const seedrandom(`${previousblockid}${blockid}${transactionid}`).double(); randomroll math.floor(random * 100) + 1; return randomroll;};// valid betting currenciesconst valid_currencies ['hive'];class dicecontract client; config; blocknumber; blockid; previousblockid; transactionid; create() runs every time register called do setup logic here (creating database, etc) destroy() unregister run close database connections, state, etc information about current block method automatically exists updateblockinfo(blocknumber, previousblockid, lifecycle sets info this.blocknumber this.blockid this.previousblockid this.transactionid /** get balance helper getting balance. case make sure has enough money pay out any bets @returns */ async getbalance() await this._client.database.getaccounts([account]); (account?.[0]) (account[0].balance string).split(' '); amount balance[0]; parsefloat(amount); when custom json action matches @param payload param1 - sender roll(payload, sender, }) destructure values payload; formatted like 100 first part, currency symbol second amounttrim amount.split(' parse numeric real amountparsed parsefloat(amounttrim[0]); format 3 decimal places amountformatted parsefloat(amounttrim[0]).tofixed(3); trim space amountcurrency amounttrim[1].trim(); console.log(`roll: ${roll} parsed: ${amountparsed} formatted: ${amountformatted} currency: ${amountcurrency}`); transaction blockchain utils.gettransaction(this._client, this.blocknumber, this.transactionid); call verifytransfer confirm transfer happened verify utils.verifytransfer(transaction, 'beggars', amount); this.getbalance(); (verify) less max bet, cancel refund (balance &lt; max_bet) send back was sent, broke utils.transferhivetokens(this._client, this._config, account, amounttrim[0], amounttrim[1], `[refund] fufill bet.`); return; bet (amountparsed &gt;= &amp;&amp; &lt;= validate ((roll 2 96) (direction === 'lesserthan' || direction 'greaterthan') valid_currencies.includes(amountcurrency)) rng(this.previousblockid, this.blockid, calculate multiplier percentage new bignumber(1).minus(house_edge).multipliedby(100).dividedby(roll); tokens won tokenswon bignumber(amountparsed).multipliedby(multiplier).tofixed(3, bignumber.round_down); memo shows users they win winningmemo `you ${tokenswon} ${token_symbol}. roll: ${random}, guess: ${roll}`; lose losingmemo lost user afford, (parsefloat(tokenswon) &gt; balance) (random roll) tokenswon, token_symbol, winningmemo); else '0.001', losingmemo); invalid parameters, their params.`); try need sent amount.`); console.log(transfer); catch (e) console.log(e); }}export default dicecontract();adding applicationcreate file app.js add following.import streamer './dice.contract';const streamer({ active_key: '', needed transfers json_id: 'testdice' identifier payloads});// contractstreamer.registercontract('hivedice', dicecontract);// starts watching blockchainstreamer.start();test outin put username then (to you). supply active key constructor (between single quotes).in field, enter stringified this:{hivecontract:{id:testdice, name:hivedice,action:roll,payload:{roll:10 }}}the id must match provided config property json_id uses transactions. case, testdice id. name registercontract method’s argument hivedice example. function finally object data call.i took liberty testing my show process works.as two transactions winning losing, works (which verified checking wallet or explorer):conclusionthis rudimentary example basic contract. improvements might include support odds, supporting more. but, hopefully build now. see: tutorial: building game @beggarsmore node.js"
    } ,
  
    
    
    
    
    
    {
      "author"    : "blocktrades",
      "title"    : "Hive workflow proposal",
      "category" : "howto, contribute, development",
      "url"      : "/howto/contribute/development/2020/04/03/hive-workflow-proposal.html",
      "date"     : "2020-04-03 14:20:39 -0700",
      "desc"     : "Note: this post is primaril...",
      "content"  : "note: this post is primarily intended for hive developers, but it may be of interest to other readers who are interested in the details software development process. i’ll make another later with ideas about how general community members can become involved process and go submitting bug reports.i propose we adopt a common workflow most if not all hive-related projects. will easier developers collaborate on multiple projects minimum amount friction.i believe primary goals (in no particular order) our should be: create an easily findable list tasks prevent duplication work effort allow easy collaboration between establish determining task priority setup testing standards each project review ensure existence code functional/compilable state where test their new against potential interactions production which safe deployed publicbelow some my initial proposals achieve above goals.creating issues taskswhen comes up, issue appropriate inside group.selecting (issue)if clear what belongs to, or existing project, called without yet. assigned specific corresponding correct close yet.describing labelschoose labels describe nature issue, such as “bug”, “enhancement”, “documentation”. currently only have group-level labels. generally preferred, unless you need that really sense group.optional assignment person taskthe at creation time developer, self-assigning assigning someone confident want take latter case, probably also contact them directly issue).using boards monitor issuesusing gitlab, individual group has “board” shows states project’s issues: open: exists, decision yet been made do: do awaiting it, blocked by precursor doing: one more working review: done, independent after completed, changed either do, doing, closed closed: completed passed reviewwhen first created show up “open” list. setting label moves from review. closing list.using board workflowin addition project-level boards, there aggregates status group: https://gitlab.syncad.com/hive/hive/-/boardsprocess statusthe likely vary across example, web site hosted entity, entity determine worked on, works them, they reviewed.some core blockchain rigorous criterion selection those reviewed, because ripple effects projects.the sensitive, features impacts memory, disk, cpu utilization could increase cost operating node.similarly, changes commonly used libraries hive-js financial-related wallet apps malicious injected.reference when committing associated source repositoryit’s very useful link possible. commit related place tag your comment to. forget code, manually update afterward adding url commit.testing requirementsunit tests image “tests”one included change, verify properly, able detect future regressions (future break functionality). backend usually too difficult required process.for user interface (ui) changes, it’s often tests, cases, attach “before” “after” set images reviewer understand was done.continuous integration (ci) projectsanother important component proper compiles developer still others. due environment differences, properly developer’s machine, then fails others.to problems, ci gitlab automatically recompile run regression pushed repository. enable rapid detection problems avoid wasting developers.branch management repositoriesthe master branch serves deployment production.tags indicate recent version approved use environment. tagged versions environments!the head represent believed compilable functional.note flow require cleanup steemd (now renamed hive) repo.public testnet codepreferably, always public testnets available apps, requiring main network. witnesses encouraged operate consensus api nodes support testnet(s).a any deemed potentially impact third party apps.we whatever being testnet. see: proposal @blocktrades"
    } ,
  
    
    
    
    
    
    {
      "author"    : "therealwolf",
      "title"    : "dhive: RPC Failover Support",
      "category" : "howto, rpc, nodejs",
      "url"      : "/howto/rpc/nodejs/2020/04/03/dhive-rpc-failover-support.html",
      "date"     : "2020-04-03 05:00:03 -0700",
      "desc"     : "Greetings #Hivers &amp; fel...",
      "content"  : "greetings #hivers &amp; fellow developers,i’ve just pushed a new version, 0.13.3, to dhive (js library) that enables native rpc node failover-support. this feature is optional and only active if an array of nodes given as the first argument in client.import {client} from '@hivechain/dhive'// failoverconst client = client(['https://api.hive.blog', 'https://api.hivekings.com', 'https://anyx.io'], { failoverthreshold: 3 /* default */})// no simpleclient client('https://api.hive.blog')relevant options parametersnew client(url, options)- failoverthreshold (default: 3): specifies number times urls (rpc nodes) should be iterated retried case timeout errors. requires url parameter array! it can set 0 iterate retry forever.- 60 * 1000ms): send timeout, how long wait milliseconds before giving up on call. forever.gitlab pull request (code)https://gitlab.syncad.com/hive/dhive/-/merge_requests/3why relevant?normally, you have take care potential failovers your application yourself. produce redundant code. having solution far cleaner.another wrapper around failover. there dsteem-pool, but didn’t work for me.infocode has been tested everything working fine: https://gitlab.syncad.com/hive/dhive/-/blob/master/test/client.ts#l15-20however, very sensitive operations, please still careful rather double-check.with said:if are any problems/questions, create issue https://gitlab.syncad.com/hive/dhive/issues#hiveonwolftherealwolf.me see: dhive: failover support by @therealwolfmore about node.js"
    } ,
  
    
    
    
    
    
    {
      "author"    : "holger80",
      "title"    : "How to review account permissions and change your recovery account",
      "category" : "howto, beem, python, account",
      "url"      : "/howto/beem/python/account/2020/04/02/how-to-review-account-permissions-and-change-your-recovery-account.html",
      "date"     : "2020-04-02 15:04:27 -0700",
      "desc"     : "sourceAll accounts on the H...",
      "content"  : "sourceall accounts on the hive blockchain that existed also before fork may have posting permissions granted to apps do not exists blockchain. it is a good idea remove them for now.you can use beempy your account. at first,all account posting/active should be printed withbeempy holger80+------------+-----------+-----------------------------------------------------------+| permission | threshold key/account |+------------+-----------+-----------------------------------------------------------+| owner 1 stm5xdyn3netqimd1wczzjf9spijqy2uqw9hrwt6lr6rqytaxwnfz (1) || active stm7ta7mh81wjv1j8ew8nyglc3xcsyxndfnhah8f8byyd8yacy6ew actifit.app dpoll.xyz esteemapp nc-client nextcolony peakd.app rewarding stm6t5exkhztql1pdkrrzjcgzbadnb3yuyczgrywdxvdnu5bp57jl |+------------+-----------+-----------------------------------------------------------+remove permissionnow, needed removed bybeempy disallow -a holger80 busy.appwhere name set with -a.this command broadcasts account_update operation and removes given from account_auths field.this done https://hivesigner.com/revoke/ followed by name, e.g. https://hivesigner.com/revoke/busy.appchanging reviewing possible peakd:https://peakd.com/@holger80/permissionsrecovery accountthe recovery check https://hiveblocks.com/@holger80it @steem my as most unlikely will ever sign request_account_recovery hive, i’m unable account, when i would accidentally leak key someone change using leaked key.this unlikely, but could happen.how does work?assuming, was changed within 30 days, previous recover signing, account: need create new public signed its then broadcast recover_account old private key. now all keys an key.currently this work me, hive.changing accounti created @recovery.account account.it hivesigner this:https://hivesigner.com/sign/change_recovery_account?account_to_recover=holger80&amp;new_recovery_account=recovery.account&amp;extensions=%5b%5dor peakd: https://peakd.com/@holger80/permissionsbut like own script:from beem.account import accountfrom beem.nodelist nodelistfrom beem steemfrom beem.transactionbuilder transactionbuilderfrom beemgraphenebase.account privatekeyimport beembaseimport getpassif __name__ == __main__: nodes = nodelist() nodes.update_nodes() getpass.getpass(prompt='owner key: ') owner_key privatekey(wif=key) print(pub: %s % str(owner_key.pubkey)) account_name input(account name: ) new_recovery_account input(new recovery_account: steem(node=nodes.get_nodes(hive=true)) assert hive.is_hive account(account_name, steem_instance=hive) new_rec_acc account(new_recovery_account, op beembase.operations.change_recovery_account(**{ 'account_to_recover': account['name'], 'new_recovery_account': new_rec_acc['name'], 'extensions': [] }) print(op) prompt input(broadcast operation? [y/n]) if prompt[0] y: tb transactionbuilder(steem_instance=hive) tb.appendops([op]) tb.appendwif(str(owner_key)) #tb.appendsigner(account['name'], 'owner') tb.sign() trx tb.broadcast() print(trx) results inthis means in days changed.i keep of safe place them.is there provider?do you want account? how work? let me know. see: review @holger80more about python"
    } ,
  
    
    
    
    
    
    {
      "author"    : "deathwing",
      "title"    : "How to set up your Witness server with MIRA?",
      "category" : "howto, witness",
      "url"      : "/howto/witness/2020/04/01/how-to-set-up-your-witness-server-with-mira.html",
      "date"     : "2020-04-01 17:30:33 -0700",
      "desc"     : "Hello there, as you may or ...",
      "content"  : "hello there, as you may or not know the server requirements for hosting a witness is growing very fast. to combat this, with recent hardforks blockchain mira was introduced.mira caches data on rocksdb files rather than random acces memory, ram. which means will require higher storage fast r/w speeds like ssds example. instead of 64 gb ram.right now, today (02.04.2020) absolute minimum node 8 gigabytes ram, 400gb ssd storage, 4 cores, 100 mbps dl/ul speed.the recommended specifications witness/seed 32 500gb 1 gbps speed.block logs currently take about 258 space while takes 37 gb.witnesses are course, crucial longevity, stability and decentralization chain. if wan create become witness, good thank volunteering! managing servers keeping tabs them no easy feat. lets forget mention, cheap.start setting up your fresh install [diy]so have decided using mira. ready, freshly installed. preferably ubuntu debian, but that’s just my taste.for setup, we be steem-docker made by someguy123 provided privex.iolet’s get started. throughout this tutorial, i assuming root.first, git so can use clone necessary from github.apt -ynow, repository github.git &lt;a href=https://github.com/someguy123/steem-docker.git&gt;https://github.com/someguy123/steem-docker.git&lt;/a&gt;now that has downloaded server, cd into folder.cd steem-dockernext, going custom-made script docker us../run.sh install_dockerthis probably minute.next, installing package../run.sh someguy123/hive:latest-miranext, .env docker.nano .envdocker_name=witnessports=paste these in file save it pressing ctrl+x then y.next step download block_log.mkdir root/data/witness_node_data_dir/blockchaincd root/data/witness_node_data_dir/blockchaincurl -fssl href=http://files.privex.io/hive/block_log.lz4&gt;http://files.privex.io/hive/block_log.lz4&lt;/a&gt; -o - | lz4 -d block_logas block_log quite big, anywhere 20 minutes several hours depending internet connection server.after been installed, privex.iofor hive,rsync -av --progress --delete rsync://files.privex.io/hive/rocksdb/ /root/steem-docker/data/rocksdb/now our downloaded, must generate brain key security.cd root/steem-docker./run.sh remote_walletsuggest_brain_keythis pair witness. copy output it.after generating keys edit config.ini main configuration server.nano root/steem-docker/data/witness_node_data_dir/config.inion first line, see p2p-endpoint should comment out goal make looking host seed keep on.you putting pound (#) front line. look this,#p2p-endpoint = 0.0.0.0:2001next, few lines below see,shared-file-size 64gplease change 16 16g on.next, scroll down until private-key lines.for part, put username “” this,witness deathwingnext, private previously saved without any quotation marks.private-key 5thisisyourpreviosulygeneratedprivatekeyagain, press y exit.you almost done!our next replay chain, long time process single-threaded can’t advantage multi-core cpus, processors’ single-thread performance, amount vary. likely an hour more../run.sh replayafter complete, start let sync network../run.sh startyou ./run.sh view log output. normal errors appearing here time. check every 20-30 something this:when seeing messages, ctrl+c leave logs.now synced ready go, update account broadcast network. do that, need run wallet../run.sh walletthe wallet prompt set password.set_password hunter2 (set own password)unlock hunter2import_key 5yourwitnessaccountsactiveprivatekeyyou find peakd https://peakd.com/@yourusername/permissionsremember import_key witnessing chain one generated tutorial.now, journey supporting stability, longevity blockchain.update_witness witnessname witnessurl stmxxxxxxx {account_creation_fee:3.000 hive,maximum_block_size:65536,sbd_interest_rate:0} truewitnessname account.witnessurl preferably, announcement post.stmxxxxxxx= paste generated.you hiveblocks.com/@yourusername everything worked transaction this;congratulations! now you!i want don’t thing servers!best way situation purchasing pre-replayed privex.io who both scripts used tutorial. option best users knowledge excellent customer support during their becoming witness.after order vps-hive from, receive mail containing information connect login in, what first, switch user root, type,suthen, using./run.sh remote_walletsuggest_brain_keythen, nano data/witness_node_data_dir/config.ini with./run.sh wait sync,then shown previously.let me questions!post scriptum remember voting witnesses important. would appreciate could vote me. peakd’s page clicking here.use hivesigner here. you! see: how mira? @deathwing"
    } ,
  
    
    
    
    
    
    {
      "author"    : "inertia",
      "title"    : "Jekyll::Hive",
      "category" : "tools, ruby, jekyll",
      "url"      : "/tools/ruby/jekyll/2020/04/01/jekyll-hive.html",
      "date"     : "2020-04-01 16:43:15 -0700",
      "desc"     : "Liquid tag for displaying Hive content in Jekyll sites: `{% hive %}`.",
      "content"  : "jekyll::hiveliquid tag for displaying hive content in jekyll sites: {% %}.installationadd this line to your application’s gemfile:gem 'jekyll-hive'and then execute:bundleor install it yourself as:gem jekyll-hivethen add the following site’s _config.yml:plugins: - jekyll-hive💡 if you are using a version less than 3.5.0, use gems key instead of plugins.usageuse as follows pages, posts and collections:{% author/permlink %}this will place associated on page.jekyll buildwhen building site with jekyll, can continue default command:jekyll buildif would like provide an alternate node:node_url=&lt;a href=https://anyx.io&gt;https://anyx.io&lt;/a&gt; buildcontributing fork ( https://github.com/inertia186/jekyll-hive/fork ) create feature branch (git checkout -b my-new-feature) commit changes -am 'add some feature') push origin new pull requestget touch!if you’re jekyll::hive, i’d love hear from you. drop me tell what think! i’m @inertia hive.licensei don’t believe intellectual “property”. do, consider jekyll::hive licensed under creative commons license. see: by"
    } ,
  
    
    
    
    
    
    {
      "author"    : "holger80",
      "title"    : "Update for beem: fixing author/curation reward calculation and more",
      "category" : "howto, beem, python, curation",
      "url"      : "/howto/beem/python/curation/2020/04/01/update-for-beem-fixing-author-curation-reward-calculation-and-more.html",
      "date"     : "2020-04-01 15:10:03 -0700",
      "desc"     : "Repositoryhttps://github.co...",
      "content"  : "repositoryhttps://github.com/holgern/beem beem is a python library for steem and hive. the current version 0.22.12.there also discord channel beem: https://discord.gg/4hm592vthe newest can be installed by:pip install -u beemcheck that you are using hive nodes. following commandbeempy updatenodes --hiveupdates nodelist uses only list of nodes checked withbeempy configandbeempy currentnodeshows currently connected node.changelog versions 0.22.12this update fixed vote classes, curation/author reward calculation, discussions classes get_feed get_account_votes accounts. add node now discussion_by_feed has been activevotes raw_data parameter added to all beempy curation, votes pending table improved fix curation author calculationfixing integration testsafter fixing remaining problems in vote, comment account, 462 tests have finally passed.========== passed, 27 skipped, 13 warnings 1551.63s (0:25:51) ===========the ci may fail from time due outs.view outgoing incoming with beempyoutgoing -o -d 1 holger80+----------+------------------+---------+--------------+---------------+---------+--------+| voter | votee sbd/hbd rshares percent weight |+----------+------------------+---------+--------------+---------------+---------+--------+| holger80 pibara 1.0 $ 0 days 23:9 2348837832917 7500 911136 || pennsif 1.34 21:17 3123742413620 9955 390108 nonameslefttouse 1.08 18:45 2517726726913 8000 323940 gtg 1.4 12:17 3279925264141 10000 281332 quochuy 1.39 10:42 3259050022456 216722 steemcleaners 0.68 10:30 1599714528677 5000 358546 dsound 1.03 9:30 2396854864854 238509 abitcoinskeptic 1.35 8:49 3167311773888 847601 jga 6:6 1590352821718 151064 creary 0.34 5:50 789079645344 2500 317630 muelli 4:50 1584677025773 364432 emrebeyler 1.01 4:28 2360837888866 649503 denmarkguy 0.57 3:20 1331770685831 4251 377530 inertia 1.02 0:40 2386404162091 256582 stellabelle 0.94 0:34 2195712375512 7000 524304 |+----------+------------------+---------+--------------+---------------+---------+--------+where d limit shown days.incoming seen -i holger80+---------------+----------+---------+--------------+---------------+---------+--------+| |+---------------+----------+---------+--------------+---------------+---------+--------+| kaymay 0.0 23:54 138492921 7 barton26 0.01 23:4 18413631854 936 dhimmel 2.0 18:59 4675461211716 235183 joey-fancy 17:3 5993194991 298 cubapl 12:52 3051877392 152 1.13 10:0 2646991658036 130928 saboin 0.16 8:36 367812173322 4500 18068 netuoso 0.33 2:39 765623609156 38036 memehub 1.15 2:5 2685197932823 132357 crokkon 0.02 1:57 40344164439 1977 dustsweeper 0.04 1:36 89501844457 2000 4393 |+---------------+----------+---------+--------------+---------------+---------+--------+pending rewardsthis command used calculating rewards posts, comments votes. conversion usd done by latest internal market price hive/hbd day median hive/usd.pending posts bybeempy --post holger80+----------+-----------+-----------+------------+--------------+| cashout hbd hp liquid invested |+----------+-----------+-----------+------------+--------------+| 4.0 16.389 84.044 14.06 16.39 0.9 16.347 83.830 14.02 16.35 sum 32.74 167.87 28.08 |+----------+-----------+-----------+------------+--------------+--author, --permlink or --title set show more information.the --days limits duration --from sets start point days. before 6 viewed (this call takes while): --curation --author holger80showing @holger80+-----------------+----------+----------+----------+------------+--------------+| |+-----------------+----------+----------+----------+------------+--------------+| anthonyadavisii 0.000 3.953 0.00 0.77 arcange 2.708 0.53 4.148 0.81 anomadsoul 0.8 5.438 1.06 exhaust 0.7 1.819 0.35 bluerobo 3.372 0.66 therealwolf 9.194 1.79 markkujantunen 0.6 2.717 4.727 0.92 moon32walker 2.043 0.40 stateofthedapps 0.5 1.780 nateaguila 4.630 0.90 jrvacation 3.617 0.71 eonwarped 0.3 2.591 0.51 steemillu 0.1 1.760 hiq 5.430 fullnodeupdate 1.585 0.31 yabapmatt 3.789 0.74 1.144 0.22 - 66.44 12.96 |+-----------------+----------+----------+----------+------------+--------------+the given values estimate, e.g. @therealwolf/dhive was estimated, but received 0.927 hp.the last 24 h holger80--comment view on comments.curation performance permlinkthe calculated already paid-out posts.the shows @therealwolf/dhive.beempy -a @therealwolf/dhive+------------+-------------+------------+-----------------+-----------+-------------+| voting early loss |+------------+-------------+------------+-----------------+-----------+-------------+| 27.4 min 0.328 0.926 55.0 % high. 688.7 10.198 21.750 41.6 cur. 4.3 0.104 0.014 0.909 170.1 36.675 0.514 86.581 45.97 |+------------+-------------+------------+-----------------+-----------+-------------+`the percentage dividing power through value higher than 0.2 --min-vote @therealwolf/dhive+-----------------+-------------+------------+-----------------+-----------+-------------+| |+-----------------+-------------+------------+-----------------+-----------+-------------+| karja 3.9 0.223 0.051 1.875 164.2 oflyhigh 4.5 1.969 0.217 11.331 112.2 deanliu 1.077 0.108 5.063 91.7 helene 0.518 0.052 2.140 80.6 xiaohui 0.394 0.035 1.535 76.0 russia-btc 17.1 0.241 0.938 75.9 17.9 2.006 6.731 65.4 lunaticpandora 58.0 0.391 0.985 49.2 solarwarrior 58.1 0.634 1.509 46.4 diggndeeper.com 64.1 0.473 0.990 40.9 fredrikaa 80.0 0.739 1.445 38.1 braaiboy 0.259 0.482 36.3 asgarth 149.3 0.825 1.415 33.4 good-karma 375.8 0.702 1.110 30.8 nextcolony 763.6 0.209 0.361 33.7 steemik 1247.0 0.737 1.248 33.0 smartsteem 6575.2 7.220 10.606 28.6 tombstone 6575.3 3.967 4.824 23.7 epicdice 0.246 0.319 25.3 |+-----------------+-------------+------------+-----------------+-----------+-------------+this works posts. influences highest curation. this useful, as low high performance, which cannot archived i see optimum around 4.2 minutes 0.4 hbd.beempy @emrebeyler/dpoll-beneficiary-updatecuration @emrebeyler/dpoll-beneficiary-update+------------+-------------+------------+-----------------+-----------+-------------+| 5.1 1.008 4.497 87.0 201.6 12.492 22.977 35.9 0.507 0.081 2.760 106.2 16.314 0.159 38.316 45.76 |+------------+-------------+------------+-----------------+-----------+-------------+if like what do, consider casting me witness hivesigner peakd. see: author/curation calculation @holger80more about"
    } ,
  
    
    
    
    
    
    {
      "author"    : "holger80",
      "title"    : "Use beempy to access the internal HIVE/HBD market",
      "category" : "howto, beem, python, market, hbd",
      "url"      : "/howto/beem/python/market/hbd/2020/03/24/use-beempy-to-access-the-internal-hive-hbd-market.html",
      "date"     : "2020-03-24 13:57:21 -0700",
      "desc"     : "sourceAlthough not visible,...",
      "content"  : "sourcealthough not visible, the internal market is already working and hbd can be exchanged for hive.prepare beempyyou need to have an up date beem version 0.22.8beempy updatenodes --hivebeempy currentnodeshould return now+----------+-----------------------+| key | value |+----------+-----------------------+| node-url &lt;a href=https://api.hive.blog&gt;https://api.hive.blog&lt;/a&gt; || 0.23.0 hive true |+----------+-----------------------+check orderbookbeempy orderbook --chart 1701.93 $ ┼ 1595.59 ┼╮ 1489.25 ┤╰─╮ ┊ 1382.90 ┤ ╰─╮ ╭─────── 1276.56 ╰╮ ╭────╯ 1170.22 ╰───╮ ╭╯ 1063.87 │ 957.53 851.19 ╭─╯ 744.84 638.50 532.16 425.81 ╰─────╮ 319.47 ╰────╮ 213.12 106.78 ╰╮┊ 0.44 ╰────╯and beempy tradehistoryreturns last trades as plot trade history 2020-03-17t20:26:22 - 2020-03-24t20:26:22hive/hbd 0.32 0.31 ╭╮ 0.30 │╰╮ 0.29 0.28 0.27 ╭─ 0.26 ╭╮╭╯ │╭──╮ ╭╯│ │││ ││ ╰─╯ 0.25 ╭╯╰╯ ╰╯ 0.24 0.23 ││╭╯ 0.22 │╰╯ 0.21 0.20 0.19 0.18 0.17 ┼───────╯a short info obtained bybeempy ticker+----------------+-------------------+| |+----------------+-------------------+| highest_bid 0.253913 hive/hbd latest 0.300000 lowest_ask 0.253994 percent_change 0.00 % sbd_volume 199.189 steem_volume 765.713 |+----------------+-------------------+let’s some hivefirst we should check our balance:beempy balance holger80and then start sell 1 hbdbeempy -a holger80 hbdi’m now asked if price ok:is following ok: hbd/hive [y/n]:and enter my active wif:password unlock wallet or posting/active wif:i see broadcasted op:wif accepted!{ expiration: 2020-03-24t20:34:03, ref_block_num: 63124, ref_block_prefix: 2805668693, operations: [ limit_order_create, { owner: holger80, orderid: 3815817900, amount_to_sell: 1.000 hbd, min_to_receive: 3.938 hive, fill_or_kill: false, 2020-03-31t20:33:33 } ] ], extensions: [], signatures: 206b30dd79130814b9f14468c573fd9154020148e43481f810343964b93bcf8c1865927d49d1e3b521ff9a2af12bd5461c2edee220b64f59108c04413c3b88cbb0 ]}and open orders:beempy openorders +------------+---------------------+------------------------------------------+----------+| orderid created order account |+------------+---------------------+------------------------------------------+----------+| 3815817900 2020-03-24t20:33:33 @ 0.253936 |+------------+---------------------+------------------------------------------+----------+cancel ordersi cancel instead of selling i also buy hiveafter checking entering wif, placed.using fulfill orderslet’s first 5 -l 5+--------------+----------------------------------------------+--------------+-------------------------------------------+| asks sum orders bids |+--------------+----------------------------------------------+--------------+-------------------------------------------+| 66.15 260.432 66.148 0.253993 1.725 0.438 240.43 637.769 174.284 0.273271 0.70 1.032 0.262 0.253876 267.93 100.000 27.500 0.275000 0.91 0.842 0.211 0.250594 283.93 53.344 16.002 0.299978 0.004 0.001 0.250000 296.29 41.191 12.357 0.299993 6.64 23.778 5.731 0.241021 |+--------------+----------------------------------------------+--------------+-------------------------------------------+i shown in column fulfilled without waiting. let’s try: 0.253993this time, wif asking price. empty this time:beempy +---------+---------+-------+---------+| |+---------+---------+-------+---------++---------+---------+-------+---------+the blockexplorer shows that was fulfilled:i hope help long has no interface. see: use access by @holger80more about python"
    } ,
  
    
    
    
    
    
    {
      "author"    : "hiveio",
      "title"    : "The Hive Blockchain Has Launched Successfully! Recap and Helpful Information",
      "category" : "news",
      "url"      : "/news/2020/03/21/the-hive-blockchain-has-launched-successfully-recap-and-helpful-information.html",
      "date"     : "2020-03-21 10:05:33 -0700",
      "desc"     : "Hello there, Hive. What a d...",
      "content"  : "hello there, hive. what a day we’ve had!welcome to the new hive blockchain. been up and running for more than 24 hours now, so this is good time take quick look at launch what’s coming immediate future. blockchain went incredibly smoothly given pressure effort involved in getting hardfork ready such tight window.the passionate team of developers who above beyond produce changes needed did an amazing job (and got very, very little sleep.) hardforks always have chance finding “an edge case” when they go live, being prepared anything necessary. came alive, slowly worked through operations that done, produced first blocks transactions, has moving steadily ever since. no stalls or crashes, fast blocktimes, all good. it huge win whole community start us off!this short post with few important points information. weeks, there are number things need be addressed we’ll posting about here: will future upgrade hive, make some fixes, bring features online those were skipped airdrop discussing script exclusions letting decide if tokens held reserve should distributed. we also talk dhf (decentralised funding), hivedao, how can used situation others help collect feedback code repo open source public at: https://github.com/openhive-network/hive/releases . condenser (for front ends) on actively finish https://hive.blog/ mvp higher standard previous iterations, then public. as well. ecosystem alive! it’s still early, but many apps projects online, making sure spread word useful services your transition https://hiveprojects.io/ place submit own project, learn going around hive.remember goal move towards true decentralized development, anyone contribute whatever like! play work, you want see.a final notes: hive.blog wallets 🔜™️, wanting secure ways wallet peakd.com wallet, well vessel available. familiar sites ported right you’re okay waiting, options. started powerdown steem, hive! don’t forget stop to. already account waiting here read depth our info refresher. new, onboard someone check signup options https://signup.hive.io/. available future- only start! key safety matters! please consider using keychain (still under review by app stores, here’s great tutorial) hivesigner (the version steemconnect). both supported integrated them, alongside their peaklock. most frontends begun work do management solution like one these. remember witness votes from steem carry over whichever use, part governance, excellent fresh discover dedicated witnesses ecosystems. people hard life, witnesses. often feel like, vote according see support. amount witnesses, consensus (top twenty) backup, considerations believe fit. exchanges working running. ionomy full, limited fee free trading enabled. other listing pairs online. 6 airdrops, them listing. however, these done safely, lot behind scenes tech support, note process while.the buzzing, that’s thanks you. spirit energy chain invigorating…. wings.edit: fumble fingered worker bee refresh while was excited forgot decline rewards. powered longer needs delegation, continue rewards sorry! see: launched successfully! recap helpful information @hiveio"
    } ,
  
    
    
    
    
    
    {
      "author"    : "arcange",
      "title"    : "HiveSQL is ready with all the Hive blockchain data",
      "category" : "news, sql, database",
      "url"      : "/news/sql/database/2020/03/20/hivesql-is-ready-with-all-the-hive-blockchain-data.html",
      "date"     : "2020-03-20 16:25:36 -0700",
      "desc"     : "  The Hive blockchain is al...",
      "content"  : "the hive blockchain is alive! congratulations to all hard workers who lately have been working night and day make our beloved decentralized again.i am happy announce that hivesql, a publicly available sql database with data, now available, in synch ready support many (d)apps analysts rely on it.better performances for futureicing cake, hivesql benefits from whole new infrastructure even more efficient. memory storage capacity doubled computing has also increased.hivesql face future most demanding users!what about steemsql?steemsql will continue run at least until end of month, longer if active subscriptions cover costs its infrastructure. this allow those wish see what going old steem world.what subscriptionsthe existing steemsql not carried over hive. it was too much hassle handle addition creating migrating everything however, they are only steemsql.to you get started as quickly possible set up your applications processes, users had an subscription receive one free subscription. check wallet credentials.the creation renewal process same before use hbd token.more information coming soona website created https://hivesql.io but still raw state. i update soon concerning be published there.you can subscribe want community stay updatedthat’s today. last few days tough need some sleep now.enjoy toolshive alive!&lt;div style=display: block; margin: 0 auto; markdown=1&gt;support me my work community.&lt;/div&gt;&lt;div markdown=1&gt;vote witness &lt;/div&gt; see: data by @arcange"
    } ,
  
    
    
    
    
    
    {
      "author"    : "hiveio",
      "title"    : "Announcing the Launch of Hive Blockchain",
      "category" : "news",
      "url"      : "/news/2020/03/17/announcing-the-launch-of-hive-blockchain.html",
      "date"     : "2020-03-17 16:30:54 -0700",
      "desc"     : "After weeks of hard teamwork, we're announcing the launch of the new Hive blockchain.",
      "content"  : "the buzz is real! after weeks of hard teamwork, we’re announcing launch new hive blockchain.this an exciting time, and opportunity to channel love power a resilient tenacious community into collaborative development for future social blockchain.hive passionate effort, created by large group steem members who have long looked move towards true decentralization help develop code base. years distribution issues reliance on central entity infrastructure has been at heart revolution sorts, blockchain culmination stepping up meet challenge returning shared values protecting celebrating vibrant that grown around our ecosystem.check out faq below info hive.what why was it created?hive dpos governance implementing fork existing code.the intention this community-driven support build strong made ecosystem so diverse exciting. direction steps away from burden steemit inc. ninja-mined stake, which impacted term ability work further years.hive begun with talented committed team developers are already paving way implement much awaited improvements robust developments blockchain. see – devs business owners end users forward embrace contribute potential hive. renewed spirit, combined codebase focus working more closely entire ecosystem, key success possibilities blockchain.what difference between steem?hive runs completely independently chain. all valid accounts will receive airdrop (more details below)while chain code, take responsibility something even better. initial be direct copy few small upgrades, allow us get back discussion development, needed changes, most wanted chain-level features.the spirit goal always single point authority, capitalize encourage gathered in community. drawing huge range talent accelerate improve communication, return ease use, onboarding, marketing. desire better connect people via never lost, it’s what makes now.what happens when launches?when launches, appear network as well. you two accounts: current one steem, account, pre-populated your content information.the history these same, but snapshot onward, independent another. actions not reflected other. means transactions belong whichever account use.if post hive, show vice versa. chains another launch.when launch?the 10am est/14:00 utc, friday, march 20th. (countdown https://hive.io/) magic happen week! place time launch. where can i find hive’s code?here public open source repo hive:### https://github.com/openhive-network/hive/releasesas holder, do airdrop?all stakeholders perfectly mirrored balance their holdings coin. include matching amounts liquid power, sbd. other state data, such claimed accounts, delegations, etc. onto hive.for example: if 10 5 sbd, 1000 sp, hbd, hp.you need claim anything. simply log coins wallet able start using blockchain.the only performed version (as date post). any “emergency hardforks” prior eligible. further, exchange participates hardfork null void participate its off-chain holding customers.how access my send coins?you logging keys. first frontend available https://hive.blog. currently pointed blockchain, switched time. popular interfaces completing switch over or finishing products, they ready use!who behind hive?there 30 experienced contributing alongside many multiple aspects individuals may announce participation through own future. therefore all. remain source, everyone wants testnet published, feel free comment here would like we’ll reach out. full thursday, 19th, updates account.what added?the important decisions chance proper feedback successfully launch, there some addressed immediately, including prevention exchanges participating attacks we witnessed blockchain).to prevent (or funding) attacks, day delay added crediting vests witness sps votes. changes developed community.this “powers up” stakes funds, before those used voting (witnesses) sps. actions, no immediately available.this mitigate risk while continuing system whole, without deciding collection wider input. included airdrop?the continue moving decentralization, showcased same goals.the containing inc actively contributed (and publicly declared for) centralization blockchain.these still choose part exist, intial airdrop.important notes cryptocurrency list steemdo plan taking customer’s credit them similar amount (yes/no)?yes) want airdrop, please notify distribute pro-rata basis customers (no fixed timeline required), corresponds hive.no) notification steem-holding forewarn participating, temporarily withdraw date, wish airdrop.if possible, let know 19 airdrop.you leaving message official contact liaisons: gandalf (located europe)telegram: @gandalf_the_greyemail: gandalf@hive.expert david jefferys us)telegram: @djefferysdirect follow-ups made, affirmative response days assume doesn’t customer balances.we’re looking hive!there’s lot come during extremely busy week, updated reflect information becomes available.thank community, being buzz. what’s ahead involved… #hiveisalive!# https://hive.io/ see: @hiveio"
    } 
  
]
