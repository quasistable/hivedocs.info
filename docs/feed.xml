<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://hivedocs.info/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hivedocs.info/" rel="alternate" type="text/html" /><updated>2020-05-04T13:02:49-07:00</updated><id>https://hivedocs.info/feed.xml</id><title type="html">Hive Chain Documentation</title><subtitle>Your resource for various levels of Hive Documentation.</subtitle><author><name>site curated by: @inertia</name></author><entry><title type="html">Hive Pressure 2: How to Answer Hive Questions?</title><link href="https://hivedocs.info/news/devops/hivemind/nodes/2020/05/04/hive-pressure-2-how-to-answer-hive-questions.html" rel="alternate" type="text/html" title="Hive Pressure 2: How to Answer Hive Questions?" /><published>2020-05-04T11:32:57-07:00</published><updated>2020-05-04T11:32:57-07:00</updated><id>https://hivedocs.info/news/devops/hivemind/nodes/2020/05/04/hive-pressure-2-how-to-answer-hive-questions</id><content type="html" xml:base="https://hivedocs.info/news/devops/hivemind/nodes/2020/05/04/hive-pressure-2-how-to-answer-hive-questions.html">&lt;p&gt;First, you need to learn how to ask good questions, and here are some of the resources that will help you to do so:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developers.hive.io/apidefinitions/&quot;&gt;https://developers.hive.io/apidefinitions/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://hive.hivesigner.com/&quot;&gt;https://hive.hivesigner.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(Kudos to @inertia and @good-karma)&lt;/p&gt;

&lt;p&gt;This set of API calls is far from perfect, but for now it has to be enough for general purpose API nodes.&lt;/p&gt;

&lt;center&gt;
&lt;a href=&quot;https://www.youtube.com/watch&quot;&gt;https://www.youtube.com/watch&lt;/a&gt;
?v=vlW9lDE3DuI&lt;/center&gt;

&lt;h1 id=&quot;the-big-the-slow-and-the-ugly&quot;&gt;The big, the slow, and the ugly.&lt;/h1&gt;
&lt;p&gt;Back in the days, we used to run a so-called “full node”, that is a single &lt;del&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;steemd&lt;/code&gt;&lt;/del&gt; (yeah, we haven’t renamed the binary yet) node that was built with &lt;code class=&quot;highlighter-rouge&quot;&gt;LOW_MEMORY_NODE=OFF&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;CLEAR_VOTES=OFF&lt;/code&gt; and configured with all the plugins you can get.
It required a lot of RAM, it replayed for ages, and it was a huge pain to keep it running.
Our code is great for running blockchain. It’s not equally efficient when it has to answer complex questions.&lt;/p&gt;

&lt;h1 id=&quot;current-architecture&quot;&gt;Current architecture&lt;/h1&gt;
&lt;p&gt;The idea is to move the workload requiring complex queries out of our blockchain nodes.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                  +----------+                                                                
                  |          &amp;lt;-----------------+             @     @@@@@@    ,@@@@@%          
                  | Hivemind |                 |            @@@@    (@@@@@*    @@@@@@         
        +-------+ |          &amp;lt;-------+         |          %@@@@@@     @@@@@@    %@@@@@,       
        |       | +-----^----+       |         |         @@@@@@@@@@    @@@@@@     @@@@@@      
        | redis |       |            |         |       ,@@@@@@@@@@@@     @@@@@@    @@@@@@     
        |       &amp;lt;--+    |       +----v-----+   |      @@@@@@@@@@@@@@@&amp;amp;    @@@@@@     @@@@@@   
        +-------+  |  +-v-+     |          |   |     @@@@@@@@@@@@@@@@@@    .@@@@@%    @@@@@@  
                   |  |   &amp;lt;-----&amp;gt; AH node  |   |   @@@@@@@@@@@@@@@@@@@@@(              .@@@@@%
        +-------+  +--&amp;gt; j |     |          |   |    @@@@@@@@@@@@@@@@@@@@               @@@@@@ 
&amp;lt;-------&amp;gt;       |     | u |     +----------+   |     *@@@@@@@@@@@@@@@@     @@@@@@    @@@@@@.  
&amp;lt;-------&amp;gt; nginx &amp;lt;-----&amp;gt; s |                    |       @@@@@@@@@@@@@@    &amp;amp;@@@@@.    @@@@@@    
&amp;lt;-------&amp;gt;       |     | s |     +----------+   |        #@@@@@@@@@@     @@@@@@    #@@@@@/     
        +-------+     | i |     |          |   |          @@@@@@@@    /@@@@@/    @@@@@@       
                      |   &amp;lt;-----&amp;gt; FAT node &amp;lt;---+           @@@@@(    @@@@@@    .@@@@@&amp;amp;        
                      +---+     |          |                 @@     @@@@@&amp;amp;    @@@@@@          
                                +----------+                                                  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;sup&gt;
Sorry, lack of GIMP skills
&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&quot;hivemind&quot;&gt;Hivemind&lt;/h2&gt;
&lt;p&gt;For this purpose I use Hivemind (hats off to @roadscape) backed by PostgreSQL.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Hive is a “consensus interpretation” layer for the Hive blockchain, maintaining the state of social features such as post feeds, follows, and communities. Written in Python, it synchronizes an SQL database with chain state, providing developers with a more flexible/extensible alternative to the raw hived API.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;fat-node&quot;&gt;FAT node&lt;/h2&gt;
&lt;p&gt;Also, instead of a single &lt;code class=&quot;highlighter-rouge&quot;&gt;hived&lt;/code&gt; node with all the plugins, I chose to run two nodes, one of them is a “fat node” (&lt;code class=&quot;highlighter-rouge&quot;&gt;LOW_MEMORY_NODE=OFF&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;CLEAR_VOTES=OFF&lt;/code&gt;) on a MIRA-enabled instance to feed the Hivemind.&lt;/p&gt;

&lt;p&gt;Please note that I have NOT included &lt;code class=&quot;highlighter-rouge&quot;&gt;market_history&lt;/code&gt; in my configuration, simply because it doesn’t require a “fat node”, but Hivemind requires it, so make sure that you have it somewhere.&lt;/p&gt;

&lt;h2 id=&quot;ah-node&quot;&gt;AH node&lt;/h2&gt;
&lt;p&gt;Account history node is the other node I use in my setup. It serves not only account history, but it’s definitely the heaviest plugin here, hence the name.
I’m not using MIRA here, because I prefer the pre-MIRA implementation of the account history plugin and MIRA had some issues with it. Also, it’s way too slow for replay.&lt;/p&gt;

&lt;h2 id=&quot;jussi&quot;&gt;Jussi&lt;/h2&gt;
&lt;p&gt;Instead of one service, I now have three specialized ones, I need to route incoming calls to them.
So the &lt;code class=&quot;highlighter-rouge&quot;&gt;get_account_history&lt;/code&gt; goes to the AH node, while the &lt;code class=&quot;highlighter-rouge&quot;&gt;get_followers&lt;/code&gt; goes to Hivemind.
That’s what jussi does, but it also caches things.&lt;/p&gt;

&lt;h2 id=&quot;redis&quot;&gt;Redis&lt;/h2&gt;
&lt;p&gt;Jussi uses Redis as in-memory data cache. This can very effectively take load off the nodes. Even though most of the entries quickly expire, it’s enough to effectively answer common questions such as “what’s in the head block?”&lt;/p&gt;

&lt;div style=&quot;display: block; margin: 0 auto;&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;https://images.hive.blog/DQmdb8PSfpBkD2dm8cJtLZJNvCYAe2aYLy5Rr9MCLQxHLoN/headblock.jpg&quot; alt=&quot;headblock.jpg&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;8 dApps asking for the latest block will result in 1 call to the node and 7 cache hits from Redis.&lt;/p&gt;

&lt;h2 id=&quot;nginx&quot;&gt;Nginx&lt;/h2&gt;
&lt;p&gt;That’s the world facing component - here you can have your SSL termination, rate limiting, load balancing, and all other fancy stuff related to serving your clients.&lt;/p&gt;

&lt;h1 id=&quot;resources&quot;&gt;Resources&lt;/h1&gt;
&lt;p&gt;Now when you know all the components, let’s take a look at what is required to run them all and (in the darkness) bind them.&lt;/p&gt;

&lt;h2 id=&quot;small-stuff&quot;&gt;Small stuff&lt;/h2&gt;
&lt;p&gt;There are no specific needs here. The more traffic you expect, the more resources you will need, but they can run on any reasonable server on instance:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nginx needs what nginx usually needs - a bunch of cores and some RAM.&lt;/li&gt;
  &lt;li&gt;Jussi is no different than nginx when it comes to resources.&lt;/li&gt;
  &lt;li&gt;Redis needs what redis usually needs - a few GB of RAM to hold the data.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;big-stuff&quot;&gt;Big stuff&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;the AH node, which is non-MIRA in my setup, requires plenty of RAM for the &lt;code class=&quot;highlighter-rouge&quot;&gt;shared_memory.bin&lt;/code&gt; file to either hold it on tmpfs or buffer/cache it, especially during replay. A machine with 32GB RAM will work, but I would rather suggest using a 64GB RAM machine these days. Of course, low latency storage such as SSD or NVMe is a must. You need 600GB of it.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;the FAT node in my setup is running MIRA, so it’s not that memory hungry, but the more RAM you have, the more effective it can be. A machine with 16GB RAM might work, but I would go with 32GB or 64GB for it. Don’t even try without a very fast SSD or NVMe. You need 400GB of it.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hivemind itself is a simple script, but it needs PostgreSQL as a database backend, and for that you need all the things that PostgreSQL usually needs. It can run on pretty much everything, as long as you have enough space to fit the data, currently 300GB. Of course, faster storage and more RAM will result in much better performance.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;from-zero-to-hero&quot;&gt;From zero to hero&lt;/h1&gt;
&lt;p&gt;Reference hardware configuration:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Intel(R) Xeon(R) E-2274G CPU @ 4.00GHz
64GB RAM, ECC, 2666MT/s
2x NVMe 960GB (SAMSUNG PM983)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;When you are starting from scratch, it’s best to get a recent &lt;code class=&quot;highlighter-rouge&quot;&gt;block_log&lt;/code&gt;
I’m providing one at 
&lt;a href=&quot;https://gtg.openhive.network/get/blockchain/&quot;&gt;https://gtg.openhive.network/get/blockchain/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;How fast you can get it depends on your network and load on my server. The average downloading speed is around 30MB/s, so you should be able to get it in less than 3 hours.&lt;/p&gt;

&lt;div style=&quot;display: block; margin: 0 auto;&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;https://images.hive.blog/DQmRTxHALWD8Nszhg7cYkqu4tQHCLotEYMK7USDF2xthbAH/replay-speed.png&quot; alt=&quot;replay-speed.png&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;div style=&quot;display: block; margin: 0 auto;&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;https://images.hive.blog/DQmeYsSaz9PTyt6wamQU76Z6Mz7gJGce8aHxmj78Q58DLuo/replay-times.png&quot; alt=&quot;replay-times.png&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Node type&lt;/th&gt;
      &lt;th&gt;Replay Time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;AH Node&lt;/td&gt;
      &lt;td&gt;15 hours 42 minutes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fat Node&lt;/td&gt;
      &lt;td&gt;48 hours 53 minutes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Hivemind&lt;/td&gt;
      &lt;td&gt;85 hours 50 minutes&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Roughly you need 4 days and 9 hours to have it synced to the latest head block.&lt;/p&gt;

&lt;div style=&quot;display: block; margin: 0 auto;&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;https://images.hive.blog/DQmTQXoQYYFenMLrvLRZzuHZQdZ6wStc394jKTnGF8bya1s/4days9hours.jpg&quot; alt=&quot;4days9hours.jpg&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;A lot can be improved at the backend, and we are working on that. To be developer-friendly, we also need to improve the set of available API calls, finally get rid of the deprecated ones such as &lt;code class=&quot;highlighter-rouge&quot;&gt;get_state&lt;/code&gt;, and move away from the all in one wrapper &lt;code class=&quot;highlighter-rouge&quot;&gt;condenser_api&lt;/code&gt;. But that’s a different story for a different occasion.&lt;/p&gt;

&lt;div style=&quot;display: block; margin: 0 auto;&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;https://images.hive.blog/DQmSJUo4g9AmoVFoAbs6gzMw6coVURUQKg7URtBSfkEj5oJ/Hive_free-file.png&quot; alt=&quot;Hive_Queen&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-160391/@gtg/hive-pressure-2-how-to-answer-hive-questions&quot;&gt;Hive Pressure 2: How to Answer Hive Questions?&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@gtg&quot;&gt;@gtg&lt;/a&gt;
&lt;/p&gt;</content><author><name>gtg</name></author><summary type="html">First, you need to learn how to ask good questions, and here are some of the resources that will help you to do so: https://developers.hive.io/apidefinitions/ https://hive.hivesigner.com/ (Kudos to @inertia and @good-karma) This set of API calls is far from perfect, but for now it has to be enough for general purpose API nodes. https://www.youtube.com/watch ?v=vlW9lDE3DuI The big, the slow, and the ugly. Back in the days, we used to run a so-called “full node”, that is a single steemd (yeah, we haven’t renamed the binary yet) node that was built with LOW_MEMORY_NODE=OFF and CLEAR_VOTES=OFF and configured with all the plugins you can get. It required a lot of RAM, it replayed for ages, and it was a huge pain to keep it running. Our code is great for running blockchain. It’s not equally efficient when it has to answer complex questions. Current architecture The idea is to move the workload requiring complex queries out of our blockchain nodes. +----------+ | &amp;lt;-----------------+ @ @@@@@@ ,@@@@@% | Hivemind | | @@@@ (@@@@@* @@@@@@ +-------+ | &amp;lt;-------+ | %@@@@@@ @@@@@@ %@@@@@, | | +-----^----+ | | @@@@@@@@@@ @@@@@@ @@@@@@ | redis | | | | ,@@@@@@@@@@@@ @@@@@@ @@@@@@ | &amp;lt;--+ | +----v-----+ | @@@@@@@@@@@@@@@&amp;amp; @@@@@@ @@@@@@ +-------+ | +-v-+ | | | @@@@@@@@@@@@@@@@@@ .@@@@@% @@@@@@ | | &amp;lt;-----&amp;gt; AH node | | @@@@@@@@@@@@@@@@@@@@@( .@@@@@% +-------+ +--&amp;gt; j | | | | @@@@@@@@@@@@@@@@@@@@ @@@@@@ &amp;lt;-------&amp;gt; | | u | +----------+ | *@@@@@@@@@@@@@@@@ @@@@@@ @@@@@@. &amp;lt;-------&amp;gt; nginx &amp;lt;-----&amp;gt; s | | @@@@@@@@@@@@@@ &amp;amp;@@@@@. @@@@@@ &amp;lt;-------&amp;gt; | | s | +----------+ | #@@@@@@@@@@ @@@@@@ #@@@@@/ +-------+ | i | | | | @@@@@@@@ /@@@@@/ @@@@@@ | &amp;lt;-----&amp;gt; FAT node &amp;lt;---+ @@@@@( @@@@@@ .@@@@@&amp;amp; +---+ | | @@ @@@@@&amp;amp; @@@@@@ +----------+ Sorry, lack of GIMP skills Hivemind For this purpose I use Hivemind (hats off to @roadscape) backed by PostgreSQL. Hive is a “consensus interpretation” layer for the Hive blockchain, maintaining the state of social features such as post feeds, follows, and communities. Written in Python, it synchronizes an SQL database with chain state, providing developers with a more flexible/extensible alternative to the raw hived API. FAT node Also, instead of a single hived node with all the plugins, I chose to run two nodes, one of them is a “fat node” (LOW_MEMORY_NODE=OFF and CLEAR_VOTES=OFF) on a MIRA-enabled instance to feed the Hivemind. Please note that I have NOT included market_history in my configuration, simply because it doesn’t require a “fat node”, but Hivemind requires it, so make sure that you have it somewhere. AH node Account history node is the other node I use in my setup. It serves not only account history, but it’s definitely the heaviest plugin here, hence the name. I’m not using MIRA here, because I prefer the pre-MIRA implementation of the account history plugin and MIRA had some issues with it. Also, it’s way too slow for replay. Jussi Instead of one service, I now have three specialized ones, I need to route incoming calls to them. So the get_account_history goes to the AH node, while the get_followers goes to Hivemind. That’s what jussi does, but it also caches things. Redis Jussi uses Redis as in-memory data cache. This can very effectively take load off the nodes. Even though most of the entries quickly expire, it’s enough to effectively answer common questions such as “what’s in the head block?” 8 dApps asking for the latest block will result in 1 call to the node and 7 cache hits from Redis. Nginx That’s the world facing component - here you can have your SSL termination, rate limiting, load balancing, and all other fancy stuff related to serving your clients. Resources Now when you know all the components, let’s take a look at what is required to run them all and (in the darkness) bind them. Small stuff There are no specific needs here. The more traffic you expect, the more resources you will need, but they can run on any reasonable server on instance: Nginx needs what nginx usually needs - a bunch of cores and some RAM. Jussi is no different than nginx when it comes to resources. Redis needs what redis usually needs - a few GB of RAM to hold the data. Big stuff the AH node, which is non-MIRA in my setup, requires plenty of RAM for the shared_memory.bin file to either hold it on tmpfs or buffer/cache it, especially during replay. A machine with 32GB RAM will work, but I would rather suggest using a 64GB RAM machine these days. Of course, low latency storage such as SSD or NVMe is a must. You need 600GB of it. the FAT node in my setup is running MIRA, so it’s not that memory hungry, but the more RAM you have, the more effective it can be. A machine with 16GB RAM might work, but I would go with 32GB or 64GB for it. Don’t even try without a very fast SSD or NVMe. You need 400GB of it. Hivemind itself is a simple script, but it needs PostgreSQL as a database backend, and for that you need all the things that PostgreSQL usually needs. It can run on pretty much everything, as long as you have enough space to fit the data, currently 300GB. Of course, faster storage and more RAM will result in much better performance. From zero to hero Reference hardware configuration: Intel(R) Xeon(R) E-2274G CPU @ 4.00GHz 64GB RAM, ECC, 2666MT/s 2x NVMe 960GB (SAMSUNG PM983) When you are starting from scratch, it’s best to get a recent block_log I’m providing one at https://gtg.openhive.network/get/blockchain/ How fast you can get it depends on your network and load on my server. The average downloading speed is around 30MB/s, so you should be able to get it in less than 3 hours. Node type Replay Time AH Node 15 hours 42 minutes Fat Node 48 hours 53 minutes Hivemind 85 hours 50 minutes Roughly you need 4 days and 9 hours to have it synced to the latest head block. A lot can be improved at the backend, and we are working on that. To be developer-friendly, we also need to improve the set of available API calls, finally get rid of the deprecated ones such as get_state, and move away from the all in one wrapper condenser_api. But that’s a different story for a different occasion. See: Hive Pressure 2: How to Answer Hive Questions? by @gtg</summary></entry><entry><title type="html">Interactive Hive API moved to Hivesigner</title><link href="https://hivedocs.info/news/swagger/api/2020/04/29/interactive-hive-api-moved-to-hivesigner.html" rel="alternate" type="text/html" title="Interactive Hive API moved to Hivesigner" /><published>2020-04-29T05:59:54-07:00</published><updated>2020-04-29T05:59:54-07:00</updated><id>https://hivedocs.info/news/swagger/api/2020/04/29/interactive-hive-api-moved-to-hivesigner</id><content type="html" xml:base="https://hivedocs.info/news/swagger/api/2020/04/29/interactive-hive-api-moved-to-hivesigner.html">&lt;p&gt;Thank you everyone for your &lt;a href=&quot;https://esteem.app/hive/@good-karma/hivesigner-ongoing-development-and-improvement&quot;&gt;support on Hivesigner proposal&lt;/a&gt;. We are almost in range of approved proposals. If you haven’t voted, please consider approving proposal to help us make Hivesigner better.&lt;/p&gt;

&lt;center&gt; 
&lt;img src=&quot;https://img.esteem.app/kbgnol.png&quot; /&gt;
 &lt;/center&gt;

&lt;h2 id=&quot;recent-updates&quot;&gt;Recent updates&lt;/h2&gt;

&lt;p&gt;Some updates if you have missed recent developments related to Hivesigner:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://esteem.app/hive-139531/@emrebeyler/powering-up-2&quot;&gt;Hivesigner Python Client&lt;/a&gt; released thanks to @emrebeyler for his awesome job and contribution. Consider voting for his witness!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/ledgerconnect/hivesigner/wiki&quot;&gt;Hivesigner wiki updated&lt;/a&gt;, we are in process of unifying all documentation via github so that website can mirror and guide developers. Integrating Hivesigner OAuth is quite simple but with proper documentation it can help even new developers to start developing on Blockchain/Hive.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Earlier today, we pushed new release that changes some links and fixes few bugs related to dhive. Chrome/Brave extension update is submitted for review, should be available soon.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Today, in effort to help onboarding more developers and new apps on Hive, we are introducing &lt;a href=&quot;https://hive.hivesigner.com&quot;&gt;Interactive Hive API explorer&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Visit 
&lt;a href=&quot;https://hive.hivesigner.com&quot;&gt;https://hive.hivesigner.com&lt;/a&gt;
 to try out Hive API directly on your browser.&lt;/li&gt;
  &lt;li&gt;It is &lt;a href=&quot;https://github.com/ledgerconnect/hiveapi&quot;&gt;opensource&lt;/a&gt;, if you find bugs or want to contribute, feel free to create pull request or &lt;a href=&quot;https://github.com/ledgerconnect/hiveapi/issues&quot;&gt;report issues on github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It has search field to find relevant APIs quickly, some queries have default values so results can be fetched with single click, I believe it is very convenient for developers to get started. Check it out!&lt;/p&gt;

&lt;p&gt;Simply studying Hive API + Hivesigner API, you can start building decentralized apps in matter of hours.&lt;/p&gt;

&lt;h2 id=&quot;buidl-on&quot;&gt;Buidl on!&lt;/h2&gt;

&lt;h1 id=&quot;support-proposal&quot;&gt;Support proposal&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B88%5D&amp;amp;approve=true&quot;&gt;Vote for Hivesigner Proposal&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;HiveDao: 
&lt;a href=&quot;https://hivedao.com/proposal/88&quot;&gt;https://hivedao.com/proposal/88&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;PeakD: 
&lt;a href=&quot;https://peakd.com/proposals/88&quot;&gt;https://peakd.com/proposals/88&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;HiveBlog Wallet: 
&lt;a href=&quot;https://wallet.hive.blog/proposals&quot;&gt;https://wallet.hive.blog/proposals&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Discord: 
&lt;a href=&quot;https://discord.gg/pNJn7wh&quot;&gt;https://discord.gg/pNJn7wh&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ledgerconnect/hivesigner/issues/2&quot;&gt;Github roadmap thread&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://esteem.app/hivesigner/@good-karma/interactive-hive-api-moved-to-hivesigner&quot;&gt;Interactive Hive API moved to Hivesigner&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@good-karma&quot;&gt;@good-karma&lt;/a&gt;
&lt;/p&gt;</content><author><name>good-karma</name></author><summary type="html">Thank you everyone for your support on Hivesigner proposal. We are almost in range of approved proposals. If you haven’t voted, please consider approving proposal to help us make Hivesigner better. Recent updates Some updates if you have missed recent developments related to Hivesigner: Hivesigner Python Client released thanks to @emrebeyler for his awesome job and contribution. Consider voting for his witness! Hivesigner wiki updated, we are in process of unifying all documentation via github so that website can mirror and guide developers. Integrating Hivesigner OAuth is quite simple but with proper documentation it can help even new developers to start developing on Blockchain/Hive. Earlier today, we pushed new release that changes some links and fixes few bugs related to dhive. Chrome/Brave extension update is submitted for review, should be available soon. Today, in effort to help onboarding more developers and new apps on Hive, we are introducing Interactive Hive API explorer Visit https://hive.hivesigner.com to try out Hive API directly on your browser. It is opensource, if you find bugs or want to contribute, feel free to create pull request or report issues on github It has search field to find relevant APIs quickly, some queries have default values so results can be fetched with single click, I believe it is very convenient for developers to get started. Check it out! Simply studying Hive API + Hivesigner API, you can start building decentralized apps in matter of hours. Buidl on! Support proposal Vote for Hivesigner Proposal HiveDao: https://hivedao.com/proposal/88 PeakD: https://peakd.com/proposals/88 HiveBlog Wallet: https://wallet.hive.blog/proposals Discord: https://discord.gg/pNJn7wh Github roadmap thread See: Interactive Hive API moved to Hivesigner by @good-karma</summary></entry><entry><title type="html">How to set up a Hive Witness or Seed node (non-MIRA) / Upgrade from Steem-Docker to Hive-Docker</title><link href="https://hivedocs.info/howto/witness/docker/node/2020/04/27/how-to-set-up-a-hive-witness-or-seed-node-non-mira-upgrade-from-steem-docker-to-hive-docker.html" rel="alternate" type="text/html" title="How to set up a Hive Witness or Seed node (non-MIRA) / Upgrade from Steem-Docker to Hive-Docker" /><published>2020-04-27T12:30:21-07:00</published><updated>2020-04-27T12:30:21-07:00</updated><id>https://hivedocs.info/howto/witness/docker/node/2020/04/27/how-to-set-up-a-hive-witness-or-seed-node-non-mira-upgrade-from-steem-docker-to-hive-docker</id><content type="html" xml:base="https://hivedocs.info/howto/witness/docker/node/2020/04/27/how-to-set-up-a-hive-witness-or-seed-node-non-mira-upgrade-from-steem-docker-to-hive-docker.html">&lt;div style=&quot;display: block; margin: 0 auto;&quot;&gt;

  &lt;p&gt;&lt;img src=&quot;https://cdn.privex.io/img/posts/hive-in-a-box.png&quot; alt=&quot;Hive-in-a-box Logo&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;

&lt;h1 id=&quot;fresh-install&quot;&gt;Fresh install&lt;/h1&gt;

&lt;p&gt;To become a witness without using MIRA, you’ll require a server with at LEAST 64GB of RAM, 500GB disk (preferably SSD / NVMe), and a fast, reliable network.&lt;/p&gt;

&lt;p&gt;If you do not have a server which meets these requirements, you can order one from &lt;a href=&quot;privex.io&quot;&gt;Privex&lt;/a&gt; (you can even pay with HIVE/HBD!)&lt;/p&gt;

&lt;p&gt;I personally use @privex for my own witness as a Top 20. While I am the CEO of Privex, there are many other customers, including witnesses who use our servers for their witness nodes, seed nodes, RPC nodes and/or other projects.&lt;/p&gt;

&lt;p&gt;You’re free to use any other server provider. I don’t recommend trying to run a witness on your home internet, as it’s likely not reliable enough for a witness.&lt;/p&gt;

&lt;p&gt;Be aware that certain server providers have poor networks or hardware, which may cause missed blocks, so you may be hopping around a few until you can find one that’s suitable for a witness node.&lt;/p&gt;

&lt;p&gt;If you want to learn more about witnesses and what they do, check out my article: &lt;a href=&quot;https://peakd.com/witness-category/@someguy123/seriously-what-is-a-witness-why-should-i-care-how-do-i-become-one-answer&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;shared-memory-note&quot;&gt;Shared memory note&lt;/h3&gt;

&lt;p&gt;Right now, the minimum RAM requirement for non-MIRA witnesses is 64GB due to shared memory.&lt;/p&gt;

&lt;p&gt;This is because Hive stores information in a file called “shared_memory.bin” which is used similar to RAM. This file is around 58GB on HF23, and will continue to grow overtime.&lt;/p&gt;

&lt;p&gt;As this file continues to grow, you will need to increase the amount of RAM in your server. So it is better to have some room.&lt;/p&gt;

&lt;h3 id=&quot;install-hive-docker-and-dependencies&quot;&gt;Install hive-docker and dependencies&lt;/h3&gt;

&lt;p&gt;First, we install some basic dependencies (assuming you’re on Ubuntu/Debian).&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt update
sudo apt install git curl wget
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Next, we install hive-docker (a line starting with a # is a comment, you don’t need to paste them)&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone 
&amp;lt;a &lt;span class=&quot;nv&quot;&gt;href&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://github.com/someguy123/hive-docker.git&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;https://github.com/someguy123/hive-docker.git&amp;lt;/a&amp;gt;

&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;hive-docker
&lt;span class=&quot;c&quot;&gt;# If you don't already have a docker installation, this will install it for you&lt;/span&gt;
./run.sh install_docker
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After the install_docker command has finished, it’s recommended to log out and back in again (e.g. close your SSH client and re-connect) to ensure that the shell correctly detects docker.&lt;/p&gt;

&lt;p&gt;Then, you can download and install the latest witness/seed docker image&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# This downloads/updates the low-memory docker image for Hive
./run.sh install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you are a witness, you need to adjust the configuration as needed e.g. witness name, private key, logging config, turn off p2p-endpoint etc.&lt;/p&gt;

&lt;p&gt;If you’re running a seed, then don’t worry about the config, it will just work and you can skip the signing key/config section&lt;/p&gt;

&lt;h3 id=&quot;generating-a-signing-key&quot;&gt;Generating a signing key&lt;/h3&gt;

&lt;p&gt;For witnesses, you’ll need to generate a signing key first. You can use the remote wallet for this.&lt;/p&gt;

&lt;p&gt;Open the wallet using a public server with the following command:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./run.sh remote_wallet
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Note: you may receive an error such as “timeout” or “invalid http status”. This is normal, it’s usually due to a server in the Privex load balancer having temporary problems.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Just run the command again a few times until it connects (you’ll see new»&amp;gt; or locked»&amp;gt;)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Create a key pair for your witness.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;suggest_brain_key
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;display: block; margin: 0 auto;&quot;&gt;

  &lt;p&gt;&lt;img src=&quot;https://cdn.privex.io/img/posts/hive-suggest-brainkey.png&quot; alt=&quot;Screenshot of cli_wallet suggest_brain_key command&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;You should get something similar to this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
  &quot;brain_priv_key&quot;: &quot;GOCART VINCENT PHOTIC IRON OUTHIT UNGLOBE SICCA LOP TASKIT BOOSTER WINDED SPRY SACKBUT UNICE WELL RUBELLE&quot;,
  &quot;wif_priv_key&quot;: &quot;5J1Wn41BbSS4L83N9n7P5nmMSVg9uaWfVySnd363TvyhWPzU2e9&quot;,
  &quot;pub_key&quot;: &quot;STM7iCEkCR261F7CeBCsmpE1RcW8hnR5pZYKCFbuVqe5HSJ41YewE&quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Put the keys in Notepad or something similar for the moment so you don’t lose them.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Press CTRL-D to exit the wallet.&lt;/p&gt;

&lt;h3 id=&quot;setting-up-your-config&quot;&gt;Setting up your config&lt;/h3&gt;

&lt;p&gt;Now, to set your witness name and private key. You can use &lt;code class=&quot;highlighter-rouge&quot;&gt;nano&lt;/code&gt; (a simple text editor on Linux) for this.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nano data/witness_node_data_dir/config.ini
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you are running a witness, you’ll want to change one of the first lines in the file to disable the seed.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Endpoint for P2P node to listen on
p2p-endpoint = 0.0.0.0:2001
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Simply place a # (hash sign) at the start of the p2p-endpoint line. This will disable the seed. Example:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Endpoint for P2P node to listen on
#p2p-endpoint = 0.0.0.0:2001
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now to add your witness settings. Scroll down the file (use the up/down arrows, or page up/down) until you see something like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Percent of witnesses (0-99) that must be participating in order to produce blocks
required-participation = 33

# name of witness controlled by this node (e.g. initwitness )
# witness =

# name of miner and its private key (e.g. [&quot;account&quot;,&quot;WIF PRIVATE KEY&quot;] )
# miner =

# Number of threads to use for proof of work mining
# mining-threads =

# WIF PRIVATE KEY to be used by one or more witnesses or miners
# private-key =
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;display: block; margin: 0 auto;&quot;&gt;

  &lt;p&gt;&lt;img src=&quot;https://cdn.privex.io/img/posts/hive-witness-config.png&quot; alt=&quot;Screenshot of witness config.ini&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;You’ll want to uncomment (remove the # from the start) the &lt;code class=&quot;highlighter-rouge&quot;&gt;witness =&lt;/code&gt; line, and the &lt;code class=&quot;highlighter-rouge&quot;&gt;private-key =&lt;/code&gt; line.&lt;/p&gt;

&lt;p&gt;Grab your public/private key that you saved earlier into notepad (or other similar app).&lt;/p&gt;

&lt;p&gt;Then, similar to below, add your witness’ name in quotes, e.g. “someguy123” in front of the &lt;code class=&quot;highlighter-rouge&quot;&gt;witness =&lt;/code&gt;, and your private key (without quotes) in front of the &lt;code class=&quot;highlighter-rouge&quot;&gt;private-key =&lt;/code&gt; line. To save you time in the future, it can be useful to place your public signing key in a comment above your private key (see example)&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# name of witness controlled by this node (e.g. initwitness )
witness = &quot;someguy123&quot;

# name of miner and its private key (e.g. [&quot;account&quot;,&quot;WIF PRIVATE KEY&quot;] )
# miner =

# Number of threads to use for proof of work mining
# mining-threads =

# WIF PRIVATE KEY to be used by one or more witnesses or miners
# public key: STM7iCEkCR261F7CeBCsmpE1RcW8hnR5pZYKCFbuVqe5HSJ41YewE
private-key = 5J1Wn41BbSS4L83N9n7P5nmMSVg9uaWfVySnd363TvyhWPzU2e9
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now (assuming you’re using nano) press CTRL-X, and press the y key when it asks if you would like to save.&lt;/p&gt;

&lt;h3 id=&quot;environment-settings&quot;&gt;Environment settings&lt;/h3&gt;

&lt;p&gt;If you’re already comfortable with Linux, and want to play around with settings for hive-docker you may want to consider setting up a .env file, see the &lt;a href=&quot;https://github.com/someguy123/hive-docker&quot;&gt;README for more information&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Otherwise, let’s continue. The defaults are generally fine for most people.&lt;/p&gt;

&lt;h3 id=&quot;setting-up-shared-memory-swap-settings-and-downloading-the-blockchain&quot;&gt;Setting up shared memory, swap settings, and downloading the blockchain&lt;/h3&gt;

&lt;p&gt;At this point you should have:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;installed hive-in-a-box&lt;/li&gt;
  &lt;li&gt;installed docker (through the run.sh command)&lt;/li&gt;
  &lt;li&gt;downloaded and installed the Hive docker container&lt;/li&gt;
  &lt;li&gt;set up your witness configuration&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Your witness is almost ready. Just a few more small things.&lt;/p&gt;

&lt;p&gt;You’ll need to set the shared memory size (use sudo if not logged in as root). 64 gigabytes is recommended (64G). Please be aware that the shared memory size changes constantly.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo ./run.sh shm_size 64G
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You’ll also want to adjust your “swappiness”. This is a setting which tells Linux how much it should use swap (virtual memory on your disk. very slow). You’ll want to set this to 1, which means “don’t use the swap unless it’s absolutely necessary”. This helps to prevent missed blocks due to excessive swapping despite plenty of free RAM.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# To persist on reboot, place 'vm.swappiness=1' in /etc/sysctl.conf
sudo sysctl -w vm.swappiness=1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now that you’ve configured your server, it’s recommended to download the block log, as replays can be faster than p2p download.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./run.sh dlblocks
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn.privex.io/img/posts/hive-dlblocks.png&quot; alt=&quot;Screenshot of run.sh dlblocks command&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;almost-ready&quot;&gt;Almost ready!&lt;/h3&gt;

&lt;p&gt;Once this is done, you should be ready to start your server. The &lt;code class=&quot;highlighter-rouge&quot;&gt;replay&lt;/code&gt; command will start &lt;code class=&quot;highlighter-rouge&quot;&gt;steemd&lt;/code&gt; (the binary is still called &lt;code class=&quot;highlighter-rouge&quot;&gt;steemd&lt;/code&gt; for Hive) in docker, and begin replaying the blockchain which was downloaded to create a block index, and the shared_memory file.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./run.sh replay
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can check the status with the &lt;code class=&quot;highlighter-rouge&quot;&gt;logs&lt;/code&gt; command.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./run.sh logs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Assuming you did everything correctly, you should see something like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;------------------------------------------------------

            STARTING HIVE NETWORK

------------------------------------------------------
initminer public key: STM8GC13uCZbP44HzMLV6zPZGwVQ8Nt4Kji8PapsPiNq1BK153XTX
chain id: 0000000000000000000000000000000000000000000000000000000000000000
blockchain version: 0.23.0
------------------------------------------------------
2393837ms main.cpp:121                  main                 ] Backtrace on segfault is enabled.
2393837ms chain_plugin.cpp:405          plugin_startup       ] Starting chain with shared_file_size: 53687091200 bytes
2393837ms chain_plugin.cpp:483          plugin_startup       ] Replaying blockchain on user request.
2393837ms database.cpp:185              reindex              ] Reindexing Blockchain
2396435ms block_log.cpp:142             open                 ] Log is nonempty
2396435ms block_log.cpp:151             open                 ] Index is nonempty
2396435ms database.cpp:193              reindex              ] Replaying blocks...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Please be aware that this can take many hours depending on your disk speed and CPU. In some cases it can take up to 24 hours.&lt;/p&gt;

&lt;p&gt;You can press CTRL-C to exit the logs, or just leave it if you want to watch it replay.&lt;/p&gt;

&lt;h3 id=&quot;after-youve-replayed&quot;&gt;After you’ve replayed&lt;/h3&gt;

&lt;p&gt;Once you see something which looks like this, it means your server is now ready to go:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1299055ms th_a       application.cpp:507           handle_block         ] Got 14 transactions on block 12928269 by pharesim -- latency: 55 ms
1302427ms th_a       application.cpp:507           handle_block         ] Got 18 transactions on block 12928270 by xeldal -- latency: 426 ms
1305291ms th_a       application.cpp:507           handle_block         ] Got 26 transactions on block 12928271 by arhag -- latency: 291 ms
1308045ms th_a       application.cpp:507           handle_block         ] Got 20 transactions on block 12928272 by pfunk -- latency: 45 ms
1311092ms th_a       application.cpp:507           handle_block         ] Got 23 transactions on block 12928273 by bhuz -- latency: 92 ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Go to your profile:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://wallet.hive.blog/@yourusername/permissions&quot;&gt;https://wallet.hive.blog/@yourusername/permissions&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://peakd.com/@yourusername/permissions&quot;&gt;https://peakd.com/@yourusername/permissions&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(for the links, you need to edit the @yourusername part)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Click Wallet, then Permissions. Next to “Active Key” you should see “Reveal”. Click that button and log in. Then press “Show private key”, to reveal it. Make sure it begins with a “5”.&lt;/p&gt;

&lt;p&gt;Copy the key.&lt;/p&gt;

&lt;p&gt;Now open the wallet with:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./run.sh wallet
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn.privex.io/img/posts/hive-wallet-activekey.png&quot; alt=&quot;Screenshot of Hive Wallet active key page&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Set a password, unlock the wallet with the same password, then import your ACTIVE private key from wallet.hive.blog / Peakd (NOT the one in notepad):&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;set_password &quot;hunter2&quot;
unlock &quot;hunter2&quot;
import_key 5somethingprivatekey
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, we can update/create the witness on the network. Replace the STMxxxx key with the public key you saved earlier in notepad (or if you wrote it as a comment in your config file, you can open that and get it from there), and replace YOURNAME with your witness name on Hive.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update_witness &quot;YOURNAME&quot; &quot;https://hive.blog/witness-category/@YOURNAME/my-witness-thread&quot; &quot;STMxxxxxxx&quot; {&quot;account_creation_fee&quot;:&quot;3.000 HIVE&quot;,&quot;maximum_block_size&quot;:65536,&quot;sbd_interest_rate&quot;:0} true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;congratulations-your-witness-should-now-be-working-and-you-can-begin-getting-votes-and-producing-blocks&quot;&gt;Congratulations, your witness should now be working, and you can begin getting votes and producing blocks&lt;/h1&gt;

&lt;h3 id=&quot;other-useful-information&quot;&gt;Other useful information&lt;/h3&gt;

&lt;p&gt;You may want to persist the /dev/shm size (shared memory) across reboots. To do this, you can edit &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/fstab&lt;/code&gt;, please be very careful, as any mistakes in this file will cause your system to become unbootable. (&lt;strong&gt;if you are not comfortable with linux, please don’t try this as you may break your server&lt;/strong&gt;).&lt;/p&gt;

&lt;p&gt;Simply add this to the bottom of the file on a new line. Be sure not to damage any other lines in the file. Adjust “64G” to whatever size you would like /dev/shm to be.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tmpfs   /dev/shm         tmpfs   nodev,nosuid,size=64G          0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;See &lt;a href=&quot;https://github.com/someguy123/hive-docker&quot;&gt;the README&lt;/a&gt; for more advanced options.&lt;/p&gt;

&lt;h1 id=&quot;upgrading-steem-docker-to-hive-docker&quot;&gt;Upgrading steem-docker to hive-docker&lt;/h1&gt;

&lt;p&gt;If you have an existing &lt;code class=&quot;highlighter-rouge&quot;&gt;steem-docker&lt;/code&gt; installation, you can convert it into a &lt;code class=&quot;highlighter-rouge&quot;&gt;hive-docker&lt;/code&gt; installation by following the below steps.&lt;/p&gt;

&lt;h2 id=&quot;updating-your-git-repository&quot;&gt;Updating your Git repository&lt;/h2&gt;

&lt;p&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;git remote set-url&lt;/code&gt; to change your steem-docker installation to track my &lt;code class=&quot;highlighter-rouge&quot;&gt;hive-docker&lt;/code&gt; repository. Then &lt;code class=&quot;highlighter-rouge&quot;&gt;git fetch&lt;/code&gt; to download any updates, checkout master, and &lt;code class=&quot;highlighter-rouge&quot;&gt;git pull&lt;/code&gt; to update to &lt;code class=&quot;highlighter-rouge&quot;&gt;hive-docker&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
~/steem-docker $ git remote set-url origin 
&amp;lt;a href=&quot;https://github.com/Someguy123/hive-docker.git&quot;&amp;gt;https://github.com/Someguy123/hive-docker.git&amp;lt;/a&amp;gt;

~/steem-docker $ git fetch
~/steem-docker $ git checkout master
~/steem-docker $ git pull
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To ensure &lt;code class=&quot;highlighter-rouge&quot;&gt;hive-docker&lt;/code&gt; always uses the Hive network, add &lt;code class=&quot;highlighter-rouge&quot;&gt;NETWORK=hive&lt;/code&gt; to your &lt;code class=&quot;highlighter-rouge&quot;&gt;.env&lt;/code&gt; file&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;NETWORK=hive&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; .env

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Download the Hive HF23 docker image using this command.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./run.sh install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;if-you-were-previously-running-steem-youll-need-to-replace-your-blockchain-and-state-files&quot;&gt;If you were previously running Steem, you’ll need to replace your blockchain and state files&lt;/h2&gt;

&lt;p&gt;Delete your blockchain files and shared memory files using the &lt;code class=&quot;highlighter-rouge&quot;&gt;clean&lt;/code&gt; command:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./run.sh clean
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn.privex.io/img/posts/hive-clean.png&quot; alt=&quot;Screenshot of run.sh clean command&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Download a fresh block_log:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./run.sh dlblocks
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://cdn.privex.io/img/posts/hive-dlblocks.png&quot; alt=&quot;Screenshot of run.sh dlblocks command&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;now-for-the-slow-part---replaying&quot;&gt;Now for the slow part - replaying&lt;/h3&gt;

&lt;p&gt;When upgrading from Steem to Hive, you’ll need to replay.&lt;/p&gt;

&lt;p&gt;To replay your witness, do the following (this will shutdown and remove the Steem software, and start a Hive one in replay mode)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./run.sh stop
./run.sh replay
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You can check the status of the replay with the logs command&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./run.sh logs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note: the command now automatically updates in realtime. to exit the logs press CTRL-C&lt;/p&gt;

&lt;p&gt;If all is well, you’ll see it replaying on v0.23.0 (or whatever version is out by the time you read this):&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;------------------------------------------------------

            STARTING HIVE NETWORK

------------------------------------------------------
initminer public key: STM8GC13uCZbP44HzMLV6zPZGwVQ8Nt4Kji8PapsPiNq1BK153XTX
chain id: 0000000000000000000000000000000000000000000000000000000000000000
blockchain version: 0.23.0
------------------------------------------------------
2393837ms main.cpp:121                  main                 ] Backtrace on segfault is enabled.
2393837ms chain_plugin.cpp:405          plugin_startup       ] Starting chain with shared_file_size: 53687091200 bytes
2393837ms chain_plugin.cpp:483          plugin_startup       ] Replaying blockchain on user request.
2393837ms database.cpp:185              reindex              ] Reindexing Blockchain
2396435ms block_log.cpp:142             open                 ] Log is nonempty
2396435ms block_log.cpp:151             open                 ] Index is nonempty
2396435ms database.cpp:193              reindex              ] Replaying blocks...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once it’s replayed (may take 3 or more hours), you’ll see the standard “got x transactions on block y”.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1668107ms p2p_plugin.cpp:210            handle_block         ] Got 54 transactions on block 25299003 by cervantes -- latency: 107 ms
1671090ms p2p_plugin.cpp:210            handle_block         ] Got 36 transactions on block 25299004 by blocktrades -- latency: 90 ms
1674098ms p2p_plugin.cpp:210            handle_block         ] Got 28 transactions on block 25299005 by roelandp -- latency: 98 ms
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you see this, you can now re-enable this server :)&lt;/p&gt;

&lt;p&gt;You’re successfully upgraded to 0.23.0 (or higher).&lt;/p&gt;

&lt;p&gt;For future HF23 releases, it will now be as simple as &lt;code class=&quot;highlighter-rouge&quot;&gt;./run.sh install &amp;amp;&amp;amp; ./run.sh restart&lt;/code&gt;, but as always, be careful, always assume a replay may be needed. Test on your backup, or disable your witness before attempting to update.&lt;/p&gt;

&lt;p&gt;To see if I’ve released a new version of the docker image and haven’t made a post yet, just check my docker hub: 
&lt;a href=&quot;https://hub.docker.com/r/someguy123/hive/tags/&quot;&gt;https://hub.docker.com/r/someguy123/hive/tags/&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div style=&quot;display: block; margin: 0 auto;&quot;&gt;

  &lt;p&gt;&lt;img src=&quot;https://i.giphy.com/media/l378lvuErndt84HII/giphy.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;GIF Avatar by @stellabelle&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;do-you-like-what-im-doing-for-hive&quot;&gt;Do you like what I’m doing for Hive?&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://wallet.hive.blog/~witnesses&quot;&gt;Vote for me to be a witness&lt;/a&gt; - every vote counts.&lt;/p&gt;

&lt;h3 id=&quot;dont-forget-to-follow-me-for-more-like-this&quot;&gt;Don’t forget to follow me for more like this.&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;Are you looking for a new server provider? My company @privex offers highly-reliable and affordable dedicated and virtual servers for HIVE, HBD, EOS, Monero, DOGE, LTC, and BTC!&lt;/p&gt;

&lt;p&gt;Check out our website at 
&lt;a href=&quot;https://www.privex.io&quot;&gt;https://www.privex.io&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Join the Privex discord at: 
&lt;a href=&quot;https://invite.gg/privex&quot;&gt;https://invite.gg/privex&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@someguy123/how-to-set-up-a-hive-witness-or-seed-node-non-mira-upgrade-from-steem-docker-to-hive-docker&quot;&gt;How to set up a Hive Witness or Seed node (non-MIRA) / Upgrade from Steem-Docker to Hive-Docker&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@someguy123&quot;&gt;@someguy123&lt;/a&gt;
&lt;/p&gt;</content><author><name>someguy123</name></author><summary type="html">Fresh install To become a witness without using MIRA, you’ll require a server with at LEAST 64GB of RAM, 500GB disk (preferably SSD / NVMe), and a fast, reliable network. If you do not have a server which meets these requirements, you can order one from Privex (you can even pay with HIVE/HBD!) I personally use @privex for my own witness as a Top 20. While I am the CEO of Privex, there are many other customers, including witnesses who use our servers for their witness nodes, seed nodes, RPC nodes and/or other projects. You’re free to use any other server provider. I don’t recommend trying to run a witness on your home internet, as it’s likely not reliable enough for a witness. Be aware that certain server providers have poor networks or hardware, which may cause missed blocks, so you may be hopping around a few until you can find one that’s suitable for a witness node. If you want to learn more about witnesses and what they do, check out my article: here Shared memory note Right now, the minimum RAM requirement for non-MIRA witnesses is 64GB due to shared memory. This is because Hive stores information in a file called “shared_memory.bin” which is used similar to RAM. This file is around 58GB on HF23, and will continue to grow overtime. As this file continues to grow, you will need to increase the amount of RAM in your server. So it is better to have some room. Install hive-docker and dependencies First, we install some basic dependencies (assuming you’re on Ubuntu/Debian). sudo apt update sudo apt install git curl wget Next, we install hive-docker (a line starting with a # is a comment, you don’t need to paste them) git clone &amp;lt;a href=&quot;https://github.com/someguy123/hive-docker.git&quot;&amp;gt;https://github.com/someguy123/hive-docker.git&amp;lt;/a&amp;gt; cd hive-docker # If you don't already have a docker installation, this will install it for you ./run.sh install_docker After the install_docker command has finished, it’s recommended to log out and back in again (e.g. close your SSH client and re-connect) to ensure that the shell correctly detects docker. Then, you can download and install the latest witness/seed docker image # This downloads/updates the low-memory docker image for Hive ./run.sh install If you are a witness, you need to adjust the configuration as needed e.g. witness name, private key, logging config, turn off p2p-endpoint etc. If you’re running a seed, then don’t worry about the config, it will just work and you can skip the signing key/config section Generating a signing key For witnesses, you’ll need to generate a signing key first. You can use the remote wallet for this. Open the wallet using a public server with the following command: ./run.sh remote_wallet Note: you may receive an error such as “timeout” or “invalid http status”. This is normal, it’s usually due to a server in the Privex load balancer having temporary problems. Just run the command again a few times until it connects (you’ll see new»&amp;gt; or locked»&amp;gt;) Create a key pair for your witness. suggest_brain_key You should get something similar to this: { &quot;brain_priv_key&quot;: &quot;GOCART VINCENT PHOTIC IRON OUTHIT UNGLOBE SICCA LOP TASKIT BOOSTER WINDED SPRY SACKBUT UNICE WELL RUBELLE&quot;, &quot;wif_priv_key&quot;: &quot;5J1Wn41BbSS4L83N9n7P5nmMSVg9uaWfVySnd363TvyhWPzU2e9&quot;, &quot;pub_key&quot;: &quot;STM7iCEkCR261F7CeBCsmpE1RcW8hnR5pZYKCFbuVqe5HSJ41YewE&quot; } Put the keys in Notepad or something similar for the moment so you don’t lose them. Press CTRL-D to exit the wallet. Setting up your config Now, to set your witness name and private key. You can use nano (a simple text editor on Linux) for this. nano data/witness_node_data_dir/config.ini If you are running a witness, you’ll want to change one of the first lines in the file to disable the seed. # Endpoint for P2P node to listen on p2p-endpoint = 0.0.0.0:2001 Simply place a # (hash sign) at the start of the p2p-endpoint line. This will disable the seed. Example: # Endpoint for P2P node to listen on #p2p-endpoint = 0.0.0.0:2001 Now to add your witness settings. Scroll down the file (use the up/down arrows, or page up/down) until you see something like this: # Percent of witnesses (0-99) that must be participating in order to produce blocks required-participation = 33 # name of witness controlled by this node (e.g. initwitness ) # witness = # name of miner and its private key (e.g. [&quot;account&quot;,&quot;WIF PRIVATE KEY&quot;] ) # miner = # Number of threads to use for proof of work mining # mining-threads = # WIF PRIVATE KEY to be used by one or more witnesses or miners # private-key = You’ll want to uncomment (remove the # from the start) the witness = line, and the private-key = line. Grab your public/private key that you saved earlier into notepad (or other similar app). Then, similar to below, add your witness’ name in quotes, e.g. “someguy123” in front of the witness =, and your private key (without quotes) in front of the private-key = line. To save you time in the future, it can be useful to place your public signing key in a comment above your private key (see example) Example: # name of witness controlled by this node (e.g. initwitness ) witness = &quot;someguy123&quot; # name of miner and its private key (e.g. [&quot;account&quot;,&quot;WIF PRIVATE KEY&quot;] ) # miner = # Number of threads to use for proof of work mining # mining-threads = # WIF PRIVATE KEY to be used by one or more witnesses or miners # public key: STM7iCEkCR261F7CeBCsmpE1RcW8hnR5pZYKCFbuVqe5HSJ41YewE private-key = 5J1Wn41BbSS4L83N9n7P5nmMSVg9uaWfVySnd363TvyhWPzU2e9 Now (assuming you’re using nano) press CTRL-X, and press the y key when it asks if you would like to save. Environment settings If you’re already comfortable with Linux, and want to play around with settings for hive-docker you may want to consider setting up a .env file, see the README for more information Otherwise, let’s continue. The defaults are generally fine for most people. Setting up shared memory, swap settings, and downloading the blockchain At this point you should have: installed hive-in-a-box installed docker (through the run.sh command) downloaded and installed the Hive docker container set up your witness configuration Your witness is almost ready. Just a few more small things. You’ll need to set the shared memory size (use sudo if not logged in as root). 64 gigabytes is recommended (64G). Please be aware that the shared memory size changes constantly. sudo ./run.sh shm_size 64G You’ll also want to adjust your “swappiness”. This is a setting which tells Linux how much it should use swap (virtual memory on your disk. very slow). You’ll want to set this to 1, which means “don’t use the swap unless it’s absolutely necessary”. This helps to prevent missed blocks due to excessive swapping despite plenty of free RAM. # To persist on reboot, place 'vm.swappiness=1' in /etc/sysctl.conf sudo sysctl -w vm.swappiness=1 Now that you’ve configured your server, it’s recommended to download the block log, as replays can be faster than p2p download. ./run.sh dlblocks Almost ready! Once this is done, you should be ready to start your server. The replay command will start steemd (the binary is still called steemd for Hive) in docker, and begin replaying the blockchain which was downloaded to create a block index, and the shared_memory file. ./run.sh replay You can check the status with the logs command. ./run.sh logs Assuming you did everything correctly, you should see something like this: ------------------------------------------------------ STARTING HIVE NETWORK ------------------------------------------------------ initminer public key: STM8GC13uCZbP44HzMLV6zPZGwVQ8Nt4Kji8PapsPiNq1BK153XTX chain id: 0000000000000000000000000000000000000000000000000000000000000000 blockchain version: 0.23.0 ------------------------------------------------------ 2393837ms main.cpp:121 main ] Backtrace on segfault is enabled. 2393837ms chain_plugin.cpp:405 plugin_startup ] Starting chain with shared_file_size: 53687091200 bytes 2393837ms chain_plugin.cpp:483 plugin_startup ] Replaying blockchain on user request. 2393837ms database.cpp:185 reindex ] Reindexing Blockchain 2396435ms block_log.cpp:142 open ] Log is nonempty 2396435ms block_log.cpp:151 open ] Index is nonempty 2396435ms database.cpp:193 reindex ] Replaying blocks... Please be aware that this can take many hours depending on your disk speed and CPU. In some cases it can take up to 24 hours. You can press CTRL-C to exit the logs, or just leave it if you want to watch it replay. After you’ve replayed Once you see something which looks like this, it means your server is now ready to go: 1299055ms th_a application.cpp:507 handle_block ] Got 14 transactions on block 12928269 by pharesim -- latency: 55 ms 1302427ms th_a application.cpp:507 handle_block ] Got 18 transactions on block 12928270 by xeldal -- latency: 426 ms 1305291ms th_a application.cpp:507 handle_block ] Got 26 transactions on block 12928271 by arhag -- latency: 291 ms 1308045ms th_a application.cpp:507 handle_block ] Got 20 transactions on block 12928272 by pfunk -- latency: 45 ms 1311092ms th_a application.cpp:507 handle_block ] Got 23 transactions on block 12928273 by bhuz -- latency: 92 ms Go to your profile: https://wallet.hive.blog/@yourusername/permissions https://peakd.com/@yourusername/permissions (for the links, you need to edit the @yourusername part) Click Wallet, then Permissions. Next to “Active Key” you should see “Reveal”. Click that button and log in. Then press “Show private key”, to reveal it. Make sure it begins with a “5”. Copy the key. Now open the wallet with: ./run.sh wallet Set a password, unlock the wallet with the same password, then import your ACTIVE private key from wallet.hive.blog / Peakd (NOT the one in notepad): set_password &quot;hunter2&quot; unlock &quot;hunter2&quot; import_key 5somethingprivatekey Finally, we can update/create the witness on the network. Replace the STMxxxx key with the public key you saved earlier in notepad (or if you wrote it as a comment in your config file, you can open that and get it from there), and replace YOURNAME with your witness name on Hive. update_witness &quot;YOURNAME&quot; &quot;https://hive.blog/witness-category/@YOURNAME/my-witness-thread&quot; &quot;STMxxxxxxx&quot; {&quot;account_creation_fee&quot;:&quot;3.000 HIVE&quot;,&quot;maximum_block_size&quot;:65536,&quot;sbd_interest_rate&quot;:0} true Congratulations, your witness should now be working, and you can begin getting votes and producing blocks Other useful information You may want to persist the /dev/shm size (shared memory) across reboots. To do this, you can edit /etc/fstab, please be very careful, as any mistakes in this file will cause your system to become unbootable. (if you are not comfortable with linux, please don’t try this as you may break your server). Simply add this to the bottom of the file on a new line. Be sure not to damage any other lines in the file. Adjust “64G” to whatever size you would like /dev/shm to be. tmpfs /dev/shm tmpfs nodev,nosuid,size=64G 0 0 See the README for more advanced options. Upgrading steem-docker to hive-docker If you have an existing steem-docker installation, you can convert it into a hive-docker installation by following the below steps. Updating your Git repository Use git remote set-url to change your steem-docker installation to track my hive-docker repository. Then git fetch to download any updates, checkout master, and git pull to update to hive-docker. ~/steem-docker $ git remote set-url origin &amp;lt;a href=&quot;https://github.com/Someguy123/hive-docker.git&quot;&amp;gt;https://github.com/Someguy123/hive-docker.git&amp;lt;/a&amp;gt; ~/steem-docker $ git fetch ~/steem-docker $ git checkout master ~/steem-docker $ git pull To ensure hive-docker always uses the Hive network, add NETWORK=hive to your .env file echo &quot;NETWORK=hive&quot; &amp;gt;&amp;gt; .env Download the Hive HF23 docker image using this command. ./run.sh install If you were previously running Steem, you’ll need to replace your blockchain and state files Delete your blockchain files and shared memory files using the clean command: ./run.sh clean Download a fresh block_log: ./run.sh dlblocks Now for the slow part - replaying When upgrading from Steem to Hive, you’ll need to replay. To replay your witness, do the following (this will shutdown and remove the Steem software, and start a Hive one in replay mode) ./run.sh stop ./run.sh replay You can check the status of the replay with the logs command ./run.sh logs Note: the command now automatically updates in realtime. to exit the logs press CTRL-C If all is well, you’ll see it replaying on v0.23.0 (or whatever version is out by the time you read this): ------------------------------------------------------ STARTING HIVE NETWORK ------------------------------------------------------ initminer public key: STM8GC13uCZbP44HzMLV6zPZGwVQ8Nt4Kji8PapsPiNq1BK153XTX chain id: 0000000000000000000000000000000000000000000000000000000000000000 blockchain version: 0.23.0 ------------------------------------------------------ 2393837ms main.cpp:121 main ] Backtrace on segfault is enabled. 2393837ms chain_plugin.cpp:405 plugin_startup ] Starting chain with shared_file_size: 53687091200 bytes 2393837ms chain_plugin.cpp:483 plugin_startup ] Replaying blockchain on user request. 2393837ms database.cpp:185 reindex ] Reindexing Blockchain 2396435ms block_log.cpp:142 open ] Log is nonempty 2396435ms block_log.cpp:151 open ] Index is nonempty 2396435ms database.cpp:193 reindex ] Replaying blocks... Once it’s replayed (may take 3 or more hours), you’ll see the standard “got x transactions on block y”. 1668107ms p2p_plugin.cpp:210 handle_block ] Got 54 transactions on block 25299003 by cervantes -- latency: 107 ms 1671090ms p2p_plugin.cpp:210 handle_block ] Got 36 transactions on block 25299004 by blocktrades -- latency: 90 ms 1674098ms p2p_plugin.cpp:210 handle_block ] Got 28 transactions on block 25299005 by roelandp -- latency: 98 ms If you see this, you can now re-enable this server :) You’re successfully upgraded to 0.23.0 (or higher). For future HF23 releases, it will now be as simple as ./run.sh install &amp;amp;&amp;amp; ./run.sh restart, but as always, be careful, always assume a replay may be needed. Test on your backup, or disable your witness before attempting to update. To see if I’ve released a new version of the docker image and haven’t made a post yet, just check my docker hub: https://hub.docker.com/r/someguy123/hive/tags/ GIF Avatar by @stellabelle Do you like what I’m doing for Hive? Vote for me to be a witness - every vote counts. Don’t forget to follow me for more like this. Are you looking for a new server provider? My company @privex offers highly-reliable and affordable dedicated and virtual servers for HIVE, HBD, EOS, Monero, DOGE, LTC, and BTC! Check out our website at https://www.privex.io Join the Privex discord at: https://invite.gg/privex See: How to set up a Hive Witness or Seed node (non-MIRA) / Upgrade from Steem-Docker to Hive-Docker by @someguy123</summary></entry><entry><title type="html">Improvements for Condenser repository, Continuous Integration and Deployments</title><link href="https://hivedocs.info/howto/devops/docker/2020/04/19/improvements-for-condenser-repository-continuous-integration-and-deployments.html" rel="alternate" type="text/html" title="Improvements for Condenser repository, Continuous Integration and Deployments" /><published>2020-04-19T13:38:27-07:00</published><updated>2020-04-19T13:38:27-07:00</updated><id>https://hivedocs.info/howto/devops/docker/2020/04/19/improvements-for-condenser-repository-continuous-integration-and-deployments</id><content type="html" xml:base="https://hivedocs.info/howto/devops/docker/2020/04/19/improvements-for-condenser-repository-continuous-integration-and-deployments.html">&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/yCIuIaF.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;I want to elaborate not only on introduced features but also on my thought and reasoning so everyone can benefit and introduce changes in their projects. This post will be long but I believe it might be useful for the entire HiveDevs community.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The workflow is built on top of Gitlab CI/CD but can be easily modified for any other CI/CD tool (i.e. CircleCI or Jenkins).&lt;/p&gt;

&lt;h1 id=&quot;docker&quot;&gt;Docker&lt;/h1&gt;

&lt;p&gt;I’ve started my work by reviewing &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt;. I’ve built the &lt;code class=&quot;highlighter-rouge&quot;&gt;condenser&lt;/code&gt; image and was a bit shocked:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ docker image ls
condenser   latest   6d57c0c8a904   19 seconds ago   1.54GB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;1.54 GB for a simple frontend application? Boy, it’s just too much. Let’s do something with it.&lt;/p&gt;

&lt;h2 id=&quot;leaner-docker-image&quot;&gt;Leaner docker image&lt;/h2&gt;

&lt;p&gt;Let’s start by recognizing the reason why is this so big. You can also look into your &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; and search for some common mistakes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;using full-sized images rather than &lt;code class=&quot;highlighter-rouge&quot;&gt;alpine&lt;/code&gt; versions&lt;/li&gt;
  &lt;li&gt;installing dev dependencies for production images&lt;/li&gt;
  &lt;li&gt;putting dev dependencies into production dependencies list&lt;/li&gt;
  &lt;li&gt;copying useless files into the final image&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Yep, you can check every point here. Let’s make some work on a new Dockerfile:&lt;/p&gt;

&lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; node:12.16.2 as development&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;WORKDIR&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; /var/app&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; package.json yarn.lock ./&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;yarn &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--non-interactive&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--frozen-lockfile&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--ignore-optional&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; . .&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;mkdir &lt;/span&gt;tmp &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; yarn build

&lt;span class=&quot;k&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; [ &quot;yarn&quot;, &quot;run&quot;, &quot;start&quot; ]&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;### REMOVE DEV DEPENDENCIES ##&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; development as dependencies&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;yarn &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--non-interactive&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--frozen-lockfile&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--ignore-optional&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--production&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;### BUILD MINIFIED PRODUCTION ##&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; node:12.16.2-alpine as production&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;WORKDIR&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; /var/app&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;ARG&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; SOURCE_COMMIT&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ENV&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; SOURCE_COMMIT ${SOURCE_COMMIT}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ARG&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; DOCKER_TAG&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ENV&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; DOCKER_TAG ${DOCKER_TAG}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=dependencies /var/app/package.json /var/app/package.json&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=dependencies /var/app/config /var/app/config&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=dependencies /var/app/dist /var/app/dist&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=dependencies /var/app/lib /var/app/lib&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=dependencies /var/app/src /var/app/src&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=dependencies /var/app/tmp /var/app/tmp&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=dependencies /var/app/webpack /var/app/webpack&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=dependencies /var/app/node_modules /var/app/node_modules&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=dependencies /var/app/healthcheck.js /var/app/healthcheck.js&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;HEALTHCHECK&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --interval=30s --timeout=5s --start-period=30s --retries=5 CMD node /var/app/healthcheck.js&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; [ &quot;yarn&quot;, &quot;run&quot;, &quot;production&quot; ]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What has been improved:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Node.js version was upgraded from &lt;code class=&quot;highlighter-rouge&quot;&gt;8.7&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;12.16.2&lt;/code&gt; which is the latest LTS at the moment. Always try using the latest framework versions, which may include security fixes and performance upgrades. It’s also a good habit to use a specific version up to the &lt;code class=&quot;highlighter-rouge&quot;&gt;patch&lt;/code&gt; number.&lt;/li&gt;
  &lt;li&gt;Multistage build was used to build an optimal image for production deployment. First, we build a &lt;code class=&quot;highlighter-rouge&quot;&gt;development&lt;/code&gt; stage with every dependency to be able to compile React application. Next, we’re removing development dependencies with &lt;code class=&quot;highlighter-rouge&quot;&gt;--production&lt;/code&gt; switch during the &lt;code class=&quot;highlighter-rouge&quot;&gt;dependencies&lt;/code&gt; stage. After all, we’re creating a minimal image from the &lt;code class=&quot;highlighter-rouge&quot;&gt;alpine&lt;/code&gt; node version which is the smallest base available, by copying only necessary files and directories.&lt;/li&gt;
  &lt;li&gt;Healthcheck has been introduced, so the docker daemon can easily manage containers with automatic restarts if necessary and zero-downtime deployments which will be explained later in this post. It will be also useful for dynamic scaling capabilities with &lt;code class=&quot;highlighter-rouge&quot;&gt;docker swarm&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Also, &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file was modified, but it’s not worth to post its content here:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Dev dependencies like &lt;code class=&quot;highlighter-rouge&quot;&gt;webpack&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;babel&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;eslint&lt;/code&gt; was moved into a proper list called &lt;code class=&quot;highlighter-rouge&quot;&gt;devDependencies&lt;/code&gt; so &lt;code class=&quot;highlighter-rouge&quot;&gt;yarn&lt;/code&gt; could install only production deps for the final image.&lt;/li&gt;
  &lt;li&gt;Strict versions were introduced for every dependency to make sure every build produces exactly the same image. Semantic versioning is popular, but there is no way to check if the package author does not introduce breaking changes with only &lt;code class=&quot;highlighter-rouge&quot;&gt;patch&lt;/code&gt; version increased. If you need to update a package, do it manually. If you have enough test coverage, you can update the package and run CI/CD to check if everything works fine.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After all that work done, the condenser image size was massively reduced:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ docker image ls
condenser   latest   58406d338e67   8 seconds ago   226MB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/xGtpXCQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/aCCoCud.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The compressed image in the docker registry is even smaller. Much better, right? Shame on you, Steemit!&lt;/p&gt;

&lt;h2 id=&quot;healthcheck&quot;&gt;Healthcheck&lt;/h2&gt;

&lt;p&gt;Simply speaking, docker is running containers and trying to keep it alive as long as possible. But the system needs to have a tool to determine if the container is &lt;code class=&quot;highlighter-rouge&quot;&gt;actually alive&lt;/code&gt;. It may seem alive, but is your app responding to requests for example? Fortunately, docker has also integrated health check mechanism which can be integrated into &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt;. Usually, you need to create an endpoint for liveness checks. Fortunately, condenser already has one so we can utilize it easily.&lt;/p&gt;

&lt;p&gt;There is a lot of examples with &lt;code class=&quot;highlighter-rouge&quot;&gt;curl&lt;/code&gt; used as a docker health check, but it’s not a good way to go. Healthcheck should work cross-platform and &lt;code class=&quot;highlighter-rouge&quot;&gt;curl&lt;/code&gt; implementation differs on Windows and Unix. You should write health check in the same technology or framework as your projects are written, for condenser it’s Node.js.&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;http&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;localhost&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;8080&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;/.well-known/healthcheck.json&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;timeout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5000&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;request&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`STATUS: &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;statusCode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;statusCode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`ERROR: &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;statusCode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;ERROR&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When ready, instruct Docker to use your health check mechanism. Add following line into your &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockefile&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;HEALTHCHECK --interval=30s --timeout=5s --start-period=30s --retries=5 CMD node /var/app/healthcheck.js&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Make sure this file &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/app/healthcheck.js&lt;/code&gt; exists inside your image. If you want to be sure your health check is working, inspect your container after running it:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ docker container ls
CONTAINER ID        IMAGE                          COMMAND                  CREATED             STATUS                   PORTS                    NAMES
060166cf52ee        hiveio/condenser:development   &quot;docker-entrypoint.s…&quot;   5 minutes ago       Up 5 minutes (healthy)   0.0.0.0:8080-&amp;gt;8080/tcp   mystifying_dhawan
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There should be a &lt;code class=&quot;highlighter-rouge&quot;&gt;(healthy)&lt;/code&gt; indicator in &lt;code class=&quot;highlighter-rouge&quot;&gt;STATUS&lt;/code&gt; column. And there is. Please also note that during the container startup process, it will indicate slightly different status (&lt;code class=&quot;highlighter-rouge&quot;&gt;starting&lt;/code&gt;), as the docker daemon will wait before making the first check. It’s because we’re giving some time for our app to startup. It’s the &lt;code class=&quot;highlighter-rouge&quot;&gt;start-period&lt;/code&gt; parameter.&lt;/p&gt;

&lt;p&gt;Depending on your app and traffic/load, those parameters should vary.&lt;/p&gt;

&lt;h2 id=&quot;pushing-images-to-docker-hub&quot;&gt;Pushing images to Docker Hub&lt;/h2&gt;

&lt;p&gt;We already have an improved (smaller) docker image, so it’s time to push it to the repository. Doing it manually is a waste of time and may cause human mistakes. The best way is to utilize Gitlab Runner to do it for us in an automatic and bullet-proof manner.&lt;/p&gt;

&lt;p&gt;Here is a &lt;code class=&quot;highlighter-rouge&quot;&gt;job&lt;/code&gt; definition from &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitlab-ci.yml&lt;/code&gt; file with some additional code which we will breakdown:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;variables&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;DOCKER_IMAGE&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;hiveio/condenser&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;.docker-job&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;&amp;amp;docker-job&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;docker:stable&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;docker:dind&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;before_script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;echo $HUB_TOKEN | docker login -u $HUB_USERNAME --password-stdin&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;build-development&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*docker-job&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;build&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;variables&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;DOCKER_TAG&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$DOCKER_IMAGE:$CI_COMMIT_SHORT_SHA&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;DOCKER_TAG_MAIN&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$DOCKER_IMAGE:development&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;SOURCE_COMMIT&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$CI_COMMIT_SHA&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;only&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;develop&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;docker build -t $DOCKER_TAG -t $DOCKER_TAG_MAIN --build-arg SOURCE_COMMIT --build-arg DOCKER_TAG .&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;docker push $DOCKER_TAG&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;docker push $DOCKER_TAG_MAIN&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;First, we’re creating global variable &lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_IMAGE&lt;/code&gt; so we can reuse it later in many places. And in case we would like to change the image name, we do it only in a single place.&lt;/p&gt;

&lt;p&gt;Hence we have multiple &lt;code class=&quot;highlighter-rouge&quot;&gt;jobs&lt;/code&gt; defined in &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitlab-ci.yml&lt;/code&gt; file, it’s good to utilize advanced YAML syntax, which includes &lt;strong&gt;hidden keys&lt;/strong&gt; and &lt;strong&gt;anchors&lt;/strong&gt;. It will decrease the duplicated code and make the file easier to read and maintain. Every job name starting with the dot will be considered as a hidden key and &lt;strong&gt;won’t be directly executed&lt;/strong&gt;. Btw, this is a quick way to temporarily disable any job in your GitLab CI/CD without commenting or removing it.&lt;/p&gt;

&lt;p&gt;By using &lt;code class=&quot;highlighter-rouge&quot;&gt;.docker-job: &amp;amp;docker-job&lt;/code&gt; we created an anchor which can be later used to extend any job. If you add &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;&amp;lt;: *docker-job&lt;/code&gt;, it will populate &lt;code class=&quot;highlighter-rouge&quot;&gt;image&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;services&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;before_script&lt;/code&gt; properties automatically. It’s a good move if you have multiple jobs that do similar things.&lt;/p&gt;

&lt;p&gt;Later on, we’re creating some additional local (job scoped) variables:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_TAG_MAIN&lt;/code&gt;  which will be evaluated to &lt;code class=&quot;highlighter-rouge&quot;&gt;hiveio/condenser:development&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_TAG&lt;/code&gt; which will be evaluated to &lt;code class=&quot;highlighter-rouge&quot;&gt;hiveio/condenser:344e55ef&lt;/code&gt; or similar&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SOURCE_COMMIT&lt;/code&gt; which will be evaluated to &lt;code class=&quot;highlighter-rouge&quot;&gt;344e55efefd56e00b15eea6ccf8560a1107b9ff6&lt;/code&gt; (or similar commit SHA)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It’s a good idea to double tag an image. &lt;code class=&quot;highlighter-rouge&quot;&gt;Latest&lt;/code&gt; tag is useless if you want to track your development process. Later on, I will describe the way how we’re using this specific, &lt;code class=&quot;highlighter-rouge&quot;&gt;sha&lt;/code&gt;-tagged image to track deployments and rollback them anytime with a single click.&lt;/p&gt;

&lt;p&gt;Finally, we’re building an image with additional build arguments by using &lt;code class=&quot;highlighter-rouge&quot;&gt;--build-arg&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;docker build -t $DOCKER_TAG -t $DOCKER_TAG_MAIN --build-arg SOURCE_COMMIT --build-arg DOCKER_TAG .&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;If you scroll up to the Dockerfile section, you will notice &lt;code class=&quot;highlighter-rouge&quot;&gt;ARG SOURCE_COMMIT&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;ENV SOURCE_COMMIT ${SOURCE_COMMIT}&lt;/code&gt; which means these build arguments will be injected as an environment variables into your containers. It’s a quick and easy way to pass additional, build-level variables into your images. Those specific variables are later returned by the condenser health endpoint. It may be useful to check a specific instance source.&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl 
&amp;lt;a &lt;span class=&quot;nv&quot;&gt;href&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://staging.condenser.engrave.dev/.well-known/healthcheck.json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;https://staging.condenser.engrave.dev/.well-known/healthcheck.json&amp;lt;/a&amp;gt;

&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;status&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;ok&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;docker_tag&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;hiveio/condenser:344e55ef&quot;&lt;/span&gt;,&lt;span class=&quot;s2&quot;&gt;&quot;source_commit&quot;&lt;/span&gt;:&lt;span class=&quot;s2&quot;&gt;&quot;344e55efefd56e00b15eea6ccf8560a1107b9ff6&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;An important thing to mention is that &lt;code class=&quot;highlighter-rouge&quot;&gt;HUB_TOKEN&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;HUB_USERNAME&lt;/code&gt; are environment variables injected into the GitLab runner job and configured in Projects Settings. To prevent unauthorized users from pushing malicious images into the official registry, those variables are configured as &lt;code class=&quot;highlighter-rouge&quot;&gt;protected&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;masked&lt;/code&gt;, which means they can be only used on specific branches and are moderated from job logs, so there is no way it can leak without internal bad actor with elevated permissions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/o3FAaQb.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;merge-requests&quot;&gt;Merge requests&lt;/h1&gt;

&lt;p&gt;To improve the process of adding new features and fixes to the codebase, Merge Requests have got a brand new CI/CD workflow which includes the following jobs:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/3kV2zPi.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The entire pipeline is fired on every Merge Request and it’s required to pass before changes could be merged. If the pipeline fails for some reason (i.e. failing unit tests), there is no way to merge changes into the main branch. This will enforce code quality and prevent regression.&lt;/p&gt;

&lt;h2 id=&quot;eslint&quot;&gt;Eslint&lt;/h2&gt;

&lt;p&gt;Code quality and standardization are important, especially if it’s an open-source project that could be maintained by totally different developers from all around the world. &lt;code class=&quot;highlighter-rouge&quot;&gt;Eslint&lt;/code&gt; is a tool that statically analyzes the code to quickly find potential problems and keep code organized with specified rules. Code analysis is especially useful when developing Javascript applications. It’s really easy to make some stupid mistakes.&lt;/p&gt;

&lt;p&gt;Eslint job will be fired on every Merge Request and on every branch pushed to the repository:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;run-eslint&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;node:12.16.2&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;only&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;branches&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;merge_requests&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;before_script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;yarn install --frozen-lockfile --ignore-optional&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;yarn ci:eslint&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;allow_failure&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# will be changed to false when all linter errors removed&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Because the codebase is a bit neglected, &lt;code class=&quot;highlighter-rouge&quot;&gt;run-eslint&lt;/code&gt; job is allowed to fail for the moment (&lt;code class=&quot;highlighter-rouge&quot;&gt;allow_failure: true&lt;/code&gt;), which is indicated by an orange exclamation mark on a MR view or pipelines list. There are “some” errors and warnings right now but it should be cleaned up soon, so we can require eslint job to pass before merging proposed changes:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ✖ 1208 problems (1187 errors, 21 warnings)
   831 errors and 0 warnings potentially fixable with the `--fix` option.
 error Command failed with exit code 1.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;unit-tests&quot;&gt;Unit tests&lt;/h2&gt;

&lt;p&gt;Extensive testing is the only way to produce bullet-proof code and stable applications. Similar to &lt;code class=&quot;highlighter-rouge&quot;&gt;run-eslint&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;run-unit-tests&lt;/code&gt; job is fired on every branch and every merge request.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;run-unit-tests&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;node:12.16.2&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;only&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;branches&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;merge_requests&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;before_script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;yarn install --frozen-lockfile --ignore-optional&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;yarn run ci:test&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;coverage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/All files[^|]*\|[^|]*\s+([\d\.]+)/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Testing suit (&lt;code class=&quot;highlighter-rouge&quot;&gt;jest&lt;/code&gt;) was configured to produce coverage report:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/43JrdbE.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This report is later parsed by a Gitlab, using &lt;code class=&quot;highlighter-rouge&quot;&gt;coverage: /All files[^|]*\|[^|]*\s+([\d\.]+)/&lt;/code&gt; configuration. It will display coverage status and percentage change on the Merge Request view, allowing reviewers to quickly inspect if the code quality is increasing or not.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/Yn6lbe8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I would advise declining merging new features not covered with tests. This may be omitted for important fixes, but we all should try to make the code better, not worse.&lt;/p&gt;

&lt;p&gt;Also, repository settings were changed and &lt;code class=&quot;highlighter-rouge&quot;&gt;Pipelines must succeed&lt;/code&gt; setting is checked by default. It means no more broken code on develop/production branches.&lt;/p&gt;

&lt;h2 id=&quot;review-apps&quot;&gt;Review apps&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Review Apps&lt;/code&gt; are a huge and very important feature. From now on, every feature can be inspected visually by the reviewer with a single click. Gitlab Runner will create a special instance built from proposed code and expose it for the reviewers:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/FOEhZ6d.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Review app requires three jobs to run on a merge request:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;build-review-app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*docker-job&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;build&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;variables&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;DOCKER_TAG&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;SOURCE_COMMIT&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$CI_COMMIT_SHA&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;only&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;merge_requests&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;before_script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;echo $CI_JOB_TOKEN | docker login -u $CI_REGISTRY_USER $CI_REGISTRY --password-stdin&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;docker build -t $DOCKER_TAG --build-arg SOURCE_COMMIT --build-arg DOCKER_TAG .&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;docker push $DOCKER_TAG&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;deploy-review-app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*docker-job&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*docker-remote-host-review&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;deploy&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;variables&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;DOCKER_TAG&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;SERVICE_NAME&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;review_$CI_ENVIRONMENT_SLUG&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;only&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;merge_requests&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;DOCKER_CERT_PATH=$CERTS docker -H $REVIEW_HOST --tlsverify pull $DOCKER_TAG&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;DOCKER_CERT_PATH=$CERTS docker -H $REVIEW_HOST --tlsverify service rm $SERVICE_NAME || &lt;/span&gt;&lt;span class=&quot;no&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# try to remove previous service but do not fail if it not exist&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;DOCKER_CERT_PATH=$CERTS docker -H $REVIEW_HOST --tlsverify service create --with-registry-auth --network infrastructure --name $SERVICE_NAME $DOCKER_TAG&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;echo &quot;Review app deployed&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;review/$CI_COMMIT_REF_NAME&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
&lt;span class=&quot;s&quot;&gt;&amp;lt;a href=&quot;https://&quot;&amp;gt;https://&amp;lt;/a&amp;gt;&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;$CI_ENVIRONMENT_SLUG$APP_REVIEW_SUBDOMAIN&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;on_stop&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;stop-review-app&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;auto_stop_in&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1 week&lt;/span&gt;
        
&lt;span class=&quot;na&quot;&gt;stop-review-app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*docker-job&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*docker-remote-host-review&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;deploy&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;variables&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;SERVICE_NAME&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;review_$CI_ENVIRONMENT_SLUG&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;only&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;merge_requests&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;when&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;manual&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;DOCKER_CERT_PATH=$CERTS docker -H $REVIEW_HOST --tlsverify service rm $SERVICE_NAME || &lt;/span&gt;&lt;span class=&quot;no&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# try to remove previous service but do not fail if it not exist&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;echo &quot;Review app stopped&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;review/$CI_COMMIT_REF_NAME&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;stop&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The first job should look familiar if you read previous parts of the post. The only difference is that we’re overwriting &lt;code class=&quot;highlighter-rouge&quot;&gt;before_script&lt;/code&gt;. Note that if you’re using &lt;strong&gt;anchors&lt;/strong&gt;, you can always overwrite the template freely which is what we did here.&lt;/p&gt;

&lt;p&gt;Because merge requests could be opened by developers which may not be well known in the community (vel. bad actors), it could be a security issue if the CI/CD on Merge Requests could push images to the official repository. To prevent this, we’re using an internal registry provided by the Gitlab itself. It’s private, will work well for Review Apps but won’t be accessible by anyone else.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;echo $CI_JOB_TOKEN | docker login -u $CI_REGISTRY_USER $CI_REGISTRY --password-stdin&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;We are using &lt;code class=&quot;highlighter-rouge&quot;&gt;CI_JOB_TOKEN&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;CI_REGISTRY_USER&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;CI_REGISTRY&lt;/code&gt; which are &lt;a href=&quot;https://docs.gitlab.com/ee/ci/variables/predefined_variables.html&quot;&gt;environment variables injected automatically by Gitlab&lt;/a&gt;, no need to configure them. Also, please note using &lt;code class=&quot;highlighter-rouge&quot;&gt;--password-stdin&lt;/code&gt; which is a more secure way to log in as it will prevent the password from being exposed in job logs.&lt;/p&gt;

&lt;p&gt;By default, docker will connect to the local daemon on unsecured, but not exposed port. It is yet possible to configure Docker daemon to validate TLS certificates so it could be exposed to the external world in a secure way, which is how we deploy services from our runners to our machine. You need to pass additional parameters:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-H&lt;/code&gt; which is remote docker address&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--tlsverify&lt;/code&gt; makes sure your daemon is trying to identify itself with certificates&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--with-registry-auth&lt;/code&gt; will send registry authentication to swarm agents&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--network&lt;/code&gt; will connect service to the specified network so the reverse proxy could expose the instance&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_CERT_PATH&lt;/code&gt; will instruct demon where to search for TLS certificates&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_CERT_PATH=$CERTS docker -H $REVIEW_HOST --tlsverify service create --with-registry-auth --network infrastructure --name $SERVICE_NAME $DOCKER_TAG&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This will create a new &lt;code class=&quot;highlighter-rouge&quot;&gt;docker service&lt;/code&gt; and expose it automatically under the URL created with &lt;code class=&quot;highlighter-rouge&quot;&gt;CI_ENVIRONMENT_SLUG&lt;/code&gt;, which is a variable provided by Gitlab. It’s guaranteed to be a valid URL or docker/kubernetes service name.&lt;/p&gt;

&lt;p&gt;Review App instances are automatically removed when MR is closed or 1 week after it’s opened. This is achieved by running &lt;code class=&quot;highlighter-rouge&quot;&gt;stop-review-app&lt;/code&gt; job which is configured to be manually triggered (&lt;code class=&quot;highlighter-rouge&quot;&gt;when: manual&lt;/code&gt;).&lt;/p&gt;

&lt;h1 id=&quot;tracking-environment-deployments&quot;&gt;Tracking environment deployments&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/8ncGrE9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;By using &lt;code class=&quot;highlighter-rouge&quot;&gt;sha&lt;/code&gt;-tagged images, it’s possible to quickly redeploy the environment at any moment, with a single click. In case of emergency, project maintainers can rollback the environment to the specified point in time (docker image to be specific)&lt;/p&gt;

&lt;h1 id=&quot;staging&quot;&gt;Staging&lt;/h1&gt;

&lt;p&gt;Deploying a staging environment is quite similar to deploying a Review App. It also uses remote docker daemon but the service is not created on-demand, it’s updated with a new image.&lt;/p&gt;

&lt;p&gt;With &lt;code class=&quot;highlighter-rouge&quot;&gt;docker swarm&lt;/code&gt; mode, you can ensure your application to be highly available. The swarm agent will take care of your containers. It will restart them or spin a new one if necessary (this is why health check is so important). It is a built-in, native docker mode everyone should start using.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;na&quot;&gt;deploy-staging&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*docker-job&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;*docker-remote-host-staging&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;deploy&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;variables&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;DOCKER_TAG&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$DOCKER_IMAGE:$CI_COMMIT_SHORT_SHA&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;SERVICE_NAME&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;staging_condenser&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;only&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;develop&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;DOCKER_CERT_PATH=$CERTS docker -H $STAGING_HOST --tlsverify pull $DOCKER_TAG&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;DOCKER_CERT_PATH=$CERTS docker -H $STAGING_HOST --tlsverify service update --image $DOCKER_TAG --update-failure-action rollback --update-order start-first $SERVICE_NAME&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;staging&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
&lt;span class=&quot;s&quot;&gt;&amp;lt;a href=&quot;https://&quot;&amp;gt;https://&amp;lt;/a&amp;gt;&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;$STAGING_DOMAIN&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Job uses protected variables to prevent  “bad” developers from pushing/deploying malicious code. It is only possible to push staging from the protected &lt;code class=&quot;highlighter-rouge&quot;&gt;develop&lt;/code&gt; branch. Pushing directly to &lt;code class=&quot;highlighter-rouge&quot;&gt;develop&lt;/code&gt; is disabled.&lt;/p&gt;

&lt;h2 id=&quot;zero-downtime-deployments&quot;&gt;Zero downtime deployments&lt;/h2&gt;

&lt;p&gt;Updating single service is easy with &lt;code class=&quot;highlighter-rouge&quot;&gt;docker swarm&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_CERT_PATH=$CERTS docker -H $STAGING_HOST --tlsverify service update --image $DOCKER_TAG --update-failure-action rollback --update-order start-first $SERVICE_NAME&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;There are additional but important parameters provided:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--image $DOCKER_TAG&lt;/code&gt; - update existing service by running new containers with the specified image. For this case, it’s sha-tagged image build from develop branch&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--update-failure-action rollback&lt;/code&gt; - by default, docker daemon will try to update the service and do nothing if it fails. By passing this parameter, we’re instructing docker to roll back the service to a previous state, which means containers using the previous image.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--update-order start-first&lt;/code&gt; - by default, docker will kill current containers and spin new ones after it. It may cause some downtime which we don’t want. By setting &lt;code class=&quot;highlighter-rouge&quot;&gt;start-first&lt;/code&gt;, we instruct docker to spin new containers first. Swarm agent will switch containers without downtime if the healtcheck result becomes positive. And in case something gone wrong (healtcheck failed for any reason), we end up with a working staging environment because old containers are not touched at all.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;resources-under-control&quot;&gt;Resources under control&lt;/h2&gt;

&lt;p&gt;With &lt;code class=&quot;highlighter-rouge&quot;&gt;docker swarm&lt;/code&gt; you have full control over your services and containers. This is an example configuration which is used for staging environment. With some tweaks, it could be used for production also:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3.7&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;condenser&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;hiveio/condenser:latest&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;deploy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;replicated&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;replicas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;limits&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;na&quot;&gt;cpus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;0.85&quot;&lt;/span&gt;
                    &lt;span class=&quot;na&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;2024M&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;restart_policy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;any&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;delay&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;5s&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;update_config&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;parallelism&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;delay&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10s&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;failure_action&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rollback&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;start-first&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;rollback_config&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;parallelism&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
                &lt;span class=&quot;na&quot;&gt;delay&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;5s&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;reverse-proxy&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;reverse-proxy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;external&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;reverse-proxy&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;production&quot;&gt;Production&lt;/h1&gt;

&lt;p&gt;It is not finished yet, but my advice is to start using &lt;code class=&quot;highlighter-rouge&quot;&gt;docker swarm&lt;/code&gt; mode for production deployments (CI/CD is ready). It’s designed to serve services like a condenser.&lt;/p&gt;

&lt;p&gt;Some key features of Docker Swarm (based on official documentation):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cluster management integrated with Docker Engine&lt;/strong&gt;: if you know how to build the docker image, start a container, read some logs, you’re ready to use Docker Swarm. You don’t need to install additional software as it is a native Docker feature.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Decentralized design&lt;/strong&gt;: adding a worker or a manager to your swarm is as easy as running a single command. Those could be machines from all around the world.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Scaling&lt;/strong&gt;: For each service, you can declare the number of tasks you want to run. When you scale up or down, the swarm manager automatically adapts by adding or removing tasks to maintain the desired state.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Multi-host networking&lt;/strong&gt;: You can specify an overlay network for your services. The swarm manager automatically assigns addresses to the containers on the overlay network when it initializes or updates the application.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Load balancing&lt;/strong&gt;: You can expose the ports for services to an external load balancer. Internally, the swarm lets you specify how to distribute service containers between nodes.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Secure by default&lt;/strong&gt;: Each node in the swarm enforces TLS mutual authentication and encryption to secure communications between itself and all other nodes. You have the option to use self-signed root certificates or certificates from a custom root CA.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Rolling updates&lt;/strong&gt;: At rollout time you can apply service updates to nodes incrementally. The swarm manager lets you control the delay between service deployment to different sets of nodes. If anything goes wrong, you can roll back to a previous version of the service.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And after all, it is called &lt;code class=&quot;highlighter-rouge&quot;&gt;Swarm&lt;/code&gt;, can’t be a coincidence! ;)&lt;/p&gt;

&lt;p&gt;I’m using Swarm mode for most of my projects. Within Engrave (dblog.org) swarm is automatically managing a set of 23 microservices with almost 30 containers at the moment.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/JMs3d48.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;my-requests-and-tips-for-condenser-developers-and-not-only&quot;&gt;My requests and tips for condenser Developers (and not only)&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Please do write unit tests covering your code. Improving coverage will only cause fewer problems and bugs. Coverage is now visible on every merge request so it’s damn easy to see a regression. Take care of the code quality.&lt;/li&gt;
  &lt;li&gt;Use exact package versions in &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file. When using &lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt;, it’s not guaranteed to install the same version on two different builds. And some developers like to introduce breaking changes without changing the &lt;code class=&quot;highlighter-rouge&quot;&gt;major&lt;/code&gt; version number.&lt;/li&gt;
  &lt;li&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;alpine&lt;/code&gt; images to create minified production images.&lt;/li&gt;
  &lt;li&gt;Use the latest images from official Docker HUB when possible.&lt;/li&gt;
  &lt;li&gt;Use &lt;a href=&quot;https://docs.docker.com/develop/develop-images/multistage-build/&quot;&gt;multi-stage builds&lt;/a&gt; to create leaner docker image&lt;/li&gt;
  &lt;li&gt;Write and configure health checks for your applications&lt;/li&gt;
  &lt;li&gt;Run &lt;code class=&quot;highlighter-rouge&quot;&gt;eslint&lt;/code&gt; to clean up your code before you push it to the repository. You can use &lt;code class=&quot;highlighter-rouge&quot;&gt;husky&lt;/code&gt; to ensure it happens automatically.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;vote-for-engrave-witness-if-you-find-my-work-valuable&quot;&gt;Vote for @engrave witness if you find my work valuable&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://hivesigner.com/sign/account-witness-vote?witness=engrave&amp;amp;approve=1&quot;&gt;&lt;img src=&quot;https://i.imgur.com/lawFvZF.png&quot; alt=&quot;Vote for @engrave witness&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@engrave/improvements-for-condenser-repository-continuous-integration-and-deployments&quot;&gt;Improvements for hive.blog, Continuous Integration and Deployments&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@engrave&quot;&gt;@engrave&lt;/a&gt;
&lt;/p&gt;</content><author><name>engrave</name></author><summary type="html">I want to elaborate not only on introduced features but also on my thought and reasoning so everyone can benefit and introduce changes in their projects. This post will be long but I believe it might be useful for the entire HiveDevs community. The workflow is built on top of Gitlab CI/CD but can be easily modified for any other CI/CD tool (i.e. CircleCI or Jenkins). Docker I’ve started my work by reviewing Dockerfile. I’ve built the condenser image and was a bit shocked: $ docker image ls condenser latest 6d57c0c8a904 19 seconds ago 1.54GB 1.54 GB for a simple frontend application? Boy, it’s just too much. Let’s do something with it. Leaner docker image Let’s start by recognizing the reason why is this so big. You can also look into your Dockerfile and package.json and search for some common mistakes: using full-sized images rather than alpine versions installing dev dependencies for production images putting dev dependencies into production dependencies list copying useless files into the final image Yep, you can check every point here. Let’s make some work on a new Dockerfile: FROM node:12.16.2 as development WORKDIR /var/app COPY package.json yarn.lock ./ RUN yarn install --non-interactive --frozen-lockfile --ignore-optional COPY . . RUN mkdir tmp &amp;amp;&amp;amp; yarn build CMD [ &quot;yarn&quot;, &quot;run&quot;, &quot;start&quot; ] ### REMOVE DEV DEPENDENCIES ## FROM development as dependencies RUN yarn install --non-interactive --frozen-lockfile --ignore-optional --production ### BUILD MINIFIED PRODUCTION ## FROM node:12.16.2-alpine as production WORKDIR /var/app ARG SOURCE_COMMIT ENV SOURCE_COMMIT ${SOURCE_COMMIT} ARG DOCKER_TAG ENV DOCKER_TAG ${DOCKER_TAG} COPY --from=dependencies /var/app/package.json /var/app/package.json COPY --from=dependencies /var/app/config /var/app/config COPY --from=dependencies /var/app/dist /var/app/dist COPY --from=dependencies /var/app/lib /var/app/lib COPY --from=dependencies /var/app/src /var/app/src COPY --from=dependencies /var/app/tmp /var/app/tmp COPY --from=dependencies /var/app/webpack /var/app/webpack COPY --from=dependencies /var/app/node_modules /var/app/node_modules COPY --from=dependencies /var/app/healthcheck.js /var/app/healthcheck.js HEALTHCHECK --interval=30s --timeout=5s --start-period=30s --retries=5 CMD node /var/app/healthcheck.js CMD [ &quot;yarn&quot;, &quot;run&quot;, &quot;production&quot; ] What has been improved: Node.js version was upgraded from 8.7 to 12.16.2 which is the latest LTS at the moment. Always try using the latest framework versions, which may include security fixes and performance upgrades. It’s also a good habit to use a specific version up to the patch number. Multistage build was used to build an optimal image for production deployment. First, we build a development stage with every dependency to be able to compile React application. Next, we’re removing development dependencies with --production switch during the dependencies stage. After all, we’re creating a minimal image from the alpine node version which is the smallest base available, by copying only necessary files and directories. Healthcheck has been introduced, so the docker daemon can easily manage containers with automatic restarts if necessary and zero-downtime deployments which will be explained later in this post. It will be also useful for dynamic scaling capabilities with docker swarm. Also, package.json file was modified, but it’s not worth to post its content here: Dev dependencies like webpack, babel or eslint was moved into a proper list called devDependencies so yarn could install only production deps for the final image. Strict versions were introduced for every dependency to make sure every build produces exactly the same image. Semantic versioning is popular, but there is no way to check if the package author does not introduce breaking changes with only patch version increased. If you need to update a package, do it manually. If you have enough test coverage, you can update the package and run CI/CD to check if everything works fine. After all that work done, the condenser image size was massively reduced: $ docker image ls condenser latest 58406d338e67 8 seconds ago 226MB The compressed image in the docker registry is even smaller. Much better, right? Shame on you, Steemit! Healthcheck Simply speaking, docker is running containers and trying to keep it alive as long as possible. But the system needs to have a tool to determine if the container is actually alive. It may seem alive, but is your app responding to requests for example? Fortunately, docker has also integrated health check mechanism which can be integrated into Dockerfile or docker-compose.yml. Usually, you need to create an endpoint for liveness checks. Fortunately, condenser already has one so we can utilize it easily. There is a lot of examples with curl used as a docker health check, but it’s not a good way to go. Healthcheck should work cross-platform and curl implementation differs on Windows and Unix. You should write health check in the same technology or framework as your projects are written, for condenser it’s Node.js. const http = require(&quot;http&quot;); const options = { host: &quot;localhost&quot;, port: &quot;8080&quot;, path: '/.well-known/healthcheck.json', timeout: 5000 }; const request = http.request(options, (res) =&amp;gt; { console.log(`STATUS: ${res.statusCode}`); if (res.statusCode == 200) { process.exit(0); } else { console.error(`ERROR: ${res.statusCode}`); process.exit(1); } }); request.on('error', (err) =&amp;gt; { console.error('ERROR', err); process.exit(1); }); request.end(); When ready, instruct Docker to use your health check mechanism. Add following line into your Dockefile: HEALTHCHECK --interval=30s --timeout=5s --start-period=30s --retries=5 CMD node /var/app/healthcheck.js Make sure this file /var/app/healthcheck.js exists inside your image. If you want to be sure your health check is working, inspect your container after running it: $ docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 060166cf52ee hiveio/condenser:development &quot;docker-entrypoint.s…&quot; 5 minutes ago Up 5 minutes (healthy) 0.0.0.0:8080-&amp;gt;8080/tcp mystifying_dhawan There should be a (healthy) indicator in STATUS column. And there is. Please also note that during the container startup process, it will indicate slightly different status (starting), as the docker daemon will wait before making the first check. It’s because we’re giving some time for our app to startup. It’s the start-period parameter. Depending on your app and traffic/load, those parameters should vary. Pushing images to Docker Hub We already have an improved (smaller) docker image, so it’s time to push it to the repository. Doing it manually is a waste of time and may cause human mistakes. The best way is to utilize Gitlab Runner to do it for us in an automatic and bullet-proof manner. Here is a job definition from .gitlab-ci.yml file with some additional code which we will breakdown: variables: DOCKER_IMAGE: hiveio/condenser .docker-job: &amp;amp;docker-job image: docker:stable services: - docker:dind before_script: - echo $HUB_TOKEN | docker login -u $HUB_USERNAME --password-stdin build-development: &amp;lt;&amp;lt;: *docker-job stage: build variables: DOCKER_TAG: $DOCKER_IMAGE:$CI_COMMIT_SHORT_SHA DOCKER_TAG_MAIN: $DOCKER_IMAGE:development SOURCE_COMMIT: $CI_COMMIT_SHA only: - develop script: - docker build -t $DOCKER_TAG -t $DOCKER_TAG_MAIN --build-arg SOURCE_COMMIT --build-arg DOCKER_TAG . - docker push $DOCKER_TAG - docker push $DOCKER_TAG_MAIN First, we’re creating global variable DOCKER_IMAGE so we can reuse it later in many places. And in case we would like to change the image name, we do it only in a single place. Hence we have multiple jobs defined in .gitlab-ci.yml file, it’s good to utilize advanced YAML syntax, which includes hidden keys and anchors. It will decrease the duplicated code and make the file easier to read and maintain. Every job name starting with the dot will be considered as a hidden key and won’t be directly executed. Btw, this is a quick way to temporarily disable any job in your GitLab CI/CD without commenting or removing it. By using .docker-job: &amp;amp;docker-job we created an anchor which can be later used to extend any job. If you add &amp;lt;&amp;lt;: *docker-job, it will populate image, services and before_script properties automatically. It’s a good move if you have multiple jobs that do similar things. Later on, we’re creating some additional local (job scoped) variables: DOCKER_TAG_MAIN which will be evaluated to hiveio/condenser:development DOCKER_TAG which will be evaluated to hiveio/condenser:344e55ef or similar SOURCE_COMMIT which will be evaluated to 344e55efefd56e00b15eea6ccf8560a1107b9ff6 (or similar commit SHA) It’s a good idea to double tag an image. Latest tag is useless if you want to track your development process. Later on, I will describe the way how we’re using this specific, sha-tagged image to track deployments and rollback them anytime with a single click. Finally, we’re building an image with additional build arguments by using --build-arg: docker build -t $DOCKER_TAG -t $DOCKER_TAG_MAIN --build-arg SOURCE_COMMIT --build-arg DOCKER_TAG . If you scroll up to the Dockerfile section, you will notice ARG SOURCE_COMMIT and ENV SOURCE_COMMIT ${SOURCE_COMMIT} which means these build arguments will be injected as an environment variables into your containers. It’s a quick and easy way to pass additional, build-level variables into your images. Those specific variables are later returned by the condenser health endpoint. It may be useful to check a specific instance source. $ curl &amp;lt;a href=&quot;https://staging.condenser.engrave.dev/.well-known/healthcheck.json&quot;&amp;gt;https://staging.condenser.engrave.dev/.well-known/healthcheck.json&amp;lt;/a&amp;gt; {&quot;status&quot;:&quot;ok&quot;,&quot;docker_tag&quot;:&quot;hiveio/condenser:344e55ef&quot;,&quot;source_commit&quot;:&quot;344e55efefd56e00b15eea6ccf8560a1107b9ff6&quot;} An important thing to mention is that HUB_TOKEN and HUB_USERNAME are environment variables injected into the GitLab runner job and configured in Projects Settings. To prevent unauthorized users from pushing malicious images into the official registry, those variables are configured as protected and masked, which means they can be only used on specific branches and are moderated from job logs, so there is no way it can leak without internal bad actor with elevated permissions. Merge requests To improve the process of adding new features and fixes to the codebase, Merge Requests have got a brand new CI/CD workflow which includes the following jobs: The entire pipeline is fired on every Merge Request and it’s required to pass before changes could be merged. If the pipeline fails for some reason (i.e. failing unit tests), there is no way to merge changes into the main branch. This will enforce code quality and prevent regression. Eslint Code quality and standardization are important, especially if it’s an open-source project that could be maintained by totally different developers from all around the world. Eslint is a tool that statically analyzes the code to quickly find potential problems and keep code organized with specified rules. Code analysis is especially useful when developing Javascript applications. It’s really easy to make some stupid mistakes. Eslint job will be fired on every Merge Request and on every branch pushed to the repository: run-eslint: stage: test image: node:12.16.2 only: - branches - merge_requests before_script: - yarn install --frozen-lockfile --ignore-optional script: - yarn ci:eslint allow_failure: true # will be changed to false when all linter errors removed Because the codebase is a bit neglected, run-eslint job is allowed to fail for the moment (allow_failure: true), which is indicated by an orange exclamation mark on a MR view or pipelines list. There are “some” errors and warnings right now but it should be cleaned up soon, so we can require eslint job to pass before merging proposed changes: ✖ 1208 problems (1187 errors, 21 warnings) 831 errors and 0 warnings potentially fixable with the `--fix` option. error Command failed with exit code 1. Unit tests Extensive testing is the only way to produce bullet-proof code and stable applications. Similar to run-eslint, run-unit-tests job is fired on every branch and every merge request. run-unit-tests: stage: test image: node:12.16.2 only: - branches - merge_requests before_script: - yarn install --frozen-lockfile --ignore-optional script: - yarn run ci:test coverage: /All files[^|]*\|[^|]*\s+([\d\.]+)/ Testing suit (jest) was configured to produce coverage report: This report is later parsed by a Gitlab, using coverage: /All files[^|]*\|[^|]*\s+([\d\.]+)/ configuration. It will display coverage status and percentage change on the Merge Request view, allowing reviewers to quickly inspect if the code quality is increasing or not. I would advise declining merging new features not covered with tests. This may be omitted for important fixes, but we all should try to make the code better, not worse. Also, repository settings were changed and Pipelines must succeed setting is checked by default. It means no more broken code on develop/production branches. Review apps Review Apps are a huge and very important feature. From now on, every feature can be inspected visually by the reviewer with a single click. Gitlab Runner will create a special instance built from proposed code and expose it for the reviewers: Review app requires three jobs to run on a merge request: build-review-app: &amp;lt;&amp;lt;: *docker-job stage: build variables: DOCKER_TAG: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA SOURCE_COMMIT: $CI_COMMIT_SHA only: - merge_requests before_script: - echo $CI_JOB_TOKEN | docker login -u $CI_REGISTRY_USER $CI_REGISTRY --password-stdin script: - docker build -t $DOCKER_TAG --build-arg SOURCE_COMMIT --build-arg DOCKER_TAG . - docker push $DOCKER_TAG deploy-review-app: &amp;lt;&amp;lt;: *docker-job &amp;lt;&amp;lt;: *docker-remote-host-review stage: deploy variables: DOCKER_TAG: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA SERVICE_NAME: review_$CI_ENVIRONMENT_SLUG only: - merge_requests script: - DOCKER_CERT_PATH=$CERTS docker -H $REVIEW_HOST --tlsverify pull $DOCKER_TAG - DOCKER_CERT_PATH=$CERTS docker -H $REVIEW_HOST --tlsverify service rm $SERVICE_NAME || true # try to remove previous service but do not fail if it not exist - DOCKER_CERT_PATH=$CERTS docker -H $REVIEW_HOST --tlsverify service create --with-registry-auth --network infrastructure --name $SERVICE_NAME $DOCKER_TAG - echo &quot;Review app deployed&quot; environment: name: review/$CI_COMMIT_REF_NAME url: &amp;lt;a href=&quot;https://&quot;&amp;gt;https://&amp;lt;/a&amp;gt; $CI_ENVIRONMENT_SLUG$APP_REVIEW_SUBDOMAIN on_stop: stop-review-app auto_stop_in: 1 week stop-review-app: &amp;lt;&amp;lt;: *docker-job &amp;lt;&amp;lt;: *docker-remote-host-review stage: deploy variables: SERVICE_NAME: review_$CI_ENVIRONMENT_SLUG only: - merge_requests when: manual script: - DOCKER_CERT_PATH=$CERTS docker -H $REVIEW_HOST --tlsverify service rm $SERVICE_NAME || true # try to remove previous service but do not fail if it not exist - echo &quot;Review app stopped&quot; environment: name: review/$CI_COMMIT_REF_NAME action: stop The first job should look familiar if you read previous parts of the post. The only difference is that we’re overwriting before_script. Note that if you’re using anchors, you can always overwrite the template freely which is what we did here. Because merge requests could be opened by developers which may not be well known in the community (vel. bad actors), it could be a security issue if the CI/CD on Merge Requests could push images to the official repository. To prevent this, we’re using an internal registry provided by the Gitlab itself. It’s private, will work well for Review Apps but won’t be accessible by anyone else. echo $CI_JOB_TOKEN | docker login -u $CI_REGISTRY_USER $CI_REGISTRY --password-stdin We are using CI_JOB_TOKEN, CI_REGISTRY_USER and CI_REGISTRY which are environment variables injected automatically by Gitlab, no need to configure them. Also, please note using --password-stdin which is a more secure way to log in as it will prevent the password from being exposed in job logs. By default, docker will connect to the local daemon on unsecured, but not exposed port. It is yet possible to configure Docker daemon to validate TLS certificates so it could be exposed to the external world in a secure way, which is how we deploy services from our runners to our machine. You need to pass additional parameters: -H which is remote docker address --tlsverify makes sure your daemon is trying to identify itself with certificates --with-registry-auth will send registry authentication to swarm agents --network will connect service to the specified network so the reverse proxy could expose the instance DOCKER_CERT_PATH will instruct demon where to search for TLS certificates DOCKER_CERT_PATH=$CERTS docker -H $REVIEW_HOST --tlsverify service create --with-registry-auth --network infrastructure --name $SERVICE_NAME $DOCKER_TAG This will create a new docker service and expose it automatically under the URL created with CI_ENVIRONMENT_SLUG, which is a variable provided by Gitlab. It’s guaranteed to be a valid URL or docker/kubernetes service name. Review App instances are automatically removed when MR is closed or 1 week after it’s opened. This is achieved by running stop-review-app job which is configured to be manually triggered (when: manual). Tracking environment deployments By using sha-tagged images, it’s possible to quickly redeploy the environment at any moment, with a single click. In case of emergency, project maintainers can rollback the environment to the specified point in time (docker image to be specific) Staging Deploying a staging environment is quite similar to deploying a Review App. It also uses remote docker daemon but the service is not created on-demand, it’s updated with a new image. With docker swarm mode, you can ensure your application to be highly available. The swarm agent will take care of your containers. It will restart them or spin a new one if necessary (this is why health check is so important). It is a built-in, native docker mode everyone should start using. deploy-staging: &amp;lt;&amp;lt;: *docker-job &amp;lt;&amp;lt;: *docker-remote-host-staging stage: deploy variables: DOCKER_TAG: $DOCKER_IMAGE:$CI_COMMIT_SHORT_SHA SERVICE_NAME: staging_condenser only: - develop script: - DOCKER_CERT_PATH=$CERTS docker -H $STAGING_HOST --tlsverify pull $DOCKER_TAG - DOCKER_CERT_PATH=$CERTS docker -H $STAGING_HOST --tlsverify service update --image $DOCKER_TAG --update-failure-action rollback --update-order start-first $SERVICE_NAME environment: name: staging url: &amp;lt;a href=&quot;https://&quot;&amp;gt;https://&amp;lt;/a&amp;gt; $STAGING_DOMAIN Job uses protected variables to prevent “bad” developers from pushing/deploying malicious code. It is only possible to push staging from the protected develop branch. Pushing directly to develop is disabled. Zero downtime deployments Updating single service is easy with docker swarm: DOCKER_CERT_PATH=$CERTS docker -H $STAGING_HOST --tlsverify service update --image $DOCKER_TAG --update-failure-action rollback --update-order start-first $SERVICE_NAME There are additional but important parameters provided: --image $DOCKER_TAG - update existing service by running new containers with the specified image. For this case, it’s sha-tagged image build from develop branch --update-failure-action rollback - by default, docker daemon will try to update the service and do nothing if it fails. By passing this parameter, we’re instructing docker to roll back the service to a previous state, which means containers using the previous image. --update-order start-first - by default, docker will kill current containers and spin new ones after it. It may cause some downtime which we don’t want. By setting start-first, we instruct docker to spin new containers first. Swarm agent will switch containers without downtime if the healtcheck result becomes positive. And in case something gone wrong (healtcheck failed for any reason), we end up with a working staging environment because old containers are not touched at all. Resources under control With docker swarm you have full control over your services and containers. This is an example configuration which is used for staging environment. With some tweaks, it could be used for production also: version: &quot;3.7&quot; services: condenser: image: hiveio/condenser:latest deploy: mode: replicated replicas: 2 resources: limits: cpus: &quot;0.85&quot; memory: 2024M restart_policy: condition: any delay: 5s update_config: parallelism: 1 delay: 10s failure_action: rollback order: start-first rollback_config: parallelism: 1 delay: 5s networks: - reverse-proxy networks: reverse-proxy: external: name: reverse-proxy Production It is not finished yet, but my advice is to start using docker swarm mode for production deployments (CI/CD is ready). It’s designed to serve services like a condenser. Some key features of Docker Swarm (based on official documentation): Cluster management integrated with Docker Engine: if you know how to build the docker image, start a container, read some logs, you’re ready to use Docker Swarm. You don’t need to install additional software as it is a native Docker feature. Decentralized design: adding a worker or a manager to your swarm is as easy as running a single command. Those could be machines from all around the world. Scaling: For each service, you can declare the number of tasks you want to run. When you scale up or down, the swarm manager automatically adapts by adding or removing tasks to maintain the desired state. Multi-host networking: You can specify an overlay network for your services. The swarm manager automatically assigns addresses to the containers on the overlay network when it initializes or updates the application. Load balancing: You can expose the ports for services to an external load balancer. Internally, the swarm lets you specify how to distribute service containers between nodes. Secure by default: Each node in the swarm enforces TLS mutual authentication and encryption to secure communications between itself and all other nodes. You have the option to use self-signed root certificates or certificates from a custom root CA. Rolling updates: At rollout time you can apply service updates to nodes incrementally. The swarm manager lets you control the delay between service deployment to different sets of nodes. If anything goes wrong, you can roll back to a previous version of the service. And after all, it is called Swarm, can’t be a coincidence! ;) I’m using Swarm mode for most of my projects. Within Engrave (dblog.org) swarm is automatically managing a set of 23 microservices with almost 30 containers at the moment. My requests and tips for condenser Developers (and not only) Please do write unit tests covering your code. Improving coverage will only cause fewer problems and bugs. Coverage is now visible on every merge request so it’s damn easy to see a regression. Take care of the code quality. Use exact package versions in package.json file. When using ^, it’s not guaranteed to install the same version on two different builds. And some developers like to introduce breaking changes without changing the major version number. Use alpine images to create minified production images. Use the latest images from official Docker HUB when possible. Use multi-stage builds to create leaner docker image Write and configure health checks for your applications Run eslint to clean up your code before you push it to the repository. You can use husky to ensure it happens automatically. Vote for @engrave witness if you find my work valuable See: Improvements for hive.blog, Continuous Integration and Deployments by @engrave</summary></entry><entry><title type="html">Hive Pressure #1: A New Hope</title><link href="https://hivedocs.info/news/devops/nodes/2020/04/19/hive-pressure-1-a-new-hope.html" rel="alternate" type="text/html" title="Hive Pressure #1: A New Hope" /><published>2020-04-19T10:28:03-07:00</published><updated>2020-04-19T10:28:03-07:00</updated><id>https://hivedocs.info/news/devops/nodes/2020/04/19/hive-pressure-1-a-new-hope</id><content type="html" xml:base="https://hivedocs.info/news/devops/nodes/2020/04/19/hive-pressure-1-a-new-hope.html">&lt;p&gt;A long time ago, in a block far, far away…
No, wait, this is NOT the story you are looking for ;-)&lt;/p&gt;

&lt;p&gt;This part was going to be filled with retrospectives, the origins of the &lt;del&gt;Steem&lt;/del&gt; Pressure series, stories about events that caused us to fork from &lt;del&gt;Steem&lt;/del&gt; but that would be just a waste of time, and time is a resource that we can’t afford to waste.
TL;DR: &lt;del&gt;Steem&lt;/del&gt; is no longer what we knew it to be.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;“No Ned to worry.”&lt;/em&gt;
&lt;sup&gt;&lt;/sup&gt;&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;Anonymous
&amp;lt;/sup&amp;gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Our future is in our hands.
We are Hive now.&lt;/p&gt;

&lt;h1 id=&quot;paint-it-hive&quot;&gt;Paint it Hive&lt;/h1&gt;
&lt;p&gt;Time to update promo materials.&lt;/p&gt;

&lt;center&gt;
&lt;a href=&quot;https://www.youtube.com/watch&quot;&gt;https://www.youtube.com/watch&lt;/a&gt;
?v=vlW9lDE3DuI&lt;/center&gt;

&lt;h1 id=&quot;new-net-new-nodes&quot;&gt;New Net, New Nodes&lt;/h1&gt;
&lt;p&gt;Since many of us have just upgraded their toys to Hive, at the time of the HF23, most of what we used is now Hive compatible.&lt;/p&gt;

&lt;h2 id=&quot;seed-nodes&quot;&gt;Seed nodes&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;seed.openhive.network:2001     # gtg
seed.roelandp.nl:2001          # roelandp
hiveseed-se.privex.io:2001     # privex (SE)
steemseed-fin.privex.io:2001   # privex (FI)
seed.liondani.com:2016         # liondani
hived.splinterlands.com:2001   # aggroed
seed.hivekings.com:2001        # drakos
node.mahdiyari.info:2001       # mahdiyari
anyx.io:2001                   # anyx
seed.buildteam.io:2001         # thecryptodrive
hive-seed.lukestokes.info:2001 # lukestokes.mhth
hive-seed.arcange.eu:2001      # arcange
seed.chitty.me:2001            # chitty
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;api-nodes&quot;&gt;API nodes&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://api.openhive.network&quot;&gt;https://api.openhive.network&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://api.hive.blog&quot;&gt;https://api.hive.blog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://anyx.io&quot;&gt;https://anyx.io&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://api.hivekings.com&quot;&gt;https://api.hivekings.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://api.pharesim.me&quot;&gt;https://api.pharesim.me&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://hived.hive-engine.com&quot;&gt;https://hived.hive-engine.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://rpc.esteem.app&quot;&gt;https://rpc.esteem.app&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://hived.privex.io&quot;&gt;https://hived.privex.io&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://techcoderx.com&quot;&gt;https://techcoderx.com&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;diy&quot;&gt;DIY&lt;/h1&gt;
&lt;p&gt;If you want to run your own node, here are some quick tips that can be useful:&lt;/p&gt;

&lt;h2 id=&quot;seed-node&quot;&gt;Seed Node&lt;/h2&gt;
&lt;p&gt;Configure your build with:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cmake \
        -DCMAKE_BUILD_TYPE=Release \
        -DLOW_MEMORY_NODE=ON \
        -DCLEAR_VOTES=ON \
        -DSKIP_BY_TX_ID=OFF \
        -DBUILD_STEEM_TESTNET=OFF \
        -DENABLE_MIRA=OFF \
        -DSTEEM_STATIC_BUILD=ON \
        ../hive
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Depending on your needs and resources, you might want to use either
&lt;code class=&quot;highlighter-rouge&quot;&gt;ENABLE_MIRA=OFF&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;ENABLE_MIRA=ON&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;config.ini&lt;/code&gt; for a seed node can be as simple as that:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;plugin = witness
p2p-endpoint = 0.0.0.0:2001
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is intended to be used as a seed node, but you can easily extend it to be more useful by enabling a webserver endpoint and useful APIs such as &lt;code class=&quot;highlighter-rouge&quot;&gt;block_api&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;network_broadcast_api&lt;/code&gt;. However, if you choose to add a plugin such as &lt;code class=&quot;highlighter-rouge&quot;&gt;account_by_key&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;market_history&lt;/code&gt; you will have to replay.&lt;/p&gt;

&lt;h2 id=&quot;api-node&quot;&gt;API Node&lt;/h2&gt;
&lt;p&gt;If you’ve read my &lt;del&gt;Steem&lt;/del&gt; Pressure series you know that I no longer use a monolithic node. Instead, I use &lt;code class=&quot;highlighter-rouge&quot;&gt;jussi&lt;/code&gt; to route specific methods to specialized endpoints.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Account History Node (non-MIRA)&lt;/li&gt;
  &lt;li&gt;Fat Node (MIRA)&lt;/li&gt;
  &lt;li&gt;Hivemind&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please note that in my setup the Fat Node itself is &lt;em&gt;not enough&lt;/em&gt; to feed the Hivemind instance because of the lack of a market_history plugin. Not an issue in my environment, because I’m running both nodes, and I prefer to run plugins on the low memory node where possible.&lt;/p&gt;

&lt;h3 id=&quot;account-history-node---reference-configuration&quot;&gt;Account History Node - reference configuration&lt;/h3&gt;
&lt;p&gt;Configure your build with:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cmake \
        -DCMAKE_BUILD_TYPE=Release \
        -DLOW_MEMORY_NODE=ON \
        -DCLEAR_VOTES=ON \
        -DSKIP_BY_TX_ID=OFF \
        -DBUILD_STEEM_TESTNET=OFF \
        -DENABLE_MIRA=OFF \
        -DSTEEM_STATIC_BUILD=ON \
        ../hive
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We can’t use MIRA here, because we are going to use the pre-MIRA implementation of account history plugin: &lt;code class=&quot;highlighter-rouge&quot;&gt;account_history_rocksdb&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Here’s reference &lt;code class=&quot;highlighter-rouge&quot;&gt;config.ini&lt;/code&gt; file:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;log-appender = {&quot;appender&quot;:&quot;stderr&quot;,&quot;stream&quot;:&quot;std_error&quot;}
log-logger = {&quot;name&quot;:&quot;default&quot;,&quot;level&quot;:&quot;info&quot;,&quot;appender&quot;:&quot;stderr&quot;}

backtrace = yes

plugin = webserver p2p json_rpc
plugin = database_api condenser_api

plugin = witness
plugin = rc

plugin = market_history
plugin = market_history_api

plugin = account_history_rocksdb
plugin = account_history_api

plugin = transaction_status
plugin = transaction_status_api

plugin = account_by_key
plugin = account_by_key_api

plugin = block_api network_broadcast_api rc_api

p2p-endpoint = 0.0.0.0:2001
p2p-seed-node = gtg.openhive.network:2001

transaction-status-block-depth = 64000
transaction-status-track-after-block = 42000000

webserver-http-endpoint = 127.0.0.1:8091
webserver-ws-endpoint = 127.0.0.1:8090

webserver-thread-pool-size = 256
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;fat-node---reference-configuration&quot;&gt;Fat Node - reference configuration&lt;/h3&gt;
&lt;p&gt;Configure your build with:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cmake \
        -DCMAKE_BUILD_TYPE=Release \
        -DLOW_MEMORY_NODE=OFF \
        -DCLEAR_VOTES=OFF \
        -DSKIP_BY_TX_ID=ON \
        -DBUILD_STEEM_TESTNET=OFF \
        -DENABLE_MIRA=ON \
        -DSTEEM_STATIC_BUILD=ON \
        ../hive
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For the fat node, I use  the MIRA build&lt;/p&gt;

&lt;p&gt;Here’s reference &lt;code class=&quot;highlighter-rouge&quot;&gt;config.ini&lt;/code&gt; file:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;log-appender = {&quot;appender&quot;:&quot;stderr&quot;,&quot;stream&quot;:&quot;std_error&quot;}
log-logger = {&quot;name&quot;:&quot;default&quot;,&quot;level&quot;:&quot;info&quot;,&quot;appender&quot;:&quot;stderr&quot;}

backtrace = yes

plugin = webserver p2p json_rpc
plugin = database_api condenser_api

plugin = reputation
plugin = reputation_api

plugin = block_api

p2p-endpoint = 0.0.0.0:32001
p2p-seed-node = gtg.openhive.network:2001

webserver-http-endpoint = 127.0.0.1:8091
webserver-ws-endpoint = 127.0.0.1:8090

webserver-thread-pool-size = 256
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;storage-needs&quot;&gt;Storage needs:&lt;/h2&gt;
&lt;p&gt;As always, make sure that you have very fast storage.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Node type&lt;/th&gt;
      &lt;th&gt;Storage&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;AH Node&lt;/td&gt;
      &lt;td&gt;600 GB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fat Node&lt;/td&gt;
      &lt;td&gt;400 GB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Hivemind&lt;/td&gt;
      &lt;td&gt;300 GB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In the next episode, I will write more about such setup and required hardware and about how long it takes nowadays to build it from scratch.&lt;/p&gt;
&lt;div style=&quot;display: block; margin: 0 auto;&quot;&gt;
  &lt;p&gt;&lt;img src=&quot;https://images.hive.blog/DQmSJUo4g9AmoVFoAbs6gzMw6coVURUQKg7URtBSfkEj5oJ/Hive_free-file.png&quot; alt=&quot;Hive_Queen&quot; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-160391/@gtg/hive-pressure-1-a-new-hope&quot;&gt;Hive Pressure #1: A New Hope&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@gtg&quot;&gt;@gtg&lt;/a&gt;
&lt;/p&gt;</content><author><name>gtg</name></author><summary type="html">A long time ago, in a block far, far away… No, wait, this is NOT the story you are looking for ;-) This part was going to be filled with retrospectives, the origins of the Steem Pressure series, stories about events that caused us to fork from Steem but that would be just a waste of time, and time is a resource that we can’t afford to waste. TL;DR: Steem is no longer what we knew it to be. “No Ned to worry.” Anonymous &amp;lt;/sup&amp;gt; Our future is in our hands. We are Hive now. Paint it Hive Time to update promo materials. https://www.youtube.com/watch ?v=vlW9lDE3DuI New Net, New Nodes Since many of us have just upgraded their toys to Hive, at the time of the HF23, most of what we used is now Hive compatible. Seed nodes seed.openhive.network:2001 # gtg seed.roelandp.nl:2001 # roelandp hiveseed-se.privex.io:2001 # privex (SE) steemseed-fin.privex.io:2001 # privex (FI) seed.liondani.com:2016 # liondani hived.splinterlands.com:2001 # aggroed seed.hivekings.com:2001 # drakos node.mahdiyari.info:2001 # mahdiyari anyx.io:2001 # anyx seed.buildteam.io:2001 # thecryptodrive hive-seed.lukestokes.info:2001 # lukestokes.mhth hive-seed.arcange.eu:2001 # arcange seed.chitty.me:2001 # chitty API nodes https://api.openhive.network https://api.hive.blog https://anyx.io https://api.hivekings.com https://api.pharesim.me https://hived.hive-engine.com https://rpc.esteem.app https://hived.privex.io https://techcoderx.com DIY If you want to run your own node, here are some quick tips that can be useful: Seed Node Configure your build with: cmake \ -DCMAKE_BUILD_TYPE=Release \ -DLOW_MEMORY_NODE=ON \ -DCLEAR_VOTES=ON \ -DSKIP_BY_TX_ID=OFF \ -DBUILD_STEEM_TESTNET=OFF \ -DENABLE_MIRA=OFF \ -DSTEEM_STATIC_BUILD=ON \ ../hive Depending on your needs and resources, you might want to use either ENABLE_MIRA=OFF or ENABLE_MIRA=ON. config.ini for a seed node can be as simple as that: plugin = witness p2p-endpoint = 0.0.0.0:2001 This is intended to be used as a seed node, but you can easily extend it to be more useful by enabling a webserver endpoint and useful APIs such as block_api or network_broadcast_api. However, if you choose to add a plugin such as account_by_key or market_history you will have to replay. API Node If you’ve read my Steem Pressure series you know that I no longer use a monolithic node. Instead, I use jussi to route specific methods to specialized endpoints. Account History Node (non-MIRA) Fat Node (MIRA) Hivemind Please note that in my setup the Fat Node itself is not enough to feed the Hivemind instance because of the lack of a market_history plugin. Not an issue in my environment, because I’m running both nodes, and I prefer to run plugins on the low memory node where possible. Account History Node - reference configuration Configure your build with: cmake \ -DCMAKE_BUILD_TYPE=Release \ -DLOW_MEMORY_NODE=ON \ -DCLEAR_VOTES=ON \ -DSKIP_BY_TX_ID=OFF \ -DBUILD_STEEM_TESTNET=OFF \ -DENABLE_MIRA=OFF \ -DSTEEM_STATIC_BUILD=ON \ ../hive We can’t use MIRA here, because we are going to use the pre-MIRA implementation of account history plugin: account_history_rocksdb. Here’s reference config.ini file: log-appender = {&quot;appender&quot;:&quot;stderr&quot;,&quot;stream&quot;:&quot;std_error&quot;} log-logger = {&quot;name&quot;:&quot;default&quot;,&quot;level&quot;:&quot;info&quot;,&quot;appender&quot;:&quot;stderr&quot;} backtrace = yes plugin = webserver p2p json_rpc plugin = database_api condenser_api plugin = witness plugin = rc plugin = market_history plugin = market_history_api plugin = account_history_rocksdb plugin = account_history_api plugin = transaction_status plugin = transaction_status_api plugin = account_by_key plugin = account_by_key_api plugin = block_api network_broadcast_api rc_api p2p-endpoint = 0.0.0.0:2001 p2p-seed-node = gtg.openhive.network:2001 transaction-status-block-depth = 64000 transaction-status-track-after-block = 42000000 webserver-http-endpoint = 127.0.0.1:8091 webserver-ws-endpoint = 127.0.0.1:8090 webserver-thread-pool-size = 256 Fat Node - reference configuration Configure your build with: cmake \ -DCMAKE_BUILD_TYPE=Release \ -DLOW_MEMORY_NODE=OFF \ -DCLEAR_VOTES=OFF \ -DSKIP_BY_TX_ID=ON \ -DBUILD_STEEM_TESTNET=OFF \ -DENABLE_MIRA=ON \ -DSTEEM_STATIC_BUILD=ON \ ../hive For the fat node, I use the MIRA build Here’s reference config.ini file: log-appender = {&quot;appender&quot;:&quot;stderr&quot;,&quot;stream&quot;:&quot;std_error&quot;} log-logger = {&quot;name&quot;:&quot;default&quot;,&quot;level&quot;:&quot;info&quot;,&quot;appender&quot;:&quot;stderr&quot;} backtrace = yes plugin = webserver p2p json_rpc plugin = database_api condenser_api plugin = reputation plugin = reputation_api plugin = block_api p2p-endpoint = 0.0.0.0:32001 p2p-seed-node = gtg.openhive.network:2001 webserver-http-endpoint = 127.0.0.1:8091 webserver-ws-endpoint = 127.0.0.1:8090 webserver-thread-pool-size = 256 Storage needs: As always, make sure that you have very fast storage. Node type Storage AH Node 600 GB Fat Node 400 GB Hivemind 300 GB In the next episode, I will write more about such setup and required hardware and about how long it takes nowadays to build it from scratch. See: Hive Pressure #1: A New Hope by @gtg</summary></entry><entry><title type="html">Hive Keychain Now Available on Chrome &amp;amp; Brave!</title><link href="https://hivedocs.info/news/nodejs/keychain/2020/04/17/hive-keychain-now-available-on-chrome-and-brave.html" rel="alternate" type="text/html" title="Hive Keychain Now Available on Chrome &amp; Brave!" /><published>2020-04-17T08:50:54-07:00</published><updated>2020-04-17T08:50:54-07:00</updated><id>https://hivedocs.info/news/nodejs/keychain/2020/04/17/hive-keychain-now-available-on-chrome-and-brave</id><content type="html" xml:base="https://hivedocs.info/news/nodejs/keychain/2020/04/17/hive-keychain-now-available-on-chrome-and-brave.html">&lt;p&gt;&lt;img src=&quot;https://files.peakd.com/file/peakd-hive/stoodkev/AmSWoznK-keychain_title.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I am extremely happy to report that the Hive Keychain browser extension has FINALLY been approved by Google and is now available for everyone to install on the Google Chrome and Brave browsers!&lt;/p&gt;

&lt;p&gt;You can use the following link to find the extension in the Google Chrome Web Store:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://chrome.google.com/webstore/detail/hive-keychain/jcacnejopjdphbnjgfaaobbfafkihpep&quot;&gt;https://chrome.google.com/webstore/detail/hive-keychain/jcacnejopjdphbnjgfaaobbfafkihpep&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;We encourage everyone to add a positive review for the extension on the Google Web Store&lt;/strong&gt; as that will help ensure that it remains listed and future updates get approved in a timely fashion.&lt;/p&gt;

&lt;p&gt;It has also been available in Firefox for a while now here: 
&lt;a href=&quot;https://addons.mozilla.org/en-US/firefox/addon/hive-keychain/&quot;&gt;https://addons.mozilla.org/en-US/firefox/addon/hive-keychain/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;@stoodkev did the vast majority of the development work on the extension with contributions also from @arcange and @quochuy, and @nateaguila took care of the design and graphics as always.&lt;/p&gt;

&lt;p&gt;To see a detailed update of the work being done on the extension please see @stoodkev’s recent development update post here: 
&lt;a href=&quot;https://peakd.com/hive-139531/@stoodkev/hive-keychain-1-8-3&quot;&gt;https://peakd.com/hive-139531/@stoodkev/hive-keychain-1-8-3&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;hdf-proposal-update&quot;&gt;HDF Proposal Update&lt;/h2&gt;

&lt;p&gt;The existing funding proposal for the extension will end in approximately one month at which time we expect to launch a new proposal to continue to fund ongoing development of the project. We do not intend to submit another proposal on Steem as we do not plan to continue to work on the Steem Keychain extension, so funding going forward will only come from Hive.&lt;/p&gt;

&lt;p&gt;We greatly appreciate the support from everyone who has backed the proposal, and we hope that the community will vote to continue the funding when the initial proposal expires.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;NOTE: All rewards from this post will go to @steem.dao (the Hive Development Fund account) to support the ongoing development of the Hive platform&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive/@yabapmatt/hive-keychain-now-available-on-chrome-and-brave&quot;&gt;Hive Keychain Now Available on Chrome &amp;amp; Brave!&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@yabapmatt&quot;&gt;@yabapmatt&lt;/a&gt;
&lt;/p&gt;</content><author><name>yabapmatt</name></author><summary type="html">I am extremely happy to report that the Hive Keychain browser extension has FINALLY been approved by Google and is now available for everyone to install on the Google Chrome and Brave browsers! You can use the following link to find the extension in the Google Chrome Web Store: https://chrome.google.com/webstore/detail/hive-keychain/jcacnejopjdphbnjgfaaobbfafkihpep We encourage everyone to add a positive review for the extension on the Google Web Store as that will help ensure that it remains listed and future updates get approved in a timely fashion. It has also been available in Firefox for a while now here: https://addons.mozilla.org/en-US/firefox/addon/hive-keychain/ @stoodkev did the vast majority of the development work on the extension with contributions also from @arcange and @quochuy, and @nateaguila took care of the design and graphics as always. To see a detailed update of the work being done on the extension please see @stoodkev’s recent development update post here: https://peakd.com/hive-139531/@stoodkev/hive-keychain-1-8-3 HDF Proposal Update The existing funding proposal for the extension will end in approximately one month at which time we expect to launch a new proposal to continue to fund ongoing development of the project. We do not intend to submit another proposal on Steem as we do not plan to continue to work on the Steem Keychain extension, so funding going forward will only come from Hive. We greatly appreciate the support from everyone who has backed the proposal, and we hope that the community will vote to continue the funding when the initial proposal expires. NOTE: All rewards from this post will go to @steem.dao (the Hive Development Fund account) to support the ongoing development of the Hive platform See: Hive Keychain Now Available on Chrome &amp;amp; Brave! by @yabapmatt</summary></entry><entry><title type="html">Hivesigner Python Client</title><link href="https://hivedocs.info/howto/python/hivesigner/2020/04/14/powering-up-2.html" rel="alternate" type="text/html" title="Hivesigner Python Client" /><published>2020-04-14T14:28:15-07:00</published><updated>2020-04-14T14:28:15-07:00</updated><id>https://hivedocs.info/howto/python/hivesigner/2020/04/14/powering-up-2</id><content type="html" xml:base="https://hivedocs.info/howto/python/hivesigner/2020/04/14/powering-up-2.html">&lt;center&gt;&lt;img src=&quot;https://images.hive.blog/p/Y2iXpRRkNSnseh3NuL6KUBitJTXrc5K2vbTzBseGEENcE?format=match&amp;amp;mode=fit&amp;amp;width=640&quot; /&gt;&lt;/center&gt;
&lt;hr /&gt;

&lt;p&gt;hivesigner-python-client is a simple yet powerful library to interact with &lt;a href=&quot;https://hivesigner.com&quot;&gt;HiveSigner&lt;/a&gt;. Hivesigner is a single sign-on solution for HIVE based applications and it implements &lt;code class=&quot;highlighter-rouge&quot;&gt;Oauth2&lt;/code&gt; for the authorization logic.&lt;/p&gt;

&lt;p&gt;With this client;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Implementing Authorization/Authentication flow w/ OAuth&lt;/li&gt;
  &lt;li&gt;Broadcasting supported operations to the HIVE blockchain with the user of your app&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;are possible through Hivesigner.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;| Repository                                       | Documentation |
|————————————————–|—————|
|&lt;a href=&quot;https://github.com/emre/hivesigner-python-client&quot;&gt;github.com/emre/hivesigner-python-client&lt;/a&gt;|   &lt;a href=&quot;https://hivesigner-python-client.readthedocs.io/en/latest/&quot;&gt;hivesigner-python-client.readthedocs.io&lt;/a&gt;            |
***&lt;/p&gt;

&lt;h4 id=&quot;installation&quot;&gt;Installation&lt;/h4&gt;
&lt;hr /&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ (sudo) pip install hivesigner
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;migrating-from-steemconnect-python-client&quot;&gt;Migrating from steemconnect-python-client&lt;/h4&gt;
&lt;hr /&gt;
&lt;p&gt;If you use &lt;code class=&quot;highlighter-rouge&quot;&gt;steemconnect-python-client&lt;/code&gt; and want to switch to HIVE version, the only change you need to do is updating imports.&lt;/p&gt;

&lt;p&gt;Old way:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;from steemconnect.client import Client&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;New way:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;from hivesigner.client import Client&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Also, &lt;code class=&quot;highlighter-rouge&quot;&gt;Resteem&lt;/code&gt; class is changed as &lt;code class=&quot;highlighter-rouge&quot;&gt;Reblog&lt;/code&gt;.  Examples and more details can be found at the documentation website.
&lt;strong&gt;*
**Note&lt;/strong&gt;:  Hivesigner is being maintained by @good-karma since the switch. There is an ongoing proposal for it’s maintenance for a while. If you didn’t see it yet, &lt;a href=&quot;https://hivedao.com/proposal/88&quot;&gt;check it out&lt;/a&gt;.&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@emrebeyler/powering-up-2&quot;&gt;Hivesigner Python Client&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@emrebeyler&quot;&gt;@emrebeyler&lt;/a&gt;
&lt;/p&gt;</content><author><name>emrebeyler</name></author><summary type="html">hivesigner-python-client is a simple yet powerful library to interact with HiveSigner. Hivesigner is a single sign-on solution for HIVE based applications and it implements Oauth2 for the authorization logic. With this client; Implementing Authorization/Authentication flow w/ OAuth Broadcasting supported operations to the HIVE blockchain with the user of your app are possible through Hivesigner. | Repository | Documentation | |————————————————–|—————| |github.com/emre/hivesigner-python-client| hivesigner-python-client.readthedocs.io | *** Installation $ (sudo) pip install hivesigner Migrating from steemconnect-python-client If you use steemconnect-python-client and want to switch to HIVE version, the only change you need to do is updating imports. Old way: from steemconnect.client import Client New way: from hivesigner.client import Client. Also, Resteem class is changed as Reblog. Examples and more details can be found at the documentation website. * **Note: Hivesigner is being maintained by @good-karma since the switch. There is an ongoing proposal for it’s maintenance for a while. If you didn’t see it yet, check it out. See: Hivesigner Python Client by @emrebeyler</summary></entry><entry><title type="html">[Hive Patched] Upvoting By Payment In 4 Easy Steps - Basic Bot</title><link href="https://hivedocs.info/howdo/nodejs/bot/2020/04/14/hive-patched-upvoting-by-payment-in-4-easy-steps-basic-bot.html" rel="alternate" type="text/html" title="[Hive Patched] Upvoting By Payment In 4 Easy Steps - Basic Bot" /><published>2020-04-14T13:14:21-07:00</published><updated>2020-04-14T13:14:21-07:00</updated><id>https://hivedocs.info/howdo/nodejs/bot/2020/04/14/hive-patched-upvoting-by-payment-in-4-easy-steps-basic-bot</id><content type="html" xml:base="https://hivedocs.info/howdo/nodejs/bot/2020/04/14/hive-patched-upvoting-by-payment-in-4-easy-steps-basic-bot.html">&lt;p&gt;&lt;img src=&quot;https://files.peakd.com/file/peakd-hive/lonelywolf/MwKfr7ni-upvote.png&quot; alt=&quot;upvote.png&quot; /&gt;
(Want to use the &lt;strong&gt;logo&lt;/strong&gt; yourself? no problem, check out the post I made about &lt;a href=&quot;https://peakd.com/hive-174578/@lonelywolf/art-design-hive-logo-by-lonelywolf-stav-art-inside-free-usage&quot;&gt;My Art Design - Hive Logo&lt;/a&gt;)
—&lt;/p&gt;
&lt;h4 id=&quot;repository&quot;&gt;Repository:&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.npmjs.com/package/steem-js-patched&quot;&gt;https://www.npmjs.com/package/steem-js-patched&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h2 id=&quot;helpful-tutorials&quot;&gt;Helpful tutorials:&lt;/h2&gt;
    &lt;p&gt;&lt;a href=&quot;https://hive.blog/hive-139531/@lonelywolf/hive-patched-steemjs-full-tutorial-all-the-functions-all-the-abilities&quot;&gt;[HIVE Patched] SteemJS Full Tutorial - All The Functions - All The Abilities&lt;/a&gt;
&lt;a href=&quot;https://hive.blog/hive-139531/@lonelywolf/hive-patched-tutorial-steemjs-vote-comment-and-follow-functions-all-in-one&quot;&gt;[Hive Patched Tutorial] SteemJS - Vote, Comment and Follow functions - All In One&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;all-of-this-tutorial-is-patched-for-hive-so-it-works-for-steem-and-hive&quot;&gt;All of this tutorial is patched for Hive, so it works for steem and &lt;strong&gt;Hive&lt;/strong&gt;!&lt;/h1&gt;
&lt;h4 id=&quot;all-of-the-examples-and-results-is-from-the-old-tutorial-but-still-same-for-hive&quot;&gt;All of the examples and results is from the old tutorial but still same for hive!&lt;/h4&gt;

&lt;p&gt;Hello!
Today you’re going to learn how to create an upvoting bot with that calculate simply the voting power by the payment, &lt;code class=&quot;highlighter-rouge&quot;&gt;note&lt;/code&gt; the calculation is a really simple calculation.&lt;/p&gt;

&lt;p&gt;Load the steem/HIVE package:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const steem = require('steem-js-patched')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;To install the package &lt;code class=&quot;highlighter-rouge&quot;&gt;npm install steem-js-patched --save&lt;/code&gt; - Repository above&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;First we will add the user guest123 (or your account) to the code, this(guest123) is a global account for steemjs developers&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const ACC_NAME = 'guest123', // Account Name
    ACC_KEY = '5JRaypasxMx1L97ZUX7YuC5Psb5EAbF821kkAGtBj7xCJFQcbLg'; // Account Private WIF Key
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;you want to add the Hive API to work with &lt;strong&gt;Hive&lt;/strong&gt; blockchain&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;steem.api.setOptions({ url: 'https://api.hive.blog' });
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So, First things first, we will get from the easiest to the hardest, firstly we’re going to get the transactions from the blockchain&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;steem.api.streamTransactions('head', function(err, result) {
    let type = result.operations[0][0]; // getting the type of the transaction
    let data = result.operations[0][1]; // getting the data of the transaction
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;this function gets the newest transactions that go through the hive blockchain, such as new blogs, transfers etc.&lt;/p&gt;

&lt;p&gt;as I already explained in the code, the type is getting the transaction type (new blogs/new transfer etc.) and data getting the data from the transaction, for the blog it will be an author, permlink, content etc. and for transfer, it will be a memo, sender, receiver etc.&lt;/p&gt;

&lt;p&gt;now we need to check if the transaction type is a transfer and if it is, we check if the receiver is our account.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;if(type == 'transfer' &amp;amp;&amp;amp; data.to == ACC_NAME) { // checking if the transaction type is a transfer and the reciever is our account

}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;simple enough, we’re checking if type(transaction type) is &lt;code class=&quot;highlighter-rouge&quot;&gt;transfer&lt;/code&gt; and if the receiver is our account.&lt;/p&gt;

&lt;p&gt;if it is we need to check the memo and check if the memo is url if it is we’re going to send the vote, if it’s not we’re getting it as normal transfers.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;var memo = data.memo.split('/');
if(memo[0] == &quot;https:&quot;){ // checking if the memo is a url
  console.log(&quot;Incoming request for vote from: &quot; + data.from +&quot;, value: &quot; + data.amount + &quot;\n\n&quot;); // sending a comment to the console and telling us that new request for vote is come.
  streamVote(data.memo, data.amount);
}else{
  console.log(&quot;Incoming transaction from: &quot; + data.from + &quot;, this is not a vote requst.&quot;);
  console.log(&quot;MEMO: &quot; + data.memo);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;everything explained above!&lt;/p&gt;

&lt;h3 id=&quot;now-create-the-functions---streamvote--calcvoteweight&quot;&gt;Now, create the functions - StreamVote &amp;amp; CalcVoteWeight&lt;/h3&gt;
&lt;p&gt;firstly, streamvote, create a function called StreamVote with the variables URL, Amount&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;function streamVote(url, amount) {

}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;now we need to get the weight and the author&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    const memo = url.split('/'); // spliting the URL to array
    const author = memo[4].split('@')[1]; // getting the author of the post
    const weight = calcVoteWeight(amount); // getting the weight value by the amount
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;memo = url
author is the author of the post that got from the url, example: ~~
&lt;a href=&quot;https://steemit.com/utopian-io&quot;&gt;https://steemit.com/utopian-io&lt;/a&gt;
&lt;del&gt;/&lt;strong&gt;@lonelywolf&lt;/strong&gt;/&lt;/del&gt;steem-bots—auto-follower-bot-steemjs–nodejs—-begginer-tutorial~~&lt;/p&gt;

&lt;p&gt;weight is the calculated weight from the calculate function that we will create after.&lt;/p&gt;

&lt;p&gt;now we just need to stream the vote to the blockchain&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;steem.broadcast.vote(ACC_KEY, ACC_NAME, author, memo[5], weight, function(err, result) { // starting the voting process
        if(!!err)
          throw err; // close the program and send comment to the console with the error details if there is an error
        console.log('Voted Succesfully, permalink: ' + memo[5] + ', author: ' + author + ', weight: ' + weight / 1000 + '%.', err); //if the vote Succesfully sent it will send all of the information to the console
});
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;so we have the broadcast. vote function, as it says it sends a vote, it uses the wif(private key), the account name, the author name, the permlink(memo[5]) and the voting weight.&lt;/p&gt;

&lt;p&gt;if there is an error we’re sending it to the console and crash the application&lt;/p&gt;

&lt;p&gt;if everything has done successfully we’re sending the info to the console.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The calculate function
create a new function with the variable &lt;code class=&quot;highlighter-rouge&quot;&gt;amountPaid&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//this function will calculate the voting weight for the paid upvote as simple as it can be
function calcVoteWeight(amountPaid){

}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;now get the token type and value&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  const token = amountPaid.split(' '),
    tokenType = token.pop(), //taking the token(coin) type [HIVE/HBD]
    tokenValue = token.shift(); // taking only the token(coin) value
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;as easy as it can be, we’re splitting the string by spaces and getting the token type &amp;amp; value&lt;/p&gt;

&lt;p&gt;now create a new variable called &lt;code class=&quot;highlighter-rouge&quot;&gt;weight&lt;/code&gt; and check for values to set the weight to it&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  let weight;
  if (tokenValue &amp;gt;= 0.6){ // checking if the token(coin) value is higher than 0.6 (example: &amp;gt;0.6$ HBD/ &amp;gt;0.6 HIVE)
    weight = 100;
  } else if (tokenValue &amp;gt;= 0.25) { // same
    weight = 40;
  } else if (tokenValue &amp;gt;= 0.1) { // same
    weight = 20;
  }else{ // just like the else but if it's lower than 0.1
    weight = 10;
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;first, we check if the value is higher or equal to &lt;code class=&quot;highlighter-rouge&quot;&gt;0.6&lt;/code&gt; if it is we’re sending a full vote&lt;/p&gt;

&lt;p&gt;if the amount is higher than &lt;code class=&quot;highlighter-rouge&quot;&gt;0.25&lt;/code&gt; we’re sending 40% vote&lt;/p&gt;

&lt;p&gt;if the amount is higher than &lt;code class=&quot;highlighter-rouge&quot;&gt;0.1&lt;/code&gt; we’re sending 20% vote&lt;/p&gt;

&lt;p&gt;if the amount is lower than &lt;code class=&quot;highlighter-rouge&quot;&gt;0.1&lt;/code&gt;(else) we’re sending 10% vote&lt;/p&gt;

&lt;p&gt;now we need to get the ratio between hive and hbd, so because it’s simple bot we’re doing it manually&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  const HbdHiveRatio = 0.5; // the ratio between HBD and HIVE, example: HIVE = 0.8 and HBD 1.2, the ratio is around the 0.5 because you need 1.5 HIVE to get 1 HBD 

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;this is the ratio between hbd and hive, example: hive = 0.8 and hbd 1.2, the ratio is around 0.5 because you need 1.5 hive to get 1 HBD&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  if( tokenType == 'HIVE') { // checking if the token(coin) type is HIVE
      return (weight * HbdHiveRatio) * 100; //if it is the value weight will calculate with the Hbd to Hive Ratio
  } else {
      return weight * 100; // if it's not Hive it will be a regular vote
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;now we’re checking if the coin type is hive if it is we’re calculating it with the &lt;code class=&quot;highlighter-rouge&quot;&gt;hbd to hive&lt;/code&gt; ratio,
if the token is HBD we’ll send a normal vote.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;simply, you’re done, just run the script and check it, send 0.01 HBD to your account (the account that on the script) with the post URL and get the vote.
if there are any problems with the code, comment down below and I’ll help you!
&lt;strong&gt;if you have any suggestions for next tutorials I will appreciate it if you can comment on your suggestions, thanks!&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;have-a-great-day&quot;&gt;Have a great day!&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@lonelywolf/hive-patched-upvoting-by-payment-in-4-easy-steps-basic-bot&quot;&gt;[Hive Patched] Upvoting By Payment In 4 Easy Steps - Basic Bot&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@lonelywolf&quot;&gt;@lonelywolf&lt;/a&gt;
&lt;/p&gt;</content><author><name>lonelywolf</name></author><summary type="html">(Want to use the logo yourself? no problem, check out the post I made about My Art Design - Hive Logo) — Repository: https://www.npmjs.com/package/steem-js-patched Helpful tutorials: [HIVE Patched] SteemJS Full Tutorial - All The Functions - All The Abilities [Hive Patched Tutorial] SteemJS - Vote, Comment and Follow functions - All In One All of this tutorial is patched for Hive, so it works for steem and Hive! All of the examples and results is from the old tutorial but still same for hive! Hello! Today you’re going to learn how to create an upvoting bot with that calculate simply the voting power by the payment, note the calculation is a really simple calculation. Load the steem/HIVE package: const steem = require('steem-js-patched') To install the package npm install steem-js-patched --save - Repository above First we will add the user guest123 (or your account) to the code, this(guest123) is a global account for steemjs developers const ACC_NAME = 'guest123', // Account Name ACC_KEY = '5JRaypasxMx1L97ZUX7YuC5Psb5EAbF821kkAGtBj7xCJFQcbLg'; // Account Private WIF Key you want to add the Hive API to work with Hive blockchain steem.api.setOptions({ url: 'https://api.hive.blog' }); So, First things first, we will get from the easiest to the hardest, firstly we’re going to get the transactions from the blockchain steem.api.streamTransactions('head', function(err, result) { let type = result.operations[0][0]; // getting the type of the transaction let data = result.operations[0][1]; // getting the data of the transaction } this function gets the newest transactions that go through the hive blockchain, such as new blogs, transfers etc. as I already explained in the code, the type is getting the transaction type (new blogs/new transfer etc.) and data getting the data from the transaction, for the blog it will be an author, permlink, content etc. and for transfer, it will be a memo, sender, receiver etc. now we need to check if the transaction type is a transfer and if it is, we check if the receiver is our account. if(type == 'transfer' &amp;amp;&amp;amp; data.to == ACC_NAME) { // checking if the transaction type is a transfer and the reciever is our account } simple enough, we’re checking if type(transaction type) is transfer and if the receiver is our account. if it is we need to check the memo and check if the memo is url if it is we’re going to send the vote, if it’s not we’re getting it as normal transfers. var memo = data.memo.split('/'); if(memo[0] == &quot;https:&quot;){ // checking if the memo is a url console.log(&quot;Incoming request for vote from: &quot; + data.from +&quot;, value: &quot; + data.amount + &quot;\n\n&quot;); // sending a comment to the console and telling us that new request for vote is come. streamVote(data.memo, data.amount); }else{ console.log(&quot;Incoming transaction from: &quot; + data.from + &quot;, this is not a vote requst.&quot;); console.log(&quot;MEMO: &quot; + data.memo); } everything explained above! Now, create the functions - StreamVote &amp;amp; CalcVoteWeight firstly, streamvote, create a function called StreamVote with the variables URL, Amount function streamVote(url, amount) { } now we need to get the weight and the author const memo = url.split('/'); // spliting the URL to array const author = memo[4].split('@')[1]; // getting the author of the post const weight = calcVoteWeight(amount); // getting the weight value by the amount memo = url author is the author of the post that got from the url, example: ~~ https://steemit.com/utopian-io /@lonelywolf/steem-bots—auto-follower-bot-steemjs–nodejs—-begginer-tutorial~~ weight is the calculated weight from the calculate function that we will create after. now we just need to stream the vote to the blockchain steem.broadcast.vote(ACC_KEY, ACC_NAME, author, memo[5], weight, function(err, result) { // starting the voting process if(!!err) throw err; // close the program and send comment to the console with the error details if there is an error console.log('Voted Succesfully, permalink: ' + memo[5] + ', author: ' + author + ', weight: ' + weight / 1000 + '%.', err); //if the vote Succesfully sent it will send all of the information to the console }); so we have the broadcast. vote function, as it says it sends a vote, it uses the wif(private key), the account name, the author name, the permlink(memo[5]) and the voting weight. if there is an error we’re sending it to the console and crash the application if everything has done successfully we’re sending the info to the console. The calculate function create a new function with the variable amountPaid //this function will calculate the voting weight for the paid upvote as simple as it can be function calcVoteWeight(amountPaid){ } now get the token type and value const token = amountPaid.split(' '), tokenType = token.pop(), //taking the token(coin) type [HIVE/HBD] tokenValue = token.shift(); // taking only the token(coin) value as easy as it can be, we’re splitting the string by spaces and getting the token type &amp;amp; value now create a new variable called weight and check for values to set the weight to it let weight; if (tokenValue &amp;gt;= 0.6){ // checking if the token(coin) value is higher than 0.6 (example: &amp;gt;0.6$ HBD/ &amp;gt;0.6 HIVE) weight = 100; } else if (tokenValue &amp;gt;= 0.25) { // same weight = 40; } else if (tokenValue &amp;gt;= 0.1) { // same weight = 20; }else{ // just like the else but if it's lower than 0.1 weight = 10; } first, we check if the value is higher or equal to 0.6 if it is we’re sending a full vote if the amount is higher than 0.25 we’re sending 40% vote if the amount is higher than 0.1 we’re sending 20% vote if the amount is lower than 0.1(else) we’re sending 10% vote now we need to get the ratio between hive and hbd, so because it’s simple bot we’re doing it manually const HbdHiveRatio = 0.5; // the ratio between HBD and HIVE, example: HIVE = 0.8 and HBD 1.2, the ratio is around the 0.5 because you need 1.5 HIVE to get 1 HBD this is the ratio between hbd and hive, example: hive = 0.8 and hbd 1.2, the ratio is around 0.5 because you need 1.5 hive to get 1 HBD if( tokenType == 'HIVE') { // checking if the token(coin) type is HIVE return (weight * HbdHiveRatio) * 100; //if it is the value weight will calculate with the Hbd to Hive Ratio } else { return weight * 100; // if it's not Hive it will be a regular vote } now we’re checking if the coin type is hive if it is we’re calculating it with the hbd to hive ratio, if the token is HBD we’ll send a normal vote. Conclusion simply, you’re done, just run the script and check it, send 0.01 HBD to your account (the account that on the script) with the post URL and get the vote. if there are any problems with the code, comment down below and I’ll help you! if you have any suggestions for next tutorials I will appreciate it if you can comment on your suggestions, thanks! Have a great day! See: [Hive Patched] Upvoting By Payment In 4 Easy Steps - Basic Bot by @lonelywolf</summary></entry><entry><title type="html">Devportal Hivesigner updates</title><link href="https://hivedocs.info/news/nodejs/hivesigner/2020/04/14/devportal-hivesigner-updates.html" rel="alternate" type="text/html" title="Devportal Hivesigner updates" /><published>2020-04-14T02:07:45-07:00</published><updated>2020-04-14T02:07:45-07:00</updated><id>https://hivedocs.info/news/nodejs/hivesigner/2020/04/14/devportal-hivesigner-updates</id><content type="html" xml:base="https://hivedocs.info/news/nodejs/hivesigner/2020/04/14/devportal-hivesigner-updates.html">&lt;p&gt;&lt;img src=&quot;https://img.esteem.app/kbgnol.png&quot; alt=&quot;kbgnol.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;devportal-updates&quot;&gt;Devportal updates&lt;/h1&gt;

&lt;p&gt;Earlier today, have made pull request to change and improve Hivesigner related dev documentation and Javascript tutorial which has been merged into master and already alive at &lt;a href=&quot;https://developers.hive.io&quot;&gt;Hive devportal&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Information about Hivesigner 
&lt;a href=&quot;http://developers.hive.io/services/#services-hivesigner&quot;&gt;http://developers.hive.io/services/#services-hivesigner&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;JS tutorial on how to integrate Hivesigner into your Hive applications:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;http://developers.hive.io/tutorials-javascript/hivesigner.html&quot;&gt;http://developers.hive.io/tutorials-javascript/hivesigner.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Documentation is important part of any service and tool, without it devs would have to hassle a lot, know how to integrate and how to use provided resources.&lt;/p&gt;

&lt;p&gt;I remember in 2016 when chain was launched, we had hard time to developing apps, had to go through blockchain code to find proper API calls and parameters, find secure way to sign transactions etc. We have come a long way since then and our documentations are way better and easier to follow.&lt;/p&gt;

&lt;p&gt;We have yet to document and implement a lot of pieces to make Hivesigner easy to understand for developers as well as users. Support our proposal to help us deliver those quicker!&lt;/p&gt;

&lt;h1 id=&quot;support-hivesigner-proposal&quot;&gt;Support Hivesigner proposal&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B88%5D&amp;amp;approve=true&quot;&gt;Vote for Proposal using Hivesigner&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;HiveDao: 
&lt;a href=&quot;https://hivedao.com/proposal/88&quot;&gt;https://hivedao.com/proposal/88&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;PeakD: 
&lt;a href=&quot;https://peakd.com/proposals/88&quot;&gt;https://peakd.com/proposals/88&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;HiveBlog Wallet: 
&lt;a href=&quot;https://wallet.hive.blog/proposals&quot;&gt;https://wallet.hive.blog/proposals&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Discord: 
&lt;a href=&quot;https://discord.gg/pNJn7wh&quot;&gt;https://discord.gg/pNJn7wh&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ledgerconnect/hivesigner/issues/2&quot;&gt;Github roadmap thread&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://esteem.app/hive-139531/@good-karma/devportal-hivesigner-updates&quot;&gt;Devportal Hivesigner updates&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@good-karma&quot;&gt;@good-karma&lt;/a&gt;
&lt;/p&gt;</content><author><name>good-karma</name></author><summary type="html">Devportal updates Earlier today, have made pull request to change and improve Hivesigner related dev documentation and Javascript tutorial which has been merged into master and already alive at Hive devportal. Information about Hivesigner http://developers.hive.io/services/#services-hivesigner JS tutorial on how to integrate Hivesigner into your Hive applications: http://developers.hive.io/tutorials-javascript/hivesigner.html Documentation is important part of any service and tool, without it devs would have to hassle a lot, know how to integrate and how to use provided resources. I remember in 2016 when chain was launched, we had hard time to developing apps, had to go through blockchain code to find proper API calls and parameters, find secure way to sign transactions etc. We have come a long way since then and our documentations are way better and easier to follow. We have yet to document and implement a lot of pieces to make Hivesigner easy to understand for developers as well as users. Support our proposal to help us deliver those quicker! Support Hivesigner proposal Vote for Proposal using Hivesigner HiveDao: https://hivedao.com/proposal/88 PeakD: https://peakd.com/proposals/88 HiveBlog Wallet: https://wallet.hive.blog/proposals Discord: https://discord.gg/pNJn7wh Github roadmap thread See: Devportal Hivesigner updates by @good-karma</summary></entry><entry><title type="html">Simple Transaction Monitor</title><link href="https://hivedocs.info/howto/stream/python/2020/04/11/simple-transaction-monitor.html" rel="alternate" type="text/html" title="Simple Transaction Monitor" /><published>2020-04-11T16:58:21-07:00</published><updated>2020-04-11T16:58:21-07:00</updated><id>https://hivedocs.info/howto/stream/python/2020/04/11/simple-transaction-monitor</id><content type="html" xml:base="https://hivedocs.info/howto/stream/python/2020/04/11/simple-transaction-monitor.html">&lt;h1 id=&quot;pretty-straight-forward-monitor&quot;&gt;Pretty straight forward monitor&lt;/h1&gt;
&lt;p&gt;I’m back again with another simple python snippet of code to use in future projects. A lot of projects begin as needing something to monitor the chain and react accordingly. I thought about this and decided the best example to show how simple it is and a teaching tool to myself was to monitor the transaction ops and insert them into a database if they were to or from me.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.peakd.com/file/peakd-hive/thecrazygm/tr5VEsVA-monitor_output.png&quot; alt=&quot;monitor_output.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is the basis of listening for memos to react with a response of sorts. (In this case, put them into a simple sqlite3 DB) another popular option is to listen for the &lt;code class=&quot;highlighter-rouge&quot;&gt;comments&lt;/code&gt; op and check if something is mentioned (that may be another project/lesson in the future)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://files.peakd.com/file/peakd-hive/thecrazygm/fG2RgesY-monitor_db_output.png&quot; alt=&quot;monitor_db_output.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This example requires both &lt;a href=&quot;https://beem.readthedocs.io/en/latest/index.html&quot;&gt;beem&lt;/a&gt; and &lt;a href=&quot;https://dataset.readthedocs.io/en/latest/index.html&quot;&gt;dataset&lt;/a&gt; and will watch for whatever account you set as the &lt;code class=&quot;highlighter-rouge&quot;&gt;watch&lt;/code&gt; variable.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#!/usr/bin/env python3
&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dataset&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;beem&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Steem&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;beem.blockchain&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Blockchain&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;watch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;thecrazygm&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;hive&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Steem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'https://anyx.io'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sqlite:///mydatabase.db'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# System Variables
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blockchain&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Blockchain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;steem_instance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockchain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opNames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'transfer'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;raw_ops&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threading&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thread_num&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;watch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# parse json data to SQL insert
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;commit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'[Error: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; moving on]'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rollback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;monitor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Starting up...]&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Read the live stream and filter out only transfers
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;post&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;to&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;watch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;from&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;watch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;[Transaction Found from &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'from'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; to &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'to'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;]&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;update_db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;monitor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The code can be found always up to date at my &lt;a href=&quot;https://gist.github.com/TheCrazyGM&quot;&gt;GitHub gist area&lt;/a&gt; at this file: &lt;a href=&quot;https://gist.github.com/TheCrazyGM/9b2882a4adcea826815489b5a00ed089&quot;&gt;monitor.py&lt;/a&gt;
If you like what I’m doing consider following me, either here or on &lt;a href=&quot;https://github.com/thecrazygm&quot;&gt;GitHub&lt;/a&gt; or buy me a coffee.&lt;/p&gt;

&lt;p&gt;Again, stay safe out there people,
Michael Garcia a.k.a. @TheCrazyGM
&lt;img src=&quot;https://files.peakd.com/file/peakd-hive/thecrazygm/LjWZDEWC-signature_fancy.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/dev/@thecrazygm/simple-transaction-monitor&quot;&gt;Simple Transaction Monitor&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@thecrazygm&quot;&gt;@thecrazygm&lt;/a&gt;
&lt;/p&gt;</content><author><name>thecrazygm</name></author><summary type="html">Pretty straight forward monitor I’m back again with another simple python snippet of code to use in future projects. A lot of projects begin as needing something to monitor the chain and react accordingly. I thought about this and decided the best example to show how simple it is and a teaching tool to myself was to monitor the transaction ops and insert them into a database if they were to or from me. This is the basis of listening for memos to react with a response of sorts. (In this case, put them into a simple sqlite3 DB) another popular option is to listen for the comments op and check if something is mentioned (that may be another project/lesson in the future) This example requires both beem and dataset and will watch for whatever account you set as the watch variable. #!/usr/bin/env python3 import dataset from beem import Steem from beem.blockchain import Blockchain watch = &quot;thecrazygm&quot; hive = Steem(node='https://anyx.io') db = dataset.connect('sqlite:///mydatabase.db') # System Variables blockchain = Blockchain(steem_instance=hive) stream = blockchain.stream(opNames=['transfer'], raw_ops=False, threading=True, thread_num=4) table = db[watch] # parse json data to SQL insert def update_db(post): try: table.insert(dict(post)) db.commit() except Exception as e: print(f'[Error: {e} moving on]') db.rollback() def monitor(): print(&quot;[Starting up...]&quot;) db.begin() # Read the live stream and filter out only transfers for post in stream: if post[&quot;to&quot;] == watch or post[&quot;from&quot;] == watch: print(f&quot;[Transaction Found from {post['from']} to {post['to']}]&quot;) update_db(post) if __name__ == &quot;__main__&quot;: monitor() The code can be found always up to date at my GitHub gist area at this file: monitor.py If you like what I’m doing consider following me, either here or on GitHub or buy me a coffee. Again, stay safe out there people, Michael Garcia a.k.a. @TheCrazyGM See: Simple Transaction Monitor by @thecrazygm</summary></entry></feed>