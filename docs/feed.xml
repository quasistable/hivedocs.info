<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://hivedocs.info/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hivedocs.info/" rel="alternate" type="text/html" /><updated>2021-07-01T17:50:53-07:00</updated><id>https://hivedocs.info/feed.xml</id><title type="html">Hive Chain Documentation</title><subtitle>Your resource for various levels of Hive Documentation.</subtitle><author><name>site curated by: @inertia</name></author><entry><title type="html">17th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/06/29/17th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="17th update of 2021 on BlockTrades work on Hive software" /><published>2021-06-29T14:48:42-07:00</published><updated>2021-06-29T14:48:42-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/29/17th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/29/17th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by BlockTrades team during last week or so:

# Hived work (blockchain node software)

Many users last week experienced problems getting their transactions accepted into the blockchain. It turns out there were two separate problems that could cause this issue, but to the outside observer they probably looked much the same:

### Beem had a problem detecting v1.25.0 Hive‚Äôs chainid, leading to invalidly signed transactions

The first problem, discovered a few days ago, was that the python-based Beem API library used by several Hive apps was misdetecting v1.25.0 Hive nodes as Steem nodes, and therefore trying to sign with the wrong chain id. This, in turn, led to Beem-based Hive Apps creating transactions that would be rejected by any Hive node, because the transactions weren‚Äôt properly signed for Hive. 

We assisted Beem developers with identifying the source of the problem and suggested a solution. Beem now checks for the configuration constant HIVE_CHAIN_ID, before it checks for the constant STEEM_CHAIN_ID, giving precedence to Hive nodes over Steem nodes in the detection process and thus using the proper chainid during transaction signing. 

In related work, we replaced the name STEEM_CHAIN_ID with OLD_CHAIN_ID and eliminated some duplicated constant values returned by get_config (but note these changes will not be included in the master branch until after the hardfork, like other changes completed in the last week):
https://gitlab.syncad.com/hive/hive/-/merge_requests/268
https://gitlab.syncad.com/hive/hive/-/merge_requests/267

### Snapshot-based initialization of Hived-nodes requires a restart to properly initialize chainid

The second problem appeared one day later, but a couple of days before the Beem library was updated, so the two problems overlapped in time, and this led to some confusion among app developers as to what was the source of the new problem. 

But by testing against various API nodes, we were able to determine that this second problem, although similar in appearance to the Beem problem, was occurring on non-Beem apps (e.g. hive.blog and peakd) and only occurring when those apps were using api.hive.blog as their API node. Since we hard recently updated the hived nodes on api.hive.blog, I suspected the problem has something to do with the update process.

After comparing update procedures used by other API node operators, I noticed that most of the API node operators had done a replay to update their nodes,  whereas we had updated our internal hived nodes from a snapshot. Ultimately this allowed us to identify a previously undetected error with nodes initialized from a snapshot: the variable that stores the chainid isn‚Äôt part of the database state that gets loaded from the snapshot data and the snapshot loading code didn‚Äôt trigger this variable to be updated. So a node updated in this way would reject validly signed transactions because it was operating with the wrong chainid (essentially the reverse of the Beem problem). 

### Snapshot  workaround

We also found that this improperly set chainid problem was resolved by stopping and restarting the node that was initialized from a snapshot, and that‚Äôs how we have worked around the issue until we release a full fix for snapshot-based node initialization. 

The code fix is currently being implemented and tested, and will be released after the hardfork (to keep things simple, we‚Äôre avoiding making too many changes to the development branch until after the hardfork has triggered).

## Completed hived work

Improvements to Testtools used to verify hived functionality: https://gitlab.syncad.com/hive/hive/-/merge_requests/266

Removed the copy/pasted version of secp256k1 library from hived and replaced with a submodule link:
https://gitlab.syncad.com/hive/hive/-/merge_requests/264

Fixed issue where enum_virtual_ops sometimes returned non-virtual ops: https://gitlab.syncad.com/hive/hive/-/merge_requests/219

We completed work to eliminate duplicated code in the command-line wallet for hived, but we‚Äôre delaying merging those changes into the develop branch until later because of the sheer amount of changes involved. The still-open merge request for that work is here: https://gitlab.syncad.com/hive/hive/-/merge_requests/170

## Continuing work on hived

We‚Äôre working on speeding up the blockchain converter that we‚Äôve developed to initialize and control a testnet configured in basically the same way as a mainnet. This is to allow for more realistic testing inside of a testnet environment (especially for better performance testing). So far, we‚Äôve identified that the performance bottleneck seems to be related to the function that generates nonces.

We‚Äôre continuing to work on the sql serializer plugin for hived that provides data to HAF-based applications. We expecting to complete that work this week, assuming no further distractions arise in the meantime (this work got delayed while we were troubleshooting the snapshot problem), then begin performance testing.

We‚Äôre also continuing to work on the CI system to automate deployment of hived for more strenuous testing scenarios (e.g. long replay testing).


# Hivemind (2nd layer applications + social media middleware)

Fix for previously report list_subscribers bug: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/513

We continue to investigate ways to improve performance of the update_rshares function immediately after massive sync of a hivemind instance. In addition to analyzing the cause of slowness of the current implementation, we‚Äôre also simultaneously looking at two different alternatives to improve overall performance: 1) eliminating the call completing and performing equivalent functionality during live sync  and 2) adding an index (at least temporarily just after massive sync) to speed up update_rshares.

The new index dramatically speeds up performance of update_rshares (time drops from 10 hours to 3 minutes and the index only takes about 10minutes to create), but it consumes 25GB of disk space (hence the idea to drop it after using it).

We‚Äôre still running functional and performance tests related to the broken reputation/ordering issue because of multiple transactions used per block. As part of this work we‚Äôre also adding ‚Äúcompletion markers‚Äù to the database state to better detect any database consistency error that can arise from an abrupt shutdown of postgres (notably, this can happen when postgres does an auto-upgrade for a security fix).

We also resumed research into the reason why some hivemind nodes consume more memory than others. It has been suggested that it may be related to differences in python or python-library installations on the different systems.

# Hive Application Framework

We made good progress last week on both HAF code and the documentation for it, but our main dev for this work is now on vacation until June 19th, at which time the work will resume. 

But in the meantime, we should be able to do performance testing of this code using the new sql_serializer plugin, and I‚Äôm looking forward to seeing just how well we do.

# Reminder: hardfork 25 triggers tomorrow

Witnesses and devs alike will be ‚Äúmanning their keyboards‚Äù tomorrow (June 30th) as hardfork 25 triggers, ready for any potential problems that may arise. The hardfork is scheduled for approximately 14:00 UTC.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/17th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/17th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;17th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by BlockTrades team during last week or so: # Hived work (blockchain node software) Many users last week experienced problems getting their transactions accepted into the blockchain. It turns out there were two separate problems that could cause this issue, but to the outside observer they probably looked much the same: ### Beem had a problem detecting v1.25.0 Hive‚Äôs chainid, leading to invalidly signed transactions The first problem, discovered a few days ago, was that the python-based Beem API library used by several Hive apps was misdetecting v1.25.0 Hive nodes as Steem nodes, and therefore trying to sign with the wrong chain id. This, in turn, led to Beem-based Hive Apps creating transactions that would be rejected by any Hive node, because the transactions weren‚Äôt properly signed for Hive. We assisted Beem developers with identifying the source of the problem and suggested a solution. Beem now checks for the configuration constant HIVE_CHAIN_ID, before it checks for the constant STEEM_CHAIN_ID, giving precedence to Hive nodes over Steem nodes in the detection process and thus using the proper chainid during transaction signing. In related work, we replaced the name STEEM_CHAIN_ID with OLD_CHAIN_ID and eliminated some duplicated constant values returned by get_config (but note these changes will not be included in the master branch until after the hardfork, like other changes completed in the last week): https://gitlab.syncad.com/hive/hive/-/merge_requests/268 https://gitlab.syncad.com/hive/hive/-/merge_requests/267 ### Snapshot-based initialization of Hived-nodes requires a restart to properly initialize chainid The second problem appeared one day later, but a couple of days before the Beem library was updated, so the two problems overlapped in time, and this led to some confusion among app developers as to what was the source of the new problem. But by testing against various API nodes, we were able to determine that this second problem, although similar in appearance to the Beem problem, was occurring on non-Beem apps (e.g. hive.blog and peakd) and only occurring when those apps were using api.hive.blog as their API node. Since we hard recently updated the hived nodes on api.hive.blog, I suspected the problem has something to do with the update process. After comparing update procedures used by other API node operators, I noticed that most of the API node operators had done a replay to update their nodes, whereas we had updated our internal hived nodes from a snapshot. Ultimately this allowed us to identify a previously undetected error with nodes initialized from a snapshot: the variable that stores the chainid isn‚Äôt part of the database state that gets loaded from the snapshot data and the snapshot loading code didn‚Äôt trigger this variable to be updated. So a node updated in this way would reject validly signed transactions because it was operating with the wrong chainid (essentially the reverse of the Beem problem). ### Snapshot workaround We also found that this improperly set chainid problem was resolved by stopping and restarting the node that was initialized from a snapshot, and that‚Äôs how we have worked around the issue until we release a full fix for snapshot-based node initialization. The code fix is currently being implemented and tested, and will be released after the hardfork (to keep things simple, we‚Äôre avoiding making too many changes to the development branch until after the hardfork has triggered). ## Completed hived work Improvements to Testtools used to verify hived functionality: https://gitlab.syncad.com/hive/hive/-/merge_requests/266 Removed the copy/pasted version of secp256k1 library from hived and replaced with a submodule link: https://gitlab.syncad.com/hive/hive/-/merge_requests/264 Fixed issue where enum_virtual_ops sometimes returned non-virtual ops: https://gitlab.syncad.com/hive/hive/-/merge_requests/219 We completed work to eliminate duplicated code in the command-line wallet for hived, but we‚Äôre delaying merging those changes into the develop branch until later because of the sheer amount of changes involved. The still-open merge request for that work is here: https://gitlab.syncad.com/hive/hive/-/merge_requests/170 ## Continuing work on hived We‚Äôre working on speeding up the blockchain converter that we‚Äôve developed to initialize and control a testnet configured in basically the same way as a mainnet. This is to allow for more realistic testing inside of a testnet environment (especially for better performance testing). So far, we‚Äôve identified that the performance bottleneck seems to be related to the function that generates nonces. We‚Äôre continuing to work on the sql serializer plugin for hived that provides data to HAF-based applications. We expecting to complete that work this week, assuming no further distractions arise in the meantime (this work got delayed while we were troubleshooting the snapshot problem), then begin performance testing. We‚Äôre also continuing to work on the CI system to automate deployment of hived for more strenuous testing scenarios (e.g. long replay testing). # Hivemind (2nd layer applications + social media middleware) Fix for previously report list_subscribers bug: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/513 We continue to investigate ways to improve performance of the update_rshares function immediately after massive sync of a hivemind instance. In addition to analyzing the cause of slowness of the current implementation, we‚Äôre also simultaneously looking at two different alternatives to improve overall performance: 1) eliminating the call completing and performing equivalent functionality during live sync and 2) adding an index (at least temporarily just after massive sync) to speed up update_rshares. The new index dramatically speeds up performance of update_rshares (time drops from 10 hours to 3 minutes and the index only takes about 10minutes to create), but it consumes 25GB of disk space (hence the idea to drop it after using it). We‚Äôre still running functional and performance tests related to the broken reputation/ordering issue because of multiple transactions used per block. As part of this work we‚Äôre also adding ‚Äúcompletion markers‚Äù to the database state to better detect any database consistency error that can arise from an abrupt shutdown of postgres (notably, this can happen when postgres does an auto-upgrade for a security fix). We also resumed research into the reason why some hivemind nodes consume more memory than others. It has been suggested that it may be related to differences in python or python-library installations on the different systems. # Hive Application Framework We made good progress last week on both HAF code and the documentation for it, but our main dev for this work is now on vacation until June 19th, at which time the work will resume. But in the meantime, we should be able to do performance testing of this code using the new sql_serializer plugin, and I‚Äôm looking forward to seeing just how well we do. # Reminder: hardfork 25 triggers tomorrow Witnesses and devs alike will be ‚Äúmanning their keyboards‚Äù tomorrow (June 30th) as hardfork 25 triggers, ready for any potential problems that may arise. The hardfork is scheduled for approximately 14:00 UTC. See: 17th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive SQL is ready for the hardfork 25 - Addendum</title><link href="https://hivedocs.info/news/sql/database/2021/06/29/hivesql-hf25-addendum.html" rel="alternate" type="text/html" title="Hive SQL is ready for the hardfork 25 - Addendum" /><published>2021-06-29T07:45:54-07:00</published><updated>2021-06-29T07:45:54-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/06/29/hivesql-hf25-addendum</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/06/29/hivesql-hf25-addendum.html">&lt;div id=&quot;content-arcange-hivesql-hf25-addendum&quot;&gt;![](https://i.imgur.com/B5TI37I.png)

The hardfork 25 (codename Equilibrium) should be activated in a few hours (less than 22 but many more than 2 at time of writing üòÅ) as all top 20 witnesses are now running the v1.25 code on their nodes ([see here](https://hive.arcange.eu/witnesses)).

My API servers have also been upgraded to the new code and are now providing HiveSQL with new data. Therefore, I added a few updates to the HiveSQL database.

## What's new?

### 1. Existing table updates

* **DynamicGlobalProperties**

New columns

|Column|Description|
|-|-|
|current_remove_threshold|number of objects that can be removed in one automatic operation (only applies to situations where many objects can accumulate over time but need to be removed in a single operation f.e. proposal votes)|
|early_voting_seconds|Duration of the first period where all votes are considered equally regarding vote time and the linear rewards curve is applied (equal weight to all voters in that window) - currently 24 hours|
|mid_voting_seconds|Duration of the second period where with reward weight/2 is applied - currently 48 hours|
|max_consecutive_recurrent_transfer_failures|Maximum number of consecutive failures for a recurring transfer before it is automatically canceled |
|max_recurrent_transfer_end_date|Maximum difference between start and end of a recurring payment - currently 730 days (2 years)|
|min_recurrent_transfers_recurrence|Minimum time to elapse between two recurring transfer - currently 24 hours|
|max_open_recurrent_transfers|Maximum number of recurring payments that can be scheduled for execution per account - currently 255|


* **Account**

New columns

|Column|Description|
|-|-|
|post_voting_power|Effective HP that are used for curation (vesting_shares - delegated_vesting_shares + received_vesting_shares)|
|post_voting_power_symbol|VESTS|
|pending_transfers|Pending transfers for escrow operations|
|governance_vote_expiration_ts|date and time that the account governance votes for witnesses and proposals will expire|
|delayed_votes_time|date and time that the additional HP recently powered up will be taken into account for governance|
|delayed_votes_val|value of the additional HP that will be taken into account for governance after delay|
|open_recurrent_transfers|Number of recurring transfers scheduled for execution|


## Documentation

HiveSQL documentation has been updated and can be viewed at https://docs.hivesql.io

## Support

If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT).

**Happy Hardfork 25!**

---
&lt;sub&gt; 

#### &lt;center&gt;Check out my apps and services
&lt;a href=&quot;/hive/@hive.engage/stay-connected-with-your-hive-audience-and-catch-attention&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GiNJqlm.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivebuzz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/B4UTun2.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivesql&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EPN8RW6.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/hive/@arcange/introducing-hive-account-recovery&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6TWeW7V.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hive.autoclaim&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ih2pEOw.png&quot; /&gt;&lt;/a&gt;&lt;/center&gt;
&lt;center&gt;

### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@arcange&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hivesql-hf25-addendum&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-arcange-hivesql-hf25-addendum').html();
      const outputElem = $('#content-arcange-hivesql-hf25-addendum');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-arcange-hivesql-hf25-addendum {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-arcange-hivesql-hf25-addendum code {
    background: white;
  }
  #content-arcange-hivesql-hf25-addendum a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-arcange-hivesql-hf25-addendum a:hover {
    border-bottom: 0;
  }
  #content-arcange-hivesql-hf25-addendum h1 {
    font-size: 2.2em;
  }
  #content-arcange-hivesql-hf25-addendum h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-arcange-hivesql-hf25-addendum header small {
    color: #999;
    font-size: 50%;
  }
  #content-arcange-hivesql-hf25-addendum img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@arcange/hivesql-hf25-addendum&quot;&gt;Hive SQL is ready for the hardfork 25 - Addendum&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@arcange&quot;&gt;@arcange&lt;/a&gt;
&lt;/p&gt;

&lt;/center&gt;&lt;/sub&gt;&lt;/div&gt;</content><author><name>arcange</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![](https://i.imgur.com/B5TI37I.png) The hardfork 25 (codename Equilibrium) should be activated in a few hours (less than 22 but many more than 2 at time of writing üòÅ) as all top 20 witnesses are now running the v1.25 code on their nodes ([see here](https://hive.arcange.eu/witnesses)). My API servers have also been upgraded to the new code and are now providing HiveSQL with new data. Therefore, I added a few updates to the HiveSQL database. ## What's new? ### 1. Existing table updates * **DynamicGlobalProperties** New columns |Column|Description| |-|-| |current_remove_threshold|number of objects that can be removed in one automatic operation (only applies to situations where many objects can accumulate over time but need to be removed in a single operation f.e. proposal votes)| |early_voting_seconds|Duration of the first period where all votes are considered equally regarding vote time and the linear rewards curve is applied (equal weight to all voters in that window) - currently 24 hours| |mid_voting_seconds|Duration of the second period where with reward weight/2 is applied - currently 48 hours| |max_consecutive_recurrent_transfer_failures|Maximum number of consecutive failures for a recurring transfer before it is automatically canceled | |max_recurrent_transfer_end_date|Maximum difference between start and end of a recurring payment - currently 730 days (2 years)| |min_recurrent_transfers_recurrence|Minimum time to elapse between two recurring transfer - currently 24 hours| |max_open_recurrent_transfers|Maximum number of recurring payments that can be scheduled for execution per account - currently 255| * **Account** New columns |Column|Description| |-|-| |post_voting_power|Effective HP that are used for curation (vesting_shares - delegated_vesting_shares + received_vesting_shares)| |post_voting_power_symbol|VESTS| |pending_transfers|Pending transfers for escrow operations| |governance_vote_expiration_ts|date and time that the account governance votes for witnesses and proposals will expire| |delayed_votes_time|date and time that the additional HP recently powered up will be taken into account for governance| |delayed_votes_val|value of the additional HP that will be taken into account for governance after delay| |open_recurrent_transfers|Number of recurring transfers scheduled for execution| ## Documentation HiveSQL documentation has been updated and can be viewed at https://docs.hivesql.io ## Support If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT). **Happy Hardfork 25!** --- #### Check out my apps and services ### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt; See: Hive SQL is ready for the hardfork 25 - Addendum by @arcange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/B5TI37I.png" /><media:content medium="image" url="https://i.imgur.com/B5TI37I.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive core developer meeting #25</title><link href="https://hivedocs.info/news/core/development/2021/06/22/hive-core-developer-meeting-25.html" rel="alternate" type="text/html" title="Hive core developer meeting #25" /><published>2021-06-22T12:40:21-07:00</published><updated>2021-06-22T12:40:21-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/22/hive-core-developer-meeting-25</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/22/hive-core-developer-meeting-25.html">&lt;div id=&quot;content-howo-hive-core-developer-meeting-25&quot;&gt;https://www.youtube.com/watch?v=D2iS7B7-8rg

I basically recommend that you listen to the whole thing, usually it's pretty easy to tl;dr but on this one we talk about a lot of various subjects that are basically dev/testnet sync.

Topics touched upon
Dev sync
Testnet sync
future testnet that mirrors the main net even more closely
List of tests/cases to focus on for remainder of testing.
State of libraries/key dapps/services ahead of HF -- ready?

as always if you have questions, feel free to ask them in the comments :)

@howo&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@howo&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-core-developer-meeting-25&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-howo-hive-core-developer-meeting-25').html();
      const outputElem = $('#content-howo-hive-core-developer-meeting-25');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-howo-hive-core-developer-meeting-25 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-howo-hive-core-developer-meeting-25 code {
    background: white;
  }
  #content-howo-hive-core-developer-meeting-25 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-howo-hive-core-developer-meeting-25 a:hover {
    border-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-25 h1 {
    font-size: 2.2em;
  }
  #content-howo-hive-core-developer-meeting-25 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-25 header small {
    color: #999;
    font-size: 50%;
  }
  #content-howo-hive-core-developer-meeting-25 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/meeting/@howo/hive-core-developer-meeting-25&quot;&gt;Hive core developer meeting #25&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@howo&quot;&gt;@howo&lt;/a&gt;
&lt;/p&gt;</content><author><name>howo</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">https://www.youtube.com/watch?v=D2iS7B7-8rg I basically recommend that you listen to the whole thing, usually it's pretty easy to tl;dr but on this one we talk about a lot of various subjects that are basically dev/testnet sync. Topics touched upon Dev sync Testnet sync future testnet that mirrors the main net even more closely List of tests/cases to focus on for remainder of testing. State of libraries/key dapps/services ahead of HF -- ready? as always if you have questions, feel free to ask them in the comments :) @howo See: Hive core developer meeting #25 by @howo</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">16th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/06/20/16th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="16th update of 2021 on BlockTrades work on Hive software" /><published>2021-06-20T18:24:24-07:00</published><updated>2021-06-20T18:24:24-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/20/16th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/20/16th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by BlockTrades team during the last week or so:

# Hived work (blockchain node software)

## Official release of Equilibrium (hived code for hardfork 25)

Last week we merged all develop branch changes since the last hardfork into the master branch and tagged an official release of hived (v1.25.0). The ‚Äúcode name‚Äù for this release is ‚ÄúEquilibrium‚Äù. 

 For the official press release associated with the new release and details about associated functional changes, see https://hive.blog/hive/@hiveio/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021

The [release notes for Equilibrium](https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0) represent a concise summary of virtually all changes that were made as part of this hardfork, along with links to review the code associated with each individual change. 

Alternatively, you can inspect [a diff with the totality of changes for this hardfork](https://gitlab.syncad.com/hive/hive/-/merge_requests/262/diffs).


## Other hived work last week

We continued performance testing of the new ‚Äúrecurrent transfers‚Äù feature written by @howo. As a side note, based on some discussion among various devs, I believe Hive frontends will use the term ‚Äúrecurring payments‚Äù to refer to the ‚Äúrecurrent transfers‚Äù feature, since that is the name most commonly used in the business world for this type of functionality.

During our still incomplete testing, we found some areas where the new ‚Äútest tools‚Äù framework that is being used to create and test massive numbers of recurrent transfers could be improved to make it faster and more stable:
https://gitlab.syncad.com/hive/hive/-/merge_requests/257
https://gitlab.syncad.com/hive/hive/-/merge_requests/263

Here‚Äôs a short list of other work done on hived:

* Fixed two unit tests that we previously had to disable and re-enabled them: https://gitlab.syncad.com/hive/hive/-/merge_requests/259
* Added a new command-line option ‚Äìexit-before-sync for configuring hived to a predictable state for running a replay or creating a statefile dump, then ending the hived process. This is useful for setting up test scenarios. https://gitlab.syncad.com/hive/hive/-/merge_requests/232
* Added new regression tests to test recent changes to last irreversible block handling (a change that was made to fix a longstanding bug with duplicate transactions in the account history plugin): https://gitlab.syncad.com/hive/hive/-/merge_requests/252
* Fixed an intermittent crash on application shutdown: https://gitlab.syncad.com/hive/hive/-/merge_requests/253
* Documentation cleanup: https://gitlab.syncad.com/hive/hive/-/merge_requests/258
*   Implemented option for automatic spawning of hived replays within our continuous integration system  (done off main servers to avoid breaking or interrupting primary development CI system).

# Hivemind (2nd layer applications + social media middleware)

* Added tests for recent changes in behavior of setLastRead operation: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/511
* Explicit specification of package versions to be used when building hivemind to avoid potential headaches when package dependencies are updated: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/498
* Update CodeQL analysis configuration: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/509
* We‚Äôre currently investigating ways to improve performance of the `update_rshares` function immediately after massive sync of a hivemind instance.
*  Fixed &quot;broken reputation&quot; problem related to ordering issue because of multiple transactions used per block. This was known to impact the calculation of reputation for at least two Hive users.
*   list_subscribers bug being worked on (tests being created first).

# Hive Application Framework

The current implementation of the Hive Application Framework requires applications to mark their constraints as DEFERRABLE to enable HAF apps to use the auto-rewind feature when a fork switch occurs. 

While this may be an acceptable limitation on the design of HAF-based apps, we decided to create an alternative implementation of HAF without that limitation and measure the performance of the two alternative designs. The ongoing discussion of this topic can be found in the latest comments attached to the still open HAF merge request: https://gitlab.syncad.com/hive/psql_tools/-/merge_requests/1

# Upcoming work in the next week

* Continue performance testing of recurring payments functionality in hived.
* Complete psql_serializer updates and begin testing hived+psql_serializer with hivemind. This is a prerequisite for testing the entire HAF code base.
* More work and testing of the Hive Application Framework (HAF), including more documentation and example HAF-based applications.
* Finish up fix for list_subscribers.
* Work with witnesses to collect performance statistics for the Equilibrium release on different hardware configurations. 

On a related note,  @drakos noted a significant performance improvement in the speed of creating statefile snapshots and @gtg has confirmed the same findings on his system. Gandalf reports v1.24.8 took 4866 seconds whereas v1.25.0 was able to complete this task in only 3134 seconds.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/16th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/16th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;16th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by BlockTrades team during the last week or so: # Hived work (blockchain node software) ## Official release of Equilibrium (hived code for hardfork 25) Last week we merged all develop branch changes since the last hardfork into the master branch and tagged an official release of hived (v1.25.0). The ‚Äúcode name‚Äù for this release is ‚ÄúEquilibrium‚Äù. For the official press release associated with the new release and details about associated functional changes, see https://hive.blog/hive/@hiveio/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 The [release notes for Equilibrium](https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0) represent a concise summary of virtually all changes that were made as part of this hardfork, along with links to review the code associated with each individual change. Alternatively, you can inspect [a diff with the totality of changes for this hardfork](https://gitlab.syncad.com/hive/hive/-/merge_requests/262/diffs). ## Other hived work last week We continued performance testing of the new ‚Äúrecurrent transfers‚Äù feature written by @howo. As a side note, based on some discussion among various devs, I believe Hive frontends will use the term ‚Äúrecurring payments‚Äù to refer to the ‚Äúrecurrent transfers‚Äù feature, since that is the name most commonly used in the business world for this type of functionality. During our still incomplete testing, we found some areas where the new ‚Äútest tools‚Äù framework that is being used to create and test massive numbers of recurrent transfers could be improved to make it faster and more stable: https://gitlab.syncad.com/hive/hive/-/merge_requests/257 https://gitlab.syncad.com/hive/hive/-/merge_requests/263 Here‚Äôs a short list of other work done on hived: * Fixed two unit tests that we previously had to disable and re-enabled them: https://gitlab.syncad.com/hive/hive/-/merge_requests/259 * Added a new command-line option ‚Äìexit-before-sync for configuring hived to a predictable state for running a replay or creating a statefile dump, then ending the hived process. This is useful for setting up test scenarios. https://gitlab.syncad.com/hive/hive/-/merge_requests/232 * Added new regression tests to test recent changes to last irreversible block handling (a change that was made to fix a longstanding bug with duplicate transactions in the account history plugin): https://gitlab.syncad.com/hive/hive/-/merge_requests/252 * Fixed an intermittent crash on application shutdown: https://gitlab.syncad.com/hive/hive/-/merge_requests/253 * Documentation cleanup: https://gitlab.syncad.com/hive/hive/-/merge_requests/258 * Implemented option for automatic spawning of hived replays within our continuous integration system (done off main servers to avoid breaking or interrupting primary development CI system). # Hivemind (2nd layer applications + social media middleware) * Added tests for recent changes in behavior of setLastRead operation: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/511 * Explicit specification of package versions to be used when building hivemind to avoid potential headaches when package dependencies are updated: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/498 * Update CodeQL analysis configuration: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/509 * We‚Äôre currently investigating ways to improve performance of the `update_rshares` function immediately after massive sync of a hivemind instance. * Fixed &quot;broken reputation&quot; problem related to ordering issue because of multiple transactions used per block. This was known to impact the calculation of reputation for at least two Hive users. * list_subscribers bug being worked on (tests being created first). # Hive Application Framework The current implementation of the Hive Application Framework requires applications to mark their constraints as DEFERRABLE to enable HAF apps to use the auto-rewind feature when a fork switch occurs. While this may be an acceptable limitation on the design of HAF-based apps, we decided to create an alternative implementation of HAF without that limitation and measure the performance of the two alternative designs. The ongoing discussion of this topic can be found in the latest comments attached to the still open HAF merge request: https://gitlab.syncad.com/hive/psql_tools/-/merge_requests/1 # Upcoming work in the next week * Continue performance testing of recurring payments functionality in hived. * Complete psql_serializer updates and begin testing hived+psql_serializer with hivemind. This is a prerequisite for testing the entire HAF code base. * More work and testing of the Hive Application Framework (HAF), including more documentation and example HAF-based applications. * Finish up fix for list_subscribers. * Work with witnesses to collect performance statistics for the Equilibrium release on different hardware configurations. On a related note, @drakos noted a significant performance improvement in the speed of creating statefile snapshots and @gtg has confirmed the same findings on his system. Gandalf reports v1.24.8 took 4866 seconds whereas v1.25.0 was able to complete this task in only 3134 seconds. See: 16th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive Hardfork 25 is on the Way: Hive to reach Equilibrium on June 30th, 2021</title><link href="https://hivedocs.info/news/core/development/2021/06/19/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021.html" rel="alternate" type="text/html" title="Hive Hardfork 25 is on the Way: Hive to reach Equilibrium on June 30th, 2021" /><published>2021-06-19T17:10:27-07:00</published><updated>2021-06-19T17:10:27-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/19/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/19/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021.html">&lt;div id=&quot;content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021&quot;&gt;![image.png](https://images.hive.blog/DQmfByqFD7d9ecpcYMhy7ucwhQLKKrrLjcp9vb378wSJwCP/image.png)

Earlier this week we notified cryptocurrency exchanges that the upcoming hardfork to the Hive blockchain network, dubbed *Equilibrium*, is planned for the end of June. 

Today's official date announcement also has a pile of helpful information including a summary of changes coming with the new hardfork, links to the software, and details for those of you who may want to get involved in testing the new software!

## TL:DR the Code; A Quick Overview of the Upcoming Changes

*Equilibrium* is a state of balance between multiple forces. In the case of the Hive blockchain network, the guiding mission from day one has been to create an ecosystem that allows anyone to become a part of our decentralized network, contribute to governance, and to own their data, connections, tokens and actions in a world where the current tech and social powers have an iron grip. 

This hardfork continues to empower people to use Hive the way they want and takes another few large steps forward in creating an ecosystem with better balanced rules and tools for building whatever we can dream up. 

Reaching equilibrium is finding a state of balance and readiness. It is the essential preparation for big moves, exciting changes, and sustained growth.

### Here's a quick summary of HF25:

Below is a list of the consensus changes that are being made as part of this hardfork:

- **changes to curation window and curation rewards calculation**
    - The most important aspect of this change is that the 5 minute reverse auction is going away, so there is no punishment for voting early. This will finally put manual voters on an equal footing with automated voters when it comes to competing for curation rewards. This change, more than any other, was the driving reason for the naming of this hardfork.
    - In addition, anyone voting in the first 24 hours will be rewarded based solely on their Hive Power and vote weight, and the reward curve applied from 24 hours to the end of the voting window will be much softer than currently, eliminating any need to feel rushed when voting in order to maximize curation rewards.
- **new operation and API to convert HIVE to HBD**
    - HBD (Hive-backed Dollars) is intended to be a feeless, trustless, USD-pegged stablecoin, a feat that has yet to be achieved in the cryptocurrency world. This new operation will stabilize the price pegging of HBD, allowing it to achieve its full potential as a frictionless medium of exchange for digital commerce.
    - While you've always been able to convert your HBD to HIVE, this new operation will allow you to convert in the opposite direction (HIVE -&amp;gt; HBD). 
    - Previously, HBD was only effectively price-pegged on the low side of USD pricing. This new conversion will create an equilibrium point where HBD will be pegged on both the low side AND the high side.
    
- **interest only paid on HBD held in your savings account**
    - You might have missed that you're earning interest on your Hive-backed Dollars, so this could be a neat surprise: simply move HBD into your savings account (3 day withdrawal waiting period) to earn interest on it just for holding! No-risk DeFi, made easy.
- **new operation and API to enable recurring payments**
    - These are periodic transfers which you schedule to happen automatically. They are intended for managing subscription payments, etc.
- **disallow voting on expired proposals**
- **witness and proposal votes by an account expire after one year if the account stops actively making governance-related votes**
    - This change was made to ensure that old votes from dormant accounts don't unduly impact governance decisions for Hive. It will enable Hive to find a new balance between incumbent block producers and new competitors for those positions.
- **proposal creators can change the end date of their Decentralized Hive Fund (DHF) proposals**
    - This allows a proposal creator to reduce their funding request (by decreasing the number of payments they receive) without having to create a new proposal and start from zero in respect to community support for the proposal.
- **re-allow vote operation for already paid posts**
    - Voting outside the rewards window should still be something you can do, to show appreciation for the content you like and to add to your curated feed. This is a quality of life change that does *not* impact anything to do with allocation of rewards. 

There are also new command-line options, a pile of bug fixes and performance optimizations, a new API call, and many other improvements to the code and documentation that the Hive blockchain relies on. Full details are available in the [release notes](https://gitlab.syncad.com/hive/hive/-/releases#v1.25.0) This is pretty critical work towards making it easier to understand, easier to run, and to create the best possible ecosystem for someone to hop in and start building with Hive.

If you're not technical and don't want to do some hands-on testing, you're all caught up! You likely won't notice anything immediately when *Equilibrium* goes live. 

However, you may want to consider changing the way you vote for posts after the hardfork, especially if you've resorted to auto-voting to maximize your curation rewards. Now you'll have more time and flexibility to find the content you love in a relaxed way, and more time to engage with your favorite authors and communities!

### In the next 12 days...

There is still time before the hardfork takes place. If you want to contribute to testing or if you are a dApp creator, project owner, or someone who just wants to start getting more involved with the ecosystem, here are some handy links so you can jump in before *Equilibrium* goes live.

## Some Technical ~~House~~Beekeeping

**Here is the link to the final official release version of Hardfork 25:**
https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0

...and here are some helpful posts that outline joining the testnet, including how to create a witness node on the testnet, if you want to dive into the decentralized tech that powers Hive.

**A guide to starting up a testnet witness:**
https://peakd.com/guide/@howo/how-to-run-a-witness-node-on-the-hf25-testnet

**And more information on the public testnet itself:**
https://peakd.com/@gtg/hf25-public-testnet-reloaded-rc2

**The testnet faucet page:**
https://hivetestnetfaucet.org/

All dApps that rely on the functions outlined above should have started testing or be starting to test as soon as possible. 

*Equilibrium* is the second community-driven hardfork of the Hive blockchain and we are very excited for it! It marks a key milestone for Hive development and for the Hive ecosystem. 

### Keep an eye out for updates here and on our various Hive social media channels! üêù&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@hiveio&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021').html();
      const outputElem = $('#content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 code {
    background: white;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 a:hover {
    border-bottom: 0;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 h1 {
    font-size: 2.2em;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 header small {
    color: #999;
    font-size: 50%;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive/@hiveio/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021&quot;&gt;Hive Hardfork 25 is on the Way: Hive to reach Equilibrium on June 30th, 2021&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@hiveio&quot;&gt;@hiveio&lt;/a&gt;
&lt;/p&gt;</content><author><name>hiveio</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![image.png](https://images.hive.blog/DQmfByqFD7d9ecpcYMhy7ucwhQLKKrrLjcp9vb378wSJwCP/image.png) Earlier this week we notified cryptocurrency exchanges that the upcoming hardfork to the Hive blockchain network, dubbed *Equilibrium*, is planned for the end of June. Today's official date announcement also has a pile of helpful information including a summary of changes coming with the new hardfork, links to the software, and details for those of you who may want to get involved in testing the new software! ## TL:DR the Code; A Quick Overview of the Upcoming Changes *Equilibrium* is a state of balance between multiple forces. In the case of the Hive blockchain network, the guiding mission from day one has been to create an ecosystem that allows anyone to become a part of our decentralized network, contribute to governance, and to own their data, connections, tokens and actions in a world where the current tech and social powers have an iron grip. This hardfork continues to empower people to use Hive the way they want and takes another few large steps forward in creating an ecosystem with better balanced rules and tools for building whatever we can dream up. Reaching equilibrium is finding a state of balance and readiness. It is the essential preparation for big moves, exciting changes, and sustained growth. ### Here's a quick summary of HF25: Below is a list of the consensus changes that are being made as part of this hardfork: - **changes to curation window and curation rewards calculation** - The most important aspect of this change is that the 5 minute reverse auction is going away, so there is no punishment for voting early. This will finally put manual voters on an equal footing with automated voters when it comes to competing for curation rewards. This change, more than any other, was the driving reason for the naming of this hardfork. - In addition, anyone voting in the first 24 hours will be rewarded based solely on their Hive Power and vote weight, and the reward curve applied from 24 hours to the end of the voting window will be much softer than currently, eliminating any need to feel rushed when voting in order to maximize curation rewards. - **new operation and API to convert HIVE to HBD** - HBD (Hive-backed Dollars) is intended to be a feeless, trustless, USD-pegged stablecoin, a feat that has yet to be achieved in the cryptocurrency world. This new operation will stabilize the price pegging of HBD, allowing it to achieve its full potential as a frictionless medium of exchange for digital commerce. - While you've always been able to convert your HBD to HIVE, this new operation will allow you to convert in the opposite direction (HIVE -&amp;gt; HBD). - Previously, HBD was only effectively price-pegged on the low side of USD pricing. This new conversion will create an equilibrium point where HBD will be pegged on both the low side AND the high side. - **interest only paid on HBD held in your savings account** - You might have missed that you're earning interest on your Hive-backed Dollars, so this could be a neat surprise: simply move HBD into your savings account (3 day withdrawal waiting period) to earn interest on it just for holding! No-risk DeFi, made easy. - **new operation and API to enable recurring payments** - These are periodic transfers which you schedule to happen automatically. They are intended for managing subscription payments, etc. - **disallow voting on expired proposals** - **witness and proposal votes by an account expire after one year if the account stops actively making governance-related votes** - This change was made to ensure that old votes from dormant accounts don't unduly impact governance decisions for Hive. It will enable Hive to find a new balance between incumbent block producers and new competitors for those positions. - **proposal creators can change the end date of their Decentralized Hive Fund (DHF) proposals** - This allows a proposal creator to reduce their funding request (by decreasing the number of payments they receive) without having to create a new proposal and start from zero in respect to community support for the proposal. - **re-allow vote operation for already paid posts** - Voting outside the rewards window should still be something you can do, to show appreciation for the content you like and to add to your curated feed. This is a quality of life change that does *not* impact anything to do with allocation of rewards. There are also new command-line options, a pile of bug fixes and performance optimizations, a new API call, and many other improvements to the code and documentation that the Hive blockchain relies on. Full details are available in the [release notes](https://gitlab.syncad.com/hive/hive/-/releases#v1.25.0) This is pretty critical work towards making it easier to understand, easier to run, and to create the best possible ecosystem for someone to hop in and start building with Hive. If you're not technical and don't want to do some hands-on testing, you're all caught up! You likely won't notice anything immediately when *Equilibrium* goes live. However, you may want to consider changing the way you vote for posts after the hardfork, especially if you've resorted to auto-voting to maximize your curation rewards. Now you'll have more time and flexibility to find the content you love in a relaxed way, and more time to engage with your favorite authors and communities! ### In the next 12 days... There is still time before the hardfork takes place. If you want to contribute to testing or if you are a dApp creator, project owner, or someone who just wants to start getting more involved with the ecosystem, here are some handy links so you can jump in before *Equilibrium* goes live. ## Some Technical ~~House~~Beekeeping **Here is the link to the final official release version of Hardfork 25:** https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0 ...and here are some helpful posts that outline joining the testnet, including how to create a witness node on the testnet, if you want to dive into the decentralized tech that powers Hive. **A guide to starting up a testnet witness:** https://peakd.com/guide/@howo/how-to-run-a-witness-node-on-the-hf25-testnet **And more information on the public testnet itself:** https://peakd.com/@gtg/hf25-public-testnet-reloaded-rc2 **The testnet faucet page:** https://hivetestnetfaucet.org/ All dApps that rely on the functions outlined above should have started testing or be starting to test as soon as possible. *Equilibrium* is the second community-driven hardfork of the Hive blockchain and we are very excited for it! It marks a key milestone for Hive development and for the Hive ecosystem. ### Keep an eye out for updates here and on our various Hive social media channels! üêù See: Hive Hardfork 25 is on the Way: Hive to reach Equilibrium on June 30th, 2021 by @hiveio</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmfByqFD7d9ecpcYMhy7ucwhQLKKrrLjcp9vb378wSJwCP/image.png" /><media:content medium="image" url="https://images.hive.blog/DQmfByqFD7d9ecpcYMhy7ucwhQLKKrrLjcp9vb378wSJwCP/image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive HardFork 25 Jump Starter Kit</title><link href="https://hivedocs.info/howto/devops/2021/06/18/hive-hardfork-25-jump-starter-kit.html" rel="alternate" type="text/html" title="Hive HardFork 25 Jump Starter Kit" /><published>2021-06-18T12:31:45-07:00</published><updated>2021-06-18T12:31:45-07:00</updated><id>https://hivedocs.info/howto/devops/2021/06/18/hive-hardfork-25-jump-starter-kit</id><content type="html" xml:base="https://hivedocs.info/howto/devops/2021/06/18/hive-hardfork-25-jump-starter-kit.html">&lt;div id=&quot;content-gtg-hive-hardfork-25-jump-starter-kit&quot;&gt;Intended for the Hive API node operators, witnesses, and developers.

At the time of Eclipse release I made a similar post that saved many (hours) of lives, so I‚Äôm creating an updated one for the upcoming Hard Fork 25.

&lt;center&gt;https://www.youtube.com/watch?v=mrwgrOhl7Yw&lt;/center&gt;&lt;sup&gt;Yes, new Hive Hard Fork, new fancy logo reveal.&lt;/sup&gt;

# Code
## GitLab
https://gitlab.syncad.com/hive/hive
Our core development efforts takes place in a community hosted GitLab repository (thanks @blocktrades). There's Hive core itself, but also many other Hive related software repositories.

## GitHub
https://github.com/openhive-network/hive
We use it as a push mirror for GitLab repository, mostly for visibility and decentralization - if you have an account on GitHub please fork at least [hive](https://github.com/openhive-network/hive) and [hivemind](https://github.com/openhive-network/hivemind) and star them if you haven‚Äôt done so yet. We haven't paid much attention to it but apparently it's important for some outside metrics.

&lt;center&gt;![star_fork.png](https://images.hive.blog/DQmQbRRrtoTFPZA9QmDRjvswPtaGuXrWXje1WHp9CeeGbV2/star_fork.png)
&lt;sup&gt;Please click both buttons&lt;/sup&gt;&lt;/center&gt;

# Services
## API node
https://api.openhive.network
Soon to be switched to `v1.25.0` but because it‚Äôs heavily used in Hive related R&amp;amp;D it might not be your best choice if you are looking for a fast API node without any rate limiting. During the maintenance mode, it will fall back to https://api.hive.blog 

## Seed node
`hived` `v1.25.0` listens on `gtg.openhive.network:2001`
to use it in your `config.ini` file just add the line:
```
p2p-seed-node = gtg.openhive.network:2001
```
If you don't have any `p2p-seed-node = ` entries in your config file, built-in defaults will be used (which contains my node too).

# Stuff for download
TL;DR https://gtg.openhive.network/get

## Binaries
`./get/bin`contains `hived` and `cli_wallet` binaries built on `Ubuntu 18.04 LTS` which should also run fine on `Ubuntu 20.04 LTS`

## Blocks
`./get/blockchain`
As usual, the `block_log` file, roughly 350GB and counting.
For testing needs there's also `block_log.5M` that is limited to first 5 million blocks.

## Snapshots

### API
`./get/snapshot/api/` contains a relatively recent snapshot of the API node with all the fancy plugins.
There‚Äôs a snapshot for the upcoming version `v1.25.0` but also for the old one `v1.24.8` if you need to switch back.
Uncompressed snapshot takes roughly 480GB
There‚Äôs also the `example-api-config.ini` file out there that contains settings compatible with the snapshot.

To decompress, you can use simply run it through something like: `lbzip2 -dc | tar xv`
(Using parallel bzip2 on multi-threaded systems might save you a lot of time)

To use snapshot you need:
- A `block_log` file, not smaller than the one used when the snapshot was made.
- A `config.ini` file, compatible with the snapshot (see above), adjusted to your needs, without changes that could affect it in a way that changes the state.
- A `hived` binary compatible with the snapshot

All of that you can find above.

 Run `hived` with `--load-snapshot name`, assuming the snapshot is stored in `snapshot/name`

`hived` API node runtime currently takes 823GB (incl. shm 19GB, excl. snapshot)

### Exchanges
There‚Äôs also a snapshot meant for exchanges in `./get/snapshot/exchange/`  that allows them to quickly get up and running, it requires a compatible configuration and that exchange account is one of those who are tracked by my node. If you run an exchange and want to be on that list to use a snapshot, just please let me know.

## Hivemind database dump
`./get/hivemind/` contains a relatively recent dump of the Hivemind database.
I use self-describing file names such as:
`hivemind-20210616-47a41c96.dump`
Date when dump was taken, revision of `hivemind` that was running it.
You need at least that version, remember about `intarray` extension
Consider running `pg_restore` with at least `-j 6` to run long running tasks in parallel
After restoring the database, make sure to run the `db_upgrade` script.

Even though during full sync database size peaks easily over 750GB, when restored from dump it takes roughly 500GB. Dump file itself is just 53GB.

### All resources are offered AS IS.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@gtg&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-hardfork-25-jump-starter-kit&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-gtg-hive-hardfork-25-jump-starter-kit').html();
      const outputElem = $('#content-gtg-hive-hardfork-25-jump-starter-kit');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-gtg-hive-hardfork-25-jump-starter-kit {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit code {
    background: white;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit a:hover {
    border-bottom: 0;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit h1 {
    font-size: 2.2em;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit header small {
    color: #999;
    font-size: 50%;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-160391/@gtg/hive-hardfork-25-jump-starter-kit&quot;&gt;Hive HardFork 25 Jump Starter Kit&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@gtg&quot;&gt;@gtg&lt;/a&gt;
&lt;/p&gt;</content><author><name>gtg</name></author><category term="howto" /><category term="devops" /><summary type="html">Intended for the Hive API node operators, witnesses, and developers. At the time of Eclipse release I made a similar post that saved many (hours) of lives, so I‚Äôm creating an updated one for the upcoming Hard Fork 25. https://www.youtube.com/watch?v=mrwgrOhl7YwYes, new Hive Hard Fork, new fancy logo reveal. # Code ## GitLab https://gitlab.syncad.com/hive/hive Our core development efforts takes place in a community hosted GitLab repository (thanks @blocktrades). There's Hive core itself, but also many other Hive related software repositories. ## GitHub https://github.com/openhive-network/hive We use it as a push mirror for GitLab repository, mostly for visibility and decentralization - if you have an account on GitHub please fork at least [hive](https://github.com/openhive-network/hive) and [hivemind](https://github.com/openhive-network/hivemind) and star them if you haven‚Äôt done so yet. We haven't paid much attention to it but apparently it's important for some outside metrics. ![star_fork.png](https://images.hive.blog/DQmQbRRrtoTFPZA9QmDRjvswPtaGuXrWXje1WHp9CeeGbV2/star_fork.png) Please click both buttons # Services ## API node https://api.openhive.network Soon to be switched to `v1.25.0` but because it‚Äôs heavily used in Hive related R&amp;amp;D it might not be your best choice if you are looking for a fast API node without any rate limiting. During the maintenance mode, it will fall back to https://api.hive.blog ## Seed node `hived` `v1.25.0` listens on `gtg.openhive.network:2001` to use it in your `config.ini` file just add the line: ``` p2p-seed-node = gtg.openhive.network:2001 ``` If you don't have any `p2p-seed-node = ` entries in your config file, built-in defaults will be used (which contains my node too). # Stuff for download TL;DR https://gtg.openhive.network/get ## Binaries `./get/bin`contains `hived` and `cli_wallet` binaries built on `Ubuntu 18.04 LTS` which should also run fine on `Ubuntu 20.04 LTS` ## Blocks `./get/blockchain` As usual, the `block_log` file, roughly 350GB and counting. For testing needs there's also `block_log.5M` that is limited to first 5 million blocks. ## Snapshots ### API `./get/snapshot/api/` contains a relatively recent snapshot of the API node with all the fancy plugins. There‚Äôs a snapshot for the upcoming version `v1.25.0` but also for the old one `v1.24.8` if you need to switch back. Uncompressed snapshot takes roughly 480GB There‚Äôs also the `example-api-config.ini` file out there that contains settings compatible with the snapshot. To decompress, you can use simply run it through something like: `lbzip2 -dc | tar xv` (Using parallel bzip2 on multi-threaded systems might save you a lot of time) To use snapshot you need: - A `block_log` file, not smaller than the one used when the snapshot was made. - A `config.ini` file, compatible with the snapshot (see above), adjusted to your needs, without changes that could affect it in a way that changes the state. - A `hived` binary compatible with the snapshot All of that you can find above. Run `hived` with `--load-snapshot name`, assuming the snapshot is stored in `snapshot/name` `hived` API node runtime currently takes 823GB (incl. shm 19GB, excl. snapshot) ### Exchanges There‚Äôs also a snapshot meant for exchanges in `./get/snapshot/exchange/` that allows them to quickly get up and running, it requires a compatible configuration and that exchange account is one of those who are tracked by my node. If you run an exchange and want to be on that list to use a snapshot, just please let me know. ## Hivemind database dump `./get/hivemind/` contains a relatively recent dump of the Hivemind database. I use self-describing file names such as: `hivemind-20210616-47a41c96.dump` Date when dump was taken, revision of `hivemind` that was running it. You need at least that version, remember about `intarray` extension Consider running `pg_restore` with at least `-j 6` to run long running tasks in parallel After restoring the database, make sure to run the `db_upgrade` script. Even though during full sync database size peaks easily over 750GB, when restored from dump it takes roughly 500GB. Dump file itself is just 53GB. ### All resources are offered AS IS. See: Hive HardFork 25 Jump Starter Kit by @gtg</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/mrwgrOhl7Yw/0.jpg" /><media:content medium="image" url="https://img.youtube.com/vi/mrwgrOhl7Yw/0.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Imagehoster cache purge for Cloudflare</title><link href="https://hivedocs.info/howto/devops/imagehoster/2021/06/14/imagehoster-cache-purge-for-cloudflare.html" rel="alternate" type="text/html" title="Imagehoster cache purge for Cloudflare" /><published>2021-06-14T01:43:48-07:00</published><updated>2021-06-14T01:43:48-07:00</updated><id>https://hivedocs.info/howto/devops/imagehoster/2021/06/14/imagehoster-cache-purge-for-cloudflare</id><content type="html" xml:base="https://hivedocs.info/howto/devops/imagehoster/2021/06/14/imagehoster-cache-purge-for-cloudflare.html">&lt;div id=&quot;content-good-karma-imagehoster-cache-purge-for-cloudflare&quot;&gt;Quick post about new script that helps with caching avatars on imagehoster instances hosted on Cloudflare.

![ecency-imagehoster-caching](https://images.ecency.com/DQmecXYP57pagKtfrUvcRG5AZsrgnwdmbsmugKcv5han8Mn/cache_work.png)

We have 2 imagehoster instances right now, one run by Ecency team and another from Blocktrades team. It is crucial part of platform without which user experience would really suffer. Images, avatars are face of every UI.

https://images.ecency.com
https://images.hive.blog

They both run in front of Cloudflare and images were not utilizing Cloudflare cache properly. For couple reasons, one - avatars cannot be cached for long time, when person updates avatar via apps/websites then they expect it see it instantly, two - Cloudflare considers them dynamic content by default.

If you force cache avatars with Cloudflare page rules then update only shown after cache is expired. That‚Äôs not acceptable for Blockchain that‚Äôs very fast but avatar update require cache expiry. On Ecency instance we had 10 seconds cache, while Hiveblog instance wasn‚Äôt using cache at first and couple days ago Blocktrades tried 4h. All other images could be cached for longer period because they don‚Äôt change at all, for avatars 4h. Which was still too long.

To solve avatar caching issue, created simple script that would purge cache from Cloudflare when account gets update on blockchain. If imagehoster instances are down or in maintenance, all images would be served from Cloudflare cache which is really great for user experience as well.

If you will be running Imagehoster instance in future or considering it, I would recommend running this script on separate server and set avatars caching to longer period safely. If you are not using Cloudflare, then consider removing caching avatars completely, it will put some load on your server but alternative is confusing user experience.

https://github.com/ecency/cf-cache

Both instances running above script now and whenever account update triggered on Blockchain, above script purges relevant user‚Äôs avatar to keep it fresh, use new avatar on all apps that depend on it. 

images.ecency.com cache period for avatars 1 week 
images.hive.blog cache period for avatar 5 hours

After change, I noticed Ecency.com became even more faster... Caching images for sure improving performance of all apps.

### Support proposals  
 
[`Ecency`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B141%5D&amp;amp;approve=true) | [`Hivesearcher`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B146%5D&amp;amp;approve=true) | [`Hivesigner`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B88%5D&amp;amp;approve=true)&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@good-karma&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/imagehoster-cache-purge-for-cloudflare&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-good-karma-imagehoster-cache-purge-for-cloudflare').html();
      const outputElem = $('#content-good-karma-imagehoster-cache-purge-for-cloudflare');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-good-karma-imagehoster-cache-purge-for-cloudflare {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare code {
    background: white;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare a:hover {
    border-bottom: 0;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare h1 {
    font-size: 2.2em;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare header small {
    color: #999;
    font-size: 50%;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://ecency.com/hive-139531/@good-karma/imagehoster-cache-purge-for-cloudflare&quot;&gt;Imagehoster cache purge for Cloudflare&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@good-karma&quot;&gt;@good-karma&lt;/a&gt;
&lt;/p&gt;</content><author><name>good-karma</name></author><category term="howto" /><category term="devops" /><category term="imagehoster" /><summary type="html">Quick post about new script that helps with caching avatars on imagehoster instances hosted on Cloudflare. ![ecency-imagehoster-caching](https://images.ecency.com/DQmecXYP57pagKtfrUvcRG5AZsrgnwdmbsmugKcv5han8Mn/cache_work.png) We have 2 imagehoster instances right now, one run by Ecency team and another from Blocktrades team. It is crucial part of platform without which user experience would really suffer. Images, avatars are face of every UI. https://images.ecency.com https://images.hive.blog They both run in front of Cloudflare and images were not utilizing Cloudflare cache properly. For couple reasons, one - avatars cannot be cached for long time, when person updates avatar via apps/websites then they expect it see it instantly, two - Cloudflare considers them dynamic content by default. If you force cache avatars with Cloudflare page rules then update only shown after cache is expired. That‚Äôs not acceptable for Blockchain that‚Äôs very fast but avatar update require cache expiry. On Ecency instance we had 10 seconds cache, while Hiveblog instance wasn‚Äôt using cache at first and couple days ago Blocktrades tried 4h. All other images could be cached for longer period because they don‚Äôt change at all, for avatars 4h. Which was still too long. To solve avatar caching issue, created simple script that would purge cache from Cloudflare when account gets update on blockchain. If imagehoster instances are down or in maintenance, all images would be served from Cloudflare cache which is really great for user experience as well. If you will be running Imagehoster instance in future or considering it, I would recommend running this script on separate server and set avatars caching to longer period safely. If you are not using Cloudflare, then consider removing caching avatars completely, it will put some load on your server but alternative is confusing user experience. https://github.com/ecency/cf-cache Both instances running above script now and whenever account update triggered on Blockchain, above script purges relevant user‚Äôs avatar to keep it fresh, use new avatar on all apps that depend on it. images.ecency.com cache period for avatars 1 week images.hive.blog cache period for avatar 5 hours After change, I noticed Ecency.com became even more faster... Caching images for sure improving performance of all apps. ### Support proposals [`Ecency`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B141%5D&amp;amp;approve=true) | [`Hivesearcher`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B146%5D&amp;amp;approve=true) | [`Hivesigner`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B88%5D&amp;amp;approve=true) See: Imagehoster cache purge for Cloudflare by @good-karma</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.ecency.com/DQmecXYP57pagKtfrUvcRG5AZsrgnwdmbsmugKcv5han8Mn/cache_work.png" /><media:content medium="image" url="https://images.ecency.com/DQmecXYP57pagKtfrUvcRG5AZsrgnwdmbsmugKcv5han8Mn/cache_work.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive Projects weekly update: 5 projects added, 131 listed in total!</title><link href="https://hivedocs.info/news/projects/2021/06/12/hiveprojects-weekly-update-2021-06-12-42368.html" rel="alternate" type="text/html" title="Hive Projects weekly update: 5 projects added, 131 listed in total!" /><published>2021-06-12T09:00:06-07:00</published><updated>2021-06-12T09:00:06-07:00</updated><id>https://hivedocs.info/news/projects/2021/06/12/hiveprojects-weekly-update-2021-06-12-42368</id><content type="html" xml:base="https://hivedocs.info/news/projects/2021/06/12/hiveprojects-weekly-update-2021-06-12-42368.html">&lt;div id=&quot;content-engrave-hiveprojects-weekly-update-2021-06-12-42368&quot;&gt;![](https://files.peakd.com/file/peakd-hive/engrave/IHxPwBD1-hiveprojects_update.png)

# What is [Hive Projects](https://hiveprojects.io)?

[Hive Projects](https://hiveprojects.io) is the biggest directory of apps, sites, tools, and scripts created for the Hive ecosystem. This website is an entirely volunteer-driven effort. That includes coding time and hosting costs. If you wish to help or show your gratitude, there are plenty of ways in which you can do that:
 * upvote this post
 * reblog or cross-post it into your favorite community
 * contribute to HiveProjects, by adding a new project - everyone can do it!
 * let us know about new project, by posting about it in [Hive Projects Community](https://peakd.com/c/hive-192847) or by cross-posting to it or simply paste us a link at [Engrave Discord server](https://discord.gg/8NktdFh)
 * vote for our @engrave witness
 * write a comment :)

***


Previous post: [Hive Projects weekly update: 4 projects added, 126 listed in total!](/@engrave/hiveprojects-weekly-update-2021-03-06-13937)

***



# Newly added projects 

All published projects were moderated and accepted by our **Content Manager** @lukmarcus, who works hard to make [Hive Projects](https://hiveprojects.io) the best and most up-to-date directory of tools and apps in our ecosystem. The entire reward from this post goes to him.




## PizzaBox
**Team:** @thebeardflex, @hivetrending

![](https://hiveprojects.io/media/imgs/136/1623453852443.png)

**Category:** [Bots](https://hiveprojects.io/categories/bots/)

**Description:** *HIVE tailored community Discord Bot focused around awareness and onboarding. Provides moderation tools for use by communities both on and off chain.

Ban, Kick, Mute, Sticky, Slowmo, Lock Channel, Purge, Music Player, Ticket System etc.
Giveaways
Market information for second-layer Hive-Engine tokens
HIVE market information
Mini-games
HIVE onboarding tools/tutorials. Some commands will be customizable per guild they exist in.*

[PizzaBox on HiveProjects.io](https://hiveprojects.io/projects/p/pizzabox/)



## Beatzchain
**Team:** @polarmystro, @lamarz7

![](https://hiveprojects.io/media/imgs/134/1618985842320.png)

**Category:** [Generic Hive Interfaces](https://hiveprojects.io/categories/generic-hive-interfaces/)

**Description:** *Beatzchain project will be a platform that would run on the Hive Blockchain that would serve for Rappers and music producers.  Beatzchain wants to change the Hip-Hop world with a network rap musicians can earn cryptocurrencies through Hive, Music producers can buy/sell beats, and rappers can use crypto to purchase beats including the ones they&amp;#39;ve earned through the Hive Blockchain.  We would like to start an NFT exchange for rappers and producers called &amp;quot;Hip-Hop Stocks&amp;quot; where musicians can create music NFTs with their songs/beats and buyers could benefit off the equity appreciation.  The goal is to give unsigned, independent, and major artists a better financial system for musicians where everyone with good talent who put the work in can sit by the table together.*

[Beatzchain on HiveProjects.io](https://hiveprojects.io/projects/p/beatzchain/)



## Hive Chain Documentation
**Team:** @inertia

![](https://hiveprojects.io/media/imgs/133/1615696720345.png)

**Category:** [Programming Tools](https://hiveprojects.io/categories/programming-tools/)

**Description:** *Your resource for various levels of Hive Documentation.*

[Hive Chain Documentation on HiveProjects.io](https://hiveprojects.io/projects/p/hive-chain-documentation/)



## Votify
**Team:** @dannychain

![](https://hiveprojects.io/media/imgs/132/1615069673826.png)

**Category:** [Witness Tools](https://hiveprojects.io/categories/witness-tools/)

**Description:** *An Open Source Voting Page for Hive-Engine Witnesses*

[Votify on HiveProjects.io](https://hiveprojects.io/projects/p/votify/)



## Karaka
**Team:** 

![](https://hiveprojects.io/media/imgs/135/1619983488995.png)

**Category:** [Bots](https://hiveprojects.io/categories/bots/)

**Description:** *Karaka is an automation (clerk) for Hive and Hive-Engine blockchains. Use it to manage tokens across multiple accounts.*

[Karaka on HiveProjects.io](https://hiveprojects.io/projects/p/karaka/)



***

&lt;center&gt;

**That would be all for today. Stay tuned for the next update and consider contributing to Hive Projects. It is a community-driven website.**

**Click on the image to vote for @engrave witness:**

[![banner_engrave 100.png](https://images.hive.blog/DQmUghvic5TCPPvVkB4iB7eXmgQ3RQ4L8jkVizvuCBW8RMT/banner_engrave%20100.png)](https://hivesigner.com/sign/account-witness-vote?witness=engrave&amp;amp;approve=1)

**Dont forget to follow @engrave account!**

&lt;/center&gt;
&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@engrave&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hiveprojects-weekly-update-2021-06-12-42368&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-engrave-hiveprojects-weekly-update-2021-06-12-42368').html();
      const outputElem = $('#content-engrave-hiveprojects-weekly-update-2021-06-12-42368');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 code {
    background: white;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 a:hover {
    border-bottom: 0;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 h1 {
    font-size: 2.2em;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 header small {
    color: #999;
    font-size: 50%;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-192847/@engrave/hiveprojects-weekly-update-2021-06-12-42368&quot;&gt;Hive Projects weekly update: 5 projects added, 131 listed in total!&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@engrave&quot;&gt;@engrave&lt;/a&gt;
&lt;/p&gt;</content><author><name>engrave</name></author><category term="news" /><category term="projects" /><summary type="html">![](https://files.peakd.com/file/peakd-hive/engrave/IHxPwBD1-hiveprojects_update.png) # What is [Hive Projects](https://hiveprojects.io)? [Hive Projects](https://hiveprojects.io) is the biggest directory of apps, sites, tools, and scripts created for the Hive ecosystem. This website is an entirely volunteer-driven effort. That includes coding time and hosting costs. If you wish to help or show your gratitude, there are plenty of ways in which you can do that: * upvote this post * reblog or cross-post it into your favorite community * contribute to HiveProjects, by adding a new project - everyone can do it! * let us know about new project, by posting about it in [Hive Projects Community](https://peakd.com/c/hive-192847) or by cross-posting to it or simply paste us a link at [Engrave Discord server](https://discord.gg/8NktdFh) * vote for our @engrave witness * write a comment :) *** Previous post: [Hive Projects weekly update: 4 projects added, 126 listed in total!](/@engrave/hiveprojects-weekly-update-2021-03-06-13937) *** # Newly added projects All published projects were moderated and accepted by our **Content Manager** @lukmarcus, who works hard to make [Hive Projects](https://hiveprojects.io) the best and most up-to-date directory of tools and apps in our ecosystem. The entire reward from this post goes to him. ## PizzaBox **Team:** @thebeardflex, @hivetrending ![](https://hiveprojects.io/media/imgs/136/1623453852443.png) **Category:** [Bots](https://hiveprojects.io/categories/bots/) **Description:** *HIVE tailored community Discord Bot focused around awareness and onboarding. Provides moderation tools for use by communities both on and off chain. Ban, Kick, Mute, Sticky, Slowmo, Lock Channel, Purge, Music Player, Ticket System etc. Giveaways Market information for second-layer Hive-Engine tokens HIVE market information Mini-games HIVE onboarding tools/tutorials. Some commands will be customizable per guild they exist in.* [PizzaBox on HiveProjects.io](https://hiveprojects.io/projects/p/pizzabox/) ## Beatzchain **Team:** @polarmystro, @lamarz7 ![](https://hiveprojects.io/media/imgs/134/1618985842320.png) **Category:** [Generic Hive Interfaces](https://hiveprojects.io/categories/generic-hive-interfaces/) **Description:** *Beatzchain project will be a platform that would run on the Hive Blockchain that would serve for Rappers and music producers. Beatzchain wants to change the Hip-Hop world with a network rap musicians can earn cryptocurrencies through Hive, Music producers can buy/sell beats, and rappers can use crypto to purchase beats including the ones they&amp;#39;ve earned through the Hive Blockchain. We would like to start an NFT exchange for rappers and producers called &amp;quot;Hip-Hop Stocks&amp;quot; where musicians can create music NFTs with their songs/beats and buyers could benefit off the equity appreciation. The goal is to give unsigned, independent, and major artists a better financial system for musicians where everyone with good talent who put the work in can sit by the table together.* [Beatzchain on HiveProjects.io](https://hiveprojects.io/projects/p/beatzchain/) ## Hive Chain Documentation **Team:** @inertia ![](https://hiveprojects.io/media/imgs/133/1615696720345.png) **Category:** [Programming Tools](https://hiveprojects.io/categories/programming-tools/) **Description:** *Your resource for various levels of Hive Documentation.* [Hive Chain Documentation on HiveProjects.io](https://hiveprojects.io/projects/p/hive-chain-documentation/) ## Votify **Team:** @dannychain ![](https://hiveprojects.io/media/imgs/132/1615069673826.png) **Category:** [Witness Tools](https://hiveprojects.io/categories/witness-tools/) **Description:** *An Open Source Voting Page for Hive-Engine Witnesses* [Votify on HiveProjects.io](https://hiveprojects.io/projects/p/votify/) ## Karaka **Team:** ![](https://hiveprojects.io/media/imgs/135/1619983488995.png) **Category:** [Bots](https://hiveprojects.io/categories/bots/) **Description:** *Karaka is an automation (clerk) for Hive and Hive-Engine blockchains. Use it to manage tokens across multiple accounts.* [Karaka on HiveProjects.io](https://hiveprojects.io/projects/p/karaka/) *** **That would be all for today. Stay tuned for the next update and consider contributing to Hive Projects. It is a community-driven website.** **Click on the image to vote for @engrave witness:** [![banner_engrave 100.png](https://images.hive.blog/DQmUghvic5TCPPvVkB4iB7eXmgQ3RQ4L8jkVizvuCBW8RMT/banner_engrave%20100.png)](https://hivesigner.com/sign/account-witness-vote?witness=engrave&amp;amp;approve=1) **Dont forget to follow @engrave account!** See: Hive Projects weekly update: 5 projects added, 131 listed in total! by @engrave</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">CryptoCurrency eXchange Trading Library | Hive &amp;amp; HBD Prices</title><link href="https://hivedocs.info/howto/nodejs/exchange/2021/06/11/cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices.html" rel="alternate" type="text/html" title="CryptoCurrency eXchange Trading Library | Hive &amp;amp; HBD Prices" /><published>2021-06-11T18:15:15-07:00</published><updated>2021-06-11T18:15:15-07:00</updated><id>https://hivedocs.info/howto/nodejs/exchange/2021/06/11/cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices</id><content type="html" xml:base="https://hivedocs.info/howto/nodejs/exchange/2021/06/11/cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices.html">&lt;div id=&quot;content-geekgirl-cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices&quot;&gt;&lt;center&gt;![ccxt.png](https://images.hive.blog/DQmP7AXNQQHk7FXFZruTqK3nagHuWBefrNA489MHsxVbH5a/ccxt.png)&lt;/center&gt;

CCXT is a cryptocurrency exchange trading library for Javascript, Python, and PHP. It is a trading API that supports more than 120 crypto exchanges and continues to add more. While my personal preference is to use in my python projects, it is nice to know that it can be used in Javascript and PHP based projects. For more details feel free to visit [CCXT GitHub page](https://github.com/ccxt/ccxt).

What is really great about this library is that it provides access to many exchanges which include major exchanges like Coinbase, CoinbasePro, Binance, Bittrex, Huobi, etc. Various exchanges have their own python packages to interact with them. I think it is much better to have one interface that can connect to multiple exchanges, get necessary data, and even automate trading.

Most of the functions are available as public and do not need API access credentials. However, for projects that need access to a trading account, we will need to obtain the API access credentials for specific exchanges that we have accounts at.

This API can be used for simple things like getting data on what is being traded on exchanges, historical cryptocurrency prices. It can also be used for more complex projects like trading bots, web applications, etc.

Getting started with this API is super easy. For python we need to first pip install ccxt. Once that is done we can start using it in our python code.

To demonstrate how work with ccxt, I wanted to see what exchanges have HIVE and HBD listed, what trading pairs are available and the latest prices.

First to see what exchanges are supported we can write the following code:

```
import ccxt

print(ccxt.exchanges)
```
If we already know what exchange we would like to use in that list, we can start connecting to this exchange, and get trading pairs and latest data about this trading pairs as below:

```
import ccxt

binance = ccxt.binance()
print(binance.load_markets())
```

If we need to access our accounts we will need to pass api key and secrets as a dictionary argument like this:

```
import ccxt

binance = ccxt.binance({
    'apiKey': 'YOUR_PUBLIC_API_KEY',
    'secret': 'YOUR_SECRET_PRIVATE_KEY',
})

```

As you can see it is very easy to get started with CCXT. Exploring more available methods and properties we can write much more useful code.

As I mentioned I was curious to see if I could use CCXT to see all the exchanges that have HIVE and HBD listed, what trading pairs they have available, and latest prices. Let's do that now.

```
import ccxt

def create_table(prices):
    table = '&lt;table&gt;&lt;tr&gt;&lt;th&gt;Ticker Symbol&lt;/th&gt;&lt;th&gt;Exchange&lt;/th&gt;&lt;th&gt;Price&lt;/th&gt;&lt;/tr&gt;'
    for price in prices:
        row = f'&lt;tr&gt;&lt;td&gt;{price[0]}&lt;/td&gt;&lt;td&gt;{price[1]}&lt;/td&gt;&lt;td&gt;{str(price[2])+&quot; &quot;+price[3]}&lt;/td&gt;&lt;/tr&gt;'
        table += row
    table += '&lt;/table&gt;'
    return table

prices = []
for exchange_id in ccxt.exchanges:
    if exchange_id == 'cdax':
        continue

    try:
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class()
        markets = exchange.load_markets()
    except:
        continue

    for market in markets:
        if 'HIVE' in market or 'HBD' in market:
            if 'HBDC' in market:
                continue
            ticker = exchange.fetch_ticker(market)
            if ticker['symbol'].split('/')[1] == 'BTC':
                prices.append((market, exchange_id, format(ticker['close'], '.8f'), ticker['symbol'].split('/')[1]))
            else:
                prices.append((market, exchange_id, ticker['close'], ticker['symbol'].split('/')[1]))

table = create_table(prices)
print(table)
```

What the main part of the code doing is, first we are trying to identify all the exchanges, then we are getting the method by the same name to create the instance of the exchange. Then we are looking what ticker symbols are traded in the exchange. If any of the tickers include Hive or HBD we are storing ticker symbol, exchange name, last close price in prices list. `create_table` is a helper function that puts together the results in a table format, so I can include them in the post. You can scroll down to see the results.

Initially when I was testing I was getting 12 exchanges that have Hive traded on. However, something went wrong when I tried to get the prices of **CDAX** exchange. After looking closely I was convinced Hive or HBD were not actually listed there. So I have do include a line of code to exclude **CDAX**. 

Another interesting thing we can see is from the results is that, for some reason **HBTC** exchange named the ticker symbol as **HIVE1/USDT** instead of just HIVE without 1.

I don't know what exchange **LATOKEN** is, but from the results we can see while HIVE seems to be listed, prices there are all zero.

This is not a full list of exchanges that have Hive or HBD listed. We can see how some exchanges like ionomy, blocktrades, beaxy, mxc, are not there. It is still great to see that all the major exchanges like Binance, Bittrex, Huobi, Upbit are supported in CCXT.

The code above can also be used for any other coins/tokens. If you learn about a new coin/token and would like to see if where it is traded, simply change the comparison logic from HIVE and HBD to that coin/token.

&lt;center&gt;&lt;h1&gt;Hive and HBD Prices&amp;lt;/h2&amp;gt;&amp;lt;/center&amp;gt;

&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th&gt;Ticker Symbol&lt;/th&gt;&lt;th&gt;Exchange&lt;/th&gt;&lt;th&gt;Price&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/BNB&lt;/td&gt;&lt;td&gt;binance&lt;/td&gt;&lt;td&gt;0.00429 BNB&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/BTC&lt;/td&gt;&lt;td&gt;binance&lt;/td&gt;&lt;td&gt;0.00000946 BTC&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/USDT&lt;/td&gt;&lt;td&gt;binance&lt;/td&gt;&lt;td&gt;0.3521 USDT&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/KRW&lt;/td&gt;&lt;td&gt;bithumb&lt;/td&gt;&lt;td&gt;410.3 KRW&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HBD/BTC&lt;/td&gt;&lt;td&gt;bittrex&lt;/td&gt;&lt;td&gt;0.00002654 BTC&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/BTC&lt;/td&gt;&lt;td&gt;bittrex&lt;/td&gt;&lt;td&gt;0.00000950 BTC&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/USD&lt;/td&gt;&lt;td&gt;bittrex&lt;/td&gt;&lt;td&gt;0.35458 USD&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/USDT&lt;/td&gt;&lt;td&gt;bittrex&lt;/td&gt;&lt;td&gt;0.35712 USDT&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/USDT&lt;/td&gt;&lt;td&gt;gateio&lt;/td&gt;&lt;td&gt;0.3524 USDT&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE1/USDT&lt;/td&gt;&lt;td&gt;hbtc&lt;/td&gt;&lt;td&gt;0.358 USDT&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/USDT&lt;/td&gt;&lt;td&gt;huobipro&lt;/td&gt;&lt;td&gt;0.3525 USDT&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/HT&lt;/td&gt;&lt;td&gt;huobipro&lt;/td&gt;&lt;td&gt;0.025623 HT&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/BTC&lt;/td&gt;&lt;td&gt;huobipro&lt;/td&gt;&lt;td&gt;0.00000947 BTC&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/IDR&lt;/td&gt;&lt;td&gt;indodax&lt;/td&gt;&lt;td&gt;5063.0 IDR&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/USDT&lt;/td&gt;&lt;td&gt;latoken&lt;/td&gt;&lt;td&gt;0.0 USDT&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/BTC&lt;/td&gt;&lt;td&gt;latoken&lt;/td&gt;&lt;td&gt;0.00000000 BTC&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/ETH&lt;/td&gt;&lt;td&gt;latoken&lt;/td&gt;&lt;td&gt;0.0 ETH&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/KRW&lt;/td&gt;&lt;td&gt;probit&lt;/td&gt;&lt;td&gt;410.9 KRW&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/USDT&lt;/td&gt;&lt;td&gt;probit&lt;/td&gt;&lt;td&gt;0.3526 USDT&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/BTC&lt;/td&gt;&lt;td&gt;probit&lt;/td&gt;&lt;td&gt;0.00000948 BTC&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/BTC&lt;/td&gt;&lt;td&gt;stex&lt;/td&gt;&lt;td&gt;0.00000107 BTC&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/BTC&lt;/td&gt;&lt;td&gt;upbit&lt;/td&gt;&lt;td&gt;0.00000955 BTC&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HBD/BTC&lt;/td&gt;&lt;td&gt;upbit&lt;/td&gt;&lt;td&gt;0.00002515 BTC&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HIVE/KRW&lt;/td&gt;&lt;td&gt;upbit&lt;/td&gt;&lt;td&gt;413.0 KRW&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;

Posted Using [LeoFinance &lt;sup&gt;Beta&lt;/sup&gt;](https://leofinance.io/@geekgirl/cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices)&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@geekgirl&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-geekgirl-cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices').html();
      const outputElem = $('#content-geekgirl-cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-geekgirl-cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-geekgirl-cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices code {
    background: white;
  }
  #content-geekgirl-cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-geekgirl-cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices a:hover {
    border-bottom: 0;
  }
  #content-geekgirl-cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices h1 {
    font-size: 2.2em;
  }
  #content-geekgirl-cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-geekgirl-cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices header small {
    color: #999;
    font-size: 50%;
  }
  #content-geekgirl-cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://leofinance.io/@geekgirl/cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices&quot;&gt;CryptoCurrency eXchange Trading Library | Hive &amp;amp; HBD Prices&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@geekgirl&quot;&gt;@geekgirl&lt;/a&gt;
&lt;/p&gt;

&lt;/h1&gt;&lt;/center&gt;&lt;/div&gt;</content><author><name>geekgirl</name></author><category term="howto" /><category term="nodejs" /><category term="exchange" /><summary type="html">![ccxt.png](https://images.hive.blog/DQmP7AXNQQHk7FXFZruTqK3nagHuWBefrNA489MHsxVbH5a/ccxt.png) CCXT is a cryptocurrency exchange trading library for Javascript, Python, and PHP. It is a trading API that supports more than 120 crypto exchanges and continues to add more. While my personal preference is to use in my python projects, it is nice to know that it can be used in Javascript and PHP based projects. For more details feel free to visit [CCXT GitHub page](https://github.com/ccxt/ccxt). What is really great about this library is that it provides access to many exchanges which include major exchanges like Coinbase, CoinbasePro, Binance, Bittrex, Huobi, etc. Various exchanges have their own python packages to interact with them. I think it is much better to have one interface that can connect to multiple exchanges, get necessary data, and even automate trading. Most of the functions are available as public and do not need API access credentials. However, for projects that need access to a trading account, we will need to obtain the API access credentials for specific exchanges that we have accounts at. This API can be used for simple things like getting data on what is being traded on exchanges, historical cryptocurrency prices. It can also be used for more complex projects like trading bots, web applications, etc. Getting started with this API is super easy. For python we need to first pip install ccxt. Once that is done we can start using it in our python code. To demonstrate how work with ccxt, I wanted to see what exchanges have HIVE and HBD listed, what trading pairs are available and the latest prices. First to see what exchanges are supported we can write the following code: ``` import ccxt print(ccxt.exchanges) ``` If we already know what exchange we would like to use in that list, we can start connecting to this exchange, and get trading pairs and latest data about this trading pairs as below: ``` import ccxt binance = ccxt.binance() print(binance.load_markets()) ``` If we need to access our accounts we will need to pass api key and secrets as a dictionary argument like this: ``` import ccxt binance = ccxt.binance({ 'apiKey': 'YOUR_PUBLIC_API_KEY', 'secret': 'YOUR_SECRET_PRIVATE_KEY', }) ``` As you can see it is very easy to get started with CCXT. Exploring more available methods and properties we can write much more useful code. As I mentioned I was curious to see if I could use CCXT to see all the exchanges that have HIVE and HBD listed, what trading pairs they have available, and latest prices. Let's do that now. ``` import ccxt def create_table(prices): table = 'Ticker SymbolExchangePrice' for price in prices: row = f'{price[0]}{price[1]}{str(price[2])+&quot; &quot;+price[3]}' table += row table += '' return table prices = [] for exchange_id in ccxt.exchanges: if exchange_id == 'cdax': continue try: exchange_class = getattr(ccxt, exchange_id) exchange = exchange_class() markets = exchange.load_markets() except: continue for market in markets: if 'HIVE' in market or 'HBD' in market: if 'HBDC' in market: continue ticker = exchange.fetch_ticker(market) if ticker['symbol'].split('/')[1] == 'BTC': prices.append((market, exchange_id, format(ticker['close'], '.8f'), ticker['symbol'].split('/')[1])) else: prices.append((market, exchange_id, ticker['close'], ticker['symbol'].split('/')[1])) table = create_table(prices) print(table) ``` What the main part of the code doing is, first we are trying to identify all the exchanges, then we are getting the method by the same name to create the instance of the exchange. Then we are looking what ticker symbols are traded in the exchange. If any of the tickers include Hive or HBD we are storing ticker symbol, exchange name, last close price in prices list. `create_table` is a helper function that puts together the results in a table format, so I can include them in the post. You can scroll down to see the results. Initially when I was testing I was getting 12 exchanges that have Hive traded on. However, something went wrong when I tried to get the prices of **CDAX** exchange. After looking closely I was convinced Hive or HBD were not actually listed there. So I have do include a line of code to exclude **CDAX**. Another interesting thing we can see is from the results is that, for some reason **HBTC** exchange named the ticker symbol as **HIVE1/USDT** instead of just HIVE without 1. I don't know what exchange **LATOKEN** is, but from the results we can see while HIVE seems to be listed, prices there are all zero. This is not a full list of exchanges that have Hive or HBD listed. We can see how some exchanges like ionomy, blocktrades, beaxy, mxc, are not there. It is still great to see that all the major exchanges like Binance, Bittrex, Huobi, Upbit are supported in CCXT. The code above can also be used for any other coins/tokens. If you learn about a new coin/token and would like to see if where it is traded, simply change the comparison logic from HIVE and HBD to that coin/token. Hive and HBD Prices&amp;lt;/h2&amp;gt;&amp;lt;/center&amp;gt; Ticker SymbolExchangePriceHIVE/BNBbinance0.00429 BNBHIVE/BTCbinance0.00000946 BTCHIVE/USDTbinance0.3521 USDTHIVE/KRWbithumb410.3 KRWHBD/BTCbittrex0.00002654 BTCHIVE/BTCbittrex0.00000950 BTCHIVE/USDbittrex0.35458 USDHIVE/USDTbittrex0.35712 USDTHIVE/USDTgateio0.3524 USDTHIVE1/USDThbtc0.358 USDTHIVE/USDThuobipro0.3525 USDTHIVE/HThuobipro0.025623 HTHIVE/BTChuobipro0.00000947 BTCHIVE/IDRindodax5063.0 IDRHIVE/USDTlatoken0.0 USDTHIVE/BTClatoken0.00000000 BTCHIVE/ETHlatoken0.0 ETHHIVE/KRWprobit410.9 KRWHIVE/USDTprobit0.3526 USDTHIVE/BTCprobit0.00000948 BTCHIVE/BTCstex0.00000107 BTCHIVE/BTCupbit0.00000955 BTCHBD/BTCupbit0.00002515 BTCHIVE/KRWupbit413.0 KRW Posted Using [LeoFinance Beta](https://leofinance.io/@geekgirl/cryptocurrency-exchange-trading-library-or-hive-and-hbd-prices)&amp;lt;/div&amp;gt; See: CryptoCurrency eXchange Trading Library | Hive &amp;amp; HBD Prices by @geekgirl</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmP7AXNQQHk7FXFZruTqK3nagHuWBefrNA489MHsxVbH5a/ccxt.png" /><media:content medium="image" url="https://images.hive.blog/DQmP7AXNQQHk7FXFZruTqK3nagHuWBefrNA489MHsxVbH5a/ccxt.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">15th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/06/10/15th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="15th update of 2021 on BlockTrades work on Hive software" /><published>2021-06-10T16:21:27-07:00</published><updated>2021-06-10T16:21:27-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/10/15th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/10/15th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-15th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Work by the BlockTrades team slowed a little in the last period, as much of our staff was off for Corpus Christi holiday, and in the past two days there was a company-sponsored recreational trip to the mountains (and today many people are probably recovering from that). Still we made progress on several fronts:

# Hived work (blockchain node software)

We expect to tag release candidate 4 tomorrow (this version has been running on the testnet for over a week now but hasn‚Äôt yet been officially tagged because of some false-positive test fails that need to be eliminated). 

Assuming no problems are reported for this release candidate by Monday (hopefully the testnet will get a lot of testing this weekend), we‚Äôll merge the code to the master branch and tag an official release of hived (aka v1.25.0). 

We‚Äôll also be doing a final review of the build and installation docs and next we‚Äôll contact exchanges and notify them of the **expected hardfork on June 30th** so that they can update their wallets ahead of time.


# Hivemind (2nd layer applications + social media middleware)

We found a bug with the latest release of hivemind and we‚Äôre working on a fix for  it now. This problem manifested most visibly as a reputation calculation error for two Hive accounts, although we believe it could possibly result in other errors. 

The root cause of the problem is where we did some code refactoring to share some of the code used during massive sync to process blocks during live sync. This version of the code processed blocks in three separate transactions, and if one of these transactions failed, the work done by the other two transactions persisted, which could lead to inconsistencies in the data on the failing node.

The likely fix will be to revert to using a single transaction for block processing during live sync, and we'll probably be able to deploy the fix late next week.

## Fix for hivemind sync time regression

We also tested/fixed a regression in hivemind sync time where the `update_posts_rshares` query was sometimes inappropriately including a sequential scan in its query planning, which resulted in about 12 hours being added to initial sync time for a database with 53M blocks. 

Our initial test of the fix shows a dramatic improvement (only takes 15 minutes now), but we need to test some more to ensure that the improvement persists under all conditions. The initial performance test for the fix was performed by starting from a database dump file, whereas the 12hr measurement was made on a database constructed from a full sync, so we still need to test performance under a full hivemind sync (which takes several days) to do a strictly accurate comparison.

I consider the current fix a bit of a workaround, because we‚Äôre essentially overriding the query planner‚Äôs plan based on its internal estimates and forcing it to avoid using a sequential scan. Later we will try to get the planner to estimate better by improving its collection of statistics and weighting of costs, because we know similar bad estimates were causing postgres 13 to apply inappropriate ‚Äújust-in-time‚Äù optimizations to this same query. So it is conceivable that if we are able to correct the planner‚Äôs estimation process, we‚Äôll get more optimal performance as the data‚Äôs statistical ‚Äúshape‚Äù changes over time.

# Hive Application Framework (HAF is new &quot;official&quot; name for modular hivemind)

Unless there‚Äôs a popular uprising, I think I‚Äôve settled on an official name for the project that we‚Äôve been developing under the ‚Äúcodename‚Äù of modular hivemind: Hive Application Framework aka HAF.

I think Hive Application Framework is much more descriptive of the actual functionality and it is more clearly distinguishable from the hivemind social media application. Plus it lends itself better to promotional taglines like: ‚ÄúHAF your blockchain app is already done!&quot;

## Initial release of HAF expected sometime in July

For the past week, we‚Äôve been reviewing and improving the code and documentation for HAF, in particular the code that provides automated fork handling. We had a teleconference on Monday to discuss the state of the work and discuss further enhancements, and based on my positive feelings from that meeting, I estimate we will be able to do an official release of HAF sometime in July.

## Ongoing work on HAF

The most recent change being made is to simplify swapping back and forth between a Hive application that only relies on irreversible blocks versus one that also processes reversible blocks.

On a related note, we‚Äôre also going to try to automate the optimization of block processing when a process that works on reversible blocks is currently processing irreversible blocks (originally the plan was to require the app to signal when it planned to work in an optimized fashion on irreversible blocks).

We‚Äôll also be creating a skeleton code template to illustrate how a typical Hive app would use the HAF framework, and later, an full-blown example application.

## Updates to sql_serializer plug for changes to hive_fork_plugin

Before we can do a full test of the framework, we also need to make some needed improvements to the sql_serializer plugin for hived that writes data to the postgres database. In particular, this code needs to be updated to support API changes that have been made to the Hive fork manager extension (this is the SQL code that manages tracking reversible blocks and reverting an application‚Äôs table changes when a fork occurs). 

The above work will begin tomorrow and I hope we will be able to execute a full test of hived + hivemind sync by late next week.

## Call for apps reviewers for HAF

At this point, while it still suffers from some typos which I‚Äôll correct shortly, I think the architectural documentation for HAF is good enough that I want feedback from all app developers with an existing or planned app, especially any applications that require their own database and custom API. 

**Please review the architectural doc and help us create the best possible starting point for Hive apps. Here‚Äôs a link to the most recent version of that document: https://gitlab.syncad.com/hive/psql_tools/-/blob/mi_hive_fork_plugin2/src/hive_fork/Readme.md**&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/15th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-15th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-15th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-15th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-15th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-15th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-15th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-15th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-15th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-15th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-15th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/15th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;15th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Work by the BlockTrades team slowed a little in the last period, as much of our staff was off for Corpus Christi holiday, and in the past two days there was a company-sponsored recreational trip to the mountains (and today many people are probably recovering from that). Still we made progress on several fronts: # Hived work (blockchain node software) We expect to tag release candidate 4 tomorrow (this version has been running on the testnet for over a week now but hasn‚Äôt yet been officially tagged because of some false-positive test fails that need to be eliminated). Assuming no problems are reported for this release candidate by Monday (hopefully the testnet will get a lot of testing this weekend), we‚Äôll merge the code to the master branch and tag an official release of hived (aka v1.25.0). We‚Äôll also be doing a final review of the build and installation docs and next we‚Äôll contact exchanges and notify them of the **expected hardfork on June 30th** so that they can update their wallets ahead of time. # Hivemind (2nd layer applications + social media middleware) We found a bug with the latest release of hivemind and we‚Äôre working on a fix for it now. This problem manifested most visibly as a reputation calculation error for two Hive accounts, although we believe it could possibly result in other errors. The root cause of the problem is where we did some code refactoring to share some of the code used during massive sync to process blocks during live sync. This version of the code processed blocks in three separate transactions, and if one of these transactions failed, the work done by the other two transactions persisted, which could lead to inconsistencies in the data on the failing node. The likely fix will be to revert to using a single transaction for block processing during live sync, and we'll probably be able to deploy the fix late next week. ## Fix for hivemind sync time regression We also tested/fixed a regression in hivemind sync time where the `update_posts_rshares` query was sometimes inappropriately including a sequential scan in its query planning, which resulted in about 12 hours being added to initial sync time for a database with 53M blocks. Our initial test of the fix shows a dramatic improvement (only takes 15 minutes now), but we need to test some more to ensure that the improvement persists under all conditions. The initial performance test for the fix was performed by starting from a database dump file, whereas the 12hr measurement was made on a database constructed from a full sync, so we still need to test performance under a full hivemind sync (which takes several days) to do a strictly accurate comparison. I consider the current fix a bit of a workaround, because we‚Äôre essentially overriding the query planner‚Äôs plan based on its internal estimates and forcing it to avoid using a sequential scan. Later we will try to get the planner to estimate better by improving its collection of statistics and weighting of costs, because we know similar bad estimates were causing postgres 13 to apply inappropriate ‚Äújust-in-time‚Äù optimizations to this same query. So it is conceivable that if we are able to correct the planner‚Äôs estimation process, we‚Äôll get more optimal performance as the data‚Äôs statistical ‚Äúshape‚Äù changes over time. # Hive Application Framework (HAF is new &quot;official&quot; name for modular hivemind) Unless there‚Äôs a popular uprising, I think I‚Äôve settled on an official name for the project that we‚Äôve been developing under the ‚Äúcodename‚Äù of modular hivemind: Hive Application Framework aka HAF. I think Hive Application Framework is much more descriptive of the actual functionality and it is more clearly distinguishable from the hivemind social media application. Plus it lends itself better to promotional taglines like: ‚ÄúHAF your blockchain app is already done!&quot; ## Initial release of HAF expected sometime in July For the past week, we‚Äôve been reviewing and improving the code and documentation for HAF, in particular the code that provides automated fork handling. We had a teleconference on Monday to discuss the state of the work and discuss further enhancements, and based on my positive feelings from that meeting, I estimate we will be able to do an official release of HAF sometime in July. ## Ongoing work on HAF The most recent change being made is to simplify swapping back and forth between a Hive application that only relies on irreversible blocks versus one that also processes reversible blocks. On a related note, we‚Äôre also going to try to automate the optimization of block processing when a process that works on reversible blocks is currently processing irreversible blocks (originally the plan was to require the app to signal when it planned to work in an optimized fashion on irreversible blocks). We‚Äôll also be creating a skeleton code template to illustrate how a typical Hive app would use the HAF framework, and later, an full-blown example application. ## Updates to sql_serializer plug for changes to hive_fork_plugin Before we can do a full test of the framework, we also need to make some needed improvements to the sql_serializer plugin for hived that writes data to the postgres database. In particular, this code needs to be updated to support API changes that have been made to the Hive fork manager extension (this is the SQL code that manages tracking reversible blocks and reverting an application‚Äôs table changes when a fork occurs). The above work will begin tomorrow and I hope we will be able to execute a full test of hived + hivemind sync by late next week. ## Call for apps reviewers for HAF At this point, while it still suffers from some typos which I‚Äôll correct shortly, I think the architectural documentation for HAF is good enough that I want feedback from all app developers with an existing or planned app, especially any applications that require their own database and custom API. **Please review the architectural doc and help us create the best possible starting point for Hive apps. Here‚Äôs a link to the most recent version of that document: https://gitlab.syncad.com/hive/psql_tools/-/blob/mi_hive_fork_plugin2/src/hive_fork/Readme.md** See: 15th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>