<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://hivedocs.info/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hivedocs.info/" rel="alternate" type="text/html" /><updated>2021-07-06T21:45:58-07:00</updated><id>https://hivedocs.info/feed.xml</id><title type="html">Hive Chain Documentation</title><subtitle>Your resource for various levels of Hive Documentation.</subtitle><author><name>site curated by: @inertia</name></author><entry><title type="html">Ledger App updated with HF25 operations</title><link href="https://hivedocs.info/news/nano/nodejs/wallet/2021/07/06/ledger-app-updated-with-hf25-operations.html" rel="alternate" type="text/html" title="Ledger App updated with HF25 operations" /><published>2021-07-06T12:38:18-07:00</published><updated>2021-07-06T12:38:18-07:00</updated><id>https://hivedocs.info/news/nano/nodejs/wallet/2021/07/06/ledger-app-updated-with-hf25-operations</id><content type="html" xml:base="https://hivedocs.info/news/nano/nodejs/wallet/2021/07/06/ledger-app-updated-with-hf25-operations.html">&lt;div id=&quot;content-engrave-ledger-app-updated-with-hf25-operations&quot;&gt;
![image.png](https://files.peakd.com/file/peakd-hive/engrave/Eo23B9HfFGSxgkzJckVtC8WSMeoEwfMcitDDJBZYJzaiVGqirgAwMZmEHpr2WcufBP6.png)
&lt;sup&gt;Image credit (@thepeakstudio)&lt;/sup&gt;

I'm slowly getting back on track to work on a Ledger Hive Application. My [previous post](https://peakd.com/hive-139531/@engrave/javascript-library-for-ledger-nano-s-hive-application) gathered a lot of traction so I feel committed to keeping you in touch.

# HF25

The latest hard fork (which happened a few days ago) introduced few new transactions, so I decided to modify both the app and the library to support it.

Javascript library is available on NPM with a newest version `2.1.0`:
 * `https://www.npmjs.com/package/@engrave/ledger-app-hive`


Because the original repository seems to be dead (my previous Merge Request hasn't been reviewed or merged), I decided to move it to the new home:

 * **Ledger Application**: `https://gitlab.com/engrave/ledger/hw-app-hive`
 * **Javascript Library**: `https://gitlab.com/engrave/ledger/ledger-app-hive`

Here is my first `recurrent_transfer` operation signed with my Ledger: `https://hiveblocks.com/tx/76293c907bf0038076f3507402a716c7d0b8ed57`


![image.png](https://files.peakd.com/file/peakd-hive/engrave/23z7Bh3LG2w23qb9SdLz1Vhmf2wRZKHztTw1H9RL58exJVe2XygcfAS4nqbPPUrTfKNqv.png)


# Code review

I'm slowly getting familiar with the codebase. What I can tell so far, is that it contains a lot of unused code which I'm removing. This seems like a copy-paste and I would really like to clean it before sending it to the official review. It also contains some code prepared for Ledger Nano X but I couldn't build it so far. This is probably some kind of a left-over from the boilerplate so there's a lot of work to be done yet.

I'm getting familiar with the ledger SDK as well to understand the code better.

# Development stack and SDK

SDK used to build the Hive app is already deprecated. There is also a new firmware version (2.0) that is not compatible with the previous one, hence we cannot run the app on new devices. I'm trying to port it to the new SDK version. The new SDK unifies the user flow for both Nano S and Nano X, so finally, we could run it on both devices.

I've even bought the Nano X to be able to test the app against this model.

Ledger prepared a docker image that contains all the necessary libraries to build the app. Unfortunately, the newest version does not work with the actual codebase so I need to make some changes to build it but at the end, this should make future development much easier.

# Ledger companion app

Simultaneously, I've started working on an electron-powered desktop app (as I promised in a previous post). I decided to go with Vue.js and for now, it contains basic CSS rules and views. Will push the code to the gitlab when it's a bit cleaner.


![image.png](https://files.peakd.com/file/peakd-hive/engrave/EowF9ezqJkPjHhLKMx9NjA82sqpuhKVddGJHDgbd5zyo9TsVhKtGc1714xjdsZxerab.png)

# What next

To get this app accepted by the Ledger, it needs to fulfill security, documentation, and functional requirements but I would also make it more user friendly, so the plan is as follow:
 * Make it compatible with a new SDK and 2.0 firmware version
 * Make it working on both Nano S and Nano X devices
 * Add Approve and Reject screens before signing the transaction
 * Prepare user guide and developer's documentation for Ledger Team
 * Develop a working version of the Hive companion app
 * Submit the app for the official review

***

Follow me to be up to date with incoming development updates!

***

&lt;center&gt;

**Click on the image to vote for @engrave witness:**

[![banner_engrave 100.png](https://images.hive.blog/DQmUghvic5TCPPvVkB4iB7eXmgQ3RQ4L8jkVizvuCBW8RMT/banner_engrave%20100.png)](https://hivesigner.com/sign/account-witness-vote?witness=engrave&amp;amp;approve=1)


&lt;/center&gt;
&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@engrave&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/ledger-app-updated-with-hf25-operations&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-engrave-ledger-app-updated-with-hf25-operations').html();
      const outputElem = $('#content-engrave-ledger-app-updated-with-hf25-operations');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-engrave-ledger-app-updated-with-hf25-operations {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations code {
    background: white;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations a:hover {
    border-bottom: 0;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations h1 {
    font-size: 2.2em;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations header small {
    color: #999;
    font-size: 50%;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@engrave/ledger-app-updated-with-hf25-operations&quot;&gt;Ledger App updated with HF25 operations&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@engrave&quot;&gt;@engrave&lt;/a&gt;
&lt;/p&gt;</content><author><name>engrave</name></author><category term="news" /><category term="nano" /><category term="nodejs" /><category term="wallet" /><summary type="html">![image.png](https://files.peakd.com/file/peakd-hive/engrave/Eo23B9HfFGSxgkzJckVtC8WSMeoEwfMcitDDJBZYJzaiVGqirgAwMZmEHpr2WcufBP6.png) Image credit (@thepeakstudio) I'm slowly getting back on track to work on a Ledger Hive Application. My [previous post](https://peakd.com/hive-139531/@engrave/javascript-library-for-ledger-nano-s-hive-application) gathered a lot of traction so I feel committed to keeping you in touch. # HF25 The latest hard fork (which happened a few days ago) introduced few new transactions, so I decided to modify both the app and the library to support it. Javascript library is available on NPM with a newest version `2.1.0`: * `https://www.npmjs.com/package/@engrave/ledger-app-hive` Because the original repository seems to be dead (my previous Merge Request hasn't been reviewed or merged), I decided to move it to the new home: * **Ledger Application**: `https://gitlab.com/engrave/ledger/hw-app-hive` * **Javascript Library**: `https://gitlab.com/engrave/ledger/ledger-app-hive` Here is my first `recurrent_transfer` operation signed with my Ledger: `https://hiveblocks.com/tx/76293c907bf0038076f3507402a716c7d0b8ed57` ![image.png](https://files.peakd.com/file/peakd-hive/engrave/23z7Bh3LG2w23qb9SdLz1Vhmf2wRZKHztTw1H9RL58exJVe2XygcfAS4nqbPPUrTfKNqv.png) # Code review I'm slowly getting familiar with the codebase. What I can tell so far, is that it contains a lot of unused code which I'm removing. This seems like a copy-paste and I would really like to clean it before sending it to the official review. It also contains some code prepared for Ledger Nano X but I couldn't build it so far. This is probably some kind of a left-over from the boilerplate so there's a lot of work to be done yet. I'm getting familiar with the ledger SDK as well to understand the code better. # Development stack and SDK SDK used to build the Hive app is already deprecated. There is also a new firmware version (2.0) that is not compatible with the previous one, hence we cannot run the app on new devices. I'm trying to port it to the new SDK version. The new SDK unifies the user flow for both Nano S and Nano X, so finally, we could run it on both devices. I've even bought the Nano X to be able to test the app against this model. Ledger prepared a docker image that contains all the necessary libraries to build the app. Unfortunately, the newest version does not work with the actual codebase so I need to make some changes to build it but at the end, this should make future development much easier. # Ledger companion app Simultaneously, I've started working on an electron-powered desktop app (as I promised in a previous post). I decided to go with Vue.js and for now, it contains basic CSS rules and views. Will push the code to the gitlab when it's a bit cleaner. ![image.png](https://files.peakd.com/file/peakd-hive/engrave/EowF9ezqJkPjHhLKMx9NjA82sqpuhKVddGJHDgbd5zyo9TsVhKtGc1714xjdsZxerab.png) # What next To get this app accepted by the Ledger, it needs to fulfill security, documentation, and functional requirements but I would also make it more user friendly, so the plan is as follow: * Make it compatible with a new SDK and 2.0 firmware version * Make it working on both Nano S and Nano X devices * Add Approve and Reject screens before signing the transaction * Prepare user guide and developer's documentation for Ledger Team * Develop a working version of the Hive companion app * Submit the app for the official review *** Follow me to be up to date with incoming development updates! *** **Click on the image to vote for @engrave witness:** [![banner_engrave 100.png](https://images.hive.blog/DQmUghvic5TCPPvVkB4iB7eXmgQ3RQ4L8jkVizvuCBW8RMT/banner_engrave%20100.png)](https://hivesigner.com/sign/account-witness-vote?witness=engrave&amp;amp;approve=1) See: Ledger App updated with HF25 operations by @engrave</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/engrave/Eo23B9HfFGSxgkzJckVtC8WSMeoEwfMcitDDJBZYJzaiVGqirgAwMZmEHpr2WcufBP6.png" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/engrave/Eo23B9HfFGSxgkzJckVtC8WSMeoEwfMcitDDJBZYJzaiVGqirgAwMZmEHpr2WcufBP6.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">[Quickstart] How to upgrade Hive-in-a-box (HIAB / hive-docker) to HF25</title><link href="https://hivedocs.info/howto/witness/docker/node/2021/06/30/quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25.html" rel="alternate" type="text/html" title="[Quickstart] How to upgrade Hive-in-a-box (HIAB / hive-docker) to HF25" /><published>2021-06-30T00:16:54-07:00</published><updated>2021-06-30T00:16:54-07:00</updated><id>https://hivedocs.info/howto/witness/docker/node/2021/06/30/quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25</id><content type="html" xml:base="https://hivedocs.info/howto/witness/docker/node/2021/06/30/quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25.html">&lt;div id=&quot;content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25&quot;&gt;
![Hive-in-a-box Logo](https://images.hive.blog/p/HuuaCwcKuiEjNgLb5Q7HbtUvB1HEHgck8hUkQMB4bFSJaxwFsYXGx7N9qtgEvLdGaoY?format=match&amp;amp;mode=fit)

I apologise for the late post, I've been overwhelmed trying to prepare @Privex for HF25, prepare my own servers, and provide one-on-one upgrade assistance to many close witness friends, and Privex customers.

This article covers how to upgrade from Hive HF24 to HF25 as quickly as possible for Privex Node-in-a-box VPS customers, as well as people who use normal Hive-in-a-box (`hive-docker`) on a Dedicated Server, or normal non-NIAB VPS.

Note that this post was written relatively quickly without fully testing the guide, nor checking for any typos / grammatical errors, to ensure any Hive witnesses who use HIAB and haven't yet upgraded - will have time to see this post and follow the instructions.

## HF25 is due at 14:00:00 (2:00 PM) UTC (15:00 / 3:00 PM United Kingdom BST Time) - or roughly 7-8 hrs from when this post was published. 

## [Click HERE to see the current UTC time, with realtime updates](https://time.is/UTC)


# Updating a Privex Node-in-a-box VPS

If you have a Privex Node-in-a-box (NIAB) VPS, e.g. a VHIVE8-SE or VHIVE16-FI which is still running HF24 - you need to [contact support for a reinstall](https://support.privex.io).

# Urgent Pre-installed HF25 Server

If you need a HF25 Hive Server urgently, and your existing servers aren't possible to repair in time for the HF, you can order one of our 8GB or 16GB Hive Node-in-a-box VPS's from @Privex - which are delivered within 20 minutes of payment (as long as you **leave the notes blank**, and **don't use a referral code unless you're 200% certain that it's a valid referral code**, since if it isn't, the order will be flagged for manual inspection to attempt to identify the intended referral).

- üá∏üá™ **SWEDEN** (SE)
    - [8GB Hive Node-in-a-box Sweden - VHIVE8-SE](https://pay.privex.io/order/package/vhive8-se)
    - [16GB Hive Node-in-a-box Sweden - VHIVE16-SE](https://pay.privex.io/order/package/vhive16-se)

- üá´üáÆ **FINLAND** (FI)
    - [8GB Hive Node-in-a-box Finland - VHIVE8-FI](https://pay.privex.io/order/package/vhive8-fi)
    - [16GB Hive Node-in-a-box Finland - VHIVE16-FI](https://pay.privex.io/order/package/vhive16-fi)


# Updating a normal Dedicated Server or non-Privex VPS from HF24 to HF25

If you're running Hive-in-a-box HF24 on either a Dedicated Server (whether Privex or not), or a normal VPS (one that is definitely not a Privex Node-in-a-box Pre-Installed Hive server), the upgrade to HF25 can be done within 30 mins to 1 hr, so long as your server has a high-speed network connection, has a recent `block_log` without any known corruption, and you're able to run the official `someguy123/hive` images which I release.

Before doing anything, enter the folder where you've installed `hive-docker`. Most people install it in their home directory.

```sh
cd ~/hive-docker
```

## Update Method 1 - Shared Memory Transplant - Fastest, but only works with my official binary docker images


First, you'll want to make sure that the `hive-docker` repository is up to date, so that you have the latest features and bug fixes required for the upgrade to go smoothly:

```sh
git fetch
git checkout master
git pull
```


Next, you'll want to install the HF25 Docker binary image. On most setups, a standard `./run.sh install` would work, but to avoid the risk of some people having configured a different default docker image in their `.env`, it's best to specify `hf25`:

```sh
./run.sh install hf25
```

Now, you'll need to stop your node - if it's actually running:

```sh
./run.sh stop
```

To help avoid corruption/contamination issues, and to potentially speed the downloads up by preventing `rsync` from having to calculate the differences between Privex's copy, and your copy of `shared_memory.bin` and `block_log.index` - it's best we remove them:

```sh
./run.sh clean shm

rm -fv data/witness_node_data_dir/blockchain/block_log.index
```

It's now time to truncate/update your block_log, replace your block_log.index, and obtain a fresh copy of shared_memory.bin for HF25:

```
DL_SERVER=&quot;se1.files.privex.io&quot; ./run.sh fix-blocks
```

![](https://images.hive.blog/p/7258xSVeJbKmECTaWChp4sJR8aZDJ7Y2HRvUHUnE6UnEtpj2Z6dqikt3ye5hs7B8Ef2bkjsjyQTre4JUb4x4j7Hxq281Uk2Fio53QLtzuovnfGtaRi2NEJC8GQ4MpvT915F6gKRVhZPwL?format=match&amp;amp;mode=fit)

- When asked whether you want to download the rest of the block_log, or truncate your block_log, press `y` and then hit enter.
- If it instead says that your `block_log` is the same size as the remote, and wants to do an &quot;integrity check&quot; or &quot;verify the block_log, press `n` and hit enter.
- When aksed if you want to replace/update/synchronise your `block_log.index` - press `y` and hit enter.
- When asked if you want to download/synchronise your snapshot files, press `n` and hit enter.
- When asked if you want to download/update/synchronise your `shared_memory.bin` - press `y` and hit enter.

Assuming everything went well, your server should now be ready to start.

Time to start your server:

```
./run.sh start
```

Now check the logs, and monitor it as it syncs. 

```
./run.sh logs
```

If it takes more than 5 minutes to start outputting &quot;Got X transactions from witness someguy123 on block 123456778&quot; - then you should run `./run.sh monitor` to see the sync progress.

Either way, it's a waiting game, it shouldn't take more than 20 mins to sync up (assuming you're following this guide within this week - this article was written on June 30th 2021), as `fix-blocks` would've gotten the recently synced chain files from [Privex's](https://www.privex.io/) file server.


+++ END OF METHOD 1 - Your node should now be up, or will be up very soon when it finishes syncing +++

----------------------

## Update Method 2 - Load a native snapshot - Slower than shared_memory.bin transplant - but this method will work with non-someguy123 built images

### ONLY FOLLOW THIS METHOD IF YOU COMPILE YOUR OWN DOCKER IMAGE, OR USE A THIRD-PARTY DOCKER IMAGE

If you use a custom image - whether one you built yourself using `./run.sh build`, `docker build`, - or one you downloaded from someone who isn't me - the shared memory transplant will likely be incompatible.

For this method, follow everything in method 1, but DO NOT follow the y/n suggestions for `fix-blocks`, instead, you'll want to answer them in the following way instead:

- When asked whether you want to download the rest of the block_log, or truncate your block_log, press `y` and then hit enter.
- If it instead says that your `block_log` is the same size as the remote, and wants to do an &quot;integrity check&quot; or &quot;verify the block_log, press `n` and hit enter.
- When aksed if you want to replace/update/synchronise your `block_log.index` - press `y` and hit enter.
- When asked if you want to download/synchronise your snapshot files, press `y` and hit enter.
- When asked if you want to download/update/synchronise your `shared_memory.bin` - press `n` and hit enter.

**ONLY FOLLOW THIS METHOD IF YOU COMPILE YOUR OWN DOCKER IMAGE, OR USE A THIRD-PARTY DOCKER IMAGE**

Now, use `./run.sh clean shm` to ensure you don't have a `shared_memory.bin`, since an existing shared_memory.bin file will cause problems.

```
./run.sh clean shm
```

You can now load the native snapshot using the command:

```
./run.sh loadsnap privexsnap
```

This will generate a `shared_memory.bin` using that snapshot, and once it's finished loading the snapshot, the node will automatically start normally, so for a witness node, that means it will be ready to start producing once it's finished loading the snapshot, and syncing up any blocks which it was behind.

All you have to do now, is monitor it (if you like), to track it's progress, and make sure nothing is going wrong:

```
./run.sh logs
```


+++ END OF METHOD 2 - Your node should now be up, or will be up very soon when it finishes syncing/loading the snapshot +++


---

Thanks for reading!
---

&lt;center&gt;

![](https://cdn.discordapp.com/attachments/379745956134125569/737091330143944806/SOMEX123.gif)

&lt;/center&gt;

GIF Avatar by @stellabelle

---

Do you like what I'm doing for Hive?
----


[Vote for me to be a Hive witness](https://peakd.com/witnesses) - every vote counts. 

----

Don't forget to follow me for more like this.
----

---

Have you ever thought about being a witness yourself? Join the [witness channel](https://openhive.chat/channel/witness). We're happy to guide you! Join in shaping the STEEM economy.

Are you looking for a new server provider? My company @privex offers highly-reliable and affordable dedicated and virtual servers for HIVE, HBD, EOS, LTC, BTC, and even DOGE! Check out our website at https://www.privex.io

You can join Privex's public Discord at https://discord.privex.io - we also have a Matrix server, sign up at https://riot.privex.io (or if you have an existing Matrix account, join our General chat at `#privex:privex.io`)

---
&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@someguy123&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25').html();
      const outputElem = $('#content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 code {
    background: white;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 a:hover {
    border-bottom: 0;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 h1 {
    font-size: 2.2em;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 header small {
    color: #999;
    font-size: 50%;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@someguy123/quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25&quot;&gt;[Quickstart] How to upgrade Hive-in-a-box (HIAB / hive-docker) to HF25&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@someguy123&quot;&gt;@someguy123&lt;/a&gt;
&lt;/p&gt;</content><author><name>someguy123</name></author><category term="howto" /><category term="witness" /><category term="docker" /><category term="node" /><summary type="html">![Hive-in-a-box Logo](https://images.hive.blog/p/HuuaCwcKuiEjNgLb5Q7HbtUvB1HEHgck8hUkQMB4bFSJaxwFsYXGx7N9qtgEvLdGaoY?format=match&amp;amp;mode=fit) I apologise for the late post, I've been overwhelmed trying to prepare @Privex for HF25, prepare my own servers, and provide one-on-one upgrade assistance to many close witness friends, and Privex customers. This article covers how to upgrade from Hive HF24 to HF25 as quickly as possible for Privex Node-in-a-box VPS customers, as well as people who use normal Hive-in-a-box (`hive-docker`) on a Dedicated Server, or normal non-NIAB VPS. Note that this post was written relatively quickly without fully testing the guide, nor checking for any typos / grammatical errors, to ensure any Hive witnesses who use HIAB and haven't yet upgraded - will have time to see this post and follow the instructions. ## HF25 is due at 14:00:00 (2:00 PM) UTC (15:00 / 3:00 PM United Kingdom BST Time) - or roughly 7-8 hrs from when this post was published. ## [Click HERE to see the current UTC time, with realtime updates](https://time.is/UTC) # Updating a Privex Node-in-a-box VPS If you have a Privex Node-in-a-box (NIAB) VPS, e.g. a VHIVE8-SE or VHIVE16-FI which is still running HF24 - you need to [contact support for a reinstall](https://support.privex.io). # Urgent Pre-installed HF25 Server If you need a HF25 Hive Server urgently, and your existing servers aren't possible to repair in time for the HF, you can order one of our 8GB or 16GB Hive Node-in-a-box VPS's from @Privex - which are delivered within 20 minutes of payment (as long as you **leave the notes blank**, and **don't use a referral code unless you're 200% certain that it's a valid referral code**, since if it isn't, the order will be flagged for manual inspection to attempt to identify the intended referral). - üá∏üá™ **SWEDEN** (SE) - [8GB Hive Node-in-a-box Sweden - VHIVE8-SE](https://pay.privex.io/order/package/vhive8-se) - [16GB Hive Node-in-a-box Sweden - VHIVE16-SE](https://pay.privex.io/order/package/vhive16-se) - üá´üáÆ **FINLAND** (FI) - [8GB Hive Node-in-a-box Finland - VHIVE8-FI](https://pay.privex.io/order/package/vhive8-fi) - [16GB Hive Node-in-a-box Finland - VHIVE16-FI](https://pay.privex.io/order/package/vhive16-fi) # Updating a normal Dedicated Server or non-Privex VPS from HF24 to HF25 If you're running Hive-in-a-box HF24 on either a Dedicated Server (whether Privex or not), or a normal VPS (one that is definitely not a Privex Node-in-a-box Pre-Installed Hive server), the upgrade to HF25 can be done within 30 mins to 1 hr, so long as your server has a high-speed network connection, has a recent `block_log` without any known corruption, and you're able to run the official `someguy123/hive` images which I release. Before doing anything, enter the folder where you've installed `hive-docker`. Most people install it in their home directory. ```sh cd ~/hive-docker ``` ## Update Method 1 - Shared Memory Transplant - Fastest, but only works with my official binary docker images First, you'll want to make sure that the `hive-docker` repository is up to date, so that you have the latest features and bug fixes required for the upgrade to go smoothly: ```sh git fetch git checkout master git pull ``` Next, you'll want to install the HF25 Docker binary image. On most setups, a standard `./run.sh install` would work, but to avoid the risk of some people having configured a different default docker image in their `.env`, it's best to specify `hf25`: ```sh ./run.sh install hf25 ``` Now, you'll need to stop your node - if it's actually running: ```sh ./run.sh stop ``` To help avoid corruption/contamination issues, and to potentially speed the downloads up by preventing `rsync` from having to calculate the differences between Privex's copy, and your copy of `shared_memory.bin` and `block_log.index` - it's best we remove them: ```sh ./run.sh clean shm rm -fv data/witness_node_data_dir/blockchain/block_log.index ``` It's now time to truncate/update your block_log, replace your block_log.index, and obtain a fresh copy of shared_memory.bin for HF25: ``` DL_SERVER=&quot;se1.files.privex.io&quot; ./run.sh fix-blocks ``` ![](https://images.hive.blog/p/7258xSVeJbKmECTaWChp4sJR8aZDJ7Y2HRvUHUnE6UnEtpj2Z6dqikt3ye5hs7B8Ef2bkjsjyQTre4JUb4x4j7Hxq281Uk2Fio53QLtzuovnfGtaRi2NEJC8GQ4MpvT915F6gKRVhZPwL?format=match&amp;amp;mode=fit) - When asked whether you want to download the rest of the block_log, or truncate your block_log, press `y` and then hit enter. - If it instead says that your `block_log` is the same size as the remote, and wants to do an &quot;integrity check&quot; or &quot;verify the block_log, press `n` and hit enter. - When aksed if you want to replace/update/synchronise your `block_log.index` - press `y` and hit enter. - When asked if you want to download/synchronise your snapshot files, press `n` and hit enter. - When asked if you want to download/update/synchronise your `shared_memory.bin` - press `y` and hit enter. Assuming everything went well, your server should now be ready to start. Time to start your server: ``` ./run.sh start ``` Now check the logs, and monitor it as it syncs. ``` ./run.sh logs ``` If it takes more than 5 minutes to start outputting &quot;Got X transactions from witness someguy123 on block 123456778&quot; - then you should run `./run.sh monitor` to see the sync progress. Either way, it's a waiting game, it shouldn't take more than 20 mins to sync up (assuming you're following this guide within this week - this article was written on June 30th 2021), as `fix-blocks` would've gotten the recently synced chain files from [Privex's](https://www.privex.io/) file server. +++ END OF METHOD 1 - Your node should now be up, or will be up very soon when it finishes syncing +++ ---------------------- ## Update Method 2 - Load a native snapshot - Slower than shared_memory.bin transplant - but this method will work with non-someguy123 built images ### ONLY FOLLOW THIS METHOD IF YOU COMPILE YOUR OWN DOCKER IMAGE, OR USE A THIRD-PARTY DOCKER IMAGE If you use a custom image - whether one you built yourself using `./run.sh build`, `docker build`, - or one you downloaded from someone who isn't me - the shared memory transplant will likely be incompatible. For this method, follow everything in method 1, but DO NOT follow the y/n suggestions for `fix-blocks`, instead, you'll want to answer them in the following way instead: - When asked whether you want to download the rest of the block_log, or truncate your block_log, press `y` and then hit enter. - If it instead says that your `block_log` is the same size as the remote, and wants to do an &quot;integrity check&quot; or &quot;verify the block_log, press `n` and hit enter. - When aksed if you want to replace/update/synchronise your `block_log.index` - press `y` and hit enter. - When asked if you want to download/synchronise your snapshot files, press `y` and hit enter. - When asked if you want to download/update/synchronise your `shared_memory.bin` - press `n` and hit enter. **ONLY FOLLOW THIS METHOD IF YOU COMPILE YOUR OWN DOCKER IMAGE, OR USE A THIRD-PARTY DOCKER IMAGE** Now, use `./run.sh clean shm` to ensure you don't have a `shared_memory.bin`, since an existing shared_memory.bin file will cause problems. ``` ./run.sh clean shm ``` You can now load the native snapshot using the command: ``` ./run.sh loadsnap privexsnap ``` This will generate a `shared_memory.bin` using that snapshot, and once it's finished loading the snapshot, the node will automatically start normally, so for a witness node, that means it will be ready to start producing once it's finished loading the snapshot, and syncing up any blocks which it was behind. All you have to do now, is monitor it (if you like), to track it's progress, and make sure nothing is going wrong: ``` ./run.sh logs ``` +++ END OF METHOD 2 - Your node should now be up, or will be up very soon when it finishes syncing/loading the snapshot +++ --- Thanks for reading! --- ![](https://cdn.discordapp.com/attachments/379745956134125569/737091330143944806/SOMEX123.gif) GIF Avatar by @stellabelle --- Do you like what I'm doing for Hive? ---- [Vote for me to be a Hive witness](https://peakd.com/witnesses) - every vote counts. ---- Don't forget to follow me for more like this. ---- --- Have you ever thought about being a witness yourself? Join the [witness channel](https://openhive.chat/channel/witness). We're happy to guide you! Join in shaping the STEEM economy. Are you looking for a new server provider? My company @privex offers highly-reliable and affordable dedicated and virtual servers for HIVE, HBD, EOS, LTC, BTC, and even DOGE! Check out our website at https://www.privex.io You can join Privex's public Discord at https://discord.privex.io - we also have a Matrix server, sign up at https://riot.privex.io (or if you have an existing Matrix account, join our General chat at `#privex:privex.io`) --- See: [Quickstart] How to upgrade Hive-in-a-box (HIAB / hive-docker) to HF25 by @someguy123</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/p/HuuaCwcKuiEjNgLb5Q7HbtUvB1HEHgck8hUkQMB4bFSJaxwFsYXGx7N9qtgEvLdGaoY?format=match&amp;amp;mode=fit" /><media:content medium="image" url="https://images.hive.blog/p/HuuaCwcKuiEjNgLb5Q7HbtUvB1HEHgck8hUkQMB4bFSJaxwFsYXGx7N9qtgEvLdGaoY?format=match&amp;amp;mode=fit" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">17th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/06/29/17th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="17th update of 2021 on BlockTrades work on Hive software" /><published>2021-06-29T14:48:42-07:00</published><updated>2021-06-29T14:48:42-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/29/17th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/29/17th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by BlockTrades team during last week or so:

# Hived work (blockchain node software)

Many users last week experienced problems getting their transactions accepted into the blockchain. It turns out there were two separate problems that could cause this issue, but to the outside observer they probably looked much the same:

### Beem had a problem detecting v1.25.0 Hive‚Äôs chainid, leading to invalidly signed transactions

The first problem, discovered a few days ago, was that the python-based Beem API library used by several Hive apps was misdetecting v1.25.0 Hive nodes as Steem nodes, and therefore trying to sign with the wrong chain id. This, in turn, led to Beem-based Hive Apps creating transactions that would be rejected by any Hive node, because the transactions weren‚Äôt properly signed for Hive. 

We assisted Beem developers with identifying the source of the problem and suggested a solution. Beem now checks for the configuration constant HIVE_CHAIN_ID, before it checks for the constant STEEM_CHAIN_ID, giving precedence to Hive nodes over Steem nodes in the detection process and thus using the proper chainid during transaction signing. 

In related work, we replaced the name STEEM_CHAIN_ID with OLD_CHAIN_ID and eliminated some duplicated constant values returned by get_config (but note these changes will not be included in the master branch until after the hardfork, like other changes completed in the last week):
https://gitlab.syncad.com/hive/hive/-/merge_requests/268
https://gitlab.syncad.com/hive/hive/-/merge_requests/267

### Snapshot-based initialization of Hived-nodes requires a restart to properly initialize chainid

The second problem appeared one day later, but a couple of days before the Beem library was updated, so the two problems overlapped in time, and this led to some confusion among app developers as to what was the source of the new problem. 

But by testing against various API nodes, we were able to determine that this second problem, although similar in appearance to the Beem problem, was occurring on non-Beem apps (e.g. hive.blog and peakd) and only occurring when those apps were using api.hive.blog as their API node. Since we hard recently updated the hived nodes on api.hive.blog, I suspected the problem has something to do with the update process.

After comparing update procedures used by other API node operators, I noticed that most of the API node operators had done a replay to update their nodes,  whereas we had updated our internal hived nodes from a snapshot. Ultimately this allowed us to identify a previously undetected error with nodes initialized from a snapshot: the variable that stores the chainid isn‚Äôt part of the database state that gets loaded from the snapshot data and the snapshot loading code didn‚Äôt trigger this variable to be updated. So a node updated in this way would reject validly signed transactions because it was operating with the wrong chainid (essentially the reverse of the Beem problem). 

### Snapshot  workaround

We also found that this improperly set chainid problem was resolved by stopping and restarting the node that was initialized from a snapshot, and that‚Äôs how we have worked around the issue until we release a full fix for snapshot-based node initialization. 

The code fix is currently being implemented and tested, and will be released after the hardfork (to keep things simple, we‚Äôre avoiding making too many changes to the development branch until after the hardfork has triggered).

## Completed hived work

Improvements to Testtools used to verify hived functionality: https://gitlab.syncad.com/hive/hive/-/merge_requests/266

Removed the copy/pasted version of secp256k1 library from hived and replaced with a submodule link:
https://gitlab.syncad.com/hive/hive/-/merge_requests/264

Fixed issue where enum_virtual_ops sometimes returned non-virtual ops: https://gitlab.syncad.com/hive/hive/-/merge_requests/219

We completed work to eliminate duplicated code in the command-line wallet for hived, but we‚Äôre delaying merging those changes into the develop branch until later because of the sheer amount of changes involved. The still-open merge request for that work is here: https://gitlab.syncad.com/hive/hive/-/merge_requests/170

## Continuing work on hived

We‚Äôre working on speeding up the blockchain converter that we‚Äôve developed to initialize and control a testnet configured in basically the same way as a mainnet. This is to allow for more realistic testing inside of a testnet environment (especially for better performance testing). So far, we‚Äôve identified that the performance bottleneck seems to be related to the function that generates nonces.

We‚Äôre continuing to work on the sql serializer plugin for hived that provides data to HAF-based applications. We expecting to complete that work this week, assuming no further distractions arise in the meantime (this work got delayed while we were troubleshooting the snapshot problem), then begin performance testing.

We‚Äôre also continuing to work on the CI system to automate deployment of hived for more strenuous testing scenarios (e.g. long replay testing).


# Hivemind (2nd layer applications + social media middleware)

Fix for previously report list_subscribers bug: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/513

We continue to investigate ways to improve performance of the update_rshares function immediately after massive sync of a hivemind instance. In addition to analyzing the cause of slowness of the current implementation, we‚Äôre also simultaneously looking at two different alternatives to improve overall performance: 1) eliminating the call completing and performing equivalent functionality during live sync  and 2) adding an index (at least temporarily just after massive sync) to speed up update_rshares.

The new index dramatically speeds up performance of update_rshares (time drops from 10 hours to 3 minutes and the index only takes about 10minutes to create), but it consumes 25GB of disk space (hence the idea to drop it after using it).

We‚Äôre still running functional and performance tests related to the broken reputation/ordering issue because of multiple transactions used per block. As part of this work we‚Äôre also adding ‚Äúcompletion markers‚Äù to the database state to better detect any database consistency error that can arise from an abrupt shutdown of postgres (notably, this can happen when postgres does an auto-upgrade for a security fix).

We also resumed research into the reason why some hivemind nodes consume more memory than others. It has been suggested that it may be related to differences in python or python-library installations on the different systems.

# Hive Application Framework

We made good progress last week on both HAF code and the documentation for it, but our main dev for this work is now on vacation until June 19th, at which time the work will resume. 

But in the meantime, we should be able to do performance testing of this code using the new sql_serializer plugin, and I‚Äôm looking forward to seeing just how well we do.

# Reminder: hardfork 25 triggers tomorrow

Witnesses and devs alike will be ‚Äúmanning their keyboards‚Äù tomorrow (June 30th) as hardfork 25 triggers, ready for any potential problems that may arise. The hardfork is scheduled for approximately 14:00 UTC.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/17th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/17th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;17th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by BlockTrades team during last week or so: # Hived work (blockchain node software) Many users last week experienced problems getting their transactions accepted into the blockchain. It turns out there were two separate problems that could cause this issue, but to the outside observer they probably looked much the same: ### Beem had a problem detecting v1.25.0 Hive‚Äôs chainid, leading to invalidly signed transactions The first problem, discovered a few days ago, was that the python-based Beem API library used by several Hive apps was misdetecting v1.25.0 Hive nodes as Steem nodes, and therefore trying to sign with the wrong chain id. This, in turn, led to Beem-based Hive Apps creating transactions that would be rejected by any Hive node, because the transactions weren‚Äôt properly signed for Hive. We assisted Beem developers with identifying the source of the problem and suggested a solution. Beem now checks for the configuration constant HIVE_CHAIN_ID, before it checks for the constant STEEM_CHAIN_ID, giving precedence to Hive nodes over Steem nodes in the detection process and thus using the proper chainid during transaction signing. In related work, we replaced the name STEEM_CHAIN_ID with OLD_CHAIN_ID and eliminated some duplicated constant values returned by get_config (but note these changes will not be included in the master branch until after the hardfork, like other changes completed in the last week): https://gitlab.syncad.com/hive/hive/-/merge_requests/268 https://gitlab.syncad.com/hive/hive/-/merge_requests/267 ### Snapshot-based initialization of Hived-nodes requires a restart to properly initialize chainid The second problem appeared one day later, but a couple of days before the Beem library was updated, so the two problems overlapped in time, and this led to some confusion among app developers as to what was the source of the new problem. But by testing against various API nodes, we were able to determine that this second problem, although similar in appearance to the Beem problem, was occurring on non-Beem apps (e.g. hive.blog and peakd) and only occurring when those apps were using api.hive.blog as their API node. Since we hard recently updated the hived nodes on api.hive.blog, I suspected the problem has something to do with the update process. After comparing update procedures used by other API node operators, I noticed that most of the API node operators had done a replay to update their nodes, whereas we had updated our internal hived nodes from a snapshot. Ultimately this allowed us to identify a previously undetected error with nodes initialized from a snapshot: the variable that stores the chainid isn‚Äôt part of the database state that gets loaded from the snapshot data and the snapshot loading code didn‚Äôt trigger this variable to be updated. So a node updated in this way would reject validly signed transactions because it was operating with the wrong chainid (essentially the reverse of the Beem problem). ### Snapshot workaround We also found that this improperly set chainid problem was resolved by stopping and restarting the node that was initialized from a snapshot, and that‚Äôs how we have worked around the issue until we release a full fix for snapshot-based node initialization. The code fix is currently being implemented and tested, and will be released after the hardfork (to keep things simple, we‚Äôre avoiding making too many changes to the development branch until after the hardfork has triggered). ## Completed hived work Improvements to Testtools used to verify hived functionality: https://gitlab.syncad.com/hive/hive/-/merge_requests/266 Removed the copy/pasted version of secp256k1 library from hived and replaced with a submodule link: https://gitlab.syncad.com/hive/hive/-/merge_requests/264 Fixed issue where enum_virtual_ops sometimes returned non-virtual ops: https://gitlab.syncad.com/hive/hive/-/merge_requests/219 We completed work to eliminate duplicated code in the command-line wallet for hived, but we‚Äôre delaying merging those changes into the develop branch until later because of the sheer amount of changes involved. The still-open merge request for that work is here: https://gitlab.syncad.com/hive/hive/-/merge_requests/170 ## Continuing work on hived We‚Äôre working on speeding up the blockchain converter that we‚Äôve developed to initialize and control a testnet configured in basically the same way as a mainnet. This is to allow for more realistic testing inside of a testnet environment (especially for better performance testing). So far, we‚Äôve identified that the performance bottleneck seems to be related to the function that generates nonces. We‚Äôre continuing to work on the sql serializer plugin for hived that provides data to HAF-based applications. We expecting to complete that work this week, assuming no further distractions arise in the meantime (this work got delayed while we were troubleshooting the snapshot problem), then begin performance testing. We‚Äôre also continuing to work on the CI system to automate deployment of hived for more strenuous testing scenarios (e.g. long replay testing). # Hivemind (2nd layer applications + social media middleware) Fix for previously report list_subscribers bug: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/513 We continue to investigate ways to improve performance of the update_rshares function immediately after massive sync of a hivemind instance. In addition to analyzing the cause of slowness of the current implementation, we‚Äôre also simultaneously looking at two different alternatives to improve overall performance: 1) eliminating the call completing and performing equivalent functionality during live sync and 2) adding an index (at least temporarily just after massive sync) to speed up update_rshares. The new index dramatically speeds up performance of update_rshares (time drops from 10 hours to 3 minutes and the index only takes about 10minutes to create), but it consumes 25GB of disk space (hence the idea to drop it after using it). We‚Äôre still running functional and performance tests related to the broken reputation/ordering issue because of multiple transactions used per block. As part of this work we‚Äôre also adding ‚Äúcompletion markers‚Äù to the database state to better detect any database consistency error that can arise from an abrupt shutdown of postgres (notably, this can happen when postgres does an auto-upgrade for a security fix). We also resumed research into the reason why some hivemind nodes consume more memory than others. It has been suggested that it may be related to differences in python or python-library installations on the different systems. # Hive Application Framework We made good progress last week on both HAF code and the documentation for it, but our main dev for this work is now on vacation until June 19th, at which time the work will resume. But in the meantime, we should be able to do performance testing of this code using the new sql_serializer plugin, and I‚Äôm looking forward to seeing just how well we do. # Reminder: hardfork 25 triggers tomorrow Witnesses and devs alike will be ‚Äúmanning their keyboards‚Äù tomorrow (June 30th) as hardfork 25 triggers, ready for any potential problems that may arise. The hardfork is scheduled for approximately 14:00 UTC. See: 17th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive SQL is ready for the hardfork 25 - Addendum</title><link href="https://hivedocs.info/news/sql/database/2021/06/29/hivesql-hf25-addendum.html" rel="alternate" type="text/html" title="Hive SQL is ready for the hardfork 25 - Addendum" /><published>2021-06-29T07:45:54-07:00</published><updated>2021-06-29T07:45:54-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/06/29/hivesql-hf25-addendum</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/06/29/hivesql-hf25-addendum.html">&lt;div id=&quot;content-arcange-hivesql-hf25-addendum&quot;&gt;![](https://i.imgur.com/B5TI37I.png)

The hardfork 25 (codename Equilibrium) should be activated in a few hours (less than 22 but many more than 2 at time of writing üòÅ) as all top 20 witnesses are now running the v1.25 code on their nodes ([see here](https://hive.arcange.eu/witnesses)).

My API servers have also been upgraded to the new code and are now providing HiveSQL with new data. Therefore, I added a few updates to the HiveSQL database.

## What's new?

### 1. Existing table updates

* **DynamicGlobalProperties**

New columns

|Column|Description|
|-|-|
|current_remove_threshold|number of objects that can be removed in one automatic operation (only applies to situations where many objects can accumulate over time but need to be removed in a single operation f.e. proposal votes)|
|early_voting_seconds|Duration of the first period where all votes are considered equally regarding vote time and the linear rewards curve is applied (equal weight to all voters in that window) - currently 24 hours|
|mid_voting_seconds|Duration of the second period where with reward weight/2 is applied - currently 48 hours|
|max_consecutive_recurrent_transfer_failures|Maximum number of consecutive failures for a recurring transfer before it is automatically canceled |
|max_recurrent_transfer_end_date|Maximum difference between start and end of a recurring payment - currently 730 days (2 years)|
|min_recurrent_transfers_recurrence|Minimum time to elapse between two recurring transfer - currently 24 hours|
|max_open_recurrent_transfers|Maximum number of recurring payments that can be scheduled for execution per account - currently 255|


* **Account**

New columns

|Column|Description|
|-|-|
|post_voting_power|Effective HP that are used for curation (vesting_shares - delegated_vesting_shares + received_vesting_shares)|
|post_voting_power_symbol|VESTS|
|pending_transfers|Pending transfers for escrow operations|
|governance_vote_expiration_ts|date and time that the account governance votes for witnesses and proposals will expire|
|delayed_votes_time|date and time that the additional HP recently powered up will be taken into account for governance|
|delayed_votes_val|value of the additional HP that will be taken into account for governance after delay|
|open_recurrent_transfers|Number of recurring transfers scheduled for execution|


## Documentation

HiveSQL documentation has been updated and can be viewed at https://docs.hivesql.io

## Support

If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT).

**Happy Hardfork 25!**

---
&lt;sub&gt; 

#### &lt;center&gt;Check out my apps and services
&lt;a href=&quot;/hive/@hive.engage/stay-connected-with-your-hive-audience-and-catch-attention&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GiNJqlm.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivebuzz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/B4UTun2.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivesql&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EPN8RW6.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/hive/@arcange/introducing-hive-account-recovery&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6TWeW7V.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hive.autoclaim&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ih2pEOw.png&quot; /&gt;&lt;/a&gt;&lt;/center&gt;
&lt;center&gt;

### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@arcange&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hivesql-hf25-addendum&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-arcange-hivesql-hf25-addendum').html();
      const outputElem = $('#content-arcange-hivesql-hf25-addendum');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-arcange-hivesql-hf25-addendum {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-arcange-hivesql-hf25-addendum code {
    background: white;
  }
  #content-arcange-hivesql-hf25-addendum a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-arcange-hivesql-hf25-addendum a:hover {
    border-bottom: 0;
  }
  #content-arcange-hivesql-hf25-addendum h1 {
    font-size: 2.2em;
  }
  #content-arcange-hivesql-hf25-addendum h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-arcange-hivesql-hf25-addendum header small {
    color: #999;
    font-size: 50%;
  }
  #content-arcange-hivesql-hf25-addendum img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@arcange/hivesql-hf25-addendum&quot;&gt;Hive SQL is ready for the hardfork 25 - Addendum&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@arcange&quot;&gt;@arcange&lt;/a&gt;
&lt;/p&gt;

&lt;/center&gt;&lt;/sub&gt;&lt;/div&gt;</content><author><name>arcange</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![](https://i.imgur.com/B5TI37I.png) The hardfork 25 (codename Equilibrium) should be activated in a few hours (less than 22 but many more than 2 at time of writing üòÅ) as all top 20 witnesses are now running the v1.25 code on their nodes ([see here](https://hive.arcange.eu/witnesses)). My API servers have also been upgraded to the new code and are now providing HiveSQL with new data. Therefore, I added a few updates to the HiveSQL database. ## What's new? ### 1. Existing table updates * **DynamicGlobalProperties** New columns |Column|Description| |-|-| |current_remove_threshold|number of objects that can be removed in one automatic operation (only applies to situations where many objects can accumulate over time but need to be removed in a single operation f.e. proposal votes)| |early_voting_seconds|Duration of the first period where all votes are considered equally regarding vote time and the linear rewards curve is applied (equal weight to all voters in that window) - currently 24 hours| |mid_voting_seconds|Duration of the second period where with reward weight/2 is applied - currently 48 hours| |max_consecutive_recurrent_transfer_failures|Maximum number of consecutive failures for a recurring transfer before it is automatically canceled | |max_recurrent_transfer_end_date|Maximum difference between start and end of a recurring payment - currently 730 days (2 years)| |min_recurrent_transfers_recurrence|Minimum time to elapse between two recurring transfer - currently 24 hours| |max_open_recurrent_transfers|Maximum number of recurring payments that can be scheduled for execution per account - currently 255| * **Account** New columns |Column|Description| |-|-| |post_voting_power|Effective HP that are used for curation (vesting_shares - delegated_vesting_shares + received_vesting_shares)| |post_voting_power_symbol|VESTS| |pending_transfers|Pending transfers for escrow operations| |governance_vote_expiration_ts|date and time that the account governance votes for witnesses and proposals will expire| |delayed_votes_time|date and time that the additional HP recently powered up will be taken into account for governance| |delayed_votes_val|value of the additional HP that will be taken into account for governance after delay| |open_recurrent_transfers|Number of recurring transfers scheduled for execution| ## Documentation HiveSQL documentation has been updated and can be viewed at https://docs.hivesql.io ## Support If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT). **Happy Hardfork 25!** --- #### Check out my apps and services ### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt; See: Hive SQL is ready for the hardfork 25 - Addendum by @arcange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/B5TI37I.png" /><media:content medium="image" url="https://i.imgur.com/B5TI37I.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive core developer meeting #25</title><link href="https://hivedocs.info/news/core/development/2021/06/22/hive-core-developer-meeting-25.html" rel="alternate" type="text/html" title="Hive core developer meeting #25" /><published>2021-06-22T12:40:21-07:00</published><updated>2021-06-22T12:40:21-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/22/hive-core-developer-meeting-25</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/22/hive-core-developer-meeting-25.html">&lt;div id=&quot;content-howo-hive-core-developer-meeting-25&quot;&gt;https://www.youtube.com/watch?v=D2iS7B7-8rg

I basically recommend that you listen to the whole thing, usually it's pretty easy to tl;dr but on this one we talk about a lot of various subjects that are basically dev/testnet sync.

Topics touched upon
Dev sync
Testnet sync
future testnet that mirrors the main net even more closely
List of tests/cases to focus on for remainder of testing.
State of libraries/key dapps/services ahead of HF -- ready?

as always if you have questions, feel free to ask them in the comments :)

@howo&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@howo&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-core-developer-meeting-25&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-howo-hive-core-developer-meeting-25').html();
      const outputElem = $('#content-howo-hive-core-developer-meeting-25');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-howo-hive-core-developer-meeting-25 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-howo-hive-core-developer-meeting-25 code {
    background: white;
  }
  #content-howo-hive-core-developer-meeting-25 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-howo-hive-core-developer-meeting-25 a:hover {
    border-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-25 h1 {
    font-size: 2.2em;
  }
  #content-howo-hive-core-developer-meeting-25 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-25 header small {
    color: #999;
    font-size: 50%;
  }
  #content-howo-hive-core-developer-meeting-25 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/meeting/@howo/hive-core-developer-meeting-25&quot;&gt;Hive core developer meeting #25&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@howo&quot;&gt;@howo&lt;/a&gt;
&lt;/p&gt;</content><author><name>howo</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">https://www.youtube.com/watch?v=D2iS7B7-8rg I basically recommend that you listen to the whole thing, usually it's pretty easy to tl;dr but on this one we talk about a lot of various subjects that are basically dev/testnet sync. Topics touched upon Dev sync Testnet sync future testnet that mirrors the main net even more closely List of tests/cases to focus on for remainder of testing. State of libraries/key dapps/services ahead of HF -- ready? as always if you have questions, feel free to ask them in the comments :) @howo See: Hive core developer meeting #25 by @howo</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">16th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/06/20/16th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="16th update of 2021 on BlockTrades work on Hive software" /><published>2021-06-20T18:24:24-07:00</published><updated>2021-06-20T18:24:24-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/20/16th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/20/16th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by BlockTrades team during the last week or so:

# Hived work (blockchain node software)

## Official release of Equilibrium (hived code for hardfork 25)

Last week we merged all develop branch changes since the last hardfork into the master branch and tagged an official release of hived (v1.25.0). The ‚Äúcode name‚Äù for this release is ‚ÄúEquilibrium‚Äù. 

 For the official press release associated with the new release and details about associated functional changes, see https://hive.blog/hive/@hiveio/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021

The [release notes for Equilibrium](https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0) represent a concise summary of virtually all changes that were made as part of this hardfork, along with links to review the code associated with each individual change. 

Alternatively, you can inspect [a diff with the totality of changes for this hardfork](https://gitlab.syncad.com/hive/hive/-/merge_requests/262/diffs).


## Other hived work last week

We continued performance testing of the new ‚Äúrecurrent transfers‚Äù feature written by @howo. As a side note, based on some discussion among various devs, I believe Hive frontends will use the term ‚Äúrecurring payments‚Äù to refer to the ‚Äúrecurrent transfers‚Äù feature, since that is the name most commonly used in the business world for this type of functionality.

During our still incomplete testing, we found some areas where the new ‚Äútest tools‚Äù framework that is being used to create and test massive numbers of recurrent transfers could be improved to make it faster and more stable:
https://gitlab.syncad.com/hive/hive/-/merge_requests/257
https://gitlab.syncad.com/hive/hive/-/merge_requests/263

Here‚Äôs a short list of other work done on hived:

* Fixed two unit tests that we previously had to disable and re-enabled them: https://gitlab.syncad.com/hive/hive/-/merge_requests/259
* Added a new command-line option ‚Äìexit-before-sync for configuring hived to a predictable state for running a replay or creating a statefile dump, then ending the hived process. This is useful for setting up test scenarios. https://gitlab.syncad.com/hive/hive/-/merge_requests/232
* Added new regression tests to test recent changes to last irreversible block handling (a change that was made to fix a longstanding bug with duplicate transactions in the account history plugin): https://gitlab.syncad.com/hive/hive/-/merge_requests/252
* Fixed an intermittent crash on application shutdown: https://gitlab.syncad.com/hive/hive/-/merge_requests/253
* Documentation cleanup: https://gitlab.syncad.com/hive/hive/-/merge_requests/258
*   Implemented option for automatic spawning of hived replays within our continuous integration system  (done off main servers to avoid breaking or interrupting primary development CI system).

# Hivemind (2nd layer applications + social media middleware)

* Added tests for recent changes in behavior of setLastRead operation: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/511
* Explicit specification of package versions to be used when building hivemind to avoid potential headaches when package dependencies are updated: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/498
* Update CodeQL analysis configuration: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/509
* We‚Äôre currently investigating ways to improve performance of the `update_rshares` function immediately after massive sync of a hivemind instance.
*  Fixed &quot;broken reputation&quot; problem related to ordering issue because of multiple transactions used per block. This was known to impact the calculation of reputation for at least two Hive users.
*   list_subscribers bug being worked on (tests being created first).

# Hive Application Framework

The current implementation of the Hive Application Framework requires applications to mark their constraints as DEFERRABLE to enable HAF apps to use the auto-rewind feature when a fork switch occurs. 

While this may be an acceptable limitation on the design of HAF-based apps, we decided to create an alternative implementation of HAF without that limitation and measure the performance of the two alternative designs. The ongoing discussion of this topic can be found in the latest comments attached to the still open HAF merge request: https://gitlab.syncad.com/hive/psql_tools/-/merge_requests/1

# Upcoming work in the next week

* Continue performance testing of recurring payments functionality in hived.
* Complete psql_serializer updates and begin testing hived+psql_serializer with hivemind. This is a prerequisite for testing the entire HAF code base.
* More work and testing of the Hive Application Framework (HAF), including more documentation and example HAF-based applications.
* Finish up fix for list_subscribers.
* Work with witnesses to collect performance statistics for the Equilibrium release on different hardware configurations. 

On a related note,  @drakos noted a significant performance improvement in the speed of creating statefile snapshots and @gtg has confirmed the same findings on his system. Gandalf reports v1.24.8 took 4866 seconds whereas v1.25.0 was able to complete this task in only 3134 seconds.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/16th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/16th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;16th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by BlockTrades team during the last week or so: # Hived work (blockchain node software) ## Official release of Equilibrium (hived code for hardfork 25) Last week we merged all develop branch changes since the last hardfork into the master branch and tagged an official release of hived (v1.25.0). The ‚Äúcode name‚Äù for this release is ‚ÄúEquilibrium‚Äù. For the official press release associated with the new release and details about associated functional changes, see https://hive.blog/hive/@hiveio/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 The [release notes for Equilibrium](https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0) represent a concise summary of virtually all changes that were made as part of this hardfork, along with links to review the code associated with each individual change. Alternatively, you can inspect [a diff with the totality of changes for this hardfork](https://gitlab.syncad.com/hive/hive/-/merge_requests/262/diffs). ## Other hived work last week We continued performance testing of the new ‚Äúrecurrent transfers‚Äù feature written by @howo. As a side note, based on some discussion among various devs, I believe Hive frontends will use the term ‚Äúrecurring payments‚Äù to refer to the ‚Äúrecurrent transfers‚Äù feature, since that is the name most commonly used in the business world for this type of functionality. During our still incomplete testing, we found some areas where the new ‚Äútest tools‚Äù framework that is being used to create and test massive numbers of recurrent transfers could be improved to make it faster and more stable: https://gitlab.syncad.com/hive/hive/-/merge_requests/257 https://gitlab.syncad.com/hive/hive/-/merge_requests/263 Here‚Äôs a short list of other work done on hived: * Fixed two unit tests that we previously had to disable and re-enabled them: https://gitlab.syncad.com/hive/hive/-/merge_requests/259 * Added a new command-line option ‚Äìexit-before-sync for configuring hived to a predictable state for running a replay or creating a statefile dump, then ending the hived process. This is useful for setting up test scenarios. https://gitlab.syncad.com/hive/hive/-/merge_requests/232 * Added new regression tests to test recent changes to last irreversible block handling (a change that was made to fix a longstanding bug with duplicate transactions in the account history plugin): https://gitlab.syncad.com/hive/hive/-/merge_requests/252 * Fixed an intermittent crash on application shutdown: https://gitlab.syncad.com/hive/hive/-/merge_requests/253 * Documentation cleanup: https://gitlab.syncad.com/hive/hive/-/merge_requests/258 * Implemented option for automatic spawning of hived replays within our continuous integration system (done off main servers to avoid breaking or interrupting primary development CI system). # Hivemind (2nd layer applications + social media middleware) * Added tests for recent changes in behavior of setLastRead operation: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/511 * Explicit specification of package versions to be used when building hivemind to avoid potential headaches when package dependencies are updated: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/498 * Update CodeQL analysis configuration: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/509 * We‚Äôre currently investigating ways to improve performance of the `update_rshares` function immediately after massive sync of a hivemind instance. * Fixed &quot;broken reputation&quot; problem related to ordering issue because of multiple transactions used per block. This was known to impact the calculation of reputation for at least two Hive users. * list_subscribers bug being worked on (tests being created first). # Hive Application Framework The current implementation of the Hive Application Framework requires applications to mark their constraints as DEFERRABLE to enable HAF apps to use the auto-rewind feature when a fork switch occurs. While this may be an acceptable limitation on the design of HAF-based apps, we decided to create an alternative implementation of HAF without that limitation and measure the performance of the two alternative designs. The ongoing discussion of this topic can be found in the latest comments attached to the still open HAF merge request: https://gitlab.syncad.com/hive/psql_tools/-/merge_requests/1 # Upcoming work in the next week * Continue performance testing of recurring payments functionality in hived. * Complete psql_serializer updates and begin testing hived+psql_serializer with hivemind. This is a prerequisite for testing the entire HAF code base. * More work and testing of the Hive Application Framework (HAF), including more documentation and example HAF-based applications. * Finish up fix for list_subscribers. * Work with witnesses to collect performance statistics for the Equilibrium release on different hardware configurations. On a related note, @drakos noted a significant performance improvement in the speed of creating statefile snapshots and @gtg has confirmed the same findings on his system. Gandalf reports v1.24.8 took 4866 seconds whereas v1.25.0 was able to complete this task in only 3134 seconds. See: 16th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive Hardfork 25 is on the Way: Hive to reach Equilibrium on June 30th, 2021</title><link href="https://hivedocs.info/news/core/development/2021/06/19/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021.html" rel="alternate" type="text/html" title="Hive Hardfork 25 is on the Way: Hive to reach Equilibrium on June 30th, 2021" /><published>2021-06-19T17:10:27-07:00</published><updated>2021-06-19T17:10:27-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/19/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/19/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021.html">&lt;div id=&quot;content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021&quot;&gt;![image.png](https://images.hive.blog/DQmfByqFD7d9ecpcYMhy7ucwhQLKKrrLjcp9vb378wSJwCP/image.png)

Earlier this week we notified cryptocurrency exchanges that the upcoming hardfork to the Hive blockchain network, dubbed *Equilibrium*, is planned for the end of June. 

Today's official date announcement also has a pile of helpful information including a summary of changes coming with the new hardfork, links to the software, and details for those of you who may want to get involved in testing the new software!

## TL:DR the Code; A Quick Overview of the Upcoming Changes

*Equilibrium* is a state of balance between multiple forces. In the case of the Hive blockchain network, the guiding mission from day one has been to create an ecosystem that allows anyone to become a part of our decentralized network, contribute to governance, and to own their data, connections, tokens and actions in a world where the current tech and social powers have an iron grip. 

This hardfork continues to empower people to use Hive the way they want and takes another few large steps forward in creating an ecosystem with better balanced rules and tools for building whatever we can dream up. 

Reaching equilibrium is finding a state of balance and readiness. It is the essential preparation for big moves, exciting changes, and sustained growth.

### Here's a quick summary of HF25:

Below is a list of the consensus changes that are being made as part of this hardfork:

- **changes to curation window and curation rewards calculation**
    - The most important aspect of this change is that the 5 minute reverse auction is going away, so there is no punishment for voting early. This will finally put manual voters on an equal footing with automated voters when it comes to competing for curation rewards. This change, more than any other, was the driving reason for the naming of this hardfork.
    - In addition, anyone voting in the first 24 hours will be rewarded based solely on their Hive Power and vote weight, and the reward curve applied from 24 hours to the end of the voting window will be much softer than currently, eliminating any need to feel rushed when voting in order to maximize curation rewards.
- **new operation and API to convert HIVE to HBD**
    - HBD (Hive-backed Dollars) is intended to be a feeless, trustless, USD-pegged stablecoin, a feat that has yet to be achieved in the cryptocurrency world. This new operation will stabilize the price pegging of HBD, allowing it to achieve its full potential as a frictionless medium of exchange for digital commerce.
    - While you've always been able to convert your HBD to HIVE, this new operation will allow you to convert in the opposite direction (HIVE -&amp;gt; HBD). 
    - Previously, HBD was only effectively price-pegged on the low side of USD pricing. This new conversion will create an equilibrium point where HBD will be pegged on both the low side AND the high side.
    
- **interest only paid on HBD held in your savings account**
    - You might have missed that you're earning interest on your Hive-backed Dollars, so this could be a neat surprise: simply move HBD into your savings account (3 day withdrawal waiting period) to earn interest on it just for holding! No-risk DeFi, made easy.
- **new operation and API to enable recurring payments**
    - These are periodic transfers which you schedule to happen automatically. They are intended for managing subscription payments, etc.
- **disallow voting on expired proposals**
- **witness and proposal votes by an account expire after one year if the account stops actively making governance-related votes**
    - This change was made to ensure that old votes from dormant accounts don't unduly impact governance decisions for Hive. It will enable Hive to find a new balance between incumbent block producers and new competitors for those positions.
- **proposal creators can change the end date of their Decentralized Hive Fund (DHF) proposals**
    - This allows a proposal creator to reduce their funding request (by decreasing the number of payments they receive) without having to create a new proposal and start from zero in respect to community support for the proposal.
- **re-allow vote operation for already paid posts**
    - Voting outside the rewards window should still be something you can do, to show appreciation for the content you like and to add to your curated feed. This is a quality of life change that does *not* impact anything to do with allocation of rewards. 

There are also new command-line options, a pile of bug fixes and performance optimizations, a new API call, and many other improvements to the code and documentation that the Hive blockchain relies on. Full details are available in the [release notes](https://gitlab.syncad.com/hive/hive/-/releases#v1.25.0) This is pretty critical work towards making it easier to understand, easier to run, and to create the best possible ecosystem for someone to hop in and start building with Hive.

If you're not technical and don't want to do some hands-on testing, you're all caught up! You likely won't notice anything immediately when *Equilibrium* goes live. 

However, you may want to consider changing the way you vote for posts after the hardfork, especially if you've resorted to auto-voting to maximize your curation rewards. Now you'll have more time and flexibility to find the content you love in a relaxed way, and more time to engage with your favorite authors and communities!

### In the next 12 days...

There is still time before the hardfork takes place. If you want to contribute to testing or if you are a dApp creator, project owner, or someone who just wants to start getting more involved with the ecosystem, here are some handy links so you can jump in before *Equilibrium* goes live.

## Some Technical ~~House~~Beekeeping

**Here is the link to the final official release version of Hardfork 25:**
https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0

...and here are some helpful posts that outline joining the testnet, including how to create a witness node on the testnet, if you want to dive into the decentralized tech that powers Hive.

**A guide to starting up a testnet witness:**
https://peakd.com/guide/@howo/how-to-run-a-witness-node-on-the-hf25-testnet

**And more information on the public testnet itself:**
https://peakd.com/@gtg/hf25-public-testnet-reloaded-rc2

**The testnet faucet page:**
https://hivetestnetfaucet.org/

All dApps that rely on the functions outlined above should have started testing or be starting to test as soon as possible. 

*Equilibrium* is the second community-driven hardfork of the Hive blockchain and we are very excited for it! It marks a key milestone for Hive development and for the Hive ecosystem. 

### Keep an eye out for updates here and on our various Hive social media channels! üêù&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@hiveio&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021').html();
      const outputElem = $('#content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 code {
    background: white;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 a:hover {
    border-bottom: 0;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 h1 {
    font-size: 2.2em;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 header small {
    color: #999;
    font-size: 50%;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive/@hiveio/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021&quot;&gt;Hive Hardfork 25 is on the Way: Hive to reach Equilibrium on June 30th, 2021&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@hiveio&quot;&gt;@hiveio&lt;/a&gt;
&lt;/p&gt;</content><author><name>hiveio</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![image.png](https://images.hive.blog/DQmfByqFD7d9ecpcYMhy7ucwhQLKKrrLjcp9vb378wSJwCP/image.png) Earlier this week we notified cryptocurrency exchanges that the upcoming hardfork to the Hive blockchain network, dubbed *Equilibrium*, is planned for the end of June. Today's official date announcement also has a pile of helpful information including a summary of changes coming with the new hardfork, links to the software, and details for those of you who may want to get involved in testing the new software! ## TL:DR the Code; A Quick Overview of the Upcoming Changes *Equilibrium* is a state of balance between multiple forces. In the case of the Hive blockchain network, the guiding mission from day one has been to create an ecosystem that allows anyone to become a part of our decentralized network, contribute to governance, and to own their data, connections, tokens and actions in a world where the current tech and social powers have an iron grip. This hardfork continues to empower people to use Hive the way they want and takes another few large steps forward in creating an ecosystem with better balanced rules and tools for building whatever we can dream up. Reaching equilibrium is finding a state of balance and readiness. It is the essential preparation for big moves, exciting changes, and sustained growth. ### Here's a quick summary of HF25: Below is a list of the consensus changes that are being made as part of this hardfork: - **changes to curation window and curation rewards calculation** - The most important aspect of this change is that the 5 minute reverse auction is going away, so there is no punishment for voting early. This will finally put manual voters on an equal footing with automated voters when it comes to competing for curation rewards. This change, more than any other, was the driving reason for the naming of this hardfork. - In addition, anyone voting in the first 24 hours will be rewarded based solely on their Hive Power and vote weight, and the reward curve applied from 24 hours to the end of the voting window will be much softer than currently, eliminating any need to feel rushed when voting in order to maximize curation rewards. - **new operation and API to convert HIVE to HBD** - HBD (Hive-backed Dollars) is intended to be a feeless, trustless, USD-pegged stablecoin, a feat that has yet to be achieved in the cryptocurrency world. This new operation will stabilize the price pegging of HBD, allowing it to achieve its full potential as a frictionless medium of exchange for digital commerce. - While you've always been able to convert your HBD to HIVE, this new operation will allow you to convert in the opposite direction (HIVE -&amp;gt; HBD). - Previously, HBD was only effectively price-pegged on the low side of USD pricing. This new conversion will create an equilibrium point where HBD will be pegged on both the low side AND the high side. - **interest only paid on HBD held in your savings account** - You might have missed that you're earning interest on your Hive-backed Dollars, so this could be a neat surprise: simply move HBD into your savings account (3 day withdrawal waiting period) to earn interest on it just for holding! No-risk DeFi, made easy. - **new operation and API to enable recurring payments** - These are periodic transfers which you schedule to happen automatically. They are intended for managing subscription payments, etc. - **disallow voting on expired proposals** - **witness and proposal votes by an account expire after one year if the account stops actively making governance-related votes** - This change was made to ensure that old votes from dormant accounts don't unduly impact governance decisions for Hive. It will enable Hive to find a new balance between incumbent block producers and new competitors for those positions. - **proposal creators can change the end date of their Decentralized Hive Fund (DHF) proposals** - This allows a proposal creator to reduce their funding request (by decreasing the number of payments they receive) without having to create a new proposal and start from zero in respect to community support for the proposal. - **re-allow vote operation for already paid posts** - Voting outside the rewards window should still be something you can do, to show appreciation for the content you like and to add to your curated feed. This is a quality of life change that does *not* impact anything to do with allocation of rewards. There are also new command-line options, a pile of bug fixes and performance optimizations, a new API call, and many other improvements to the code and documentation that the Hive blockchain relies on. Full details are available in the [release notes](https://gitlab.syncad.com/hive/hive/-/releases#v1.25.0) This is pretty critical work towards making it easier to understand, easier to run, and to create the best possible ecosystem for someone to hop in and start building with Hive. If you're not technical and don't want to do some hands-on testing, you're all caught up! You likely won't notice anything immediately when *Equilibrium* goes live. However, you may want to consider changing the way you vote for posts after the hardfork, especially if you've resorted to auto-voting to maximize your curation rewards. Now you'll have more time and flexibility to find the content you love in a relaxed way, and more time to engage with your favorite authors and communities! ### In the next 12 days... There is still time before the hardfork takes place. If you want to contribute to testing or if you are a dApp creator, project owner, or someone who just wants to start getting more involved with the ecosystem, here are some handy links so you can jump in before *Equilibrium* goes live. ## Some Technical ~~House~~Beekeeping **Here is the link to the final official release version of Hardfork 25:** https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0 ...and here are some helpful posts that outline joining the testnet, including how to create a witness node on the testnet, if you want to dive into the decentralized tech that powers Hive. **A guide to starting up a testnet witness:** https://peakd.com/guide/@howo/how-to-run-a-witness-node-on-the-hf25-testnet **And more information on the public testnet itself:** https://peakd.com/@gtg/hf25-public-testnet-reloaded-rc2 **The testnet faucet page:** https://hivetestnetfaucet.org/ All dApps that rely on the functions outlined above should have started testing or be starting to test as soon as possible. *Equilibrium* is the second community-driven hardfork of the Hive blockchain and we are very excited for it! It marks a key milestone for Hive development and for the Hive ecosystem. ### Keep an eye out for updates here and on our various Hive social media channels! üêù See: Hive Hardfork 25 is on the Way: Hive to reach Equilibrium on June 30th, 2021 by @hiveio</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmfByqFD7d9ecpcYMhy7ucwhQLKKrrLjcp9vb378wSJwCP/image.png" /><media:content medium="image" url="https://images.hive.blog/DQmfByqFD7d9ecpcYMhy7ucwhQLKKrrLjcp9vb378wSJwCP/image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive HardFork 25 Jump Starter Kit</title><link href="https://hivedocs.info/howto/devops/2021/06/18/hive-hardfork-25-jump-starter-kit.html" rel="alternate" type="text/html" title="Hive HardFork 25 Jump Starter Kit" /><published>2021-06-18T12:31:45-07:00</published><updated>2021-06-18T12:31:45-07:00</updated><id>https://hivedocs.info/howto/devops/2021/06/18/hive-hardfork-25-jump-starter-kit</id><content type="html" xml:base="https://hivedocs.info/howto/devops/2021/06/18/hive-hardfork-25-jump-starter-kit.html">&lt;div id=&quot;content-gtg-hive-hardfork-25-jump-starter-kit&quot;&gt;Intended for the Hive API node operators, witnesses, and developers.

At the time of Eclipse release I made a similar post that saved many (hours) of lives, so I‚Äôm creating an updated one for the upcoming Hard Fork 25.

&lt;center&gt;https://www.youtube.com/watch?v=mrwgrOhl7Yw&lt;/center&gt;&lt;sup&gt;Yes, new Hive Hard Fork, new fancy logo reveal.&lt;/sup&gt;

# Code
## GitLab
https://gitlab.syncad.com/hive/hive
Our core development efforts takes place in a community hosted GitLab repository (thanks @blocktrades). There's Hive core itself, but also many other Hive related software repositories.

## GitHub
https://github.com/openhive-network/hive
We use it as a push mirror for GitLab repository, mostly for visibility and decentralization - if you have an account on GitHub please fork at least [hive](https://github.com/openhive-network/hive) and [hivemind](https://github.com/openhive-network/hivemind) and star them if you haven‚Äôt done so yet. We haven't paid much attention to it but apparently it's important for some outside metrics.

&lt;center&gt;![star_fork.png](https://images.hive.blog/DQmQbRRrtoTFPZA9QmDRjvswPtaGuXrWXje1WHp9CeeGbV2/star_fork.png)
&lt;sup&gt;Please click both buttons&lt;/sup&gt;&lt;/center&gt;

# Services
## API node
https://api.openhive.network
Soon to be switched to `v1.25.0` but because it‚Äôs heavily used in Hive related R&amp;amp;D it might not be your best choice if you are looking for a fast API node without any rate limiting. During the maintenance mode, it will fall back to https://api.hive.blog 

## Seed node
`hived` `v1.25.0` listens on `gtg.openhive.network:2001`
to use it in your `config.ini` file just add the line:
```
p2p-seed-node = gtg.openhive.network:2001
```
If you don't have any `p2p-seed-node = ` entries in your config file, built-in defaults will be used (which contains my node too).

# Stuff for download
TL;DR https://gtg.openhive.network/get

## Binaries
`./get/bin`contains `hived` and `cli_wallet` binaries built on `Ubuntu 18.04 LTS` which should also run fine on `Ubuntu 20.04 LTS`

## Blocks
`./get/blockchain`
As usual, the `block_log` file, roughly 350GB and counting.
For testing needs there's also `block_log.5M` that is limited to first 5 million blocks.

## Snapshots

### API
`./get/snapshot/api/` contains a relatively recent snapshot of the API node with all the fancy plugins.
There‚Äôs a snapshot for the upcoming version `v1.25.0` but also for the old one `v1.24.8` if you need to switch back.
Uncompressed snapshot takes roughly 480GB
There‚Äôs also the `example-api-config.ini` file out there that contains settings compatible with the snapshot.

To decompress, you can use simply run it through something like: `lbzip2 -dc | tar xv`
(Using parallel bzip2 on multi-threaded systems might save you a lot of time)

To use snapshot you need:
- A `block_log` file, not smaller than the one used when the snapshot was made.
- A `config.ini` file, compatible with the snapshot (see above), adjusted to your needs, without changes that could affect it in a way that changes the state.
- A `hived` binary compatible with the snapshot

All of that you can find above.

 Run `hived` with `--load-snapshot name`, assuming the snapshot is stored in `snapshot/name`

`hived` API node runtime currently takes 823GB (incl. shm 19GB, excl. snapshot)

### Exchanges
There‚Äôs also a snapshot meant for exchanges in `./get/snapshot/exchange/`  that allows them to quickly get up and running, it requires a compatible configuration and that exchange account is one of those who are tracked by my node. If you run an exchange and want to be on that list to use a snapshot, just please let me know.

## Hivemind database dump
`./get/hivemind/` contains a relatively recent dump of the Hivemind database.
I use self-describing file names such as:
`hivemind-20210616-47a41c96.dump`
Date when dump was taken, revision of `hivemind` that was running it.
You need at least that version, remember about `intarray` extension
Consider running `pg_restore` with at least `-j 6` to run long running tasks in parallel
After restoring the database, make sure to run the `db_upgrade` script.

Even though during full sync database size peaks easily over 750GB, when restored from dump it takes roughly 500GB. Dump file itself is just 53GB.

### All resources are offered AS IS.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@gtg&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-hardfork-25-jump-starter-kit&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-gtg-hive-hardfork-25-jump-starter-kit').html();
      const outputElem = $('#content-gtg-hive-hardfork-25-jump-starter-kit');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-gtg-hive-hardfork-25-jump-starter-kit {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit code {
    background: white;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit a:hover {
    border-bottom: 0;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit h1 {
    font-size: 2.2em;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit header small {
    color: #999;
    font-size: 50%;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-160391/@gtg/hive-hardfork-25-jump-starter-kit&quot;&gt;Hive HardFork 25 Jump Starter Kit&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@gtg&quot;&gt;@gtg&lt;/a&gt;
&lt;/p&gt;</content><author><name>gtg</name></author><category term="howto" /><category term="devops" /><summary type="html">Intended for the Hive API node operators, witnesses, and developers. At the time of Eclipse release I made a similar post that saved many (hours) of lives, so I‚Äôm creating an updated one for the upcoming Hard Fork 25. https://www.youtube.com/watch?v=mrwgrOhl7YwYes, new Hive Hard Fork, new fancy logo reveal. # Code ## GitLab https://gitlab.syncad.com/hive/hive Our core development efforts takes place in a community hosted GitLab repository (thanks @blocktrades). There's Hive core itself, but also many other Hive related software repositories. ## GitHub https://github.com/openhive-network/hive We use it as a push mirror for GitLab repository, mostly for visibility and decentralization - if you have an account on GitHub please fork at least [hive](https://github.com/openhive-network/hive) and [hivemind](https://github.com/openhive-network/hivemind) and star them if you haven‚Äôt done so yet. We haven't paid much attention to it but apparently it's important for some outside metrics. ![star_fork.png](https://images.hive.blog/DQmQbRRrtoTFPZA9QmDRjvswPtaGuXrWXje1WHp9CeeGbV2/star_fork.png) Please click both buttons # Services ## API node https://api.openhive.network Soon to be switched to `v1.25.0` but because it‚Äôs heavily used in Hive related R&amp;amp;D it might not be your best choice if you are looking for a fast API node without any rate limiting. During the maintenance mode, it will fall back to https://api.hive.blog ## Seed node `hived` `v1.25.0` listens on `gtg.openhive.network:2001` to use it in your `config.ini` file just add the line: ``` p2p-seed-node = gtg.openhive.network:2001 ``` If you don't have any `p2p-seed-node = ` entries in your config file, built-in defaults will be used (which contains my node too). # Stuff for download TL;DR https://gtg.openhive.network/get ## Binaries `./get/bin`contains `hived` and `cli_wallet` binaries built on `Ubuntu 18.04 LTS` which should also run fine on `Ubuntu 20.04 LTS` ## Blocks `./get/blockchain` As usual, the `block_log` file, roughly 350GB and counting. For testing needs there's also `block_log.5M` that is limited to first 5 million blocks. ## Snapshots ### API `./get/snapshot/api/` contains a relatively recent snapshot of the API node with all the fancy plugins. There‚Äôs a snapshot for the upcoming version `v1.25.0` but also for the old one `v1.24.8` if you need to switch back. Uncompressed snapshot takes roughly 480GB There‚Äôs also the `example-api-config.ini` file out there that contains settings compatible with the snapshot. To decompress, you can use simply run it through something like: `lbzip2 -dc | tar xv` (Using parallel bzip2 on multi-threaded systems might save you a lot of time) To use snapshot you need: - A `block_log` file, not smaller than the one used when the snapshot was made. - A `config.ini` file, compatible with the snapshot (see above), adjusted to your needs, without changes that could affect it in a way that changes the state. - A `hived` binary compatible with the snapshot All of that you can find above. Run `hived` with `--load-snapshot name`, assuming the snapshot is stored in `snapshot/name` `hived` API node runtime currently takes 823GB (incl. shm 19GB, excl. snapshot) ### Exchanges There‚Äôs also a snapshot meant for exchanges in `./get/snapshot/exchange/` that allows them to quickly get up and running, it requires a compatible configuration and that exchange account is one of those who are tracked by my node. If you run an exchange and want to be on that list to use a snapshot, just please let me know. ## Hivemind database dump `./get/hivemind/` contains a relatively recent dump of the Hivemind database. I use self-describing file names such as: `hivemind-20210616-47a41c96.dump` Date when dump was taken, revision of `hivemind` that was running it. You need at least that version, remember about `intarray` extension Consider running `pg_restore` with at least `-j 6` to run long running tasks in parallel After restoring the database, make sure to run the `db_upgrade` script. Even though during full sync database size peaks easily over 750GB, when restored from dump it takes roughly 500GB. Dump file itself is just 53GB. ### All resources are offered AS IS. See: Hive HardFork 25 Jump Starter Kit by @gtg</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/mrwgrOhl7Yw/0.jpg" /><media:content medium="image" url="https://img.youtube.com/vi/mrwgrOhl7Yw/0.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Imagehoster cache purge for Cloudflare</title><link href="https://hivedocs.info/howto/devops/imagehoster/2021/06/14/imagehoster-cache-purge-for-cloudflare.html" rel="alternate" type="text/html" title="Imagehoster cache purge for Cloudflare" /><published>2021-06-14T01:43:48-07:00</published><updated>2021-06-14T01:43:48-07:00</updated><id>https://hivedocs.info/howto/devops/imagehoster/2021/06/14/imagehoster-cache-purge-for-cloudflare</id><content type="html" xml:base="https://hivedocs.info/howto/devops/imagehoster/2021/06/14/imagehoster-cache-purge-for-cloudflare.html">&lt;div id=&quot;content-good-karma-imagehoster-cache-purge-for-cloudflare&quot;&gt;Quick post about new script that helps with caching avatars on imagehoster instances hosted on Cloudflare.

![ecency-imagehoster-caching](https://images.ecency.com/DQmecXYP57pagKtfrUvcRG5AZsrgnwdmbsmugKcv5han8Mn/cache_work.png)

We have 2 imagehoster instances right now, one run by Ecency team and another from Blocktrades team. It is crucial part of platform without which user experience would really suffer. Images, avatars are face of every UI.

https://images.ecency.com
https://images.hive.blog

They both run in front of Cloudflare and images were not utilizing Cloudflare cache properly. For couple reasons, one - avatars cannot be cached for long time, when person updates avatar via apps/websites then they expect it see it instantly, two - Cloudflare considers them dynamic content by default.

If you force cache avatars with Cloudflare page rules then update only shown after cache is expired. That‚Äôs not acceptable for Blockchain that‚Äôs very fast but avatar update require cache expiry. On Ecency instance we had 10 seconds cache, while Hiveblog instance wasn‚Äôt using cache at first and couple days ago Blocktrades tried 4h. All other images could be cached for longer period because they don‚Äôt change at all, for avatars 4h. Which was still too long.

To solve avatar caching issue, created simple script that would purge cache from Cloudflare when account gets update on blockchain. If imagehoster instances are down or in maintenance, all images would be served from Cloudflare cache which is really great for user experience as well.

If you will be running Imagehoster instance in future or considering it, I would recommend running this script on separate server and set avatars caching to longer period safely. If you are not using Cloudflare, then consider removing caching avatars completely, it will put some load on your server but alternative is confusing user experience.

https://github.com/ecency/cf-cache

Both instances running above script now and whenever account update triggered on Blockchain, above script purges relevant user‚Äôs avatar to keep it fresh, use new avatar on all apps that depend on it. 

images.ecency.com cache period for avatars 1 week 
images.hive.blog cache period for avatar 5 hours

After change, I noticed Ecency.com became even more faster... Caching images for sure improving performance of all apps.

### Support proposals  
 
[`Ecency`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B141%5D&amp;amp;approve=true) | [`Hivesearcher`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B146%5D&amp;amp;approve=true) | [`Hivesigner`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B88%5D&amp;amp;approve=true)&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@good-karma&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/imagehoster-cache-purge-for-cloudflare&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-good-karma-imagehoster-cache-purge-for-cloudflare').html();
      const outputElem = $('#content-good-karma-imagehoster-cache-purge-for-cloudflare');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-good-karma-imagehoster-cache-purge-for-cloudflare {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare code {
    background: white;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare a:hover {
    border-bottom: 0;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare h1 {
    font-size: 2.2em;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare header small {
    color: #999;
    font-size: 50%;
  }
  #content-good-karma-imagehoster-cache-purge-for-cloudflare img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://ecency.com/hive-139531/@good-karma/imagehoster-cache-purge-for-cloudflare&quot;&gt;Imagehoster cache purge for Cloudflare&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@good-karma&quot;&gt;@good-karma&lt;/a&gt;
&lt;/p&gt;</content><author><name>good-karma</name></author><category term="howto" /><category term="devops" /><category term="imagehoster" /><summary type="html">Quick post about new script that helps with caching avatars on imagehoster instances hosted on Cloudflare. ![ecency-imagehoster-caching](https://images.ecency.com/DQmecXYP57pagKtfrUvcRG5AZsrgnwdmbsmugKcv5han8Mn/cache_work.png) We have 2 imagehoster instances right now, one run by Ecency team and another from Blocktrades team. It is crucial part of platform without which user experience would really suffer. Images, avatars are face of every UI. https://images.ecency.com https://images.hive.blog They both run in front of Cloudflare and images were not utilizing Cloudflare cache properly. For couple reasons, one - avatars cannot be cached for long time, when person updates avatar via apps/websites then they expect it see it instantly, two - Cloudflare considers them dynamic content by default. If you force cache avatars with Cloudflare page rules then update only shown after cache is expired. That‚Äôs not acceptable for Blockchain that‚Äôs very fast but avatar update require cache expiry. On Ecency instance we had 10 seconds cache, while Hiveblog instance wasn‚Äôt using cache at first and couple days ago Blocktrades tried 4h. All other images could be cached for longer period because they don‚Äôt change at all, for avatars 4h. Which was still too long. To solve avatar caching issue, created simple script that would purge cache from Cloudflare when account gets update on blockchain. If imagehoster instances are down or in maintenance, all images would be served from Cloudflare cache which is really great for user experience as well. If you will be running Imagehoster instance in future or considering it, I would recommend running this script on separate server and set avatars caching to longer period safely. If you are not using Cloudflare, then consider removing caching avatars completely, it will put some load on your server but alternative is confusing user experience. https://github.com/ecency/cf-cache Both instances running above script now and whenever account update triggered on Blockchain, above script purges relevant user‚Äôs avatar to keep it fresh, use new avatar on all apps that depend on it. images.ecency.com cache period for avatars 1 week images.hive.blog cache period for avatar 5 hours After change, I noticed Ecency.com became even more faster... Caching images for sure improving performance of all apps. ### Support proposals [`Ecency`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B141%5D&amp;amp;approve=true) | [`Hivesearcher`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B146%5D&amp;amp;approve=true) | [`Hivesigner`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B88%5D&amp;amp;approve=true) See: Imagehoster cache purge for Cloudflare by @good-karma</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.ecency.com/DQmecXYP57pagKtfrUvcRG5AZsrgnwdmbsmugKcv5han8Mn/cache_work.png" /><media:content medium="image" url="https://images.ecency.com/DQmecXYP57pagKtfrUvcRG5AZsrgnwdmbsmugKcv5han8Mn/cache_work.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive Projects weekly update: 5 projects added, 131 listed in total!</title><link href="https://hivedocs.info/news/projects/2021/06/12/hiveprojects-weekly-update-2021-06-12-42368.html" rel="alternate" type="text/html" title="Hive Projects weekly update: 5 projects added, 131 listed in total!" /><published>2021-06-12T09:00:06-07:00</published><updated>2021-06-12T09:00:06-07:00</updated><id>https://hivedocs.info/news/projects/2021/06/12/hiveprojects-weekly-update-2021-06-12-42368</id><content type="html" xml:base="https://hivedocs.info/news/projects/2021/06/12/hiveprojects-weekly-update-2021-06-12-42368.html">&lt;div id=&quot;content-engrave-hiveprojects-weekly-update-2021-06-12-42368&quot;&gt;![](https://files.peakd.com/file/peakd-hive/engrave/IHxPwBD1-hiveprojects_update.png)

# What is [Hive Projects](https://hiveprojects.io)?

[Hive Projects](https://hiveprojects.io) is the biggest directory of apps, sites, tools, and scripts created for the Hive ecosystem. This website is an entirely volunteer-driven effort. That includes coding time and hosting costs. If you wish to help or show your gratitude, there are plenty of ways in which you can do that:
 * upvote this post
 * reblog or cross-post it into your favorite community
 * contribute to HiveProjects, by adding a new project - everyone can do it!
 * let us know about new project, by posting about it in [Hive Projects Community](https://peakd.com/c/hive-192847) or by cross-posting to it or simply paste us a link at [Engrave Discord server](https://discord.gg/8NktdFh)
 * vote for our @engrave witness
 * write a comment :)

***


Previous post: [Hive Projects weekly update: 4 projects added, 126 listed in total!](/@engrave/hiveprojects-weekly-update-2021-03-06-13937)

***



# Newly added projects 

All published projects were moderated and accepted by our **Content Manager** @lukmarcus, who works hard to make [Hive Projects](https://hiveprojects.io) the best and most up-to-date directory of tools and apps in our ecosystem. The entire reward from this post goes to him.




## PizzaBox
**Team:** @thebeardflex, @hivetrending

![](https://hiveprojects.io/media/imgs/136/1623453852443.png)

**Category:** [Bots](https://hiveprojects.io/categories/bots/)

**Description:** *HIVE tailored community Discord Bot focused around awareness and onboarding. Provides moderation tools for use by communities both on and off chain.

Ban, Kick, Mute, Sticky, Slowmo, Lock Channel, Purge, Music Player, Ticket System etc.
Giveaways
Market information for second-layer Hive-Engine tokens
HIVE market information
Mini-games
HIVE onboarding tools/tutorials. Some commands will be customizable per guild they exist in.*

[PizzaBox on HiveProjects.io](https://hiveprojects.io/projects/p/pizzabox/)



## Beatzchain
**Team:** @polarmystro, @lamarz7

![](https://hiveprojects.io/media/imgs/134/1618985842320.png)

**Category:** [Generic Hive Interfaces](https://hiveprojects.io/categories/generic-hive-interfaces/)

**Description:** *Beatzchain project will be a platform that would run on the Hive Blockchain that would serve for Rappers and music producers.  Beatzchain wants to change the Hip-Hop world with a network rap musicians can earn cryptocurrencies through Hive, Music producers can buy/sell beats, and rappers can use crypto to purchase beats including the ones they&amp;#39;ve earned through the Hive Blockchain.  We would like to start an NFT exchange for rappers and producers called &amp;quot;Hip-Hop Stocks&amp;quot; where musicians can create music NFTs with their songs/beats and buyers could benefit off the equity appreciation.  The goal is to give unsigned, independent, and major artists a better financial system for musicians where everyone with good talent who put the work in can sit by the table together.*

[Beatzchain on HiveProjects.io](https://hiveprojects.io/projects/p/beatzchain/)



## Hive Chain Documentation
**Team:** @inertia

![](https://hiveprojects.io/media/imgs/133/1615696720345.png)

**Category:** [Programming Tools](https://hiveprojects.io/categories/programming-tools/)

**Description:** *Your resource for various levels of Hive Documentation.*

[Hive Chain Documentation on HiveProjects.io](https://hiveprojects.io/projects/p/hive-chain-documentation/)



## Votify
**Team:** @dannychain

![](https://hiveprojects.io/media/imgs/132/1615069673826.png)

**Category:** [Witness Tools](https://hiveprojects.io/categories/witness-tools/)

**Description:** *An Open Source Voting Page for Hive-Engine Witnesses*

[Votify on HiveProjects.io](https://hiveprojects.io/projects/p/votify/)



## Karaka
**Team:** 

![](https://hiveprojects.io/media/imgs/135/1619983488995.png)

**Category:** [Bots](https://hiveprojects.io/categories/bots/)

**Description:** *Karaka is an automation (clerk) for Hive and Hive-Engine blockchains. Use it to manage tokens across multiple accounts.*

[Karaka on HiveProjects.io](https://hiveprojects.io/projects/p/karaka/)



***

&lt;center&gt;

**That would be all for today. Stay tuned for the next update and consider contributing to Hive Projects. It is a community-driven website.**

**Click on the image to vote for @engrave witness:**

[![banner_engrave 100.png](https://images.hive.blog/DQmUghvic5TCPPvVkB4iB7eXmgQ3RQ4L8jkVizvuCBW8RMT/banner_engrave%20100.png)](https://hivesigner.com/sign/account-witness-vote?witness=engrave&amp;amp;approve=1)

**Dont forget to follow @engrave account!**

&lt;/center&gt;
&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@engrave&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hiveprojects-weekly-update-2021-06-12-42368&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-engrave-hiveprojects-weekly-update-2021-06-12-42368').html();
      const outputElem = $('#content-engrave-hiveprojects-weekly-update-2021-06-12-42368');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 code {
    background: white;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 a:hover {
    border-bottom: 0;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 h1 {
    font-size: 2.2em;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 header small {
    color: #999;
    font-size: 50%;
  }
  #content-engrave-hiveprojects-weekly-update-2021-06-12-42368 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-192847/@engrave/hiveprojects-weekly-update-2021-06-12-42368&quot;&gt;Hive Projects weekly update: 5 projects added, 131 listed in total!&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@engrave&quot;&gt;@engrave&lt;/a&gt;
&lt;/p&gt;</content><author><name>engrave</name></author><category term="news" /><category term="projects" /><summary type="html">![](https://files.peakd.com/file/peakd-hive/engrave/IHxPwBD1-hiveprojects_update.png) # What is [Hive Projects](https://hiveprojects.io)? [Hive Projects](https://hiveprojects.io) is the biggest directory of apps, sites, tools, and scripts created for the Hive ecosystem. This website is an entirely volunteer-driven effort. That includes coding time and hosting costs. If you wish to help or show your gratitude, there are plenty of ways in which you can do that: * upvote this post * reblog or cross-post it into your favorite community * contribute to HiveProjects, by adding a new project - everyone can do it! * let us know about new project, by posting about it in [Hive Projects Community](https://peakd.com/c/hive-192847) or by cross-posting to it or simply paste us a link at [Engrave Discord server](https://discord.gg/8NktdFh) * vote for our @engrave witness * write a comment :) *** Previous post: [Hive Projects weekly update: 4 projects added, 126 listed in total!](/@engrave/hiveprojects-weekly-update-2021-03-06-13937) *** # Newly added projects All published projects were moderated and accepted by our **Content Manager** @lukmarcus, who works hard to make [Hive Projects](https://hiveprojects.io) the best and most up-to-date directory of tools and apps in our ecosystem. The entire reward from this post goes to him. ## PizzaBox **Team:** @thebeardflex, @hivetrending ![](https://hiveprojects.io/media/imgs/136/1623453852443.png) **Category:** [Bots](https://hiveprojects.io/categories/bots/) **Description:** *HIVE tailored community Discord Bot focused around awareness and onboarding. Provides moderation tools for use by communities both on and off chain. Ban, Kick, Mute, Sticky, Slowmo, Lock Channel, Purge, Music Player, Ticket System etc. Giveaways Market information for second-layer Hive-Engine tokens HIVE market information Mini-games HIVE onboarding tools/tutorials. Some commands will be customizable per guild they exist in.* [PizzaBox on HiveProjects.io](https://hiveprojects.io/projects/p/pizzabox/) ## Beatzchain **Team:** @polarmystro, @lamarz7 ![](https://hiveprojects.io/media/imgs/134/1618985842320.png) **Category:** [Generic Hive Interfaces](https://hiveprojects.io/categories/generic-hive-interfaces/) **Description:** *Beatzchain project will be a platform that would run on the Hive Blockchain that would serve for Rappers and music producers. Beatzchain wants to change the Hip-Hop world with a network rap musicians can earn cryptocurrencies through Hive, Music producers can buy/sell beats, and rappers can use crypto to purchase beats including the ones they&amp;#39;ve earned through the Hive Blockchain. We would like to start an NFT exchange for rappers and producers called &amp;quot;Hip-Hop Stocks&amp;quot; where musicians can create music NFTs with their songs/beats and buyers could benefit off the equity appreciation. The goal is to give unsigned, independent, and major artists a better financial system for musicians where everyone with good talent who put the work in can sit by the table together.* [Beatzchain on HiveProjects.io](https://hiveprojects.io/projects/p/beatzchain/) ## Hive Chain Documentation **Team:** @inertia ![](https://hiveprojects.io/media/imgs/133/1615696720345.png) **Category:** [Programming Tools](https://hiveprojects.io/categories/programming-tools/) **Description:** *Your resource for various levels of Hive Documentation.* [Hive Chain Documentation on HiveProjects.io](https://hiveprojects.io/projects/p/hive-chain-documentation/) ## Votify **Team:** @dannychain ![](https://hiveprojects.io/media/imgs/132/1615069673826.png) **Category:** [Witness Tools](https://hiveprojects.io/categories/witness-tools/) **Description:** *An Open Source Voting Page for Hive-Engine Witnesses* [Votify on HiveProjects.io](https://hiveprojects.io/projects/p/votify/) ## Karaka **Team:** ![](https://hiveprojects.io/media/imgs/135/1619983488995.png) **Category:** [Bots](https://hiveprojects.io/categories/bots/) **Description:** *Karaka is an automation (clerk) for Hive and Hive-Engine blockchains. Use it to manage tokens across multiple accounts.* [Karaka on HiveProjects.io](https://hiveprojects.io/projects/p/karaka/) *** **That would be all for today. Stay tuned for the next update and consider contributing to Hive Projects. It is a community-driven website.** **Click on the image to vote for @engrave witness:** [![banner_engrave 100.png](https://images.hive.blog/DQmUghvic5TCPPvVkB4iB7eXmgQ3RQ4L8jkVizvuCBW8RMT/banner_engrave%20100.png)](https://hivesigner.com/sign/account-witness-vote?witness=engrave&amp;amp;approve=1) **Dont forget to follow @engrave account!** See: Hive Projects weekly update: 5 projects added, 131 listed in total! by @engrave</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>