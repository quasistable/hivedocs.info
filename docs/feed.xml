<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://hivedocs.info/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hivedocs.info/" rel="alternate" type="text/html" /><updated>2021-07-12T21:00:34-07:00</updated><id>https://hivedocs.info/feed.xml</id><title type="html">Hive Chain Documentation</title><subtitle>Your resource for various levels of Hive Documentation.</subtitle><author><name>site curated by: @inertia</name></author><entry><title type="html">Core development report #12: Good progress on direct rc delegations</title><link href="https://hivedocs.info/news/core/development/2021/07/12/core-development-report-12-good-progress-on-direct-rc-delegations.html" rel="alternate" type="text/html" title="Core development report #12: Good progress on direct rc delegations" /><published>2021-07-12T13:30:15-07:00</published><updated>2021-07-12T13:30:15-07:00</updated><id>https://hivedocs.info/news/core/development/2021/07/12/core-development-report-12-good-progress-on-direct-rc-delegations</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/07/12/core-development-report-12-good-progress-on-direct-rc-delegations.html">&lt;div id=&quot;content-howo-core-development-report-12-good-progress-on-direct-rc-delegations&quot;&gt;
![image.png](https://files.peakd.com/file/peakd-hive/howo/AJeaeqp3EAX2QSK997FwxcZdJuACo817654t7riwiGf3aSNSLCLRwP5yGvpwrcb.png)

Hey,

I usually do my reports via voice during the hive developers meeting, but due to some vacations here and there and rush with hard fork 25, we decided to postpone it a few times so I figured I'd make an update about my progress via text.

Nowadays I am working on direct rc delegations, if you didn't follow, the initial implementation was judged too complex and there was a fear that this complexity could hide bug in the edge cases. Plus it makes it less user friendly. So I made a new specification here https://gitlab.syncad.com/hive/hive/-/issues/152.

And now I'm implementing it, work is in progress on that branch https://gitlab.syncad.com/hive/hive/-/tree/feature/direct_rc_delegations

The core core is done, you can delegate rc, update an existing delegation, delete a delegation and rc delegations are taken into account when calculating rc. I have also added some api endpoint so that when you call find_rc_account and list_rc_account the amount of RC received/delegated is reflected there.

I also added an endpoint to fetch direct rc delegations but I'm having some issues with the indexes (it induces a uniqueness constraint in the blockchain which is a problem because then if you want to delegate to one person and then another person you end up with a conflict because &quot;from&quot; is unique).

I've also included everything above in the cli_wallet for easy use. I'll update hive-js later on too so that most dapps will be able to play with it.

Apart from that I need to handle the edge cases where you lose RC (you delegated all your rc but then you power downs so you can no longer sustain those delegations) and write a mountain of automated tests.

Once that's done, I'll go through a bunch of reviews with @blocktrades' team (which I'm assuming won't happen until a few weeks as some of the core team is in vacations). Then we'll launch a testnet (or update the ongoing testnet, that part is unclear) so that some of the power users/ dapp users can test it out.

@howo&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@howo&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/core-development-report-12-good-progress-on-direct-rc-delegations&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-howo-core-development-report-12-good-progress-on-direct-rc-delegations').html();
      const outputElem = $('#content-howo-core-development-report-12-good-progress-on-direct-rc-delegations');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-howo-core-development-report-12-good-progress-on-direct-rc-delegations {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-howo-core-development-report-12-good-progress-on-direct-rc-delegations code {
    background: white;
  }
  #content-howo-core-development-report-12-good-progress-on-direct-rc-delegations a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-howo-core-development-report-12-good-progress-on-direct-rc-delegations a:hover {
    border-bottom: 0;
  }
  #content-howo-core-development-report-12-good-progress-on-direct-rc-delegations h1 {
    font-size: 2.2em;
  }
  #content-howo-core-development-report-12-good-progress-on-direct-rc-delegations h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-howo-core-development-report-12-good-progress-on-direct-rc-delegations header small {
    color: #999;
    font-size: 50%;
  }
  #content-howo-core-development-report-12-good-progress-on-direct-rc-delegations img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/core/@howo/core-development-report-12-good-progress-on-direct-rc-delegations&quot;&gt;Core development report #12: Good progress on direct rc delegations&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@howo&quot;&gt;@howo&lt;/a&gt;
&lt;/p&gt;</content><author><name>howo</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![image.png](https://files.peakd.com/file/peakd-hive/howo/AJeaeqp3EAX2QSK997FwxcZdJuACo817654t7riwiGf3aSNSLCLRwP5yGvpwrcb.png) Hey, I usually do my reports via voice during the hive developers meeting, but due to some vacations here and there and rush with hard fork 25, we decided to postpone it a few times so I figured I'd make an update about my progress via text. Nowadays I am working on direct rc delegations, if you didn't follow, the initial implementation was judged too complex and there was a fear that this complexity could hide bug in the edge cases. Plus it makes it less user friendly. So I made a new specification here https://gitlab.syncad.com/hive/hive/-/issues/152. And now I'm implementing it, work is in progress on that branch https://gitlab.syncad.com/hive/hive/-/tree/feature/direct_rc_delegations The core core is done, you can delegate rc, update an existing delegation, delete a delegation and rc delegations are taken into account when calculating rc. I have also added some api endpoint so that when you call find_rc_account and list_rc_account the amount of RC received/delegated is reflected there. I also added an endpoint to fetch direct rc delegations but I'm having some issues with the indexes (it induces a uniqueness constraint in the blockchain which is a problem because then if you want to delegate to one person and then another person you end up with a conflict because &quot;from&quot; is unique). I've also included everything above in the cli_wallet for easy use. I'll update hive-js later on too so that most dapps will be able to play with it. Apart from that I need to handle the edge cases where you lose RC (you delegated all your rc but then you power downs so you can no longer sustain those delegations) and write a mountain of automated tests. Once that's done, I'll go through a bunch of reviews with @blocktrades' team (which I'm assuming won't happen until a few weeks as some of the core team is in vacations). Then we'll launch a testnet (or update the ongoing testnet, that part is unclear) so that some of the power users/ dapp users can test it out. @howo See: Core development report #12: Good progress on direct rc delegations by @howo</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/howo/AJeaeqp3EAX2QSK997FwxcZdJuACo817654t7riwiGf3aSNSLCLRwP5yGvpwrcb.png" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/howo/AJeaeqp3EAX2QSK997FwxcZdJuACo817654t7riwiGf3aSNSLCLRwP5yGvpwrcb.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">18th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/07/09/18th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="18th update of 2021 on BlockTrades work on Hive software" /><published>2021-07-09T14:26:30-07:00</published><updated>2021-07-09T14:26:30-07:00</updated><id>https://hivedocs.info/news/core/development/2021/07/09/18th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/07/09/18th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-18th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by BlockTrades team since my last report. 

# Hive network upgraded to Equilibrium
The most significant accomplishment was successful upgrade of Hive via hardfork 25 (the Equilibrium release), and a lot of time was spent monitoring the upgrade and supporting Hive apps as needed during the transition.

The Equilibrium upgrade did have one unanticipated side-effect: the change in curation rules resulted in votes cast after the hardfork being much stronger than votes cast before the hardfork with respect to curation weight, which meant that votes cast in the days before the hardfork generally didn‚Äôt receive much in the way of curation rewards. This was a temporary effect that has now been resolved since all posts being actively voted on now were created after the hardfork, but hopefully we‚Äôll have enough traffic on our next iteration of the testnet that we‚Äôll be able to detect such issues ahead of time.

# Hived work (blockchain node software)

Improvements to Testtools and tests used to verify hived functionality: https://gitlab.syncad.com/hive/hive/-/merge_requests/272

Added new ‚Äìexit-before-sync flag to hived‚Äôs command-line interface (useful for dumping a snapshot without then syncing, see https://gitlab.syncad.com/hive/hive/-/issues/66 for more details on why this option was added):
https://gitlab.syncad.com/hive/hive/-/merge_requests/232
https://gitlab.syncad.com/hive/hive/-/merge_requests/273

We fixed the previously reported bug that requires a hived to be restarted after loading a snapshot:
https://gitlab.syncad.com/hive/hive/-/merge_requests/274

We have been analyzing the performance of our new ‚Äúblockchain converter‚Äù tool for creating testnets quickly that mirror the mainnet and we‚Äôve identified some code associated with nonces as the potential bottleneck.

# Hivemind (social media middleware)

We‚Äôve added a new programmer to our hivemind team and he‚Äôll initially be working on testing and minor bug fixes as a means of learning the code base. His first merge request is here:
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/518

We added code for checking consistency of the hive_blocks table (this is part of previously mentioned plan to ensure robust operation in the case where hivemind‚Äôs postgres process shuts down suddenly or a rollback fails):
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/516


We‚Äôre continuing work on improving performance of the update_rshares function immediately after massive sync of a hivemind instance. We‚Äôre trying two different alternatives to improve overall performance: 1) changing massive sync so that it updates rshares for paid posts on-the-fly, reducing the work of update_rshares to only updating rshares for unpaid posts (this approach requires introducing a new hived virtual_operation) and 2) adding an index (at least temporarily just after massive sync) to speed up update_rshares. Both approaches are currently undergoing testing.

We also resumed research into the reason why some hivemind nodes consume more memory than others. It has been suggested that it may be related to differences in python or python-library installations on the different systems, which I‚Äôm inclined to believe at this point, as we‚Äôre no longer seeing unexpected memory consumption on any of our production nodes running the latest official hivemind version. So if we‚Äôre unable to replicate this issue in our forthcoming tests, we‚Äôll likely drop this issue soon, after merging in our diagnostic changes that identify sources of memory usage better.

# Hive Application Framework (HAF)

Our primary dev for this work is currently on vacation. 

I had hoped we would still be able to work on the psql_serializer plugin (which feeds data from hived to hivemind under the HAF system) in the meantime, but the dev tasked with that was tied up with other issues (e.g. fix of snapshot problem). A new dev has been assigned to work on psql_serializer this week (the previously tasked one is going on vacation for two weeks).

# Condenser and wallet (open-source code base for https://hive.blog and other similar frontends)

We reviewed and merged in a number of community-contributed upgrades to condenser and its wallet.

From @quochuy: https://gitlab.syncad.com/hive/wallet/-/merge_requests/102

From @guiltyparties: 
https://gitlab.syncad.com/hive/wallet/-/merge_requests/101
https://gitlab.syncad.com/hive/condenser/-/merge_requests/268

From @eonwarped: https://gitlab.syncad.com/hive/condenser/-/merge_requests/269


# What‚Äôs next?

Several of our Hive devs are either on vacation now or going on vacation this coming week (they had been delaying their vacations to be available for the hardfork and any potential problems that might arise afterwards). So we‚Äôll only have 8 BlockTrades devs working on Hive for the next two weeks, and our progress will inevitably slow some during this time. 

After all our Hive devs return from vacation, we‚Äôll take a couple of weeks to begin planning what work to schedule for the next hardfork (HF26). I have some preliminary ideas for improvements that our team will work on, but we‚Äôll make a full list of proposed changes, then begin to prioritize what we want to fit on the roadmap for HF26. My plan at this time is to stick to our existing ‚Äúupgrade Hive protocol every six months‚Äù schedule if possible.

Also, as during previous hardforks, our roadmaps aren‚Äôt fixed in stone, so we may consider making other proposed changes even after the initial roadmap is published, assuming the changes aren‚Äôt too big.

Note that the above process doesn‚Äôt mean we don‚Äôt have clear development goals prior to the completion of the HF26 roadmap. For one thing, we will be making performance upgrades to hived that don‚Äôt require an actual hardfork, and these changes will generally be released as they are completed.

Even more importantly, at this point our highest priority tasks revolve around the creation of the HAF framework and HAF-based applications, and this is all layer 2 work that doesn‚Äôt require any Hive protocol changes that would necessitate a hardfork. In other words, we can also release HAF and associated apps to the dev community as soon as they are ready, without the labor and scheduling issues involved in getting nodes to upgrade as part of a hardfork.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/18th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-18th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-18th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-18th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-18th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-18th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-18th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-18th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-18th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-18th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-18th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/18th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;18th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by BlockTrades team since my last report. # Hive network upgraded to Equilibrium The most significant accomplishment was successful upgrade of Hive via hardfork 25 (the Equilibrium release), and a lot of time was spent monitoring the upgrade and supporting Hive apps as needed during the transition. The Equilibrium upgrade did have one unanticipated side-effect: the change in curation rules resulted in votes cast after the hardfork being much stronger than votes cast before the hardfork with respect to curation weight, which meant that votes cast in the days before the hardfork generally didn‚Äôt receive much in the way of curation rewards. This was a temporary effect that has now been resolved since all posts being actively voted on now were created after the hardfork, but hopefully we‚Äôll have enough traffic on our next iteration of the testnet that we‚Äôll be able to detect such issues ahead of time. # Hived work (blockchain node software) Improvements to Testtools and tests used to verify hived functionality: https://gitlab.syncad.com/hive/hive/-/merge_requests/272 Added new ‚Äìexit-before-sync flag to hived‚Äôs command-line interface (useful for dumping a snapshot without then syncing, see https://gitlab.syncad.com/hive/hive/-/issues/66 for more details on why this option was added): https://gitlab.syncad.com/hive/hive/-/merge_requests/232 https://gitlab.syncad.com/hive/hive/-/merge_requests/273 We fixed the previously reported bug that requires a hived to be restarted after loading a snapshot: https://gitlab.syncad.com/hive/hive/-/merge_requests/274 We have been analyzing the performance of our new ‚Äúblockchain converter‚Äù tool for creating testnets quickly that mirror the mainnet and we‚Äôve identified some code associated with nonces as the potential bottleneck. # Hivemind (social media middleware) We‚Äôve added a new programmer to our hivemind team and he‚Äôll initially be working on testing and minor bug fixes as a means of learning the code base. His first merge request is here: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/518 We added code for checking consistency of the hive_blocks table (this is part of previously mentioned plan to ensure robust operation in the case where hivemind‚Äôs postgres process shuts down suddenly or a rollback fails): https://gitlab.syncad.com/hive/hivemind/-/merge_requests/516 We‚Äôre continuing work on improving performance of the update_rshares function immediately after massive sync of a hivemind instance. We‚Äôre trying two different alternatives to improve overall performance: 1) changing massive sync so that it updates rshares for paid posts on-the-fly, reducing the work of update_rshares to only updating rshares for unpaid posts (this approach requires introducing a new hived virtual_operation) and 2) adding an index (at least temporarily just after massive sync) to speed up update_rshares. Both approaches are currently undergoing testing. We also resumed research into the reason why some hivemind nodes consume more memory than others. It has been suggested that it may be related to differences in python or python-library installations on the different systems, which I‚Äôm inclined to believe at this point, as we‚Äôre no longer seeing unexpected memory consumption on any of our production nodes running the latest official hivemind version. So if we‚Äôre unable to replicate this issue in our forthcoming tests, we‚Äôll likely drop this issue soon, after merging in our diagnostic changes that identify sources of memory usage better. # Hive Application Framework (HAF) Our primary dev for this work is currently on vacation. I had hoped we would still be able to work on the psql_serializer plugin (which feeds data from hived to hivemind under the HAF system) in the meantime, but the dev tasked with that was tied up with other issues (e.g. fix of snapshot problem). A new dev has been assigned to work on psql_serializer this week (the previously tasked one is going on vacation for two weeks). # Condenser and wallet (open-source code base for https://hive.blog and other similar frontends) We reviewed and merged in a number of community-contributed upgrades to condenser and its wallet. From @quochuy: https://gitlab.syncad.com/hive/wallet/-/merge_requests/102 From @guiltyparties: https://gitlab.syncad.com/hive/wallet/-/merge_requests/101 https://gitlab.syncad.com/hive/condenser/-/merge_requests/268 From @eonwarped: https://gitlab.syncad.com/hive/condenser/-/merge_requests/269 # What‚Äôs next? Several of our Hive devs are either on vacation now or going on vacation this coming week (they had been delaying their vacations to be available for the hardfork and any potential problems that might arise afterwards). So we‚Äôll only have 8 BlockTrades devs working on Hive for the next two weeks, and our progress will inevitably slow some during this time. After all our Hive devs return from vacation, we‚Äôll take a couple of weeks to begin planning what work to schedule for the next hardfork (HF26). I have some preliminary ideas for improvements that our team will work on, but we‚Äôll make a full list of proposed changes, then begin to prioritize what we want to fit on the roadmap for HF26. My plan at this time is to stick to our existing ‚Äúupgrade Hive protocol every six months‚Äù schedule if possible. Also, as during previous hardforks, our roadmaps aren‚Äôt fixed in stone, so we may consider making other proposed changes even after the initial roadmap is published, assuming the changes aren‚Äôt too big. Note that the above process doesn‚Äôt mean we don‚Äôt have clear development goals prior to the completion of the HF26 roadmap. For one thing, we will be making performance upgrades to hived that don‚Äôt require an actual hardfork, and these changes will generally be released as they are completed. Even more importantly, at this point our highest priority tasks revolve around the creation of the HAF framework and HAF-based applications, and this is all layer 2 work that doesn‚Äôt require any Hive protocol changes that would necessitate a hardfork. In other words, we can also release HAF and associated apps to the dev community as soon as they are ready, without the labor and scheduling issues involved in getting nodes to upgrade as part of a hardfork. See: 18th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Ledger App updated with HF25 operations</title><link href="https://hivedocs.info/news/nano/nodejs/wallet/2021/07/06/ledger-app-updated-with-hf25-operations.html" rel="alternate" type="text/html" title="Ledger App updated with HF25 operations" /><published>2021-07-06T12:38:18-07:00</published><updated>2021-07-06T12:38:18-07:00</updated><id>https://hivedocs.info/news/nano/nodejs/wallet/2021/07/06/ledger-app-updated-with-hf25-operations</id><content type="html" xml:base="https://hivedocs.info/news/nano/nodejs/wallet/2021/07/06/ledger-app-updated-with-hf25-operations.html">&lt;div id=&quot;content-engrave-ledger-app-updated-with-hf25-operations&quot;&gt;
![image.png](https://files.peakd.com/file/peakd-hive/engrave/Eo23B9HfFGSxgkzJckVtC8WSMeoEwfMcitDDJBZYJzaiVGqirgAwMZmEHpr2WcufBP6.png)
&lt;sup&gt;Image credit (@thepeakstudio)&lt;/sup&gt;

I'm slowly getting back on track to work on a Ledger Hive Application. My [previous post](https://peakd.com/hive-139531/@engrave/javascript-library-for-ledger-nano-s-hive-application) gathered a lot of traction so I feel committed to keeping you in touch.

# HF25

The latest hard fork (which happened a few days ago) introduced few new transactions, so I decided to modify both the app and the library to support it.

Javascript library is available on NPM with a newest version `2.1.0`:
 * `https://www.npmjs.com/package/@engrave/ledger-app-hive`


Because the original repository seems to be dead (my previous Merge Request hasn't been reviewed or merged), I decided to move it to the new home:

 * **Ledger Application**: `https://gitlab.com/engrave/ledger/hw-app-hive`
 * **Javascript Library**: `https://gitlab.com/engrave/ledger/ledger-app-hive`

Here is my first `recurrent_transfer` operation signed with my Ledger: `https://hiveblocks.com/tx/76293c907bf0038076f3507402a716c7d0b8ed57`


![image.png](https://files.peakd.com/file/peakd-hive/engrave/23z7Bh3LG2w23qb9SdLz1Vhmf2wRZKHztTw1H9RL58exJVe2XygcfAS4nqbPPUrTfKNqv.png)


# Code review

I'm slowly getting familiar with the codebase. What I can tell so far, is that it contains a lot of unused code which I'm removing. This seems like a copy-paste and I would really like to clean it before sending it to the official review. It also contains some code prepared for Ledger Nano X but I couldn't build it so far. This is probably some kind of a left-over from the boilerplate so there's a lot of work to be done yet.

I'm getting familiar with the ledger SDK as well to understand the code better.

# Development stack and SDK

SDK used to build the Hive app is already deprecated. There is also a new firmware version (2.0) that is not compatible with the previous one, hence we cannot run the app on new devices. I'm trying to port it to the new SDK version. The new SDK unifies the user flow for both Nano S and Nano X, so finally, we could run it on both devices.

I've even bought the Nano X to be able to test the app against this model.

Ledger prepared a docker image that contains all the necessary libraries to build the app. Unfortunately, the newest version does not work with the actual codebase so I need to make some changes to build it but at the end, this should make future development much easier.

# Ledger companion app

Simultaneously, I've started working on an electron-powered desktop app (as I promised in a previous post). I decided to go with Vue.js and for now, it contains basic CSS rules and views. Will push the code to the gitlab when it's a bit cleaner.


![image.png](https://files.peakd.com/file/peakd-hive/engrave/EowF9ezqJkPjHhLKMx9NjA82sqpuhKVddGJHDgbd5zyo9TsVhKtGc1714xjdsZxerab.png)

# What next

To get this app accepted by the Ledger, it needs to fulfill security, documentation, and functional requirements but I would also make it more user friendly, so the plan is as follow:
 * Make it compatible with a new SDK and 2.0 firmware version
 * Make it working on both Nano S and Nano X devices
 * Add Approve and Reject screens before signing the transaction
 * Prepare user guide and developer's documentation for Ledger Team
 * Develop a working version of the Hive companion app
 * Submit the app for the official review

***

Follow me to be up to date with incoming development updates!

***

&lt;center&gt;

**Click on the image to vote for @engrave witness:**

[![banner_engrave 100.png](https://images.hive.blog/DQmUghvic5TCPPvVkB4iB7eXmgQ3RQ4L8jkVizvuCBW8RMT/banner_engrave%20100.png)](https://hivesigner.com/sign/account-witness-vote?witness=engrave&amp;amp;approve=1)


&lt;/center&gt;
&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@engrave&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/ledger-app-updated-with-hf25-operations&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-engrave-ledger-app-updated-with-hf25-operations').html();
      const outputElem = $('#content-engrave-ledger-app-updated-with-hf25-operations');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-engrave-ledger-app-updated-with-hf25-operations {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations code {
    background: white;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations a:hover {
    border-bottom: 0;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations h1 {
    font-size: 2.2em;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations header small {
    color: #999;
    font-size: 50%;
  }
  #content-engrave-ledger-app-updated-with-hf25-operations img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@engrave/ledger-app-updated-with-hf25-operations&quot;&gt;Ledger App updated with HF25 operations&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@engrave&quot;&gt;@engrave&lt;/a&gt;
&lt;/p&gt;</content><author><name>engrave</name></author><category term="news" /><category term="nano" /><category term="nodejs" /><category term="wallet" /><summary type="html">![image.png](https://files.peakd.com/file/peakd-hive/engrave/Eo23B9HfFGSxgkzJckVtC8WSMeoEwfMcitDDJBZYJzaiVGqirgAwMZmEHpr2WcufBP6.png) Image credit (@thepeakstudio) I'm slowly getting back on track to work on a Ledger Hive Application. My [previous post](https://peakd.com/hive-139531/@engrave/javascript-library-for-ledger-nano-s-hive-application) gathered a lot of traction so I feel committed to keeping you in touch. # HF25 The latest hard fork (which happened a few days ago) introduced few new transactions, so I decided to modify both the app and the library to support it. Javascript library is available on NPM with a newest version `2.1.0`: * `https://www.npmjs.com/package/@engrave/ledger-app-hive` Because the original repository seems to be dead (my previous Merge Request hasn't been reviewed or merged), I decided to move it to the new home: * **Ledger Application**: `https://gitlab.com/engrave/ledger/hw-app-hive` * **Javascript Library**: `https://gitlab.com/engrave/ledger/ledger-app-hive` Here is my first `recurrent_transfer` operation signed with my Ledger: `https://hiveblocks.com/tx/76293c907bf0038076f3507402a716c7d0b8ed57` ![image.png](https://files.peakd.com/file/peakd-hive/engrave/23z7Bh3LG2w23qb9SdLz1Vhmf2wRZKHztTw1H9RL58exJVe2XygcfAS4nqbPPUrTfKNqv.png) # Code review I'm slowly getting familiar with the codebase. What I can tell so far, is that it contains a lot of unused code which I'm removing. This seems like a copy-paste and I would really like to clean it before sending it to the official review. It also contains some code prepared for Ledger Nano X but I couldn't build it so far. This is probably some kind of a left-over from the boilerplate so there's a lot of work to be done yet. I'm getting familiar with the ledger SDK as well to understand the code better. # Development stack and SDK SDK used to build the Hive app is already deprecated. There is also a new firmware version (2.0) that is not compatible with the previous one, hence we cannot run the app on new devices. I'm trying to port it to the new SDK version. The new SDK unifies the user flow for both Nano S and Nano X, so finally, we could run it on both devices. I've even bought the Nano X to be able to test the app against this model. Ledger prepared a docker image that contains all the necessary libraries to build the app. Unfortunately, the newest version does not work with the actual codebase so I need to make some changes to build it but at the end, this should make future development much easier. # Ledger companion app Simultaneously, I've started working on an electron-powered desktop app (as I promised in a previous post). I decided to go with Vue.js and for now, it contains basic CSS rules and views. Will push the code to the gitlab when it's a bit cleaner. ![image.png](https://files.peakd.com/file/peakd-hive/engrave/EowF9ezqJkPjHhLKMx9NjA82sqpuhKVddGJHDgbd5zyo9TsVhKtGc1714xjdsZxerab.png) # What next To get this app accepted by the Ledger, it needs to fulfill security, documentation, and functional requirements but I would also make it more user friendly, so the plan is as follow: * Make it compatible with a new SDK and 2.0 firmware version * Make it working on both Nano S and Nano X devices * Add Approve and Reject screens before signing the transaction * Prepare user guide and developer's documentation for Ledger Team * Develop a working version of the Hive companion app * Submit the app for the official review *** Follow me to be up to date with incoming development updates! *** **Click on the image to vote for @engrave witness:** [![banner_engrave 100.png](https://images.hive.blog/DQmUghvic5TCPPvVkB4iB7eXmgQ3RQ4L8jkVizvuCBW8RMT/banner_engrave%20100.png)](https://hivesigner.com/sign/account-witness-vote?witness=engrave&amp;amp;approve=1) See: Ledger App updated with HF25 operations by @engrave</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/engrave/Eo23B9HfFGSxgkzJckVtC8WSMeoEwfMcitDDJBZYJzaiVGqirgAwMZmEHpr2WcufBP6.png" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/engrave/Eo23B9HfFGSxgkzJckVtC8WSMeoEwfMcitDDJBZYJzaiVGqirgAwMZmEHpr2WcufBP6.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">[Quickstart] How to upgrade Hive-in-a-box (HIAB / hive-docker) to HF25</title><link href="https://hivedocs.info/howto/witness/docker/node/2021/06/30/quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25.html" rel="alternate" type="text/html" title="[Quickstart] How to upgrade Hive-in-a-box (HIAB / hive-docker) to HF25" /><published>2021-06-30T00:16:54-07:00</published><updated>2021-06-30T00:16:54-07:00</updated><id>https://hivedocs.info/howto/witness/docker/node/2021/06/30/quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25</id><content type="html" xml:base="https://hivedocs.info/howto/witness/docker/node/2021/06/30/quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25.html">&lt;div id=&quot;content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25&quot;&gt;
![Hive-in-a-box Logo](https://images.hive.blog/p/HuuaCwcKuiEjNgLb5Q7HbtUvB1HEHgck8hUkQMB4bFSJaxwFsYXGx7N9qtgEvLdGaoY?format=match&amp;amp;mode=fit)

I apologise for the late post, I've been overwhelmed trying to prepare @Privex for HF25, prepare my own servers, and provide one-on-one upgrade assistance to many close witness friends, and Privex customers.

This article covers how to upgrade from Hive HF24 to HF25 as quickly as possible for Privex Node-in-a-box VPS customers, as well as people who use normal Hive-in-a-box (`hive-docker`) on a Dedicated Server, or normal non-NIAB VPS.

Note that this post was written relatively quickly without fully testing the guide, nor checking for any typos / grammatical errors, to ensure any Hive witnesses who use HIAB and haven't yet upgraded - will have time to see this post and follow the instructions.

## HF25 is due at 14:00:00 (2:00 PM) UTC (15:00 / 3:00 PM United Kingdom BST Time) - or roughly 7-8 hrs from when this post was published. 

## [Click HERE to see the current UTC time, with realtime updates](https://time.is/UTC)


# Updating a Privex Node-in-a-box VPS

If you have a Privex Node-in-a-box (NIAB) VPS, e.g. a VHIVE8-SE or VHIVE16-FI which is still running HF24 - you need to [contact support for a reinstall](https://support.privex.io).

# Urgent Pre-installed HF25 Server

If you need a HF25 Hive Server urgently, and your existing servers aren't possible to repair in time for the HF, you can order one of our 8GB or 16GB Hive Node-in-a-box VPS's from @Privex - which are delivered within 20 minutes of payment (as long as you **leave the notes blank**, and **don't use a referral code unless you're 200% certain that it's a valid referral code**, since if it isn't, the order will be flagged for manual inspection to attempt to identify the intended referral).

- üá∏üá™ **SWEDEN** (SE)
    - [8GB Hive Node-in-a-box Sweden - VHIVE8-SE](https://pay.privex.io/order/package/vhive8-se)
    - [16GB Hive Node-in-a-box Sweden - VHIVE16-SE](https://pay.privex.io/order/package/vhive16-se)

- üá´üáÆ **FINLAND** (FI)
    - [8GB Hive Node-in-a-box Finland - VHIVE8-FI](https://pay.privex.io/order/package/vhive8-fi)
    - [16GB Hive Node-in-a-box Finland - VHIVE16-FI](https://pay.privex.io/order/package/vhive16-fi)


# Updating a normal Dedicated Server or non-Privex VPS from HF24 to HF25

If you're running Hive-in-a-box HF24 on either a Dedicated Server (whether Privex or not), or a normal VPS (one that is definitely not a Privex Node-in-a-box Pre-Installed Hive server), the upgrade to HF25 can be done within 30 mins to 1 hr, so long as your server has a high-speed network connection, has a recent `block_log` without any known corruption, and you're able to run the official `someguy123/hive` images which I release.

Before doing anything, enter the folder where you've installed `hive-docker`. Most people install it in their home directory.

```sh
cd ~/hive-docker
```

## Update Method 1 - Shared Memory Transplant - Fastest, but only works with my official binary docker images


First, you'll want to make sure that the `hive-docker` repository is up to date, so that you have the latest features and bug fixes required for the upgrade to go smoothly:

```sh
git fetch
git checkout master
git pull
```


Next, you'll want to install the HF25 Docker binary image. On most setups, a standard `./run.sh install` would work, but to avoid the risk of some people having configured a different default docker image in their `.env`, it's best to specify `hf25`:

```sh
./run.sh install hf25
```

Now, you'll need to stop your node - if it's actually running:

```sh
./run.sh stop
```

To help avoid corruption/contamination issues, and to potentially speed the downloads up by preventing `rsync` from having to calculate the differences between Privex's copy, and your copy of `shared_memory.bin` and `block_log.index` - it's best we remove them:

```sh
./run.sh clean shm

rm -fv data/witness_node_data_dir/blockchain/block_log.index
```

It's now time to truncate/update your block_log, replace your block_log.index, and obtain a fresh copy of shared_memory.bin for HF25:

```
DL_SERVER=&quot;se1.files.privex.io&quot; ./run.sh fix-blocks
```

![](https://images.hive.blog/p/7258xSVeJbKmECTaWChp4sJR8aZDJ7Y2HRvUHUnE6UnEtpj2Z6dqikt3ye5hs7B8Ef2bkjsjyQTre4JUb4x4j7Hxq281Uk2Fio53QLtzuovnfGtaRi2NEJC8GQ4MpvT915F6gKRVhZPwL?format=match&amp;amp;mode=fit)

- When asked whether you want to download the rest of the block_log, or truncate your block_log, press `y` and then hit enter.
- If it instead says that your `block_log` is the same size as the remote, and wants to do an &quot;integrity check&quot; or &quot;verify the block_log, press `n` and hit enter.
- When aksed if you want to replace/update/synchronise your `block_log.index` - press `y` and hit enter.
- When asked if you want to download/synchronise your snapshot files, press `n` and hit enter.
- When asked if you want to download/update/synchronise your `shared_memory.bin` - press `y` and hit enter.

Assuming everything went well, your server should now be ready to start.

Time to start your server:

```
./run.sh start
```

Now check the logs, and monitor it as it syncs. 

```
./run.sh logs
```

If it takes more than 5 minutes to start outputting &quot;Got X transactions from witness someguy123 on block 123456778&quot; - then you should run `./run.sh monitor` to see the sync progress.

Either way, it's a waiting game, it shouldn't take more than 20 mins to sync up (assuming you're following this guide within this week - this article was written on June 30th 2021), as `fix-blocks` would've gotten the recently synced chain files from [Privex's](https://www.privex.io/) file server.


+++ END OF METHOD 1 - Your node should now be up, or will be up very soon when it finishes syncing +++

----------------------

## Update Method 2 - Load a native snapshot - Slower than shared_memory.bin transplant - but this method will work with non-someguy123 built images

### ONLY FOLLOW THIS METHOD IF YOU COMPILE YOUR OWN DOCKER IMAGE, OR USE A THIRD-PARTY DOCKER IMAGE

If you use a custom image - whether one you built yourself using `./run.sh build`, `docker build`, - or one you downloaded from someone who isn't me - the shared memory transplant will likely be incompatible.

For this method, follow everything in method 1, but DO NOT follow the y/n suggestions for `fix-blocks`, instead, you'll want to answer them in the following way instead:

- When asked whether you want to download the rest of the block_log, or truncate your block_log, press `y` and then hit enter.
- If it instead says that your `block_log` is the same size as the remote, and wants to do an &quot;integrity check&quot; or &quot;verify the block_log, press `n` and hit enter.
- When aksed if you want to replace/update/synchronise your `block_log.index` - press `y` and hit enter.
- When asked if you want to download/synchronise your snapshot files, press `y` and hit enter.
- When asked if you want to download/update/synchronise your `shared_memory.bin` - press `n` and hit enter.

**ONLY FOLLOW THIS METHOD IF YOU COMPILE YOUR OWN DOCKER IMAGE, OR USE A THIRD-PARTY DOCKER IMAGE**

Now, use `./run.sh clean shm` to ensure you don't have a `shared_memory.bin`, since an existing shared_memory.bin file will cause problems.

```
./run.sh clean shm
```

You can now load the native snapshot using the command:

```
./run.sh loadsnap privexsnap
```

This will generate a `shared_memory.bin` using that snapshot, and once it's finished loading the snapshot, the node will automatically start normally, so for a witness node, that means it will be ready to start producing once it's finished loading the snapshot, and syncing up any blocks which it was behind.

All you have to do now, is monitor it (if you like), to track it's progress, and make sure nothing is going wrong:

```
./run.sh logs
```


+++ END OF METHOD 2 - Your node should now be up, or will be up very soon when it finishes syncing/loading the snapshot +++


---

Thanks for reading!
---

&lt;center&gt;

![](https://cdn.discordapp.com/attachments/379745956134125569/737091330143944806/SOMEX123.gif)

&lt;/center&gt;

GIF Avatar by @stellabelle

---

Do you like what I'm doing for Hive?
----


[Vote for me to be a Hive witness](https://peakd.com/witnesses) - every vote counts. 

----

Don't forget to follow me for more like this.
----

---

Have you ever thought about being a witness yourself? Join the [witness channel](https://openhive.chat/channel/witness). We're happy to guide you! Join in shaping the STEEM economy.

Are you looking for a new server provider? My company @privex offers highly-reliable and affordable dedicated and virtual servers for HIVE, HBD, EOS, LTC, BTC, and even DOGE! Check out our website at https://www.privex.io

You can join Privex's public Discord at https://discord.privex.io - we also have a Matrix server, sign up at https://riot.privex.io (or if you have an existing Matrix account, join our General chat at `#privex:privex.io`)

---
&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@someguy123&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25').html();
      const outputElem = $('#content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 code {
    background: white;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 a:hover {
    border-bottom: 0;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 h1 {
    font-size: 2.2em;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 header small {
    color: #999;
    font-size: 50%;
  }
  #content-someguy123-quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@someguy123/quickstart-how-to-upgrade-hive-in-a-box-hiab-hive-docker-to-hf25&quot;&gt;[Quickstart] How to upgrade Hive-in-a-box (HIAB / hive-docker) to HF25&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@someguy123&quot;&gt;@someguy123&lt;/a&gt;
&lt;/p&gt;</content><author><name>someguy123</name></author><category term="howto" /><category term="witness" /><category term="docker" /><category term="node" /><summary type="html">![Hive-in-a-box Logo](https://images.hive.blog/p/HuuaCwcKuiEjNgLb5Q7HbtUvB1HEHgck8hUkQMB4bFSJaxwFsYXGx7N9qtgEvLdGaoY?format=match&amp;amp;mode=fit) I apologise for the late post, I've been overwhelmed trying to prepare @Privex for HF25, prepare my own servers, and provide one-on-one upgrade assistance to many close witness friends, and Privex customers. This article covers how to upgrade from Hive HF24 to HF25 as quickly as possible for Privex Node-in-a-box VPS customers, as well as people who use normal Hive-in-a-box (`hive-docker`) on a Dedicated Server, or normal non-NIAB VPS. Note that this post was written relatively quickly without fully testing the guide, nor checking for any typos / grammatical errors, to ensure any Hive witnesses who use HIAB and haven't yet upgraded - will have time to see this post and follow the instructions. ## HF25 is due at 14:00:00 (2:00 PM) UTC (15:00 / 3:00 PM United Kingdom BST Time) - or roughly 7-8 hrs from when this post was published. ## [Click HERE to see the current UTC time, with realtime updates](https://time.is/UTC) # Updating a Privex Node-in-a-box VPS If you have a Privex Node-in-a-box (NIAB) VPS, e.g. a VHIVE8-SE or VHIVE16-FI which is still running HF24 - you need to [contact support for a reinstall](https://support.privex.io). # Urgent Pre-installed HF25 Server If you need a HF25 Hive Server urgently, and your existing servers aren't possible to repair in time for the HF, you can order one of our 8GB or 16GB Hive Node-in-a-box VPS's from @Privex - which are delivered within 20 minutes of payment (as long as you **leave the notes blank**, and **don't use a referral code unless you're 200% certain that it's a valid referral code**, since if it isn't, the order will be flagged for manual inspection to attempt to identify the intended referral). - üá∏üá™ **SWEDEN** (SE) - [8GB Hive Node-in-a-box Sweden - VHIVE8-SE](https://pay.privex.io/order/package/vhive8-se) - [16GB Hive Node-in-a-box Sweden - VHIVE16-SE](https://pay.privex.io/order/package/vhive16-se) - üá´üáÆ **FINLAND** (FI) - [8GB Hive Node-in-a-box Finland - VHIVE8-FI](https://pay.privex.io/order/package/vhive8-fi) - [16GB Hive Node-in-a-box Finland - VHIVE16-FI](https://pay.privex.io/order/package/vhive16-fi) # Updating a normal Dedicated Server or non-Privex VPS from HF24 to HF25 If you're running Hive-in-a-box HF24 on either a Dedicated Server (whether Privex or not), or a normal VPS (one that is definitely not a Privex Node-in-a-box Pre-Installed Hive server), the upgrade to HF25 can be done within 30 mins to 1 hr, so long as your server has a high-speed network connection, has a recent `block_log` without any known corruption, and you're able to run the official `someguy123/hive` images which I release. Before doing anything, enter the folder where you've installed `hive-docker`. Most people install it in their home directory. ```sh cd ~/hive-docker ``` ## Update Method 1 - Shared Memory Transplant - Fastest, but only works with my official binary docker images First, you'll want to make sure that the `hive-docker` repository is up to date, so that you have the latest features and bug fixes required for the upgrade to go smoothly: ```sh git fetch git checkout master git pull ``` Next, you'll want to install the HF25 Docker binary image. On most setups, a standard `./run.sh install` would work, but to avoid the risk of some people having configured a different default docker image in their `.env`, it's best to specify `hf25`: ```sh ./run.sh install hf25 ``` Now, you'll need to stop your node - if it's actually running: ```sh ./run.sh stop ``` To help avoid corruption/contamination issues, and to potentially speed the downloads up by preventing `rsync` from having to calculate the differences between Privex's copy, and your copy of `shared_memory.bin` and `block_log.index` - it's best we remove them: ```sh ./run.sh clean shm rm -fv data/witness_node_data_dir/blockchain/block_log.index ``` It's now time to truncate/update your block_log, replace your block_log.index, and obtain a fresh copy of shared_memory.bin for HF25: ``` DL_SERVER=&quot;se1.files.privex.io&quot; ./run.sh fix-blocks ``` ![](https://images.hive.blog/p/7258xSVeJbKmECTaWChp4sJR8aZDJ7Y2HRvUHUnE6UnEtpj2Z6dqikt3ye5hs7B8Ef2bkjsjyQTre4JUb4x4j7Hxq281Uk2Fio53QLtzuovnfGtaRi2NEJC8GQ4MpvT915F6gKRVhZPwL?format=match&amp;amp;mode=fit) - When asked whether you want to download the rest of the block_log, or truncate your block_log, press `y` and then hit enter. - If it instead says that your `block_log` is the same size as the remote, and wants to do an &quot;integrity check&quot; or &quot;verify the block_log, press `n` and hit enter. - When aksed if you want to replace/update/synchronise your `block_log.index` - press `y` and hit enter. - When asked if you want to download/synchronise your snapshot files, press `n` and hit enter. - When asked if you want to download/update/synchronise your `shared_memory.bin` - press `y` and hit enter. Assuming everything went well, your server should now be ready to start. Time to start your server: ``` ./run.sh start ``` Now check the logs, and monitor it as it syncs. ``` ./run.sh logs ``` If it takes more than 5 minutes to start outputting &quot;Got X transactions from witness someguy123 on block 123456778&quot; - then you should run `./run.sh monitor` to see the sync progress. Either way, it's a waiting game, it shouldn't take more than 20 mins to sync up (assuming you're following this guide within this week - this article was written on June 30th 2021), as `fix-blocks` would've gotten the recently synced chain files from [Privex's](https://www.privex.io/) file server. +++ END OF METHOD 1 - Your node should now be up, or will be up very soon when it finishes syncing +++ ---------------------- ## Update Method 2 - Load a native snapshot - Slower than shared_memory.bin transplant - but this method will work with non-someguy123 built images ### ONLY FOLLOW THIS METHOD IF YOU COMPILE YOUR OWN DOCKER IMAGE, OR USE A THIRD-PARTY DOCKER IMAGE If you use a custom image - whether one you built yourself using `./run.sh build`, `docker build`, - or one you downloaded from someone who isn't me - the shared memory transplant will likely be incompatible. For this method, follow everything in method 1, but DO NOT follow the y/n suggestions for `fix-blocks`, instead, you'll want to answer them in the following way instead: - When asked whether you want to download the rest of the block_log, or truncate your block_log, press `y` and then hit enter. - If it instead says that your `block_log` is the same size as the remote, and wants to do an &quot;integrity check&quot; or &quot;verify the block_log, press `n` and hit enter. - When aksed if you want to replace/update/synchronise your `block_log.index` - press `y` and hit enter. - When asked if you want to download/synchronise your snapshot files, press `y` and hit enter. - When asked if you want to download/update/synchronise your `shared_memory.bin` - press `n` and hit enter. **ONLY FOLLOW THIS METHOD IF YOU COMPILE YOUR OWN DOCKER IMAGE, OR USE A THIRD-PARTY DOCKER IMAGE** Now, use `./run.sh clean shm` to ensure you don't have a `shared_memory.bin`, since an existing shared_memory.bin file will cause problems. ``` ./run.sh clean shm ``` You can now load the native snapshot using the command: ``` ./run.sh loadsnap privexsnap ``` This will generate a `shared_memory.bin` using that snapshot, and once it's finished loading the snapshot, the node will automatically start normally, so for a witness node, that means it will be ready to start producing once it's finished loading the snapshot, and syncing up any blocks which it was behind. All you have to do now, is monitor it (if you like), to track it's progress, and make sure nothing is going wrong: ``` ./run.sh logs ``` +++ END OF METHOD 2 - Your node should now be up, or will be up very soon when it finishes syncing/loading the snapshot +++ --- Thanks for reading! --- ![](https://cdn.discordapp.com/attachments/379745956134125569/737091330143944806/SOMEX123.gif) GIF Avatar by @stellabelle --- Do you like what I'm doing for Hive? ---- [Vote for me to be a Hive witness](https://peakd.com/witnesses) - every vote counts. ---- Don't forget to follow me for more like this. ---- --- Have you ever thought about being a witness yourself? Join the [witness channel](https://openhive.chat/channel/witness). We're happy to guide you! Join in shaping the STEEM economy. Are you looking for a new server provider? My company @privex offers highly-reliable and affordable dedicated and virtual servers for HIVE, HBD, EOS, LTC, BTC, and even DOGE! Check out our website at https://www.privex.io You can join Privex's public Discord at https://discord.privex.io - we also have a Matrix server, sign up at https://riot.privex.io (or if you have an existing Matrix account, join our General chat at `#privex:privex.io`) --- See: [Quickstart] How to upgrade Hive-in-a-box (HIAB / hive-docker) to HF25 by @someguy123</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/p/HuuaCwcKuiEjNgLb5Q7HbtUvB1HEHgck8hUkQMB4bFSJaxwFsYXGx7N9qtgEvLdGaoY?format=match&amp;amp;mode=fit" /><media:content medium="image" url="https://images.hive.blog/p/HuuaCwcKuiEjNgLb5Q7HbtUvB1HEHgck8hUkQMB4bFSJaxwFsYXGx7N9qtgEvLdGaoY?format=match&amp;amp;mode=fit" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">17th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/06/29/17th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="17th update of 2021 on BlockTrades work on Hive software" /><published>2021-06-29T14:48:42-07:00</published><updated>2021-06-29T14:48:42-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/29/17th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/29/17th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by BlockTrades team during last week or so:

# Hived work (blockchain node software)

Many users last week experienced problems getting their transactions accepted into the blockchain. It turns out there were two separate problems that could cause this issue, but to the outside observer they probably looked much the same:

### Beem had a problem detecting v1.25.0 Hive‚Äôs chainid, leading to invalidly signed transactions

The first problem, discovered a few days ago, was that the python-based Beem API library used by several Hive apps was misdetecting v1.25.0 Hive nodes as Steem nodes, and therefore trying to sign with the wrong chain id. This, in turn, led to Beem-based Hive Apps creating transactions that would be rejected by any Hive node, because the transactions weren‚Äôt properly signed for Hive. 

We assisted Beem developers with identifying the source of the problem and suggested a solution. Beem now checks for the configuration constant HIVE_CHAIN_ID, before it checks for the constant STEEM_CHAIN_ID, giving precedence to Hive nodes over Steem nodes in the detection process and thus using the proper chainid during transaction signing. 

In related work, we replaced the name STEEM_CHAIN_ID with OLD_CHAIN_ID and eliminated some duplicated constant values returned by get_config (but note these changes will not be included in the master branch until after the hardfork, like other changes completed in the last week):
https://gitlab.syncad.com/hive/hive/-/merge_requests/268
https://gitlab.syncad.com/hive/hive/-/merge_requests/267

### Snapshot-based initialization of Hived-nodes requires a restart to properly initialize chainid

The second problem appeared one day later, but a couple of days before the Beem library was updated, so the two problems overlapped in time, and this led to some confusion among app developers as to what was the source of the new problem. 

But by testing against various API nodes, we were able to determine that this second problem, although similar in appearance to the Beem problem, was occurring on non-Beem apps (e.g. hive.blog and peakd) and only occurring when those apps were using api.hive.blog as their API node. Since we hard recently updated the hived nodes on api.hive.blog, I suspected the problem has something to do with the update process.

After comparing update procedures used by other API node operators, I noticed that most of the API node operators had done a replay to update their nodes,  whereas we had updated our internal hived nodes from a snapshot. Ultimately this allowed us to identify a previously undetected error with nodes initialized from a snapshot: the variable that stores the chainid isn‚Äôt part of the database state that gets loaded from the snapshot data and the snapshot loading code didn‚Äôt trigger this variable to be updated. So a node updated in this way would reject validly signed transactions because it was operating with the wrong chainid (essentially the reverse of the Beem problem). 

### Snapshot  workaround

We also found that this improperly set chainid problem was resolved by stopping and restarting the node that was initialized from a snapshot, and that‚Äôs how we have worked around the issue until we release a full fix for snapshot-based node initialization. 

The code fix is currently being implemented and tested, and will be released after the hardfork (to keep things simple, we‚Äôre avoiding making too many changes to the development branch until after the hardfork has triggered).

## Completed hived work

Improvements to Testtools used to verify hived functionality: https://gitlab.syncad.com/hive/hive/-/merge_requests/266

Removed the copy/pasted version of secp256k1 library from hived and replaced with a submodule link:
https://gitlab.syncad.com/hive/hive/-/merge_requests/264

Fixed issue where enum_virtual_ops sometimes returned non-virtual ops: https://gitlab.syncad.com/hive/hive/-/merge_requests/219

We completed work to eliminate duplicated code in the command-line wallet for hived, but we‚Äôre delaying merging those changes into the develop branch until later because of the sheer amount of changes involved. The still-open merge request for that work is here: https://gitlab.syncad.com/hive/hive/-/merge_requests/170

## Continuing work on hived

We‚Äôre working on speeding up the blockchain converter that we‚Äôve developed to initialize and control a testnet configured in basically the same way as a mainnet. This is to allow for more realistic testing inside of a testnet environment (especially for better performance testing). So far, we‚Äôve identified that the performance bottleneck seems to be related to the function that generates nonces.

We‚Äôre continuing to work on the sql serializer plugin for hived that provides data to HAF-based applications. We expecting to complete that work this week, assuming no further distractions arise in the meantime (this work got delayed while we were troubleshooting the snapshot problem), then begin performance testing.

We‚Äôre also continuing to work on the CI system to automate deployment of hived for more strenuous testing scenarios (e.g. long replay testing).


# Hivemind (2nd layer applications + social media middleware)

Fix for previously report list_subscribers bug: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/513

We continue to investigate ways to improve performance of the update_rshares function immediately after massive sync of a hivemind instance. In addition to analyzing the cause of slowness of the current implementation, we‚Äôre also simultaneously looking at two different alternatives to improve overall performance: 1) eliminating the call completing and performing equivalent functionality during live sync  and 2) adding an index (at least temporarily just after massive sync) to speed up update_rshares.

The new index dramatically speeds up performance of update_rshares (time drops from 10 hours to 3 minutes and the index only takes about 10minutes to create), but it consumes 25GB of disk space (hence the idea to drop it after using it).

We‚Äôre still running functional and performance tests related to the broken reputation/ordering issue because of multiple transactions used per block. As part of this work we‚Äôre also adding ‚Äúcompletion markers‚Äù to the database state to better detect any database consistency error that can arise from an abrupt shutdown of postgres (notably, this can happen when postgres does an auto-upgrade for a security fix).

We also resumed research into the reason why some hivemind nodes consume more memory than others. It has been suggested that it may be related to differences in python or python-library installations on the different systems.

# Hive Application Framework

We made good progress last week on both HAF code and the documentation for it, but our main dev for this work is now on vacation until June 19th, at which time the work will resume. 

But in the meantime, we should be able to do performance testing of this code using the new sql_serializer plugin, and I‚Äôm looking forward to seeing just how well we do.

# Reminder: hardfork 25 triggers tomorrow

Witnesses and devs alike will be ‚Äúmanning their keyboards‚Äù tomorrow (June 30th) as hardfork 25 triggers, ready for any potential problems that may arise. The hardfork is scheduled for approximately 14:00 UTC.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/17th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-17th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/17th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;17th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by BlockTrades team during last week or so: # Hived work (blockchain node software) Many users last week experienced problems getting their transactions accepted into the blockchain. It turns out there were two separate problems that could cause this issue, but to the outside observer they probably looked much the same: ### Beem had a problem detecting v1.25.0 Hive‚Äôs chainid, leading to invalidly signed transactions The first problem, discovered a few days ago, was that the python-based Beem API library used by several Hive apps was misdetecting v1.25.0 Hive nodes as Steem nodes, and therefore trying to sign with the wrong chain id. This, in turn, led to Beem-based Hive Apps creating transactions that would be rejected by any Hive node, because the transactions weren‚Äôt properly signed for Hive. We assisted Beem developers with identifying the source of the problem and suggested a solution. Beem now checks for the configuration constant HIVE_CHAIN_ID, before it checks for the constant STEEM_CHAIN_ID, giving precedence to Hive nodes over Steem nodes in the detection process and thus using the proper chainid during transaction signing. In related work, we replaced the name STEEM_CHAIN_ID with OLD_CHAIN_ID and eliminated some duplicated constant values returned by get_config (but note these changes will not be included in the master branch until after the hardfork, like other changes completed in the last week): https://gitlab.syncad.com/hive/hive/-/merge_requests/268 https://gitlab.syncad.com/hive/hive/-/merge_requests/267 ### Snapshot-based initialization of Hived-nodes requires a restart to properly initialize chainid The second problem appeared one day later, but a couple of days before the Beem library was updated, so the two problems overlapped in time, and this led to some confusion among app developers as to what was the source of the new problem. But by testing against various API nodes, we were able to determine that this second problem, although similar in appearance to the Beem problem, was occurring on non-Beem apps (e.g. hive.blog and peakd) and only occurring when those apps were using api.hive.blog as their API node. Since we hard recently updated the hived nodes on api.hive.blog, I suspected the problem has something to do with the update process. After comparing update procedures used by other API node operators, I noticed that most of the API node operators had done a replay to update their nodes, whereas we had updated our internal hived nodes from a snapshot. Ultimately this allowed us to identify a previously undetected error with nodes initialized from a snapshot: the variable that stores the chainid isn‚Äôt part of the database state that gets loaded from the snapshot data and the snapshot loading code didn‚Äôt trigger this variable to be updated. So a node updated in this way would reject validly signed transactions because it was operating with the wrong chainid (essentially the reverse of the Beem problem). ### Snapshot workaround We also found that this improperly set chainid problem was resolved by stopping and restarting the node that was initialized from a snapshot, and that‚Äôs how we have worked around the issue until we release a full fix for snapshot-based node initialization. The code fix is currently being implemented and tested, and will be released after the hardfork (to keep things simple, we‚Äôre avoiding making too many changes to the development branch until after the hardfork has triggered). ## Completed hived work Improvements to Testtools used to verify hived functionality: https://gitlab.syncad.com/hive/hive/-/merge_requests/266 Removed the copy/pasted version of secp256k1 library from hived and replaced with a submodule link: https://gitlab.syncad.com/hive/hive/-/merge_requests/264 Fixed issue where enum_virtual_ops sometimes returned non-virtual ops: https://gitlab.syncad.com/hive/hive/-/merge_requests/219 We completed work to eliminate duplicated code in the command-line wallet for hived, but we‚Äôre delaying merging those changes into the develop branch until later because of the sheer amount of changes involved. The still-open merge request for that work is here: https://gitlab.syncad.com/hive/hive/-/merge_requests/170 ## Continuing work on hived We‚Äôre working on speeding up the blockchain converter that we‚Äôve developed to initialize and control a testnet configured in basically the same way as a mainnet. This is to allow for more realistic testing inside of a testnet environment (especially for better performance testing). So far, we‚Äôve identified that the performance bottleneck seems to be related to the function that generates nonces. We‚Äôre continuing to work on the sql serializer plugin for hived that provides data to HAF-based applications. We expecting to complete that work this week, assuming no further distractions arise in the meantime (this work got delayed while we were troubleshooting the snapshot problem), then begin performance testing. We‚Äôre also continuing to work on the CI system to automate deployment of hived for more strenuous testing scenarios (e.g. long replay testing). # Hivemind (2nd layer applications + social media middleware) Fix for previously report list_subscribers bug: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/513 We continue to investigate ways to improve performance of the update_rshares function immediately after massive sync of a hivemind instance. In addition to analyzing the cause of slowness of the current implementation, we‚Äôre also simultaneously looking at two different alternatives to improve overall performance: 1) eliminating the call completing and performing equivalent functionality during live sync and 2) adding an index (at least temporarily just after massive sync) to speed up update_rshares. The new index dramatically speeds up performance of update_rshares (time drops from 10 hours to 3 minutes and the index only takes about 10minutes to create), but it consumes 25GB of disk space (hence the idea to drop it after using it). We‚Äôre still running functional and performance tests related to the broken reputation/ordering issue because of multiple transactions used per block. As part of this work we‚Äôre also adding ‚Äúcompletion markers‚Äù to the database state to better detect any database consistency error that can arise from an abrupt shutdown of postgres (notably, this can happen when postgres does an auto-upgrade for a security fix). We also resumed research into the reason why some hivemind nodes consume more memory than others. It has been suggested that it may be related to differences in python or python-library installations on the different systems. # Hive Application Framework We made good progress last week on both HAF code and the documentation for it, but our main dev for this work is now on vacation until June 19th, at which time the work will resume. But in the meantime, we should be able to do performance testing of this code using the new sql_serializer plugin, and I‚Äôm looking forward to seeing just how well we do. # Reminder: hardfork 25 triggers tomorrow Witnesses and devs alike will be ‚Äúmanning their keyboards‚Äù tomorrow (June 30th) as hardfork 25 triggers, ready for any potential problems that may arise. The hardfork is scheduled for approximately 14:00 UTC. See: 17th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive SQL is ready for the hardfork 25 - Addendum</title><link href="https://hivedocs.info/news/sql/database/2021/06/29/hivesql-hf25-addendum.html" rel="alternate" type="text/html" title="Hive SQL is ready for the hardfork 25 - Addendum" /><published>2021-06-29T07:45:54-07:00</published><updated>2021-06-29T07:45:54-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/06/29/hivesql-hf25-addendum</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/06/29/hivesql-hf25-addendum.html">&lt;div id=&quot;content-arcange-hivesql-hf25-addendum&quot;&gt;![](https://i.imgur.com/B5TI37I.png)

The hardfork 25 (codename Equilibrium) should be activated in a few hours (less than 22 but many more than 2 at time of writing üòÅ) as all top 20 witnesses are now running the v1.25 code on their nodes ([see here](https://hive.arcange.eu/witnesses)).

My API servers have also been upgraded to the new code and are now providing HiveSQL with new data. Therefore, I added a few updates to the HiveSQL database.

## What's new?

### 1. Existing table updates

* **DynamicGlobalProperties**

New columns

|Column|Description|
|-|-|
|current_remove_threshold|number of objects that can be removed in one automatic operation (only applies to situations where many objects can accumulate over time but need to be removed in a single operation f.e. proposal votes)|
|early_voting_seconds|Duration of the first period where all votes are considered equally regarding vote time and the linear rewards curve is applied (equal weight to all voters in that window) - currently 24 hours|
|mid_voting_seconds|Duration of the second period where with reward weight/2 is applied - currently 48 hours|
|max_consecutive_recurrent_transfer_failures|Maximum number of consecutive failures for a recurring transfer before it is automatically canceled |
|max_recurrent_transfer_end_date|Maximum difference between start and end of a recurring payment - currently 730 days (2 years)|
|min_recurrent_transfers_recurrence|Minimum time to elapse between two recurring transfer - currently 24 hours|
|max_open_recurrent_transfers|Maximum number of recurring payments that can be scheduled for execution per account - currently 255|


* **Account**

New columns

|Column|Description|
|-|-|
|post_voting_power|Effective HP that are used for curation (vesting_shares - delegated_vesting_shares + received_vesting_shares)|
|post_voting_power_symbol|VESTS|
|pending_transfers|Pending transfers for escrow operations|
|governance_vote_expiration_ts|date and time that the account governance votes for witnesses and proposals will expire|
|delayed_votes_time|date and time that the additional HP recently powered up will be taken into account for governance|
|delayed_votes_val|value of the additional HP that will be taken into account for governance after delay|
|open_recurrent_transfers|Number of recurring transfers scheduled for execution|


## Documentation

HiveSQL documentation has been updated and can be viewed at https://docs.hivesql.io

## Support

If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT).

**Happy Hardfork 25!**

---
&lt;sub&gt; 

#### &lt;center&gt;Check out my apps and services
&lt;a href=&quot;/hive/@hive.engage/stay-connected-with-your-hive-audience-and-catch-attention&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GiNJqlm.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivebuzz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/B4UTun2.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivesql&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EPN8RW6.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/hive/@arcange/introducing-hive-account-recovery&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6TWeW7V.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hive.autoclaim&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ih2pEOw.png&quot; /&gt;&lt;/a&gt;&lt;/center&gt;
&lt;center&gt;

### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@arcange&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hivesql-hf25-addendum&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-arcange-hivesql-hf25-addendum').html();
      const outputElem = $('#content-arcange-hivesql-hf25-addendum');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-arcange-hivesql-hf25-addendum {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-arcange-hivesql-hf25-addendum code {
    background: white;
  }
  #content-arcange-hivesql-hf25-addendum a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-arcange-hivesql-hf25-addendum a:hover {
    border-bottom: 0;
  }
  #content-arcange-hivesql-hf25-addendum h1 {
    font-size: 2.2em;
  }
  #content-arcange-hivesql-hf25-addendum h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-arcange-hivesql-hf25-addendum header small {
    color: #999;
    font-size: 50%;
  }
  #content-arcange-hivesql-hf25-addendum img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@arcange/hivesql-hf25-addendum&quot;&gt;Hive SQL is ready for the hardfork 25 - Addendum&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@arcange&quot;&gt;@arcange&lt;/a&gt;
&lt;/p&gt;

&lt;/center&gt;&lt;/sub&gt;&lt;/div&gt;</content><author><name>arcange</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![](https://i.imgur.com/B5TI37I.png) The hardfork 25 (codename Equilibrium) should be activated in a few hours (less than 22 but many more than 2 at time of writing üòÅ) as all top 20 witnesses are now running the v1.25 code on their nodes ([see here](https://hive.arcange.eu/witnesses)). My API servers have also been upgraded to the new code and are now providing HiveSQL with new data. Therefore, I added a few updates to the HiveSQL database. ## What's new? ### 1. Existing table updates * **DynamicGlobalProperties** New columns |Column|Description| |-|-| |current_remove_threshold|number of objects that can be removed in one automatic operation (only applies to situations where many objects can accumulate over time but need to be removed in a single operation f.e. proposal votes)| |early_voting_seconds|Duration of the first period where all votes are considered equally regarding vote time and the linear rewards curve is applied (equal weight to all voters in that window) - currently 24 hours| |mid_voting_seconds|Duration of the second period where with reward weight/2 is applied - currently 48 hours| |max_consecutive_recurrent_transfer_failures|Maximum number of consecutive failures for a recurring transfer before it is automatically canceled | |max_recurrent_transfer_end_date|Maximum difference between start and end of a recurring payment - currently 730 days (2 years)| |min_recurrent_transfers_recurrence|Minimum time to elapse between two recurring transfer - currently 24 hours| |max_open_recurrent_transfers|Maximum number of recurring payments that can be scheduled for execution per account - currently 255| * **Account** New columns |Column|Description| |-|-| |post_voting_power|Effective HP that are used for curation (vesting_shares - delegated_vesting_shares + received_vesting_shares)| |post_voting_power_symbol|VESTS| |pending_transfers|Pending transfers for escrow operations| |governance_vote_expiration_ts|date and time that the account governance votes for witnesses and proposals will expire| |delayed_votes_time|date and time that the additional HP recently powered up will be taken into account for governance| |delayed_votes_val|value of the additional HP that will be taken into account for governance after delay| |open_recurrent_transfers|Number of recurring transfers scheduled for execution| ## Documentation HiveSQL documentation has been updated and can be viewed at https://docs.hivesql.io ## Support If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT). **Happy Hardfork 25!** --- #### Check out my apps and services ### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt; See: Hive SQL is ready for the hardfork 25 - Addendum by @arcange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/B5TI37I.png" /><media:content medium="image" url="https://i.imgur.com/B5TI37I.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive core developer meeting #25</title><link href="https://hivedocs.info/news/core/development/2021/06/22/hive-core-developer-meeting-25.html" rel="alternate" type="text/html" title="Hive core developer meeting #25" /><published>2021-06-22T12:40:21-07:00</published><updated>2021-06-22T12:40:21-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/22/hive-core-developer-meeting-25</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/22/hive-core-developer-meeting-25.html">&lt;div id=&quot;content-howo-hive-core-developer-meeting-25&quot;&gt;https://www.youtube.com/watch?v=D2iS7B7-8rg

I basically recommend that you listen to the whole thing, usually it's pretty easy to tl;dr but on this one we talk about a lot of various subjects that are basically dev/testnet sync.

Topics touched upon
Dev sync
Testnet sync
future testnet that mirrors the main net even more closely
List of tests/cases to focus on for remainder of testing.
State of libraries/key dapps/services ahead of HF -- ready?

as always if you have questions, feel free to ask them in the comments :)

@howo&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@howo&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-core-developer-meeting-25&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-howo-hive-core-developer-meeting-25').html();
      const outputElem = $('#content-howo-hive-core-developer-meeting-25');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-howo-hive-core-developer-meeting-25 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-howo-hive-core-developer-meeting-25 code {
    background: white;
  }
  #content-howo-hive-core-developer-meeting-25 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-howo-hive-core-developer-meeting-25 a:hover {
    border-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-25 h1 {
    font-size: 2.2em;
  }
  #content-howo-hive-core-developer-meeting-25 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-25 header small {
    color: #999;
    font-size: 50%;
  }
  #content-howo-hive-core-developer-meeting-25 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/meeting/@howo/hive-core-developer-meeting-25&quot;&gt;Hive core developer meeting #25&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@howo&quot;&gt;@howo&lt;/a&gt;
&lt;/p&gt;</content><author><name>howo</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">https://www.youtube.com/watch?v=D2iS7B7-8rg I basically recommend that you listen to the whole thing, usually it's pretty easy to tl;dr but on this one we talk about a lot of various subjects that are basically dev/testnet sync. Topics touched upon Dev sync Testnet sync future testnet that mirrors the main net even more closely List of tests/cases to focus on for remainder of testing. State of libraries/key dapps/services ahead of HF -- ready? as always if you have questions, feel free to ask them in the comments :) @howo See: Hive core developer meeting #25 by @howo</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">16th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/06/20/16th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="16th update of 2021 on BlockTrades work on Hive software" /><published>2021-06-20T18:24:24-07:00</published><updated>2021-06-20T18:24:24-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/20/16th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/20/16th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by BlockTrades team during the last week or so:

# Hived work (blockchain node software)

## Official release of Equilibrium (hived code for hardfork 25)

Last week we merged all develop branch changes since the last hardfork into the master branch and tagged an official release of hived (v1.25.0). The ‚Äúcode name‚Äù for this release is ‚ÄúEquilibrium‚Äù. 

 For the official press release associated with the new release and details about associated functional changes, see https://hive.blog/hive/@hiveio/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021

The [release notes for Equilibrium](https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0) represent a concise summary of virtually all changes that were made as part of this hardfork, along with links to review the code associated with each individual change. 

Alternatively, you can inspect [a diff with the totality of changes for this hardfork](https://gitlab.syncad.com/hive/hive/-/merge_requests/262/diffs).


## Other hived work last week

We continued performance testing of the new ‚Äúrecurrent transfers‚Äù feature written by @howo. As a side note, based on some discussion among various devs, I believe Hive frontends will use the term ‚Äúrecurring payments‚Äù to refer to the ‚Äúrecurrent transfers‚Äù feature, since that is the name most commonly used in the business world for this type of functionality.

During our still incomplete testing, we found some areas where the new ‚Äútest tools‚Äù framework that is being used to create and test massive numbers of recurrent transfers could be improved to make it faster and more stable:
https://gitlab.syncad.com/hive/hive/-/merge_requests/257
https://gitlab.syncad.com/hive/hive/-/merge_requests/263

Here‚Äôs a short list of other work done on hived:

* Fixed two unit tests that we previously had to disable and re-enabled them: https://gitlab.syncad.com/hive/hive/-/merge_requests/259
* Added a new command-line option ‚Äìexit-before-sync for configuring hived to a predictable state for running a replay or creating a statefile dump, then ending the hived process. This is useful for setting up test scenarios. https://gitlab.syncad.com/hive/hive/-/merge_requests/232
* Added new regression tests to test recent changes to last irreversible block handling (a change that was made to fix a longstanding bug with duplicate transactions in the account history plugin): https://gitlab.syncad.com/hive/hive/-/merge_requests/252
* Fixed an intermittent crash on application shutdown: https://gitlab.syncad.com/hive/hive/-/merge_requests/253
* Documentation cleanup: https://gitlab.syncad.com/hive/hive/-/merge_requests/258
*   Implemented option for automatic spawning of hived replays within our continuous integration system  (done off main servers to avoid breaking or interrupting primary development CI system).

# Hivemind (2nd layer applications + social media middleware)

* Added tests for recent changes in behavior of setLastRead operation: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/511
* Explicit specification of package versions to be used when building hivemind to avoid potential headaches when package dependencies are updated: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/498
* Update CodeQL analysis configuration: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/509
* We‚Äôre currently investigating ways to improve performance of the `update_rshares` function immediately after massive sync of a hivemind instance.
*  Fixed &quot;broken reputation&quot; problem related to ordering issue because of multiple transactions used per block. This was known to impact the calculation of reputation for at least two Hive users.
*   list_subscribers bug being worked on (tests being created first).

# Hive Application Framework

The current implementation of the Hive Application Framework requires applications to mark their constraints as DEFERRABLE to enable HAF apps to use the auto-rewind feature when a fork switch occurs. 

While this may be an acceptable limitation on the design of HAF-based apps, we decided to create an alternative implementation of HAF without that limitation and measure the performance of the two alternative designs. The ongoing discussion of this topic can be found in the latest comments attached to the still open HAF merge request: https://gitlab.syncad.com/hive/psql_tools/-/merge_requests/1

# Upcoming work in the next week

* Continue performance testing of recurring payments functionality in hived.
* Complete psql_serializer updates and begin testing hived+psql_serializer with hivemind. This is a prerequisite for testing the entire HAF code base.
* More work and testing of the Hive Application Framework (HAF), including more documentation and example HAF-based applications.
* Finish up fix for list_subscribers.
* Work with witnesses to collect performance statistics for the Equilibrium release on different hardware configurations. 

On a related note,  @drakos noted a significant performance improvement in the speed of creating statefile snapshots and @gtg has confirmed the same findings on his system. Gandalf reports v1.24.8 took 4866 seconds whereas v1.25.0 was able to complete this task in only 3134 seconds.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/16th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-16th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/16th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;16th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by BlockTrades team during the last week or so: # Hived work (blockchain node software) ## Official release of Equilibrium (hived code for hardfork 25) Last week we merged all develop branch changes since the last hardfork into the master branch and tagged an official release of hived (v1.25.0). The ‚Äúcode name‚Äù for this release is ‚ÄúEquilibrium‚Äù. For the official press release associated with the new release and details about associated functional changes, see https://hive.blog/hive/@hiveio/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 The [release notes for Equilibrium](https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0) represent a concise summary of virtually all changes that were made as part of this hardfork, along with links to review the code associated with each individual change. Alternatively, you can inspect [a diff with the totality of changes for this hardfork](https://gitlab.syncad.com/hive/hive/-/merge_requests/262/diffs). ## Other hived work last week We continued performance testing of the new ‚Äúrecurrent transfers‚Äù feature written by @howo. As a side note, based on some discussion among various devs, I believe Hive frontends will use the term ‚Äúrecurring payments‚Äù to refer to the ‚Äúrecurrent transfers‚Äù feature, since that is the name most commonly used in the business world for this type of functionality. During our still incomplete testing, we found some areas where the new ‚Äútest tools‚Äù framework that is being used to create and test massive numbers of recurrent transfers could be improved to make it faster and more stable: https://gitlab.syncad.com/hive/hive/-/merge_requests/257 https://gitlab.syncad.com/hive/hive/-/merge_requests/263 Here‚Äôs a short list of other work done on hived: * Fixed two unit tests that we previously had to disable and re-enabled them: https://gitlab.syncad.com/hive/hive/-/merge_requests/259 * Added a new command-line option ‚Äìexit-before-sync for configuring hived to a predictable state for running a replay or creating a statefile dump, then ending the hived process. This is useful for setting up test scenarios. https://gitlab.syncad.com/hive/hive/-/merge_requests/232 * Added new regression tests to test recent changes to last irreversible block handling (a change that was made to fix a longstanding bug with duplicate transactions in the account history plugin): https://gitlab.syncad.com/hive/hive/-/merge_requests/252 * Fixed an intermittent crash on application shutdown: https://gitlab.syncad.com/hive/hive/-/merge_requests/253 * Documentation cleanup: https://gitlab.syncad.com/hive/hive/-/merge_requests/258 * Implemented option for automatic spawning of hived replays within our continuous integration system (done off main servers to avoid breaking or interrupting primary development CI system). # Hivemind (2nd layer applications + social media middleware) * Added tests for recent changes in behavior of setLastRead operation: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/511 * Explicit specification of package versions to be used when building hivemind to avoid potential headaches when package dependencies are updated: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/498 * Update CodeQL analysis configuration: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/509 * We‚Äôre currently investigating ways to improve performance of the `update_rshares` function immediately after massive sync of a hivemind instance. * Fixed &quot;broken reputation&quot; problem related to ordering issue because of multiple transactions used per block. This was known to impact the calculation of reputation for at least two Hive users. * list_subscribers bug being worked on (tests being created first). # Hive Application Framework The current implementation of the Hive Application Framework requires applications to mark their constraints as DEFERRABLE to enable HAF apps to use the auto-rewind feature when a fork switch occurs. While this may be an acceptable limitation on the design of HAF-based apps, we decided to create an alternative implementation of HAF without that limitation and measure the performance of the two alternative designs. The ongoing discussion of this topic can be found in the latest comments attached to the still open HAF merge request: https://gitlab.syncad.com/hive/psql_tools/-/merge_requests/1 # Upcoming work in the next week * Continue performance testing of recurring payments functionality in hived. * Complete psql_serializer updates and begin testing hived+psql_serializer with hivemind. This is a prerequisite for testing the entire HAF code base. * More work and testing of the Hive Application Framework (HAF), including more documentation and example HAF-based applications. * Finish up fix for list_subscribers. * Work with witnesses to collect performance statistics for the Equilibrium release on different hardware configurations. On a related note, @drakos noted a significant performance improvement in the speed of creating statefile snapshots and @gtg has confirmed the same findings on his system. Gandalf reports v1.24.8 took 4866 seconds whereas v1.25.0 was able to complete this task in only 3134 seconds. See: 16th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive Hardfork 25 is on the Way: Hive to reach Equilibrium on June 30th, 2021</title><link href="https://hivedocs.info/news/core/development/2021/06/19/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021.html" rel="alternate" type="text/html" title="Hive Hardfork 25 is on the Way: Hive to reach Equilibrium on June 30th, 2021" /><published>2021-06-19T17:10:27-07:00</published><updated>2021-06-19T17:10:27-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/19/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/19/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021.html">&lt;div id=&quot;content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021&quot;&gt;![image.png](https://images.hive.blog/DQmfByqFD7d9ecpcYMhy7ucwhQLKKrrLjcp9vb378wSJwCP/image.png)

Earlier this week we notified cryptocurrency exchanges that the upcoming hardfork to the Hive blockchain network, dubbed *Equilibrium*, is planned for the end of June. 

Today's official date announcement also has a pile of helpful information including a summary of changes coming with the new hardfork, links to the software, and details for those of you who may want to get involved in testing the new software!

## TL:DR the Code; A Quick Overview of the Upcoming Changes

*Equilibrium* is a state of balance between multiple forces. In the case of the Hive blockchain network, the guiding mission from day one has been to create an ecosystem that allows anyone to become a part of our decentralized network, contribute to governance, and to own their data, connections, tokens and actions in a world where the current tech and social powers have an iron grip. 

This hardfork continues to empower people to use Hive the way they want and takes another few large steps forward in creating an ecosystem with better balanced rules and tools for building whatever we can dream up. 

Reaching equilibrium is finding a state of balance and readiness. It is the essential preparation for big moves, exciting changes, and sustained growth.

### Here's a quick summary of HF25:

Below is a list of the consensus changes that are being made as part of this hardfork:

- **changes to curation window and curation rewards calculation**
    - The most important aspect of this change is that the 5 minute reverse auction is going away, so there is no punishment for voting early. This will finally put manual voters on an equal footing with automated voters when it comes to competing for curation rewards. This change, more than any other, was the driving reason for the naming of this hardfork.
    - In addition, anyone voting in the first 24 hours will be rewarded based solely on their Hive Power and vote weight, and the reward curve applied from 24 hours to the end of the voting window will be much softer than currently, eliminating any need to feel rushed when voting in order to maximize curation rewards.
- **new operation and API to convert HIVE to HBD**
    - HBD (Hive-backed Dollars) is intended to be a feeless, trustless, USD-pegged stablecoin, a feat that has yet to be achieved in the cryptocurrency world. This new operation will stabilize the price pegging of HBD, allowing it to achieve its full potential as a frictionless medium of exchange for digital commerce.
    - While you've always been able to convert your HBD to HIVE, this new operation will allow you to convert in the opposite direction (HIVE -&amp;gt; HBD). 
    - Previously, HBD was only effectively price-pegged on the low side of USD pricing. This new conversion will create an equilibrium point where HBD will be pegged on both the low side AND the high side.
    
- **interest only paid on HBD held in your savings account**
    - You might have missed that you're earning interest on your Hive-backed Dollars, so this could be a neat surprise: simply move HBD into your savings account (3 day withdrawal waiting period) to earn interest on it just for holding! No-risk DeFi, made easy.
- **new operation and API to enable recurring payments**
    - These are periodic transfers which you schedule to happen automatically. They are intended for managing subscription payments, etc.
- **disallow voting on expired proposals**
- **witness and proposal votes by an account expire after one year if the account stops actively making governance-related votes**
    - This change was made to ensure that old votes from dormant accounts don't unduly impact governance decisions for Hive. It will enable Hive to find a new balance between incumbent block producers and new competitors for those positions.
- **proposal creators can change the end date of their Decentralized Hive Fund (DHF) proposals**
    - This allows a proposal creator to reduce their funding request (by decreasing the number of payments they receive) without having to create a new proposal and start from zero in respect to community support for the proposal.
- **re-allow vote operation for already paid posts**
    - Voting outside the rewards window should still be something you can do, to show appreciation for the content you like and to add to your curated feed. This is a quality of life change that does *not* impact anything to do with allocation of rewards. 

There are also new command-line options, a pile of bug fixes and performance optimizations, a new API call, and many other improvements to the code and documentation that the Hive blockchain relies on. Full details are available in the [release notes](https://gitlab.syncad.com/hive/hive/-/releases#v1.25.0) This is pretty critical work towards making it easier to understand, easier to run, and to create the best possible ecosystem for someone to hop in and start building with Hive.

If you're not technical and don't want to do some hands-on testing, you're all caught up! You likely won't notice anything immediately when *Equilibrium* goes live. 

However, you may want to consider changing the way you vote for posts after the hardfork, especially if you've resorted to auto-voting to maximize your curation rewards. Now you'll have more time and flexibility to find the content you love in a relaxed way, and more time to engage with your favorite authors and communities!

### In the next 12 days...

There is still time before the hardfork takes place. If you want to contribute to testing or if you are a dApp creator, project owner, or someone who just wants to start getting more involved with the ecosystem, here are some handy links so you can jump in before *Equilibrium* goes live.

## Some Technical ~~House~~Beekeeping

**Here is the link to the final official release version of Hardfork 25:**
https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0

...and here are some helpful posts that outline joining the testnet, including how to create a witness node on the testnet, if you want to dive into the decentralized tech that powers Hive.

**A guide to starting up a testnet witness:**
https://peakd.com/guide/@howo/how-to-run-a-witness-node-on-the-hf25-testnet

**And more information on the public testnet itself:**
https://peakd.com/@gtg/hf25-public-testnet-reloaded-rc2

**The testnet faucet page:**
https://hivetestnetfaucet.org/

All dApps that rely on the functions outlined above should have started testing or be starting to test as soon as possible. 

*Equilibrium* is the second community-driven hardfork of the Hive blockchain and we are very excited for it! It marks a key milestone for Hive development and for the Hive ecosystem. 

### Keep an eye out for updates here and on our various Hive social media channels! üêù&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@hiveio&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021').html();
      const outputElem = $('#content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 code {
    background: white;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 a:hover {
    border-bottom: 0;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 h1 {
    font-size: 2.2em;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 header small {
    color: #999;
    font-size: 50%;
  }
  #content-hiveio-hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive/@hiveio/hive-hardfork-25-is-on-the-way-hive-to-reach-equilibrium-on-june-30th-2021&quot;&gt;Hive Hardfork 25 is on the Way: Hive to reach Equilibrium on June 30th, 2021&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@hiveio&quot;&gt;@hiveio&lt;/a&gt;
&lt;/p&gt;</content><author><name>hiveio</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![image.png](https://images.hive.blog/DQmfByqFD7d9ecpcYMhy7ucwhQLKKrrLjcp9vb378wSJwCP/image.png) Earlier this week we notified cryptocurrency exchanges that the upcoming hardfork to the Hive blockchain network, dubbed *Equilibrium*, is planned for the end of June. Today's official date announcement also has a pile of helpful information including a summary of changes coming with the new hardfork, links to the software, and details for those of you who may want to get involved in testing the new software! ## TL:DR the Code; A Quick Overview of the Upcoming Changes *Equilibrium* is a state of balance between multiple forces. In the case of the Hive blockchain network, the guiding mission from day one has been to create an ecosystem that allows anyone to become a part of our decentralized network, contribute to governance, and to own their data, connections, tokens and actions in a world where the current tech and social powers have an iron grip. This hardfork continues to empower people to use Hive the way they want and takes another few large steps forward in creating an ecosystem with better balanced rules and tools for building whatever we can dream up. Reaching equilibrium is finding a state of balance and readiness. It is the essential preparation for big moves, exciting changes, and sustained growth. ### Here's a quick summary of HF25: Below is a list of the consensus changes that are being made as part of this hardfork: - **changes to curation window and curation rewards calculation** - The most important aspect of this change is that the 5 minute reverse auction is going away, so there is no punishment for voting early. This will finally put manual voters on an equal footing with automated voters when it comes to competing for curation rewards. This change, more than any other, was the driving reason for the naming of this hardfork. - In addition, anyone voting in the first 24 hours will be rewarded based solely on their Hive Power and vote weight, and the reward curve applied from 24 hours to the end of the voting window will be much softer than currently, eliminating any need to feel rushed when voting in order to maximize curation rewards. - **new operation and API to convert HIVE to HBD** - HBD (Hive-backed Dollars) is intended to be a feeless, trustless, USD-pegged stablecoin, a feat that has yet to be achieved in the cryptocurrency world. This new operation will stabilize the price pegging of HBD, allowing it to achieve its full potential as a frictionless medium of exchange for digital commerce. - While you've always been able to convert your HBD to HIVE, this new operation will allow you to convert in the opposite direction (HIVE -&amp;gt; HBD). - Previously, HBD was only effectively price-pegged on the low side of USD pricing. This new conversion will create an equilibrium point where HBD will be pegged on both the low side AND the high side. - **interest only paid on HBD held in your savings account** - You might have missed that you're earning interest on your Hive-backed Dollars, so this could be a neat surprise: simply move HBD into your savings account (3 day withdrawal waiting period) to earn interest on it just for holding! No-risk DeFi, made easy. - **new operation and API to enable recurring payments** - These are periodic transfers which you schedule to happen automatically. They are intended for managing subscription payments, etc. - **disallow voting on expired proposals** - **witness and proposal votes by an account expire after one year if the account stops actively making governance-related votes** - This change was made to ensure that old votes from dormant accounts don't unduly impact governance decisions for Hive. It will enable Hive to find a new balance between incumbent block producers and new competitors for those positions. - **proposal creators can change the end date of their Decentralized Hive Fund (DHF) proposals** - This allows a proposal creator to reduce their funding request (by decreasing the number of payments they receive) without having to create a new proposal and start from zero in respect to community support for the proposal. - **re-allow vote operation for already paid posts** - Voting outside the rewards window should still be something you can do, to show appreciation for the content you like and to add to your curated feed. This is a quality of life change that does *not* impact anything to do with allocation of rewards. There are also new command-line options, a pile of bug fixes and performance optimizations, a new API call, and many other improvements to the code and documentation that the Hive blockchain relies on. Full details are available in the [release notes](https://gitlab.syncad.com/hive/hive/-/releases#v1.25.0) This is pretty critical work towards making it easier to understand, easier to run, and to create the best possible ecosystem for someone to hop in and start building with Hive. If you're not technical and don't want to do some hands-on testing, you're all caught up! You likely won't notice anything immediately when *Equilibrium* goes live. However, you may want to consider changing the way you vote for posts after the hardfork, especially if you've resorted to auto-voting to maximize your curation rewards. Now you'll have more time and flexibility to find the content you love in a relaxed way, and more time to engage with your favorite authors and communities! ### In the next 12 days... There is still time before the hardfork takes place. If you want to contribute to testing or if you are a dApp creator, project owner, or someone who just wants to start getting more involved with the ecosystem, here are some handy links so you can jump in before *Equilibrium* goes live. ## Some Technical ~~House~~Beekeeping **Here is the link to the final official release version of Hardfork 25:** https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0 ...and here are some helpful posts that outline joining the testnet, including how to create a witness node on the testnet, if you want to dive into the decentralized tech that powers Hive. **A guide to starting up a testnet witness:** https://peakd.com/guide/@howo/how-to-run-a-witness-node-on-the-hf25-testnet **And more information on the public testnet itself:** https://peakd.com/@gtg/hf25-public-testnet-reloaded-rc2 **The testnet faucet page:** https://hivetestnetfaucet.org/ All dApps that rely on the functions outlined above should have started testing or be starting to test as soon as possible. *Equilibrium* is the second community-driven hardfork of the Hive blockchain and we are very excited for it! It marks a key milestone for Hive development and for the Hive ecosystem. ### Keep an eye out for updates here and on our various Hive social media channels! üêù See: Hive Hardfork 25 is on the Way: Hive to reach Equilibrium on June 30th, 2021 by @hiveio</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmfByqFD7d9ecpcYMhy7ucwhQLKKrrLjcp9vb378wSJwCP/image.png" /><media:content medium="image" url="https://images.hive.blog/DQmfByqFD7d9ecpcYMhy7ucwhQLKKrrLjcp9vb378wSJwCP/image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive HardFork 25 Jump Starter Kit</title><link href="https://hivedocs.info/howto/devops/2021/06/18/hive-hardfork-25-jump-starter-kit.html" rel="alternate" type="text/html" title="Hive HardFork 25 Jump Starter Kit" /><published>2021-06-18T12:31:45-07:00</published><updated>2021-06-18T12:31:45-07:00</updated><id>https://hivedocs.info/howto/devops/2021/06/18/hive-hardfork-25-jump-starter-kit</id><content type="html" xml:base="https://hivedocs.info/howto/devops/2021/06/18/hive-hardfork-25-jump-starter-kit.html">&lt;div id=&quot;content-gtg-hive-hardfork-25-jump-starter-kit&quot;&gt;Intended for the Hive API node operators, witnesses, and developers.

At the time of Eclipse release I made a similar post that saved many (hours) of lives, so I‚Äôm creating an updated one for the upcoming Hard Fork 25.

&lt;center&gt;https://www.youtube.com/watch?v=mrwgrOhl7Yw&lt;/center&gt;&lt;sup&gt;Yes, new Hive Hard Fork, new fancy logo reveal.&lt;/sup&gt;

# Code
## GitLab
https://gitlab.syncad.com/hive/hive
Our core development efforts takes place in a community hosted GitLab repository (thanks @blocktrades). There's Hive core itself, but also many other Hive related software repositories.

## GitHub
https://github.com/openhive-network/hive
We use it as a push mirror for GitLab repository, mostly for visibility and decentralization - if you have an account on GitHub please fork at least [hive](https://github.com/openhive-network/hive) and [hivemind](https://github.com/openhive-network/hivemind) and star them if you haven‚Äôt done so yet. We haven't paid much attention to it but apparently it's important for some outside metrics.

&lt;center&gt;![star_fork.png](https://images.hive.blog/DQmQbRRrtoTFPZA9QmDRjvswPtaGuXrWXje1WHp9CeeGbV2/star_fork.png)
&lt;sup&gt;Please click both buttons&lt;/sup&gt;&lt;/center&gt;

# Services
## API node
https://api.openhive.network
Soon to be switched to `v1.25.0` but because it‚Äôs heavily used in Hive related R&amp;amp;D it might not be your best choice if you are looking for a fast API node without any rate limiting. During the maintenance mode, it will fall back to https://api.hive.blog 

## Seed node
`hived` `v1.25.0` listens on `gtg.openhive.network:2001`
to use it in your `config.ini` file just add the line:
```
p2p-seed-node = gtg.openhive.network:2001
```
If you don't have any `p2p-seed-node = ` entries in your config file, built-in defaults will be used (which contains my node too).

# Stuff for download
TL;DR https://gtg.openhive.network/get

## Binaries
`./get/bin`contains `hived` and `cli_wallet` binaries built on `Ubuntu 18.04 LTS` which should also run fine on `Ubuntu 20.04 LTS`

## Blocks
`./get/blockchain`
As usual, the `block_log` file, roughly 350GB and counting.
For testing needs there's also `block_log.5M` that is limited to first 5 million blocks.

## Snapshots

### API
`./get/snapshot/api/` contains a relatively recent snapshot of the API node with all the fancy plugins.
There‚Äôs a snapshot for the upcoming version `v1.25.0` but also for the old one `v1.24.8` if you need to switch back.
Uncompressed snapshot takes roughly 480GB
There‚Äôs also the `example-api-config.ini` file out there that contains settings compatible with the snapshot.

To decompress, you can use simply run it through something like: `lbzip2 -dc | tar xv`
(Using parallel bzip2 on multi-threaded systems might save you a lot of time)

To use snapshot you need:
- A `block_log` file, not smaller than the one used when the snapshot was made.
- A `config.ini` file, compatible with the snapshot (see above), adjusted to your needs, without changes that could affect it in a way that changes the state.
- A `hived` binary compatible with the snapshot

All of that you can find above.

 Run `hived` with `--load-snapshot name`, assuming the snapshot is stored in `snapshot/name`

`hived` API node runtime currently takes 823GB (incl. shm 19GB, excl. snapshot)

### Exchanges
There‚Äôs also a snapshot meant for exchanges in `./get/snapshot/exchange/`  that allows them to quickly get up and running, it requires a compatible configuration and that exchange account is one of those who are tracked by my node. If you run an exchange and want to be on that list to use a snapshot, just please let me know.

## Hivemind database dump
`./get/hivemind/` contains a relatively recent dump of the Hivemind database.
I use self-describing file names such as:
`hivemind-20210616-47a41c96.dump`
Date when dump was taken, revision of `hivemind` that was running it.
You need at least that version, remember about `intarray` extension
Consider running `pg_restore` with at least `-j 6` to run long running tasks in parallel
After restoring the database, make sure to run the `db_upgrade` script.

Even though during full sync database size peaks easily over 750GB, when restored from dump it takes roughly 500GB. Dump file itself is just 53GB.

### All resources are offered AS IS.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@gtg&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-hardfork-25-jump-starter-kit&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-gtg-hive-hardfork-25-jump-starter-kit').html();
      const outputElem = $('#content-gtg-hive-hardfork-25-jump-starter-kit');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-gtg-hive-hardfork-25-jump-starter-kit {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit code {
    background: white;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit a:hover {
    border-bottom: 0;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit h1 {
    font-size: 2.2em;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit header small {
    color: #999;
    font-size: 50%;
  }
  #content-gtg-hive-hardfork-25-jump-starter-kit img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-160391/@gtg/hive-hardfork-25-jump-starter-kit&quot;&gt;Hive HardFork 25 Jump Starter Kit&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@gtg&quot;&gt;@gtg&lt;/a&gt;
&lt;/p&gt;</content><author><name>gtg</name></author><category term="howto" /><category term="devops" /><summary type="html">Intended for the Hive API node operators, witnesses, and developers. At the time of Eclipse release I made a similar post that saved many (hours) of lives, so I‚Äôm creating an updated one for the upcoming Hard Fork 25. https://www.youtube.com/watch?v=mrwgrOhl7YwYes, new Hive Hard Fork, new fancy logo reveal. # Code ## GitLab https://gitlab.syncad.com/hive/hive Our core development efforts takes place in a community hosted GitLab repository (thanks @blocktrades). There's Hive core itself, but also many other Hive related software repositories. ## GitHub https://github.com/openhive-network/hive We use it as a push mirror for GitLab repository, mostly for visibility and decentralization - if you have an account on GitHub please fork at least [hive](https://github.com/openhive-network/hive) and [hivemind](https://github.com/openhive-network/hivemind) and star them if you haven‚Äôt done so yet. We haven't paid much attention to it but apparently it's important for some outside metrics. ![star_fork.png](https://images.hive.blog/DQmQbRRrtoTFPZA9QmDRjvswPtaGuXrWXje1WHp9CeeGbV2/star_fork.png) Please click both buttons # Services ## API node https://api.openhive.network Soon to be switched to `v1.25.0` but because it‚Äôs heavily used in Hive related R&amp;amp;D it might not be your best choice if you are looking for a fast API node without any rate limiting. During the maintenance mode, it will fall back to https://api.hive.blog ## Seed node `hived` `v1.25.0` listens on `gtg.openhive.network:2001` to use it in your `config.ini` file just add the line: ``` p2p-seed-node = gtg.openhive.network:2001 ``` If you don't have any `p2p-seed-node = ` entries in your config file, built-in defaults will be used (which contains my node too). # Stuff for download TL;DR https://gtg.openhive.network/get ## Binaries `./get/bin`contains `hived` and `cli_wallet` binaries built on `Ubuntu 18.04 LTS` which should also run fine on `Ubuntu 20.04 LTS` ## Blocks `./get/blockchain` As usual, the `block_log` file, roughly 350GB and counting. For testing needs there's also `block_log.5M` that is limited to first 5 million blocks. ## Snapshots ### API `./get/snapshot/api/` contains a relatively recent snapshot of the API node with all the fancy plugins. There‚Äôs a snapshot for the upcoming version `v1.25.0` but also for the old one `v1.24.8` if you need to switch back. Uncompressed snapshot takes roughly 480GB There‚Äôs also the `example-api-config.ini` file out there that contains settings compatible with the snapshot. To decompress, you can use simply run it through something like: `lbzip2 -dc | tar xv` (Using parallel bzip2 on multi-threaded systems might save you a lot of time) To use snapshot you need: - A `block_log` file, not smaller than the one used when the snapshot was made. - A `config.ini` file, compatible with the snapshot (see above), adjusted to your needs, without changes that could affect it in a way that changes the state. - A `hived` binary compatible with the snapshot All of that you can find above. Run `hived` with `--load-snapshot name`, assuming the snapshot is stored in `snapshot/name` `hived` API node runtime currently takes 823GB (incl. shm 19GB, excl. snapshot) ### Exchanges There‚Äôs also a snapshot meant for exchanges in `./get/snapshot/exchange/` that allows them to quickly get up and running, it requires a compatible configuration and that exchange account is one of those who are tracked by my node. If you run an exchange and want to be on that list to use a snapshot, just please let me know. ## Hivemind database dump `./get/hivemind/` contains a relatively recent dump of the Hivemind database. I use self-describing file names such as: `hivemind-20210616-47a41c96.dump` Date when dump was taken, revision of `hivemind` that was running it. You need at least that version, remember about `intarray` extension Consider running `pg_restore` with at least `-j 6` to run long running tasks in parallel After restoring the database, make sure to run the `db_upgrade` script. Even though during full sync database size peaks easily over 750GB, when restored from dump it takes roughly 500GB. Dump file itself is just 53GB. ### All resources are offered AS IS. See: Hive HardFork 25 Jump Starter Kit by @gtg</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/mrwgrOhl7Yw/0.jpg" /><media:content medium="image" url="https://img.youtube.com/vi/mrwgrOhl7Yw/0.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>