<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://hivedocs.info/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hivedocs.info/" rel="alternate" type="text/html" /><updated>2021-05-31T15:59:39-07:00</updated><id>https://hivedocs.info/feed.xml</id><title type="html">Hive Chain Documentation</title><subtitle>Your resource for various levels of Hive Documentation.</subtitle><author><name>site curated by: @inertia</name></author><entry><title type="html">How to run a witness node on the hf25 testnet</title><link href="https://hivedocs.info/howto/witness/testnet/2021/05/31/how-to-run-a-witness-node-on-the-hf25-testnet.html" rel="alternate" type="text/html" title="How to run a witness node on the hf25 testnet" /><published>2021-05-31T06:51:27-07:00</published><updated>2021-05-31T06:51:27-07:00</updated><id>https://hivedocs.info/howto/witness/testnet/2021/05/31/how-to-run-a-witness-node-on-the-hf25-testnet</id><content type="html" xml:base="https://hivedocs.info/howto/witness/testnet/2021/05/31/how-to-run-a-witness-node-on-the-hf25-testnet.html">&lt;div id=&quot;content-howo-how-to-run-a-witness-node-on-the-hf25-testnet&quot;&gt;![image.png](https://files.peakd.com/file/peakd-hive/howo/23xe7eZsnrPcykgbjNqyAudjuQ8nfGfqRzVCpTShns5vRs2J9gcknbewso9v32YFhw54x.png)

Hi ! the testnet phase for HF25 is now in full swing, here's some info on it from @gtg https://peakd.com/@gtg/hf25-public-testnet-reloaded-rc2

One important thing to understand about the testnet is much more lightweight than the main net (because the chain is brand new) so you can actually get it running on a super small machine, to prove my point I'm going to write this tutorial using the 6$ a month doplet (1 core, 25gb storage) from digitalocean. I recommend ubuntu 18.04 LTS, 20.04 is also supported by hive but it can be more tricky depending on the versions of GCC+boost+cmake that are provided with it.

If you participated in the last testnet you will find this guide very similar to the previous one https://peakd.com/hive/@howo/how-to-participate-in-the-tesntets-this-week-full-guide but I felt like making a new one was better than telling you  &quot;follow the outdated guide and at step 35 do this instead&quot; 

### step 1: Build hive or download binaries

#### download binaries

If you're on a low end hardware compiling may take a while, so it's faster to let someone compile the binaries for you so you can just run them instead.

@gtg offers pre-built binaries at https://gtg.openhive.network/get/testnet/bin/ just download both hived and cli_wallet and you're good to go:

```
mkdir programs
cd programs
wget https://gtg.openhive.network/get/testnet/bin/cli_wallet-v1.25.0rc2
wget https://gtg.openhive.network/get/testnet/bin/hived-v1.25.0rc2
chmod +x *
```

This is a hassle-free solution but binaries may not always be available and it's generally better security-wise to compile it yourself.

### build hive

If you are running on low end hardware like me, you will probably need to setup some swap to compile hive:  https://linuxize.com/post/how-to-add-swap-space-on-ubuntu-18-04/ I personally added 16GB of swap. I don't know how much is actually needed I just figured that it would be enough, feel free to tell me in the comments if you experiment with it.


Let's install the dependencies first:
```
apt-get install -y \
        autoconf \
        automake \
        autotools-dev \
        build-essential \
        cmake \
        doxygen \
        git \
        libboost-all-dev \
        libyajl-dev \
        libreadline-dev \
        libssl-dev \
        libtool \
        liblz4-tool \
        ncurses-dev \
        python3 \
        python3-dev \
        python3-jinja2 \
        python3-pip \
        libgflags-dev \
        libsnappy-dev \
        zlib1g-dev \
        libbz2-dev \
        liblz4-dev \
        libzstd-dev
```

Then get hive and compile it, change `v1.25.0rc2` to whatever is the current release tag, follow @gtg he is usually the one announcing the release notes, alternatively you can look on https://gitlab.syncad.com/hive/hive/-/tags and look at the most recent tags.  

```
git clone git@gitlab.syncad.com:hive/hive.git
cd hive
git checkout v1.25.0rc2
git submodule update --init --recursive
mkdir build
cd build

cmake -DENABLE_COVERAGE_TESTING=ON -DBUILD_HIVE_TESTNET=ON -DLOW_MEMORY_NODE=ON ..

make -j$(nproc) hived cli_wallet
```

Compiling may take a while if you are on low end hardware it could take up to a few hours if not more, I forgot to measure it when I did it myself so ü§∑‚Äç. On high end hardware you can expect 3-5 minutes.
 
## Run the node

I am using the directory structure and binary names that you get when you compile hive so straight copy paste may not work if you use binaries but everything else works the same you just have to use the right paths and right binary names.


Run the node a few seconds and then exit hived like so

`./programs/hive/hived -d testnet/`

this will create a testnet directory with the default config file.

open the config.ini file

nano testnet/config.ini

replace the config.ini with this one:

```
# tells the node which seeds he should listen to to get blocks
p2p-seed-node = testnet.openhive.network:2001

# Local http endpoint for webserver requests.
webserver-http-endpoint = 127.0.0.1:8090

# Local websocket endpoint for webserver requests.
webserver-ws-endpoint =127.0.0.1:8091

log-appender = {&quot;appender&quot;:&quot;stderr&quot;,&quot;stream&quot;:&quot;std_error&quot;}
log-logger = {&quot;name&quot;:&quot;default&quot;,&quot;level&quot;:&quot;info&quot;,&quot;appender&quot;:&quot;stderr&quot;}

backtrace = yes

plugin = webserver p2p json_rpc
plugin = database_api condenser_api

plugin = witness
plugin = rc

plugin = market_history
plugin = market_history_api

plugin = account_history_rocksdb
plugin = account_history_api

plugin = transaction_status
plugin = transaction_status_api

plugin = account_by_key
plugin = account_by_key_api

plugin = reputation
plugin = reputation_api

plugin = block_api network_broadcast_api rc_api

account-history-rocksdb-path = &quot;blockchain/account-history-rocksdb-storage&quot;

shared-file-size = 10G

shared-file-full-threshold = 9500
shared-file-scale-rate = 1000

flush-state-interval = 0

market-history-bucket-size = [15,60,300,3600,86400]
market-history-buckets-per-size = 5760

p2p-endpoint = 0.0.0.0:2001

transaction-status-block-depth = 64000
transaction-status-track-after-block = 46000000

webserver-thread-pool-size = 256
```

Then run hived again, this time we want it to stay up so setup a way for it to persist even if you log out, like screen. I personally use pm2 for the testnets just because it's convenient. This is not optimal for a production setup but it's fine for those testnets. (see https://pm2.keymetrics.io/docs/usage/quick-start/)

for the testnet I run hived like this with pm2:

pm2 start --name testnet ./programs/hived/hived -- -d testnet


It will take some time (a few minutes to a few hours) before you get your blocks.
You can look at https://test.ausbit.dev/ to see what is the head block to get a sense of how far you are.
When you are synched with the testnet and you should see messages like this:

```
3|hf23     | 1526617ms p2p_plugin.cpp:212            handle_block         ] Got 0 transactions on block 4415 by howo -- Block Time Offset: -382 ms
3|hf23     | 1532618ms p2p_plugin.cpp:212            handle_block         ] Got 0 transactions on block 4416 by howo -- Block Time Offset: -381 ms
3|hf23     | 1538612ms p2p_plugin.cpp:212            handle_block         ] Got 0 transactions on block 4417 by howo -- Block Time Offset: -387 ms
3|hf23     | 1544620ms p2p_plugin.cpp:212            handle_block         ] Got 0 transactions on block 4418 by howo -- Block Time Offset: -379 ms
3|hf23     | 1550615ms p2p_plugin.cpp:212            handle_block         ] Got 0 transactions on block 4419 by howo -- Block Time Offset: -384 ms

```

now your node is running ! So that's great, but it's not producing.

So you need to setup your witness.

## Setting up your witness 

### cli_wallet 

Open up the cli wallet:

`./programs/cli_wallet/cli_wallet --server-rpc-endpoint=&quot;ws://127.0.0.1:8091&quot;`

it'll ask for a password, so execute:

`set_password yourpassword`

then unlock it using:

`unlock yourpassword`

Now execute those commands:

import your active key to do various actions, note that the keys on the testnet are the same than the keys on main net (they have been ported) so you can just use your account  
`import_key 5JNHfZYKGaomSFvd4NUdQ9qMcEAC43kujbfjueTHpVapX1Kzq2n`

then generate keys for your witness:
`suggest_brain_key`

it'll be something like this:
```
{
  &quot;brain_priv_key&quot;: &quot;STRANGE ROADWAY TWASOME MOLER CENTIMO THOFT COMPORT VARIANT OUTSWIM EGGER SCRIBE GLAVER CROWDED DOLLIER AWNED DOPPER&quot;,
  &quot;wif_priv_key&quot;: &quot;5KJUxvUSdAV6H7LiutRJMVwEVptmoaDhM73Cg1itzYjG8zs7tWF&quot;,
  &quot;pub_key&quot;: &quot;TST71oeHrdBZEKDG1GaC75VKDaRGcXk2R8htD8J6wkP6p1zDRPzFZ&quot;
}
```
Save these for later !

Then set yourself as a witness (notice how I used the pub_key generated above)
```
update_witness &quot;yourusername&quot; &quot;http://example.org&quot; &quot;TST71oeHrdBZEKDG1GaC75VKDaRGcXk2R8htD8J6wkP6p1zDRPzFZ&quot; {&quot;account_creation_fee&quot;:&quot;0.000 TESTS&quot;,&quot;maximum_block_size&quot;:65536,&quot;hbd_interest_rate&quot;:300} true
```

then request some test hive via https://hivetestnetfaucet.org/

and power it up, this is important to do even if you already have hp. Because of the power up delay introduced in hf24, your initial HP don't have any effect:

`transfer_to_vesting &quot;yourusername&quot; &quot;yourusername&quot; &quot;10.000 TESTS&quot; true`

and finally vote for yourself so you get scheduled for blocks. If you don't have stake feel free to request some via https://hivetestnetfaucet.org/

`vote_for_witness &quot;yourusername&quot; &quot;yourusername&quot; true true`

and we are done with cli_wallet ! but not with the setup.

### final config

Open the config one final time to set yourself as a witness by adding these fields:

I use the private key that you generated with the cli above not the one that I put here. I put one here to show that you don't put quotes around the private key.
```
witness = &quot;yourusername&quot;

# WIF PRIVATE KEY to be used by one or more witnesses or miners
private-key = 5KJUxvUSdAV6H7LiutRJMVwEVptmoaDhM73Cg1itzYjG8zs7tWF
```

restart the node and you should be producing blocks, the logs should look something like this:

```
3|hf23     | 2687621ms p2p_plugin.cpp:212            handle_block         ] Got 0 transactions on block 4595 by howo -- Block Time Offset: -378 ms
3|hf23     | 2690613ms witness_plugin.cpp:343        block_production_loo ] Generated block #4596 with timestamp 2020-08-25T19:44:51 at time 2020-08-25T19:44:51
```

## Seed node

Go the extra mile and setup a seed node ! this is quite important as the testnet have very few seed nodes, so it helps a lot if you make one.

Your node is already configured to be a seed node so you just need to open the corresponding port:
(note that this command may vary depending on the firewall setup of your computer)
```
sudo iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 2001 -j ACCEPT
```

And now you can communicate the new seed node to everyone. Please post your ip as a comment of that post so that I can update this link to use your seed as well :).

Thank you for reading.

If you liked this writeup, please consider voting for @steempress it's the witness that I co-manage with @fredrikaa:
![](https://i.imgur.com/oPJ63jA.png)
&lt;center&gt;&lt;sup&gt;You can vote for our witness directly using Hivesigner &lt;a href=&quot;https://hivesigner.com/sign/account-witness-vote?witness=steempress&amp;amp;approve=1&quot;&gt;here&lt;/a&gt;.&lt;/sup&gt;&lt;/center&gt;&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@howo&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/how-to-run-a-witness-node-on-the-hf25-testnet&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-howo-how-to-run-a-witness-node-on-the-hf25-testnet').html();
      const outputElem = $('#content-howo-how-to-run-a-witness-node-on-the-hf25-testnet');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet code {
    background: white;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet a:hover {
    border-bottom: 0;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet h1 {
    font-size: 2.2em;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet header small {
    color: #999;
    font-size: 50%;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/guide/@howo/how-to-run-a-witness-node-on-the-hf25-testnet&quot;&gt;How to run a witness node on the hf25 testnet&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@howo&quot;&gt;@howo&lt;/a&gt;
&lt;/p&gt;</content><author><name>howo</name></author><category term="howto" /><category term="witness" /><category term="testnet" /><summary type="html">![image.png](https://files.peakd.com/file/peakd-hive/howo/23xe7eZsnrPcykgbjNqyAudjuQ8nfGfqRzVCpTShns5vRs2J9gcknbewso9v32YFhw54x.png) Hi ! the testnet phase for HF25 is now in full swing, here's some info on it from @gtg https://peakd.com/@gtg/hf25-public-testnet-reloaded-rc2 One important thing to understand about the testnet is much more lightweight than the main net (because the chain is brand new) so you can actually get it running on a super small machine, to prove my point I'm going to write this tutorial using the 6$ a month doplet (1 core, 25gb storage) from digitalocean. I recommend ubuntu 18.04 LTS, 20.04 is also supported by hive but it can be more tricky depending on the versions of GCC+boost+cmake that are provided with it. If you participated in the last testnet you will find this guide very similar to the previous one https://peakd.com/hive/@howo/how-to-participate-in-the-tesntets-this-week-full-guide but I felt like making a new one was better than telling you &quot;follow the outdated guide and at step 35 do this instead&quot; ### step 1: Build hive or download binaries #### download binaries If you're on a low end hardware compiling may take a while, so it's faster to let someone compile the binaries for you so you can just run them instead. @gtg offers pre-built binaries at https://gtg.openhive.network/get/testnet/bin/ just download both hived and cli_wallet and you're good to go: ``` mkdir programs cd programs wget https://gtg.openhive.network/get/testnet/bin/cli_wallet-v1.25.0rc2 wget https://gtg.openhive.network/get/testnet/bin/hived-v1.25.0rc2 chmod +x * ``` This is a hassle-free solution but binaries may not always be available and it's generally better security-wise to compile it yourself. ### build hive If you are running on low end hardware like me, you will probably need to setup some swap to compile hive: https://linuxize.com/post/how-to-add-swap-space-on-ubuntu-18-04/ I personally added 16GB of swap. I don't know how much is actually needed I just figured that it would be enough, feel free to tell me in the comments if you experiment with it. Let's install the dependencies first: ``` apt-get install -y \ autoconf \ automake \ autotools-dev \ build-essential \ cmake \ doxygen \ git \ libboost-all-dev \ libyajl-dev \ libreadline-dev \ libssl-dev \ libtool \ liblz4-tool \ ncurses-dev \ python3 \ python3-dev \ python3-jinja2 \ python3-pip \ libgflags-dev \ libsnappy-dev \ zlib1g-dev \ libbz2-dev \ liblz4-dev \ libzstd-dev ``` Then get hive and compile it, change `v1.25.0rc2` to whatever is the current release tag, follow @gtg he is usually the one announcing the release notes, alternatively you can look on https://gitlab.syncad.com/hive/hive/-/tags and look at the most recent tags. ``` git clone git@gitlab.syncad.com:hive/hive.git cd hive git checkout v1.25.0rc2 git submodule update --init --recursive mkdir build cd build cmake -DENABLE_COVERAGE_TESTING=ON -DBUILD_HIVE_TESTNET=ON -DLOW_MEMORY_NODE=ON .. make -j$(nproc) hived cli_wallet ``` Compiling may take a while if you are on low end hardware it could take up to a few hours if not more, I forgot to measure it when I did it myself so ü§∑‚Äç. On high end hardware you can expect 3-5 minutes. ## Run the node I am using the directory structure and binary names that you get when you compile hive so straight copy paste may not work if you use binaries but everything else works the same you just have to use the right paths and right binary names. Run the node a few seconds and then exit hived like so `./programs/hive/hived -d testnet/` this will create a testnet directory with the default config file. open the config.ini file nano testnet/config.ini replace the config.ini with this one: ``` # tells the node which seeds he should listen to to get blocks p2p-seed-node = testnet.openhive.network:2001 # Local http endpoint for webserver requests. webserver-http-endpoint = 127.0.0.1:8090 # Local websocket endpoint for webserver requests. webserver-ws-endpoint =127.0.0.1:8091 log-appender = {&quot;appender&quot;:&quot;stderr&quot;,&quot;stream&quot;:&quot;std_error&quot;} log-logger = {&quot;name&quot;:&quot;default&quot;,&quot;level&quot;:&quot;info&quot;,&quot;appender&quot;:&quot;stderr&quot;} backtrace = yes plugin = webserver p2p json_rpc plugin = database_api condenser_api plugin = witness plugin = rc plugin = market_history plugin = market_history_api plugin = account_history_rocksdb plugin = account_history_api plugin = transaction_status plugin = transaction_status_api plugin = account_by_key plugin = account_by_key_api plugin = reputation plugin = reputation_api plugin = block_api network_broadcast_api rc_api account-history-rocksdb-path = &quot;blockchain/account-history-rocksdb-storage&quot; shared-file-size = 10G shared-file-full-threshold = 9500 shared-file-scale-rate = 1000 flush-state-interval = 0 market-history-bucket-size = [15,60,300,3600,86400] market-history-buckets-per-size = 5760 p2p-endpoint = 0.0.0.0:2001 transaction-status-block-depth = 64000 transaction-status-track-after-block = 46000000 webserver-thread-pool-size = 256 ``` Then run hived again, this time we want it to stay up so setup a way for it to persist even if you log out, like screen. I personally use pm2 for the testnets just because it's convenient. This is not optimal for a production setup but it's fine for those testnets. (see https://pm2.keymetrics.io/docs/usage/quick-start/) for the testnet I run hived like this with pm2: pm2 start --name testnet ./programs/hived/hived -- -d testnet It will take some time (a few minutes to a few hours) before you get your blocks. You can look at https://test.ausbit.dev/ to see what is the head block to get a sense of how far you are. When you are synched with the testnet and you should see messages like this: ``` 3|hf23 | 1526617ms p2p_plugin.cpp:212 handle_block ] Got 0 transactions on block 4415 by howo -- Block Time Offset: -382 ms 3|hf23 | 1532618ms p2p_plugin.cpp:212 handle_block ] Got 0 transactions on block 4416 by howo -- Block Time Offset: -381 ms 3|hf23 | 1538612ms p2p_plugin.cpp:212 handle_block ] Got 0 transactions on block 4417 by howo -- Block Time Offset: -387 ms 3|hf23 | 1544620ms p2p_plugin.cpp:212 handle_block ] Got 0 transactions on block 4418 by howo -- Block Time Offset: -379 ms 3|hf23 | 1550615ms p2p_plugin.cpp:212 handle_block ] Got 0 transactions on block 4419 by howo -- Block Time Offset: -384 ms ``` now your node is running ! So that's great, but it's not producing. So you need to setup your witness. ## Setting up your witness ### cli_wallet Open up the cli wallet: `./programs/cli_wallet/cli_wallet --server-rpc-endpoint=&quot;ws://127.0.0.1:8091&quot;` it'll ask for a password, so execute: `set_password yourpassword` then unlock it using: `unlock yourpassword` Now execute those commands: import your active key to do various actions, note that the keys on the testnet are the same than the keys on main net (they have been ported) so you can just use your account `import_key 5JNHfZYKGaomSFvd4NUdQ9qMcEAC43kujbfjueTHpVapX1Kzq2n` then generate keys for your witness: `suggest_brain_key` it'll be something like this: ``` { &quot;brain_priv_key&quot;: &quot;STRANGE ROADWAY TWASOME MOLER CENTIMO THOFT COMPORT VARIANT OUTSWIM EGGER SCRIBE GLAVER CROWDED DOLLIER AWNED DOPPER&quot;, &quot;wif_priv_key&quot;: &quot;5KJUxvUSdAV6H7LiutRJMVwEVptmoaDhM73Cg1itzYjG8zs7tWF&quot;, &quot;pub_key&quot;: &quot;TST71oeHrdBZEKDG1GaC75VKDaRGcXk2R8htD8J6wkP6p1zDRPzFZ&quot; } ``` Save these for later ! Then set yourself as a witness (notice how I used the pub_key generated above) ``` update_witness &quot;yourusername&quot; &quot;http://example.org&quot; &quot;TST71oeHrdBZEKDG1GaC75VKDaRGcXk2R8htD8J6wkP6p1zDRPzFZ&quot; {&quot;account_creation_fee&quot;:&quot;0.000 TESTS&quot;,&quot;maximum_block_size&quot;:65536,&quot;hbd_interest_rate&quot;:300} true ``` then request some test hive via https://hivetestnetfaucet.org/ and power it up, this is important to do even if you already have hp. Because of the power up delay introduced in hf24, your initial HP don't have any effect: `transfer_to_vesting &quot;yourusername&quot; &quot;yourusername&quot; &quot;10.000 TESTS&quot; true` and finally vote for yourself so you get scheduled for blocks. If you don't have stake feel free to request some via https://hivetestnetfaucet.org/ `vote_for_witness &quot;yourusername&quot; &quot;yourusername&quot; true true` and we are done with cli_wallet ! but not with the setup. ### final config Open the config one final time to set yourself as a witness by adding these fields: I use the private key that you generated with the cli above not the one that I put here. I put one here to show that you don't put quotes around the private key. ``` witness = &quot;yourusername&quot; # WIF PRIVATE KEY to be used by one or more witnesses or miners private-key = 5KJUxvUSdAV6H7LiutRJMVwEVptmoaDhM73Cg1itzYjG8zs7tWF ``` restart the node and you should be producing blocks, the logs should look something like this: ``` 3|hf23 | 2687621ms p2p_plugin.cpp:212 handle_block ] Got 0 transactions on block 4595 by howo -- Block Time Offset: -378 ms 3|hf23 | 2690613ms witness_plugin.cpp:343 block_production_loo ] Generated block #4596 with timestamp 2020-08-25T19:44:51 at time 2020-08-25T19:44:51 ``` ## Seed node Go the extra mile and setup a seed node ! this is quite important as the testnet have very few seed nodes, so it helps a lot if you make one. Your node is already configured to be a seed node so you just need to open the corresponding port: (note that this command may vary depending on the firewall setup of your computer) ``` sudo iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 2001 -j ACCEPT ``` And now you can communicate the new seed node to everyone. Please post your ip as a comment of that post so that I can update this link to use your seed as well :). Thank you for reading. If you liked this writeup, please consider voting for @steempress it's the witness that I co-manage with @fredrikaa: ![](https://i.imgur.com/oPJ63jA.png) You can vote for our witness directly using Hivesigner here. See: How to run a witness node on the hf25 testnet by @howo</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/howo/23xe7eZsnrPcykgbjNqyAudjuQ8nfGfqRzVCpTShns5vRs2J9gcknbewso9v32YFhw54x.png" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/howo/23xe7eZsnrPcykgbjNqyAudjuQ8nfGfqRzVCpTShns5vRs2J9gcknbewso9v32YFhw54x.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive SQL is ready for the hardfork 25</title><link href="https://hivedocs.info/news/sql/database/2021/05/31/hivesql-update-hardfork25.html" rel="alternate" type="text/html" title="Hive SQL is ready for the hardfork 25" /><published>2021-05-31T06:27:45-07:00</published><updated>2021-05-31T06:27:45-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/05/31/hivesql-update-hardfork25</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/05/31/hivesql-update-hardfork25.html">&lt;div id=&quot;content-arcange-hivesql-update-hardfork25&quot;&gt;![](https://i.imgur.com/IQw9dbJ.png)

The hardfork 25 (codename Equilibrium) should be activated in a few weeks. With these harfork will come many changes in the blockchain data which must obviously be passed on to HiveSQL.

Therfore HiveSQL has undergo a lot of updates to be prepared to the new specs and configuration of the blockchain after the hardfork.

Of course, all of these changes have been implemented in such a way as to minimize the impact on users, apps and processes relying on HiveSQL, which means... they shouldn't be affected at all!

## What's new?

Here is the list of all these changes.

### 1. New Operation tables

Two new operation tables and height virtual operation tables have been created to store the new virtual operations data.

* **TxCollateralizedConverts**

The `collateralized_convert` operation is similar to the `convert` operation and instructs the blockchain to convert HIVE to HBD. The operation is performed after a 3.5 days delay, but the owner gets HBD immediately. The price risk is cushioned by extra HIVE. After actual conversion takes place the excess HIVE is returned to the owner.
    
|Column|Description|
|-|-|
|owner|The account requesting the conversion|
|requestid|A request identifier|
|amount|The amount of HIVE to convert|
|amount_symbol|HIVE|

* **TxRecurrentTransfers**

The `recurrent_transfer` operation creates/updates/removes a recurrent transfer (Transfers any liquid asset every fixed amount of time from one account to another). If the amount is set to 0, the recurrent transfer is be deleted. If there is already a recurrent transfer matching from and to, the recurrent transfer is updated.
    
|Column|Description|
|-|-|
|from|Account to transfer an asset from|
|to|Account to transfer an asset to|
|amount|The amount of asset to transfer|
|amount_symbol|The symbol of the asset to transfer|
|memo|communication that accompanies the transfer. The memo is plain-text, any encryption on the memo is up to a higher-level protocol|
|recurrence|How often will the payment be triggered (hours)|
|executions|How many times the recurrent payment will be executed|
|extensions|reserved for future use|

### 2. New Virtual Operation tables

* **VOAccountCreateds**

This virtual operation is issued each time a new account has been successfully created.

|Column|Description|
|-|-|
|new_account_name|name of the newly created account|
|creator|name of the account creator|
|initial_vesting_shares|Amount of VESTS given to the created account|
|initial_vesting_shares_symbol|VESTS|
|initial_delegation|Amount of VESTS delegated if created with account_create_with_delegation|
|initial_delegation_symbol|VESTS|

* **VOChangedRecoveryAccounts**

This virtual operation is issued when the blockchain effectively changes the recovery account of an account after it issued such a request.

|Column|Description|
|-|-|
|account|account who changed its recovery account|
|old_recovery_account|old recovery account|
|new_recovery_account|new recovery account|

* **VOCommentsVotes**

This virtual operation is issued when a vote on a post or comment becomes effective.

|Column|Description|
|-|-|
|voter|account performing the vote|
|author|author of the post or comment being voted|
|permlink|permlink of the post or comment being voted|
|weight|defines the score this vote receives, used by vote payout calc. 0 if a negative vote or changed votes|
|rshares|The number of rshares this vote is responsible for|
|total_vote_weight|the total weight of voting rewards. It is used to calculate the pro-rata share of curation payouts|
|pending_payout|potential payout of related comment at the moment of this vote|
|pending_payout_symbol|HBD|

* **VOExpiredAccountNotifications**

This virtual operation is issued when governance votes for an account have expired and are removed.

|Column|Description|
|-|-|
|account|Account for who governance votes have expired|

* **VOFailedRecurrentTransfers**

This virtual operation is issued when a recurrent transfer has failed to be executed.

|Column|Description|
|-|-|
|from|Account to transfer an asset from|
|to|Account to transfer an asset to|
|amount|The amount of asset to transfer|
|amount_symbol|The symbol of the asset to transfer|
|memo||
|consecutive_failures|How many times the recurrent payment failed to be executed|
|remaining_executions|How many times the recurrent payment should still be executed|
|deleted|Indicates that the recurrent transfer was deleted due to too many consecutive failures|

* **VOFillCollateralizedConvertRequests**

This virtual operation is issued when a HIVE to HBD conversion is completed.

|Column|Description|
|-|-|
|owner|Account requesting the conversion|
|requestid|conversion request identifier|
|amount_in|Amount of hive to be converted|
|amount_in_symbol|HIVE|
|amount_out|Amount of HBD to be received|
|amount_out_symbol|HBD|
|excess_collateral|excess HIVE returned to the owner|
|excess_collateral_symbol|HIVE|

* **VOFillRecurrentTransfers**

This virtual operation is issued when a recurrent transfer is executed.

|Column|Description|
|-|-|
|from|account sending assets|
|to|account receiving assets|
|amount|amount sent|
|amount_symbol|asset symbol|
|memo|a communication that accompanies the transfer. The memo is plain-text, any encryption on the memo is up to a higher-level protocol|
|remaining_executions|Number of remaining executions|

* **VOTransferToVestingCompleteds**

This virtual operation is issued when a power-up is finally taken into account for governance votes.

|Column|Description|
|-|-|
|from_account|account powering up HIVE|
|to_account|account receiving VESTS|
|hive_vested|amount of HIVE powered up|
|hive_vested_symbol|HIVE|
|vesting_shares_received|amount of VESTS received|
|vesting_shares_received_symbol|VESTS|

## Documentation

The HiveSQL documentation has been updated accordingly and can be viewed at https://docs.hivesql.io

## Support

If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT).

Thank you.

#### &lt;center&gt; &lt;/center&gt;
|&lt;center&gt;Support the HiveSQL proposal to keep it free for all&lt;/center&gt;|
|-|
|&lt;center&gt;[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/138)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)&lt;/center&gt;|

&lt;center&gt;

### Check out my apps and services
&lt;a href=&quot;/hive/@hive.engage/stay-connected-with-your-hive-audience-and-catch-attention&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GiNJqlm.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivebuzz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/B4UTun2.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivesql&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EPN8RW6.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/hive/@arcange/introducing-hive-account-recovery&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6TWeW7V.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hive.autoclaim&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ih2pEOw.png&quot; /&gt;&lt;/a&gt;&lt;/center&gt;
&lt;center&gt;

### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@arcange&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hivesql-update-hardfork25&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-arcange-hivesql-update-hardfork25').html();
      const outputElem = $('#content-arcange-hivesql-update-hardfork25');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-arcange-hivesql-update-hardfork25 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-arcange-hivesql-update-hardfork25 code {
    background: white;
  }
  #content-arcange-hivesql-update-hardfork25 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-arcange-hivesql-update-hardfork25 a:hover {
    border-bottom: 0;
  }
  #content-arcange-hivesql-update-hardfork25 h1 {
    font-size: 2.2em;
  }
  #content-arcange-hivesql-update-hardfork25 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-arcange-hivesql-update-hardfork25 header small {
    color: #999;
    font-size: 50%;
  }
  #content-arcange-hivesql-update-hardfork25 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@arcange/hivesql-update-hardfork25&quot;&gt;Hive SQL is ready for the hardfork 25&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@arcange&quot;&gt;@arcange&lt;/a&gt;
&lt;/p&gt;

&lt;/center&gt;&lt;/div&gt;</content><author><name>arcange</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![](https://i.imgur.com/IQw9dbJ.png) The hardfork 25 (codename Equilibrium) should be activated in a few weeks. With these harfork will come many changes in the blockchain data which must obviously be passed on to HiveSQL. Therfore HiveSQL has undergo a lot of updates to be prepared to the new specs and configuration of the blockchain after the hardfork. Of course, all of these changes have been implemented in such a way as to minimize the impact on users, apps and processes relying on HiveSQL, which means... they shouldn't be affected at all! ## What's new? Here is the list of all these changes. ### 1. New Operation tables Two new operation tables and height virtual operation tables have been created to store the new virtual operations data. * **TxCollateralizedConverts** The `collateralized_convert` operation is similar to the `convert` operation and instructs the blockchain to convert HIVE to HBD. The operation is performed after a 3.5 days delay, but the owner gets HBD immediately. The price risk is cushioned by extra HIVE. After actual conversion takes place the excess HIVE is returned to the owner. |Column|Description| |-|-| |owner|The account requesting the conversion| |requestid|A request identifier| |amount|The amount of HIVE to convert| |amount_symbol|HIVE| * **TxRecurrentTransfers** The `recurrent_transfer` operation creates/updates/removes a recurrent transfer (Transfers any liquid asset every fixed amount of time from one account to another). If the amount is set to 0, the recurrent transfer is be deleted. If there is already a recurrent transfer matching from and to, the recurrent transfer is updated. |Column|Description| |-|-| |from|Account to transfer an asset from| |to|Account to transfer an asset to| |amount|The amount of asset to transfer| |amount_symbol|The symbol of the asset to transfer| |memo|communication that accompanies the transfer. The memo is plain-text, any encryption on the memo is up to a higher-level protocol| |recurrence|How often will the payment be triggered (hours)| |executions|How many times the recurrent payment will be executed| |extensions|reserved for future use| ### 2. New Virtual Operation tables * **VOAccountCreateds** This virtual operation is issued each time a new account has been successfully created. |Column|Description| |-|-| |new_account_name|name of the newly created account| |creator|name of the account creator| |initial_vesting_shares|Amount of VESTS given to the created account| |initial_vesting_shares_symbol|VESTS| |initial_delegation|Amount of VESTS delegated if created with account_create_with_delegation| |initial_delegation_symbol|VESTS| * **VOChangedRecoveryAccounts** This virtual operation is issued when the blockchain effectively changes the recovery account of an account after it issued such a request. |Column|Description| |-|-| |account|account who changed its recovery account| |old_recovery_account|old recovery account| |new_recovery_account|new recovery account| * **VOCommentsVotes** This virtual operation is issued when a vote on a post or comment becomes effective. |Column|Description| |-|-| |voter|account performing the vote| |author|author of the post or comment being voted| |permlink|permlink of the post or comment being voted| |weight|defines the score this vote receives, used by vote payout calc. 0 if a negative vote or changed votes| |rshares|The number of rshares this vote is responsible for| |total_vote_weight|the total weight of voting rewards. It is used to calculate the pro-rata share of curation payouts| |pending_payout|potential payout of related comment at the moment of this vote| |pending_payout_symbol|HBD| * **VOExpiredAccountNotifications** This virtual operation is issued when governance votes for an account have expired and are removed. |Column|Description| |-|-| |account|Account for who governance votes have expired| * **VOFailedRecurrentTransfers** This virtual operation is issued when a recurrent transfer has failed to be executed. |Column|Description| |-|-| |from|Account to transfer an asset from| |to|Account to transfer an asset to| |amount|The amount of asset to transfer| |amount_symbol|The symbol of the asset to transfer| |memo|| |consecutive_failures|How many times the recurrent payment failed to be executed| |remaining_executions|How many times the recurrent payment should still be executed| |deleted|Indicates that the recurrent transfer was deleted due to too many consecutive failures| * **VOFillCollateralizedConvertRequests** This virtual operation is issued when a HIVE to HBD conversion is completed. |Column|Description| |-|-| |owner|Account requesting the conversion| |requestid|conversion request identifier| |amount_in|Amount of hive to be converted| |amount_in_symbol|HIVE| |amount_out|Amount of HBD to be received| |amount_out_symbol|HBD| |excess_collateral|excess HIVE returned to the owner| |excess_collateral_symbol|HIVE| * **VOFillRecurrentTransfers** This virtual operation is issued when a recurrent transfer is executed. |Column|Description| |-|-| |from|account sending assets| |to|account receiving assets| |amount|amount sent| |amount_symbol|asset symbol| |memo|a communication that accompanies the transfer. The memo is plain-text, any encryption on the memo is up to a higher-level protocol| |remaining_executions|Number of remaining executions| * **VOTransferToVestingCompleteds** This virtual operation is issued when a power-up is finally taken into account for governance votes. |Column|Description| |-|-| |from_account|account powering up HIVE| |to_account|account receiving VESTS| |hive_vested|amount of HIVE powered up| |hive_vested_symbol|HIVE| |vesting_shares_received|amount of VESTS received| |vesting_shares_received_symbol|VESTS| ## Documentation The HiveSQL documentation has been updated accordingly and can be viewed at https://docs.hivesql.io ## Support If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT). Thank you. #### |Support the HiveSQL proposal to keep it free for all| |-| |[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)[Vote for the proposal on Ecency](https://ecency.com/proposals/138)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)| ### Check out my apps and services ### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt; See: Hive SQL is ready for the hardfork 25 by @arcange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/IQw9dbJ.png" /><media:content medium="image" url="https://i.imgur.com/IQw9dbJ.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Updates to Hive.io</title><link href="https://hivedocs.info/news/projects/hive/2021/05/30/updates-to-hiveio.html" rel="alternate" type="text/html" title="Updates to Hive.io" /><published>2021-05-30T04:03:36-07:00</published><updated>2021-05-30T04:03:36-07:00</updated><id>https://hivedocs.info/news/projects/hive/2021/05/30/updates-to-hiveio</id><content type="html" xml:base="https://hivedocs.info/news/projects/hive/2021/05/30/updates-to-hiveio.html">&lt;div id=&quot;content-therealwolf-updates-to-hiveio&quot;&gt;
![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23wgiuoC5oSm54NFdpopv9SdzZjtdjhSonHUoJh6MLngntYMjXysbmrPjfVj3RHhzwTjz.png)

---


I've recently made some updates to hive.io.

This primarily includes:

- Upgraded Landing Page (https://hive.io)
- Upgraded Ecosystem Page (https://hive.io/eco)
- New Contributors Page (https://hive.io/contributors)
- New Updates Page (https://hive.io/updates)
- Upgraded Wallets Page (https://hive.io/wallets)

I want to thank @mahydiari and @good-karma for their input and feedback and ofc. everybody else who gave feedback.

There's still a bit more I've planned, mainly I want to redo the first part of the landing page (Fast, Scalable, Powerful. Hive Logo =&amp;gt; too generic, every blockchain project says that. Want to put focus on the fact that Hive made blockchain history i.e. https://twitter.com/lopp/status/1262786986013798400 and https://twitter.com/vitalikbuterin/status/1240605327122464768) but I'll need more time for planning/design.



## Contributors

I've first asked on [GitLab](https://gitlab.syncad.com/hive/hive-io/-/issues/15) who wants to be listed on there and got some fast replies, but then decided on at least adding TOP 30 Witnesses and those who are also actively working within the Hive ecosystem.

![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23z7X3CbQQda4oEQ4FuyNrxdY48L9nKiiZkg67hXJewHKFBVxiE8iAjfURNkixm6MKeRJ.png)

https://hive.io/contributors

---

Please let me know if:

- you don't want to be listed
- you want to be listed (see below)
- some data should be changed (optimally in this format https://gitlab.syncad.com/hive/hive-io/-/blob/develop/src/helpers/contributors.ts)
- you have ideas about more categories (like Core Dev, Marketing,..)

## Changing Data

Hive.io is open-source and you can also add apps/contributors yourself (technical). Checkout the Readme on GitLab: https://gitlab.syncad.com/hive/hive-io/-/blob/master/README.md

---

Have a nice Sunday!

Hive On
Wolf&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@therealwolf&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/updates-to-hiveio&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-therealwolf-updates-to-hiveio').html();
      const outputElem = $('#content-therealwolf-updates-to-hiveio');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-therealwolf-updates-to-hiveio {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-therealwolf-updates-to-hiveio code {
    background: white;
  }
  #content-therealwolf-updates-to-hiveio a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-therealwolf-updates-to-hiveio a:hover {
    border-bottom: 0;
  }
  #content-therealwolf-updates-to-hiveio h1 {
    font-size: 2.2em;
  }
  #content-therealwolf-updates-to-hiveio h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-therealwolf-updates-to-hiveio header small {
    color: #999;
    font-size: 50%;
  }
  #content-therealwolf-updates-to-hiveio img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-102930/@therealwolf/updates-to-hiveio&quot;&gt;Updates to Hive.io&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@therealwolf&quot;&gt;@therealwolf&lt;/a&gt;
&lt;/p&gt;</content><author><name>therealwolf</name></author><category term="news" /><category term="projects" /><category term="hive" /><summary type="html">![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23wgiuoC5oSm54NFdpopv9SdzZjtdjhSonHUoJh6MLngntYMjXysbmrPjfVj3RHhzwTjz.png) --- I've recently made some updates to hive.io. This primarily includes: - Upgraded Landing Page (https://hive.io) - Upgraded Ecosystem Page (https://hive.io/eco) - New Contributors Page (https://hive.io/contributors) - New Updates Page (https://hive.io/updates) - Upgraded Wallets Page (https://hive.io/wallets) I want to thank @mahydiari and @good-karma for their input and feedback and ofc. everybody else who gave feedback. There's still a bit more I've planned, mainly I want to redo the first part of the landing page (Fast, Scalable, Powerful. Hive Logo =&amp;gt; too generic, every blockchain project says that. Want to put focus on the fact that Hive made blockchain history i.e. https://twitter.com/lopp/status/1262786986013798400 and https://twitter.com/vitalikbuterin/status/1240605327122464768) but I'll need more time for planning/design. ## Contributors I've first asked on [GitLab](https://gitlab.syncad.com/hive/hive-io/-/issues/15) who wants to be listed on there and got some fast replies, but then decided on at least adding TOP 30 Witnesses and those who are also actively working within the Hive ecosystem. ![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23z7X3CbQQda4oEQ4FuyNrxdY48L9nKiiZkg67hXJewHKFBVxiE8iAjfURNkixm6MKeRJ.png) https://hive.io/contributors --- Please let me know if: - you don't want to be listed - you want to be listed (see below) - some data should be changed (optimally in this format https://gitlab.syncad.com/hive/hive-io/-/blob/develop/src/helpers/contributors.ts) - you have ideas about more categories (like Core Dev, Marketing,..) ## Changing Data Hive.io is open-source and you can also add apps/contributors yourself (technical). Checkout the Readme on GitLab: https://gitlab.syncad.com/hive/hive-io/-/blob/master/README.md --- Have a nice Sunday! Hive On Wolf See: Updates to Hive.io by @therealwolf</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/therealwolf/23wgiuoC5oSm54NFdpopv9SdzZjtdjhSonHUoJh6MLngntYMjXysbmrPjfVj3RHhzwTjz.png" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/therealwolf/23wgiuoC5oSm54NFdpopv9SdzZjtdjhSonHUoJh6MLngntYMjXysbmrPjfVj3RHhzwTjz.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">HF25 Public Testnet Reloaded (RC2)</title><link href="https://hivedocs.info/news/projects/testnet/2021/05/29/hf25-public-testnet-reloaded-rc2.html" rel="alternate" type="text/html" title="HF25 Public Testnet Reloaded (RC2)" /><published>2021-05-29T14:46:00-07:00</published><updated>2021-05-29T14:46:00-07:00</updated><id>https://hivedocs.info/news/projects/testnet/2021/05/29/hf25-public-testnet-reloaded-rc2</id><content type="html" xml:base="https://hivedocs.info/news/projects/testnet/2021/05/29/hf25-public-testnet-reloaded-rc2.html">&lt;div id=&quot;content-gtg-hf25-public-testnet-reloaded-rc2&quot;&gt;I just started brand new instance of a public Hive testnet based on `v1.25.0rc2`
https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0rc2

Re-initialization was needed due to changes in governance voting rules (rc1 would fork, because different rules impacts witness schedule):

```
witness.owner == scheduled_witness: Witness produced block at wrong time
    {&quot;block witness&quot;:&quot;gtg-rc1-10&quot;,&quot;scheduled&quot;:&quot;gtg-rc1-13&quot;,&quot;slot_num&quot;:1}
    database.cpp:4838 validate_block_header
```

Unless your account was created very recently, you should be able to participate in the testnet using your own mainnet account and keys (though please be careful, if you leak your key during testnet, your mainnet account will be compromised)

To get some tokens for testing you can use https://hivetestnetfaucet.org/ created by @howo or reach out to witnesses using your favorite communication channels such as https://openhive.chat ;-)

- Hive testnet chain-id: `18dcf0a285365fc58b71f18b3d3fec954aa0c141c44e4e5cb4cf777b9eab274e`
- Hive seed node: `p2p-seed-node = testnet.openhive.network:2001`
- API endpoint (via jussi): `https://testnet.openhive.network`
- Hive Testnet Condenser instance: https://testblog.openhive.network
- Hive Testnet Wallet instance: https://testwallet.openhive.network
- Binaries: https://gtg.openhive.network/get/testnet/bin/
- hived direct http server `http://testnet.openhive.network:8091`
- hived direct websocket server `ws://testnet.openhive.network:8090`
- hivemind server direct server `http://testnet.openhive.network:8080`

To join testnet with your hived, you need a testnet-enabled version, which you can get from here:
https://gtg.openhive.network/get/testnet/bin 
or build yourself (as usual plus `-DBUILD_HIVE_TESTNET=ON` during cmake step)

## See also
CyberBuzz Radio is LIVE: Community Q&amp;amp;A For the Upcoming Hive Blockchain Hardfork:
&lt;center&gt;https://www.youtube.com/watch?v=FtyhMAWto90&amp;amp;t=448s&lt;/center&gt;

(@hbdstabilizer as 50% beneficiary)&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@gtg&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hf25-public-testnet-reloaded-rc2&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-gtg-hf25-public-testnet-reloaded-rc2').html();
      const outputElem = $('#content-gtg-hf25-public-testnet-reloaded-rc2');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-gtg-hf25-public-testnet-reloaded-rc2 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 code {
    background: white;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 a:hover {
    border-bottom: 0;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 h1 {
    font-size: 2.2em;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 header small {
    color: #999;
    font-size: 50%;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@gtg/hf25-public-testnet-reloaded-rc2&quot;&gt;HF25 Public Testnet Reloaded (RC2)&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@gtg&quot;&gt;@gtg&lt;/a&gt;
&lt;/p&gt;</content><author><name>gtg</name></author><category term="news" /><category term="projects" /><category term="testnet" /><summary type="html">I just started brand new instance of a public Hive testnet based on `v1.25.0rc2` https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0rc2 Re-initialization was needed due to changes in governance voting rules (rc1 would fork, because different rules impacts witness schedule): ``` witness.owner == scheduled_witness: Witness produced block at wrong time {&quot;block witness&quot;:&quot;gtg-rc1-10&quot;,&quot;scheduled&quot;:&quot;gtg-rc1-13&quot;,&quot;slot_num&quot;:1} database.cpp:4838 validate_block_header ``` Unless your account was created very recently, you should be able to participate in the testnet using your own mainnet account and keys (though please be careful, if you leak your key during testnet, your mainnet account will be compromised) To get some tokens for testing you can use https://hivetestnetfaucet.org/ created by @howo or reach out to witnesses using your favorite communication channels such as https://openhive.chat ;-) - Hive testnet chain-id: `18dcf0a285365fc58b71f18b3d3fec954aa0c141c44e4e5cb4cf777b9eab274e` - Hive seed node: `p2p-seed-node = testnet.openhive.network:2001` - API endpoint (via jussi): `https://testnet.openhive.network` - Hive Testnet Condenser instance: https://testblog.openhive.network - Hive Testnet Wallet instance: https://testwallet.openhive.network - Binaries: https://gtg.openhive.network/get/testnet/bin/ - hived direct http server `http://testnet.openhive.network:8091` - hived direct websocket server `ws://testnet.openhive.network:8090` - hivemind server direct server `http://testnet.openhive.network:8080` To join testnet with your hived, you need a testnet-enabled version, which you can get from here: https://gtg.openhive.network/get/testnet/bin or build yourself (as usual plus `-DBUILD_HIVE_TESTNET=ON` during cmake step) ## See also CyberBuzz Radio is LIVE: Community Q&amp;amp;A For the Upcoming Hive Blockchain Hardfork: https://www.youtube.com/watch?v=FtyhMAWto90&amp;amp;t=448s (@hbdstabilizer as 50% beneficiary) See: HF25 Public Testnet Reloaded (RC2) by @gtg</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/FtyhMAWto90/0.jpg" /><media:content medium="image" url="https://img.youtube.com/vi/FtyhMAWto90/0.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">13th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/sql/database/2021/05/25/13th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="13th update of 2021 on BlockTrades work on Hive software" /><published>2021-05-25T16:30:27-07:00</published><updated>2021-05-25T16:30:27-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/05/25/13th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/05/25/13th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by BlockTrades team during the last week or so:

# Hived work (blockchain node software)

We‚Äôre continuing to test and make fixes as a precursor to tagging a second release candidate for hived.

We‚Äôve created a new python-based library currently called ‚Äútesttools‚Äù for creating test scenarios for hived and hived‚Äôs CLI wallet. We‚Äôre replacing the beempy library that was previously used for this purpose in order to accelerate the speed at which the tests execute. 

For now, the primary purpose for this python library is testing hived, but it may have more general applicability as a library for communicating with hived, in which case we will rename it later to something more appropriate: 
https://gitlab.syncad.com/hive/hive/-/merge_requests/242

We created some unit-test based stress tests for the new recurrent transfers functionality, and initially we found some surprising results in terms of memory usage, but ultimately this was traced to a misconfiguration of the hived instance (it was configured with the deprecated chainbase account history plugin which is known to consume too much memory). With that plugin replaced by the rocksdb-account-history plugin, memory consumption and general performance was fine.

We also fixed some minor issues with the recurrent transfer operation: https://gitlab.syncad.com/hive/hive/-/merge_requests/246

We‚Äôve added a few new network API calls to hived for getting peer count, getting connected peers, adding peers, and setting allowed peers. These functions were primarily added to facilitate testing scenarios (e.g. testing forking logic), but they can be useful to node operators as well: https://gitlab.syncad.com/hive/hive/-/merge_requests/244

We‚Äôve added support for building with boost 1.70 (tested on Ubuntu 18 and 20).

We also modified the fc library to enable a simplified logging syntax. For example, instead of:
`ilog(‚Äúmy variable=${my_variable}‚Äù,(‚Äúmy_variable‚Äù,my_variable));`
you can simply use:
`ilog(‚Äúmy variable=${my_variable}‚Äù,(my_variable));`
Note that the older syntax is still required when you need to call a function on the variable to get the value to log. The two syntaxes can be mixed-and-matched in a single log statement.

During our testing of the fix of the longstanding ‚Äúduplicate operations in account history‚Äù bug, we found that this problem could also arise when the value of the last irreversible block was ‚Äúundone‚Äù as part of the shutdown of hived (i.e. when a node operator presses Ctrl-C to shutdown the node). On a subsequent start, with the last irreversible block set to an earlier block, the code would re-add the operations from the already processed blocks. To fix this, we‚Äôre making sure the irreversible block number doesn‚Äôt get reverted by the database state undo operation anymore.

Once the above issue is fixed and tested in replay mode in conjunction with a full sync of hivemind, we‚Äôll be tagging a second release candidate for the testnet (probably Thursday or Friday). Barring any unexpected issues during testnet testing, I expect that this will be our last release candidate before the official release, based on testing results so far.

# Hivemind (2nd layer applications + social media middleware)

Last week we‚Äôve been making final fixes and doing performance tests in preparation for a new release of hivemind for API node operators later this week.

## Changing back to using pip for hivemind installation

We recently found that our current installation methodology for hivemind could lead to unexpected package versioning issues, so we‚Äôre switching back to using pip (python package installer) and pinning the versions of packages that hivemind uses.


## Performance testing and optimization for hivemind

While testing the develop branch of hivemind on our production API node (https://api.hive.blog), we noticed a slowdown in performance of the query `bridge_get_ranked_post_by_created_for_tag` (went from average of 64ms to nearly 2s average time). 

This problem was ultimately traced down to a lack of sufficient statistics being accumulated for the tags_ids column in the hive_posts table. The collected statistics weren‚Äôt sufficient to model the probability distribution of the tags used by posts, which resulted in the query planner selecting an under-performing query plan.

What‚Äôs interesting here is that this was a latent performance issue that could have potentially occurred on any given API node if it collected an unlucky statistical set (the problem wasn‚Äôt really a master vs develop branch issue). We fixed the issue by increasing the statistics collected for this column from 100 to 1000: 
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/503

## Hivemind memory consumption

We‚Äôre still researching potential ways to decrease the amount of memory consumed by the hivemind sync process over time. We‚Äôve reduced memory consumption some, but more looks possible.

## Postgres 13 vs Postgres 10 for hivemind

During our search for a possible solution to the above problem (before we realized increasing statistics was the best solution), we also tried updating our SQL database from postgres 10 with postgres 13, to see if it would select a better query plan. 

The database upgrade had no impact on the above problem, but we found another slowdown during hive sync (the indexer that adds data from the blockchain to the database) tied to postgres 13. This problem occurs because the postgres13 planner incorrectly estimates the costs of updating rshare totals during ‚Äòlive sync‚Äô and decides to do a just-in-time (jit) optimization which adds 100ms to the query time. 

We confirmed this was the issue by increasing the threshold cost required before the planner was allowed to employ jit optimization (effectively disabling jit usage in the query). In this scenario, performance was just slightly better for postgres 13 than for 10. Once we move to 13, we‚Äôll need to select a long term solution for this issue (either improve the cost estimation or just disable jit for this query), but that‚Äôs an issue for a later day.

## Functional testing and fixes for hivemind

While working on fixes to community-related API calls, we also improved mock testing capabilities to verify the changes (mock testing allows us to generate ‚Äúfake‚Äù data for testing purposes into an existing hivemind data set).
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/496

https://gitlab.syncad.com/hive/hivemind/-/merge_requests/499
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/501


# Modular hivemind (Application framework for Hive apps)

We‚Äôre currently building a sample application with the prototype for our modular hivemind framework that will support the account history API. Hopefully we‚Äôll be able to perform a full test of this sample application by sometime next week.

# Condenser wallet

We‚Äôve been doing some condenser wallet testing and bug fixing. We fixed a bug in the new feature by @quochuy that generates a CSV file with a user‚Äôs transaction history. The fix has been deployed to https://wallet.hive.blog.
https://gitlab.syncad.com/hive/wallet/-/merge_requests/106

# Testnet

We‚Äôve had a few brave souls do some testing with the testnet, but I‚Äôd like to see a lot more, especially from users supporting Hive API libraries and Hive-based apps. 

But everyone is welcome to play around on the testnet and try to break things. As a regular Hive user, you can login with your normal credentials via:
https://testblog.openhive.network (hive.blog-like testing site)
or
https://testnet.peakd.com/ (peakd-like testing site)

You can also browse the testnet with this block explorer: https://test.ausbit.dev/ 

Going forward, the testnet should be the preferred vehicle for initial testing of Hive apps. And testing new features now, before the hardfork, helps us to identify areas where we may want to make changes to API responses, etc, before there‚Äôs an ‚Äúofficial‚Äù API response that must then be changed later.

# Planned date for hardfork 25

I‚Äôm still projecting the hardfork will be in the last week of June.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/13th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/13th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;13th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by BlockTrades team during the last week or so: # Hived work (blockchain node software) We‚Äôre continuing to test and make fixes as a precursor to tagging a second release candidate for hived. We‚Äôve created a new python-based library currently called ‚Äútesttools‚Äù for creating test scenarios for hived and hived‚Äôs CLI wallet. We‚Äôre replacing the beempy library that was previously used for this purpose in order to accelerate the speed at which the tests execute. For now, the primary purpose for this python library is testing hived, but it may have more general applicability as a library for communicating with hived, in which case we will rename it later to something more appropriate: https://gitlab.syncad.com/hive/hive/-/merge_requests/242 We created some unit-test based stress tests for the new recurrent transfers functionality, and initially we found some surprising results in terms of memory usage, but ultimately this was traced to a misconfiguration of the hived instance (it was configured with the deprecated chainbase account history plugin which is known to consume too much memory). With that plugin replaced by the rocksdb-account-history plugin, memory consumption and general performance was fine. We also fixed some minor issues with the recurrent transfer operation: https://gitlab.syncad.com/hive/hive/-/merge_requests/246 We‚Äôve added a few new network API calls to hived for getting peer count, getting connected peers, adding peers, and setting allowed peers. These functions were primarily added to facilitate testing scenarios (e.g. testing forking logic), but they can be useful to node operators as well: https://gitlab.syncad.com/hive/hive/-/merge_requests/244 We‚Äôve added support for building with boost 1.70 (tested on Ubuntu 18 and 20). We also modified the fc library to enable a simplified logging syntax. For example, instead of: `ilog(‚Äúmy variable=${my_variable}‚Äù,(‚Äúmy_variable‚Äù,my_variable));` you can simply use: `ilog(‚Äúmy variable=${my_variable}‚Äù,(my_variable));` Note that the older syntax is still required when you need to call a function on the variable to get the value to log. The two syntaxes can be mixed-and-matched in a single log statement. During our testing of the fix of the longstanding ‚Äúduplicate operations in account history‚Äù bug, we found that this problem could also arise when the value of the last irreversible block was ‚Äúundone‚Äù as part of the shutdown of hived (i.e. when a node operator presses Ctrl-C to shutdown the node). On a subsequent start, with the last irreversible block set to an earlier block, the code would re-add the operations from the already processed blocks. To fix this, we‚Äôre making sure the irreversible block number doesn‚Äôt get reverted by the database state undo operation anymore. Once the above issue is fixed and tested in replay mode in conjunction with a full sync of hivemind, we‚Äôll be tagging a second release candidate for the testnet (probably Thursday or Friday). Barring any unexpected issues during testnet testing, I expect that this will be our last release candidate before the official release, based on testing results so far. # Hivemind (2nd layer applications + social media middleware) Last week we‚Äôve been making final fixes and doing performance tests in preparation for a new release of hivemind for API node operators later this week. ## Changing back to using pip for hivemind installation We recently found that our current installation methodology for hivemind could lead to unexpected package versioning issues, so we‚Äôre switching back to using pip (python package installer) and pinning the versions of packages that hivemind uses. ## Performance testing and optimization for hivemind While testing the develop branch of hivemind on our production API node (https://api.hive.blog), we noticed a slowdown in performance of the query `bridge_get_ranked_post_by_created_for_tag` (went from average of 64ms to nearly 2s average time). This problem was ultimately traced down to a lack of sufficient statistics being accumulated for the tags_ids column in the hive_posts table. The collected statistics weren‚Äôt sufficient to model the probability distribution of the tags used by posts, which resulted in the query planner selecting an under-performing query plan. What‚Äôs interesting here is that this was a latent performance issue that could have potentially occurred on any given API node if it collected an unlucky statistical set (the problem wasn‚Äôt really a master vs develop branch issue). We fixed the issue by increasing the statistics collected for this column from 100 to 1000: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/503 ## Hivemind memory consumption We‚Äôre still researching potential ways to decrease the amount of memory consumed by the hivemind sync process over time. We‚Äôve reduced memory consumption some, but more looks possible. ## Postgres 13 vs Postgres 10 for hivemind During our search for a possible solution to the above problem (before we realized increasing statistics was the best solution), we also tried updating our SQL database from postgres 10 with postgres 13, to see if it would select a better query plan. The database upgrade had no impact on the above problem, but we found another slowdown during hive sync (the indexer that adds data from the blockchain to the database) tied to postgres 13. This problem occurs because the postgres13 planner incorrectly estimates the costs of updating rshare totals during ‚Äòlive sync‚Äô and decides to do a just-in-time (jit) optimization which adds 100ms to the query time. We confirmed this was the issue by increasing the threshold cost required before the planner was allowed to employ jit optimization (effectively disabling jit usage in the query). In this scenario, performance was just slightly better for postgres 13 than for 10. Once we move to 13, we‚Äôll need to select a long term solution for this issue (either improve the cost estimation or just disable jit for this query), but that‚Äôs an issue for a later day. ## Functional testing and fixes for hivemind While working on fixes to community-related API calls, we also improved mock testing capabilities to verify the changes (mock testing allows us to generate ‚Äúfake‚Äù data for testing purposes into an existing hivemind data set). https://gitlab.syncad.com/hive/hivemind/-/merge_requests/496 https://gitlab.syncad.com/hive/hivemind/-/merge_requests/499 https://gitlab.syncad.com/hive/hivemind/-/merge_requests/501 # Modular hivemind (Application framework for Hive apps) We‚Äôre currently building a sample application with the prototype for our modular hivemind framework that will support the account history API. Hopefully we‚Äôll be able to perform a full test of this sample application by sometime next week. # Condenser wallet We‚Äôve been doing some condenser wallet testing and bug fixing. We fixed a bug in the new feature by @quochuy that generates a CSV file with a user‚Äôs transaction history. The fix has been deployed to https://wallet.hive.blog. https://gitlab.syncad.com/hive/wallet/-/merge_requests/106 # Testnet We‚Äôve had a few brave souls do some testing with the testnet, but I‚Äôd like to see a lot more, especially from users supporting Hive API libraries and Hive-based apps. But everyone is welcome to play around on the testnet and try to break things. As a regular Hive user, you can login with your normal credentials via: https://testblog.openhive.network (hive.blog-like testing site) or https://testnet.peakd.com/ (peakd-like testing site) You can also browse the testnet with this block explorer: https://test.ausbit.dev/ Going forward, the testnet should be the preferred vehicle for initial testing of Hive apps. And testing new features now, before the hardfork, helps us to identify areas where we may want to make changes to API responses, etc, before there‚Äôs an ‚Äúofficial‚Äù API response that must then be changed later. # Planned date for hardfork 25 I‚Äôm still projecting the hardfork will be in the last week of June. See: 13th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive core developer meeting #24</title><link href="https://hivedocs.info/news/core/development/2021/05/25/hive-core-developer-meeting-24.html" rel="alternate" type="text/html" title="Hive core developer meeting #24" /><published>2021-05-25T10:03:27-07:00</published><updated>2021-05-25T10:03:27-07:00</updated><id>https://hivedocs.info/news/core/development/2021/05/25/hive-core-developer-meeting-24</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/05/25/hive-core-developer-meeting-24.html">&lt;div id=&quot;content-howo-hive-core-developer-meeting-24&quot;&gt;https://www.youtube.com/watch?v=pxUvrI0pyPs

Hi, 

This meeting was very focused on the testnet and it's operation and what was needed, if you are reading this and are a dapp creator, please test your app against the new testnet, or even better create a testnet version of your app, this testnet will keep on running after testing is over and if you are missing a tool to deploy your app, please tell us which.

meeting tl;dr:

### Dev sync

you should listen to that part

### Dynamic RC costs

We discussed a few solutions we have in mind to make RC costs more in line with the actual cost of an operation on the chain

### vop for instant hbd conversion when transferring hive to the dhf

Not discussed, postponed to a later meeting.


### support for new consensus changes in related libraries, who's down to do it ?

I volunteered to do it in hive-js, we need to speak with other maintainers to see who will do what.

### How is the public testing going for the  account expiration due to lack of governance activity ?

We realized the expiration was set to 20 days which is too much time, so we will soon update the testnet with a new version that includes some fixes and lowers it.



### have front ends been updated to include notifications about account expiration or at least presenting the expiration date ?

So far, no.

### What about testing recurrent transfer/proposal update publicly ? Best by using 3rd party libraries wrapping direct blockchain operations

That has been tested on my own testnets, but not on that testnet, I'm gonna run some tests on it later this week 

### We did internally test creating max. number of recurrent transfers for 10% accounts: 120000*255. Results show dramatic memory allocation (under investigation). Changes are here:
https://gitlab.syncad.com/hive/hive/-/tree/km_operation_tests_recurrent

We talked a bunch on this, the expected memory consumption was 8gb but ended up being 40 gb, we are not sure what is causing it but it could be that it's the nature of the testing environment that caused it and it wouldn't be reproduced in the real world, we are still investigating that part.

### Anyone [outside of Blocktrades group] tested new HBD conversion operation ?

No

### Anyone [outside of Blocktrades group] tested/analyzed new author/curator rewarding ?

No

^ on these last discussion points, there are a bunch of discussions on the gitlab issue that you can read here: https://gitlab.syncad.com/hive/tasks_without_projects_yet/-/issues/39

Have a nice day

@howo&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@howo&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-core-developer-meeting-24&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-howo-hive-core-developer-meeting-24').html();
      const outputElem = $('#content-howo-hive-core-developer-meeting-24');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-howo-hive-core-developer-meeting-24 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-howo-hive-core-developer-meeting-24 code {
    background: white;
  }
  #content-howo-hive-core-developer-meeting-24 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-howo-hive-core-developer-meeting-24 a:hover {
    border-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-24 h1 {
    font-size: 2.2em;
  }
  #content-howo-hive-core-developer-meeting-24 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-24 header small {
    color: #999;
    font-size: 50%;
  }
  #content-howo-hive-core-developer-meeting-24 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/meeting/@howo/hive-core-developer-meeting-24&quot;&gt;Hive core developer meeting #24&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@howo&quot;&gt;@howo&lt;/a&gt;
&lt;/p&gt;</content><author><name>howo</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">https://www.youtube.com/watch?v=pxUvrI0pyPs Hi, This meeting was very focused on the testnet and it's operation and what was needed, if you are reading this and are a dapp creator, please test your app against the new testnet, or even better create a testnet version of your app, this testnet will keep on running after testing is over and if you are missing a tool to deploy your app, please tell us which. meeting tl;dr: ### Dev sync you should listen to that part ### Dynamic RC costs We discussed a few solutions we have in mind to make RC costs more in line with the actual cost of an operation on the chain ### vop for instant hbd conversion when transferring hive to the dhf Not discussed, postponed to a later meeting. ### support for new consensus changes in related libraries, who's down to do it ? I volunteered to do it in hive-js, we need to speak with other maintainers to see who will do what. ### How is the public testing going for the account expiration due to lack of governance activity ? We realized the expiration was set to 20 days which is too much time, so we will soon update the testnet with a new version that includes some fixes and lowers it. ### have front ends been updated to include notifications about account expiration or at least presenting the expiration date ? So far, no. ### What about testing recurrent transfer/proposal update publicly ? Best by using 3rd party libraries wrapping direct blockchain operations That has been tested on my own testnets, but not on that testnet, I'm gonna run some tests on it later this week ### We did internally test creating max. number of recurrent transfers for 10% accounts: 120000*255. Results show dramatic memory allocation (under investigation). Changes are here: https://gitlab.syncad.com/hive/hive/-/tree/km_operation_tests_recurrent We talked a bunch on this, the expected memory consumption was 8gb but ended up being 40 gb, we are not sure what is causing it but it could be that it's the nature of the testing environment that caused it and it wouldn't be reproduced in the real world, we are still investigating that part. ### Anyone [outside of Blocktrades group] tested new HBD conversion operation ? No ### Anyone [outside of Blocktrades group] tested/analyzed new author/curator rewarding ? No ^ on these last discussion points, there are a bunch of discussions on the gitlab issue that you can read here: https://gitlab.syncad.com/hive/tasks_without_projects_yet/-/issues/39 Have a nice day @howo See: Hive core developer meeting #24 by @howo</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">The HiveSQL documentation is now available</title><link href="https://hivedocs.info/news/sql/database/2021/05/25/hivesql-documentation.html" rel="alternate" type="text/html" title="The HiveSQL documentation is now available" /><published>2021-05-25T05:52:09-07:00</published><updated>2021-05-25T05:52:09-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/05/25/hivesql-documentation</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/05/25/hivesql-documentation.html">&lt;div id=&quot;content-arcange-hivesql-documentation&quot;&gt;![](https://i.imgur.com/rq7Ab3K.png)

Promises are made to be kept! HiveSQL's proposal mentioned the creation of documentation and tutorials. Here is finally the culmination of a long work that I undertook several weeks ago: the [HiveSQL documentation](https://docs.hivesql.io).

After many tests with different documentation solutions, my choice finally fell on gitbooks which, in my opinion, offer a lot of flexibility, both in terms of content editing and maintenance.

TL;DR: HiveSQL documentation can be found at **https://docs.hivesql.io**

### What's in it?

First, there is general information on 
* what is HiveSQL.
* how to access it.
* how to get support. 

Things that current HiveSQL users are already used to.

You will then find more technical information such as: 
* a [database diagram](https://docs.hivesql.io/technical-informations/database-diagram)
* an exhaustive list of all available tables
* a description for each table's column

Yes, you read it well: for all operations, virtual operations and state tables, each column of each table is described. This should interest many developers, even if they do not use Hiveql.

The documentation describes:
* [Operations](https://docs.hivesql.io/technical-informations/operations)
* [Virtual Operations](https://docs.hivesql.io/technical-informations/virtual-operations)
* [State tables](https://docs.hivesql.io/technical-informations/state-tables) like Accounts and Comments

It also describes how to use HiveSQL exclusive features like [Full-Text Search](https://docs.hivesql.io/technical-informations/full-text-search) and [Language Detection](https://docs.hivesql.io/technical-informations/language-detection).

The documentation also contains various tutorials for developers, notably PHP, Python, Ruby and even for Microsoft Excel users. More to come.

### Other Resources

I also searched the blockchain to find the various posts that have been written about HiveSQL. So I grouped the links to these different posts on a resource page to make it easier for you to find them. 

If you have made a post that deserves to appear there, do not hesitate to contact me as well.

### What's next?

There is still room to improve this documentation. I am thinking about examples of complex queries, more detailed information on the blockchain content and operations.

Some of the tutorials provided are quite rudimentary. I plan to improve them too. Do not hesitate to contact me if you want to add your contribution.

But I first wish to have your feedback on its current state before going further.

Feel free to use the HiveSQL [Discord](https://discord.gg/kyEFDfT) channel to report typos or make suggestions.

### One last word

Thank you to @inertia for the amazing work he did with the [Hive Developer Documentation](https://developers.hive.io) from which I borrowed a few sentences.

I truly believe that both documentations are complementary resources and that they will help everyone, developers and non-developers, to understand the content and organization of our blockchain.

The HiveSQL Documentation is available at **https://docs.hivesql.io**

---
#### &lt;center&gt; Support our proposals&lt;/center&gt;
|HiveSQL (to keep it free for all)|HiveBuzz (to keep it entertaining)|
|-|-|
|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/138)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/147)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/147)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22147%22%5D&amp;amp;approve=true)|

&lt;center&gt;
### Check out my apps and services
&lt;a href=&quot;/hive/@hive.engage/stay-connected-with-your-hive-audience-and-catch-attention&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GiNJqlm.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivebuzz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/B4UTun2.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivesql&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EPN8RW6.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/hive/@arcange/introducing-hive-account-recovery&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6TWeW7V.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hive.autoclaim&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ih2pEOw.png&quot; /&gt;&lt;/a&gt;&lt;/center&gt;
&lt;center&gt;

### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@arcange&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hivesql-documentation&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-arcange-hivesql-documentation').html();
      const outputElem = $('#content-arcange-hivesql-documentation');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-arcange-hivesql-documentation {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-arcange-hivesql-documentation code {
    background: white;
  }
  #content-arcange-hivesql-documentation a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-arcange-hivesql-documentation a:hover {
    border-bottom: 0;
  }
  #content-arcange-hivesql-documentation h1 {
    font-size: 2.2em;
  }
  #content-arcange-hivesql-documentation h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-arcange-hivesql-documentation header small {
    color: #999;
    font-size: 50%;
  }
  #content-arcange-hivesql-documentation img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@arcange/hivesql-documentation&quot;&gt;The HiveSQL documentation is now available&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@arcange&quot;&gt;@arcange&lt;/a&gt;
&lt;/p&gt;

&lt;/center&gt;&lt;/div&gt;</content><author><name>arcange</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![](https://i.imgur.com/rq7Ab3K.png) Promises are made to be kept! HiveSQL's proposal mentioned the creation of documentation and tutorials. Here is finally the culmination of a long work that I undertook several weeks ago: the [HiveSQL documentation](https://docs.hivesql.io). After many tests with different documentation solutions, my choice finally fell on gitbooks which, in my opinion, offer a lot of flexibility, both in terms of content editing and maintenance. TL;DR: HiveSQL documentation can be found at **https://docs.hivesql.io** ### What's in it? First, there is general information on * what is HiveSQL. * how to access it. * how to get support. Things that current HiveSQL users are already used to. You will then find more technical information such as: * a [database diagram](https://docs.hivesql.io/technical-informations/database-diagram) * an exhaustive list of all available tables * a description for each table's column Yes, you read it well: for all operations, virtual operations and state tables, each column of each table is described. This should interest many developers, even if they do not use Hiveql. The documentation describes: * [Operations](https://docs.hivesql.io/technical-informations/operations) * [Virtual Operations](https://docs.hivesql.io/technical-informations/virtual-operations) * [State tables](https://docs.hivesql.io/technical-informations/state-tables) like Accounts and Comments It also describes how to use HiveSQL exclusive features like [Full-Text Search](https://docs.hivesql.io/technical-informations/full-text-search) and [Language Detection](https://docs.hivesql.io/technical-informations/language-detection). The documentation also contains various tutorials for developers, notably PHP, Python, Ruby and even for Microsoft Excel users. More to come. ### Other Resources I also searched the blockchain to find the various posts that have been written about HiveSQL. So I grouped the links to these different posts on a resource page to make it easier for you to find them. If you have made a post that deserves to appear there, do not hesitate to contact me as well. ### What's next? There is still room to improve this documentation. I am thinking about examples of complex queries, more detailed information on the blockchain content and operations. Some of the tutorials provided are quite rudimentary. I plan to improve them too. Do not hesitate to contact me if you want to add your contribution. But I first wish to have your feedback on its current state before going further. Feel free to use the HiveSQL [Discord](https://discord.gg/kyEFDfT) channel to report typos or make suggestions. ### One last word Thank you to @inertia for the amazing work he did with the [Hive Developer Documentation](https://developers.hive.io) from which I borrowed a few sentences. I truly believe that both documentations are complementary resources and that they will help everyone, developers and non-developers, to understand the content and organization of our blockchain. The HiveSQL Documentation is available at **https://docs.hivesql.io** --- #### Support our proposals |HiveSQL (to keep it free for all)|HiveBuzz (to keep it entertaining)| |-|-| |[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)[Vote for the proposal on Ecency](https://ecency.com/proposals/138)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/147)[Vote for the proposal on Ecency](https://ecency.com/proposals/147)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22147%22%5D&amp;amp;approve=true)| ### Check out my apps and services ### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt; See: The HiveSQL documentation is now available by @arcange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/rq7Ab3K.png" /><media:content medium="image" url="https://i.imgur.com/rq7Ab3K.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">12th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/sql/database/2021/05/17/12th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="12th update of 2021 on BlockTrades work on Hive software" /><published>2021-05-17T16:04:24-07:00</published><updated>2021-05-17T16:04:24-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/05/17/12th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/05/17/12th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by the BlockTrades team during the last week:

# Hived work (blockchain node software)

This week we‚Äôve been testing the first release candidate for hardfork 25.  In addition to manual testing of node operation, we're also writing a few more tests to test consensus changes under stress conditions.

Although we haven‚Äôt found any bugs in the new consensus changes yet, we have made several fixes to long-standing bugs that we found as part of our manual node testing. Most of the bugs are related to startup issues and confusing log messages that might mislead a node operator:

* We fixed an error message that erroneously reported that a peer node was on an irreversible fork when it most likely was just ahead of the user‚Äôs node.
* We fixed a long-standing error that could cause a crash at startup if a node started receiving API requests before the node had fully initialized.
* hived now reports the peer count in warning messages when the blockchain thread is warning that it hasn‚Äôt received any transactions or blocks from the P2P thread in the last 30 seconds.
* Hived now delays connecting to seed nodes until the P2P network is initialized and ready to process peer requests. This prevent seed nodes from disconnecting because the user's node doesn't respond to them in a timely manner.
* ulog messages are now logged to stderr (console) for the node. Ulog messages are used by the P2P thread to report important issues that should be seen by node operators. In particular, the user now receives a console warning when the node startup is delayed while the P2P thread is trying to get access to the P2P port from the operating system (when a node is shutdown via Ctrl-C, the OS may take up to 1 minute to release the port, delaying recapture of the port when the node is restarted).

We‚Äôve also updated hived nodes to begin reporting the Hive chainid of BEEABODE at startup (as a temporary measure, the node used to report a chainid of 0 at startup, then swap to reporting BEEABODE after they hit the genesis fork for Hive). 

For the initial release of hardfork 25, hived nodes will still continue to allow connections from nodes with chainid of 0, despite reporting the new chainid, but after all Hive nodes have updated to the hardfork 25 code, we‚Äôll change the code to reject connections from older nodes.

## Second release candidate for hived soon

We‚Äôll likely be publishing a second release candidate of hived in the next couple of days that contains the diagnostics and fixes discussed above (those changes have already been merged into the develop branch, so you can get them now for testing), plus one or two more small improvements that are still pending review.

# Hivemind (2nd layer applications + social media middleware)

We‚Äôre continuing to work on a few hivemind tests, running performance tests, and preparing database migration scripts in preparation for a new hivemind release (should be sometime this week).

# Modular hivemind (framework for hive applications)

We still didn‚Äôt have time to make the changes for the sql serializer last week due to the time spent fixing the various issues discussed in this post, but we will likely? complete that work in the coming week. Then we‚Äôll be able to do a full performance test of the sql serializer in combination with a full sync of hivemind.

In the meantime, we‚Äôre doing preparatory work to create an example modular hivemind-based application that just supports the account history API.

# Condenser (code base for https://hive.blog)

We‚Äôre testing condenser code against the testnet. We had some problems with condenser being able to broadcast transactions to the testnest which were ultimately traced to condenser using an older version of the hive-js package. It‚Äôs being updated currently and testing will continue. The same change will also be applied to the condenser wallet.

# Hived testnet

We launched and began testing the new public testnet based on release candidate 1. 

We‚Äôve also setup an API node configured to draw data from the testnet. This API node should be used by Hive applications to begin adding code changes to support new features added by the hardfork, such as vote expiration reporting.

If you want to add a node to the public testnet, use this seednode:
`p2p-seed-node = testnet.openhive.network:2001`

To use the API node for the testnet:

API endpoint via jussi:¬† https://testnet.openhive.network
hived direct http server: ¬†http://testnet.openhive.network:8091
hived direct websocket server:  ws://testnet.openhive.network:8090
hivemind server direct server: ¬†http://testnet.openhive.network:8080 

As mentioned previously, we‚Äôve begun testing this testnet API node with condenser. You can visit it here: https://testblog.openhive.network 

 We will also setup a block explorer and a condenser-based wallet for the testnet soon.
Update: @ausbitbank added block explorer for testnet https://test.ausbit.dev/

We plan to leave this testnet running as a permanent testnet that apps can use to test against prior to making changes to their app operating on the mainnet. So Hive app devs are strongly urged to take advantage of this opportunity. As a side note, when doing so, please make sure to use the latest version of hive-js to make sure it's compatible with the testnet API node. We've also tested beempy successfully against the testnet API node.

# Planned date for hardfork 25

I‚Äôm still projecting the hardfork will be in the latter part of June, probably in the last week.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/12th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/12th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;12th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by the BlockTrades team during the last week: # Hived work (blockchain node software) This week we‚Äôve been testing the first release candidate for hardfork 25. In addition to manual testing of node operation, we're also writing a few more tests to test consensus changes under stress conditions. Although we haven‚Äôt found any bugs in the new consensus changes yet, we have made several fixes to long-standing bugs that we found as part of our manual node testing. Most of the bugs are related to startup issues and confusing log messages that might mislead a node operator: * We fixed an error message that erroneously reported that a peer node was on an irreversible fork when it most likely was just ahead of the user‚Äôs node. * We fixed a long-standing error that could cause a crash at startup if a node started receiving API requests before the node had fully initialized. * hived now reports the peer count in warning messages when the blockchain thread is warning that it hasn‚Äôt received any transactions or blocks from the P2P thread in the last 30 seconds. * Hived now delays connecting to seed nodes until the P2P network is initialized and ready to process peer requests. This prevent seed nodes from disconnecting because the user's node doesn't respond to them in a timely manner. * ulog messages are now logged to stderr (console) for the node. Ulog messages are used by the P2P thread to report important issues that should be seen by node operators. In particular, the user now receives a console warning when the node startup is delayed while the P2P thread is trying to get access to the P2P port from the operating system (when a node is shutdown via Ctrl-C, the OS may take up to 1 minute to release the port, delaying recapture of the port when the node is restarted). We‚Äôve also updated hived nodes to begin reporting the Hive chainid of BEEABODE at startup (as a temporary measure, the node used to report a chainid of 0 at startup, then swap to reporting BEEABODE after they hit the genesis fork for Hive). For the initial release of hardfork 25, hived nodes will still continue to allow connections from nodes with chainid of 0, despite reporting the new chainid, but after all Hive nodes have updated to the hardfork 25 code, we‚Äôll change the code to reject connections from older nodes. ## Second release candidate for hived soon We‚Äôll likely be publishing a second release candidate of hived in the next couple of days that contains the diagnostics and fixes discussed above (those changes have already been merged into the develop branch, so you can get them now for testing), plus one or two more small improvements that are still pending review. # Hivemind (2nd layer applications + social media middleware) We‚Äôre continuing to work on a few hivemind tests, running performance tests, and preparing database migration scripts in preparation for a new hivemind release (should be sometime this week). # Modular hivemind (framework for hive applications) We still didn‚Äôt have time to make the changes for the sql serializer last week due to the time spent fixing the various issues discussed in this post, but we will likely? complete that work in the coming week. Then we‚Äôll be able to do a full performance test of the sql serializer in combination with a full sync of hivemind. In the meantime, we‚Äôre doing preparatory work to create an example modular hivemind-based application that just supports the account history API. # Condenser (code base for https://hive.blog) We‚Äôre testing condenser code against the testnet. We had some problems with condenser being able to broadcast transactions to the testnest which were ultimately traced to condenser using an older version of the hive-js package. It‚Äôs being updated currently and testing will continue. The same change will also be applied to the condenser wallet. # Hived testnet We launched and began testing the new public testnet based on release candidate 1. We‚Äôve also setup an API node configured to draw data from the testnet. This API node should be used by Hive applications to begin adding code changes to support new features added by the hardfork, such as vote expiration reporting. If you want to add a node to the public testnet, use this seednode: `p2p-seed-node = testnet.openhive.network:2001` To use the API node for the testnet: API endpoint via jussi:¬† https://testnet.openhive.network hived direct http server: ¬†http://testnet.openhive.network:8091 hived direct websocket server: ws://testnet.openhive.network:8090 hivemind server direct server: ¬†http://testnet.openhive.network:8080 As mentioned previously, we‚Äôve begun testing this testnet API node with condenser. You can visit it here: https://testblog.openhive.network We will also setup a block explorer and a condenser-based wallet for the testnet soon. Update: @ausbitbank added block explorer for testnet https://test.ausbit.dev/ We plan to leave this testnet running as a permanent testnet that apps can use to test against prior to making changes to their app operating on the mainnet. So Hive app devs are strongly urged to take advantage of this opportunity. As a side note, when doing so, please make sure to use the latest version of hive-js to make sure it's compatible with the testnet API node. We've also tested beempy successfully against the testnet API node. # Planned date for hardfork 25 I‚Äôm still projecting the hardfork will be in the latter part of June, probably in the last week. See: 12th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">HiveSQL Upate - New Virtual Operation tables</title><link href="https://hivedocs.info/news/sql/database/2021/05/17/hivesql-upate-20210517.html" rel="alternate" type="text/html" title="HiveSQL Upate - New Virtual Operation tables" /><published>2021-05-17T07:53:39-07:00</published><updated>2021-05-17T07:53:39-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/05/17/hivesql-upate-20210517</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/05/17/hivesql-upate-20210517.html">&lt;div id=&quot;content-arcange-hivesql-upate-20210517&quot;&gt;![](https://i.imgur.com/FE9D32t.png)

I am finalizing a consequent work I started weeks ago to create the HiveSQL documentation, which should be available soon. While performing this job, I realized that the database was missing a few Virtual Operations tables. Therefore, I hastened to add them so that the database content is as complete as possible.

### What new?

Two new tables are now available:
 
**VOClearNullAccountBalances**

This table contains virtual operations created by the blockchain when the @null account balances need to be zeroed.

|Column|Description|
|-|-|
|total_cleared|a JSON array with the assets that have been burned|

**VOSPSConverts**

This table contains virtual operations issued when a Proposals Fund (DHF) conversion from HIVE to HBD occurs.

|Column|Description|
|-|-|
|fund_account|DHF account|
|hive_amount_in|amount of HIVE burned|
|hbd_amount_out|amount of HBD created|

**VODelayedVotings**

This table contains virtual operations issued when newly powered up VESTS (Hive Power) become counted towards witnesses and DHF proposals votes (after a 30 days delay is complete - HF24).

|Column|Description|
|-|-|
|voter|account who performed a power-up and whose votes will be impacted|
|votes|amount of additional VESTS to take into account for votes|

### What else?

**&lt;div class=&quot;phishy&quot;&gt;I made a major change&lt;/div&gt;** to the `TxCustoms` table which contains all the `custom_json` operation broadcasted to the blockchain.

Its `json_metadata` column has been renamed to `json` to match the blockchain field name (and because it does not contain &quot;metadata&quot;).

However, in order not to break (d)Apps and processes that currently use `json_metadata`, **the two column [names] will stay available for another month**. This will give applications ample time to adapt. After that, `json_metadata` will be permanently removed.


## Support

If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT).

Thank you for reading.

---
**Let's keep HiveSQL free to use - Support its proposals**!
|HiveSQL|HiveBuzz|
|-|-|
|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/138)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/147)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/147)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22147%22%5D&amp;amp;approve=true)|

---
&lt;center&gt;

### Check out my apps and services
&lt;a href=&quot;/hive/@hive.engage/stay-connected-with-your-hive-audience-and-catch-attention&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GiNJqlm.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivebuzz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/B4UTun2.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivesql&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EPN8RW6.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/hive/@arcange/introducing-hive-account-recovery&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6TWeW7V.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hive.autoclaim&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ih2pEOw.png&quot; /&gt;&lt;/a&gt;&lt;/center&gt;
&lt;center&gt;

### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)
&lt;/center&gt;&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@arcange&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hivesql-upate-20210517&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-arcange-hivesql-upate-20210517').html();
      const outputElem = $('#content-arcange-hivesql-upate-20210517');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-arcange-hivesql-upate-20210517 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-arcange-hivesql-upate-20210517 code {
    background: white;
  }
  #content-arcange-hivesql-upate-20210517 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-arcange-hivesql-upate-20210517 a:hover {
    border-bottom: 0;
  }
  #content-arcange-hivesql-upate-20210517 h1 {
    font-size: 2.2em;
  }
  #content-arcange-hivesql-upate-20210517 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-arcange-hivesql-upate-20210517 header small {
    color: #999;
    font-size: 50%;
  }
  #content-arcange-hivesql-upate-20210517 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@arcange/hivesql-upate-20210517&quot;&gt;HiveSQL Upate - New Virtual Operation tables&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@arcange&quot;&gt;@arcange&lt;/a&gt;
&lt;/p&gt;</content><author><name>arcange</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![](https://i.imgur.com/FE9D32t.png) I am finalizing a consequent work I started weeks ago to create the HiveSQL documentation, which should be available soon. While performing this job, I realized that the database was missing a few Virtual Operations tables. Therefore, I hastened to add them so that the database content is as complete as possible. ### What new? Two new tables are now available: **VOClearNullAccountBalances** This table contains virtual operations created by the blockchain when the @null account balances need to be zeroed. |Column|Description| |-|-| |total_cleared|a JSON array with the assets that have been burned| **VOSPSConverts** This table contains virtual operations issued when a Proposals Fund (DHF) conversion from HIVE to HBD occurs. |Column|Description| |-|-| |fund_account|DHF account| |hive_amount_in|amount of HIVE burned| |hbd_amount_out|amount of HBD created| **VODelayedVotings** This table contains virtual operations issued when newly powered up VESTS (Hive Power) become counted towards witnesses and DHF proposals votes (after a 30 days delay is complete - HF24). |Column|Description| |-|-| |voter|account who performed a power-up and whose votes will be impacted| |votes|amount of additional VESTS to take into account for votes| ### What else? **I made a major change** to the `TxCustoms` table which contains all the `custom_json` operation broadcasted to the blockchain. Its `json_metadata` column has been renamed to `json` to match the blockchain field name (and because it does not contain &quot;metadata&quot;). However, in order not to break (d)Apps and processes that currently use `json_metadata`, **the two column [names] will stay available for another month**. This will give applications ample time to adapt. After that, `json_metadata` will be permanently removed. ## Support If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT). Thank you for reading. --- **Let's keep HiveSQL free to use - Support its proposals**! |HiveSQL|HiveBuzz| |-|-| |[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)[Vote for the proposal on Ecency](https://ecency.com/proposals/138)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/147)[Vote for the proposal on Ecency](https://ecency.com/proposals/147)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22147%22%5D&amp;amp;approve=true)| --- ### Check out my apps and services ### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1) See: HiveSQL Upate - New Virtual Operation tables by @arcange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/FE9D32t.png" /><media:content medium="image" url="https://i.imgur.com/FE9D32t.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Making a Decentralized Game on Hive - Last part</title><link href="https://hivedocs.info/howto/nodejs/2021/05/14/making-a-decentralized-game-on-hive-last-part.html" rel="alternate" type="text/html" title="Making a Decentralized Game on Hive - Last part" /><published>2021-05-14T15:17:36-07:00</published><updated>2021-05-14T15:17:36-07:00</updated><id>https://hivedocs.info/howto/nodejs/2021/05/14/making-a-decentralized-game-on-hive-last-part</id><content type="html" xml:base="https://hivedocs.info/howto/nodejs/2021/05/14/making-a-decentralized-game-on-hive-last-part.html">&lt;div id=&quot;content-mahdiyari-making-a-decentralized-game-on-hive-last-part&quot;&gt;&lt;center&gt;![desktop-pixabay.jpg](https://images.hive.blog/DQmah3PBKL6JDe3omk8wi2RFp3Lk2X8BZgb3FUpnkRTsfap/desktop-1245714_1280.jpg)&lt;/center&gt;
First of all, thank you for following me and making these posts available for a bigger audience by sharing them.

This post took too long but finally, it's done. I think I could make 5 posts with the content of just this yet-to-be-written post. I will make it short as possible. I was going to make a few excuses for taking it too long but TBH I could deliver it maybe 2 weeks earlier if I worked on it. Lazy me is for the blame.

The game itself is not important for me, the important part was writing these posts to show how easy it is to make true decentralized applications and games. Of course, it's not for everybody. But now we have something to share with other developers who want to start a game or app. It's not perfect but it's something.

Anyway, it's online and it's fully functional. You can try it with a friend on [https://tic-tac-toe.mahdiyari.info/](https://tic-tac-toe.mahdiyari.info/). Create a game and the other user can join it. Then the game should start. There is no time limit on the game.

Link to the GitLab repository and the previous posts are at the end of the post. Maybe you can try running your instance of the game for the experiment! It will start syncing blocks and become identical to the official website.

Now moving to the development side of things. I won't drop all the codes here because it's massive. All the codes are almost 2,000 lines. I will only explain the parts that seem necessary.
***
#### Development
We can use pm2 to launch our application. So let's make a config file for it.
`ecosystem.config.js`
```
module.exports = {
  apps: [
    {
      name: 'app-tictactoe',
      script: 'index.js',
      instances: 1,
      max_memory_restart: '1G',
      exec_mode: 'fork'
    },
    {
      name: 'api-tictactoe',
      script: 'api/server.js',
      instances: 2,
      max_memory_restart: '1G',
      exec_mode: 'cluster'
    }
  ]
}
```
This will launch the API in a cluster mode with 2 instances for better handling of the traffic. You can increase the number of instances up to the number of your CPU threads. **ONLY** the API. We can't run the main application in a cluster mode and it's not necessary at all. We set both scripts to use a maximum of 1GB RAM but in reality, both will use less than 40mb. It's just to be safe.

I added the necessary scripts in the `package.json` for running the application.
```
&quot;scripts&quot;: {
    &quot;test&quot;: &quot;echo \&quot;Error: no test specified\&quot; &amp;amp;&amp;amp; exit 1&quot;,
    &quot;start&quot;: &quot;pm2 start ecosystem.config.js&quot;,
    &quot;stop&quot;: &quot;pm2 delete ecosystem.config.js&quot;,
    &quot;restart&quot;: &quot;pm2 restart ecosystem.config.js&quot;,
    &quot;reload&quot;: &quot;pm2 reload ecosystem.config.js&quot;,
    &quot;logs&quot;: &quot;pm2 logs&quot;
  }
```
For example, for starting the app I can type `npm run start` and `npm run logs` for logs and so on. It will use the installed `pm2` with the app itself.
***
For the ability to sync blocks in a row one by one, we use a queue. I call this implementation `rapidQueue`. It's in pure JS and is faster than the other methods. You can check it out [on GitLab](https://gitlab.com/mahdiyari/decentralized-game-on-hive/-/blob/master/back-end/helpers/rapidQueue.js).

I set the genesis block of our game to `53,886,076` just because it was the head block at the time of launch. Every time a fresh instance of the game is installed, it will go through all the blocks one by one from the genesis block until the current head block and continue listening for the future blocks.

So here it is our syncing method:
`index.js`
```
const start = async () =&amp;gt; {
  try {
    await initDatabase()
    stream.streamBlockNumber(async blockNum =&amp;gt; {
      if (!blockNum) {
        return
      }
      if (firstRun) {
        firstRun = false
        await queueOldBlocks(blockNum)
      }
      queue.push(blockNum)
    })
    processQueue()
  } catch (e) {
    throw new Error(e)
  }
}
```
First, initializes database then puts into the queue not synced blocks, then puts the newly generated blocks into the back of the queue. Then call another function that will check the queue at an interval.

The code below is responsible for putting not synced blocks into the queue.
```
const queueOldBlocks = async nowBlock =&amp;gt; {
  let oldestBlock
  const latestBlock = await mysql.query(
    'SELECT `block_number` FROM `lastblock` WHERE `id`=1'
  )
  if (latestBlock[0].block_number === 0) {
    oldestBlock = genesisBlock
  } else {
    oldestBlock = latestBlock[0].block_number
  }
  if (oldestBlock &amp;lt; nowBlock) {
    for (let i = oldestBlock; i &amp;lt; nowBlock; i++) {
      queue.push(i)
    }
  }
}
```
The following code is the part that takes block numbers one by one out of the queue. It runs every 5ms to check if the current block is processed or not. If yes, goes to the next block in the queue. `queueIndex` is the counter of the currently running `processBlock()`s. Which will be a maximum of 1.
```
const intervalTime = 5
const maxI = 1
let queueIndex = 0
const processQueue = () =&amp;gt; {
  setInterval(() =&amp;gt; {
    const L = queue.length()
    if (queueIndex &amp;lt; maxI &amp;amp;&amp;amp; L &amp;gt; 0) {
      const n = maxI - queueIndex &amp;gt; L ? L : maxI - queueIndex
      for (let k = 0; k &amp;lt; n; k++) {
        const blockNum = queue.shift()
        processBlock(blockNum)
      }
    }
  }, intervalTime)
}
```
You can see the counter in action:
```
const processBlock = async blockNum =&amp;gt; {
  if (!blockNum) {
    return
  }
  queueIndex++
  try {
    const operations = await stream.getOperations(blockNum)
    if (operations &amp;amp;&amp;amp; operations.length &amp;gt; 0) {
      for (const ops of operations) {
        for (const op of ops) {
          if (op &amp;amp;&amp;amp; op[0] === 'custom_json' &amp;amp;&amp;amp; op[1].id === 'tictactoe') {
            await processData(op[1].json, op[1].required_posting_auths)
          }
        }
      }
    }
    await updateLastblock(blockNum)
    totalSyncedBlocks++
  } catch (e) {}
  queueIndex--
}
```
***
The heart of the game is the `play` function. It determines the finished games and winners. It is triggered when a player plays a move.
```
const play = async (data, user) =&amp;gt; {
  if (
    !data ||
    !data.id ||
    !data.col ||
    !data.row ||
    isNaN(data.col) ||
    isNaN(data.row) ||
    data.id.length !== 20 ||
    data.col &amp;lt; 1 ||
    data.col &amp;gt; 3 ||
    data.row &amp;lt; 1 ||
    data.row &amp;gt; 3
  ) {
    return
  }
  // Validate game in database
  const game = await mysql.query(
    'SELECT `player1`, `player2`, `starting_player` FROM `games` WHERE `game_id`= ? AND `status`= ? AND (player1=? OR player2=?)',
    [data.id, 'running', user, user]
  )
  if (!game || !Array.isArray(game) || game.length &amp;lt; 1) {
    return
  }
  // Validate the player round
  let round = ''
  const computedMoves = new Array(9)
  const moves = await mysql.query(
    'SELECT `player`, `col`, `row` FROM `moves` WHERE `game_id`= ? ORDER BY `id` ASC',
    [data.id]
  )
  if (!moves || !Array.isArray(moves) || moves.length &amp;lt; 1) {
    round = game[0].starting_player
  } else {
    if (moves[moves.length - 1].player === game[0].player1) {
      round = 'second'
    } else {
      round = 'first'
    }
  }
  if (moves.length &amp;gt; 8) {
    return
  }
  if (round === 'first' &amp;amp;&amp;amp; game[0].player2 === user) {
    return
  }
  if (round === 'second' &amp;amp;&amp;amp; game[0].player1 === user) {
    return
  }
  // Play game and check winner
  await mysql.query(
    'INSERT INTO `moves`(`game_id`, `player`, `col`, `row`) VALUES (?,?,?,?)',
    [data.id, user, data.col, data.row]
  )
  moves.push({ player: user, col: data.col, row: data.row })
  for (let i = 0; i &amp;lt; moves.length; i++) {
    const move = moves[i]
    let mark
    if (move.player === game[0].player1) {
      mark = 'x'
    } else if (move.player === game[0].player2) {
      mark = 'o'
    } else {
      continue
    }
    if (move.row === 1) {
      computedMoves[move.col - 1] = mark
    } else if (move.row === 2) {
      computedMoves[move.col + 2] = mark
    } else if (move.row === 3) {
      computedMoves[move.col + 5] = mark
    }
  }
  checkWinner(computedMoves, data.id)
}
```
The `play` function validates the data, then places the played move, then checks for the game status for a possible winner or draw.
The `checkWinner` function:
```
const checkWinner = async (computedMoves, id) =&amp;gt; {
  if (checkWinningMark(computedMoves, 'x')) {
    await mysql.query(
      'UPDATE `games` SET `status`=?, `winner`=? WHERE `game_id`=?',
      ['finished', 'player1', id]
    )
  } else if (checkWinningMark(computedMoves, 'o')) {
    await mysql.query(
      'UPDATE `games` SET `status`=?, `winner`=? WHERE `game_id`=?',
      ['finished', 'player2', id]
    )
  } else {
    for (let i = 0; i &amp;lt; 9; i++) {
      if (!computedMoves[i]) {
        return
      }
    }
    await mysql.query(
      'UPDATE `games` SET `status`=?, `winner`=? WHERE `game_id`=?',
      ['finished', 'none', id]
    )
  }
}
```
It checks for the winning of player1 or &quot;X&quot; and then player2 or &quot;O&quot; then checks for the filled board for a draw. Then the database is updated.
`checkWinningMark()` is not interesting. It just checks each row and col for a winning pattern for the provided mark. X or O.
***
At the end of the file, we call the `start()` method to start the application. Then inform the user current state of sync.
```
start()
console.log('Tic Tac Toe Application')
console.log(
  'Starting application... It is highly recommended to use a local node for syncing blocks otherwise it might take too long.'
)
const interval = setInterval(() =&amp;gt; {
  if (queue.length() &amp;lt; 2) {
    clearInterval(interval)
    console.log('Sync completed. Application is running.')
  } else {
    console.log('Syncing blocks... Total synced blocks: ' + totalSyncedBlocks)
  }
}, 5000)
```
With a local node, it syncs ~70 blocks per second (depends on many things). It can be boosted in certain ways but it's not necessary for this project. 70 blocks/s is still impressive enough. It all depends on the latency of the connected RPC node because the syncing is done by selecting blocks in a row one by one and waiting for the one to finish before going to the next one.
***
### Client-side
There are many things on the client-side. I'm not going near front-end codes. You can always check the full code on the [GitLab repository](https://gitlab.com/mahdiyari/decentralized-game-on-hive).

Our game board is designed with Canvas. I don't think it's necessary to talk about those codes.

Here is the function for broadcasting a move.
`js/app.js`
```
const submitMove = async () =&amp;gt; {
  if (!userData.authorized) {
    document.getElementById('login-button').click()
    return
  }
  if (!userMove || userMove.length &amp;lt; 2) {
    return
  }
  if (!urlParams.has('id')) {
    return
  }
  const error = document.getElementById('submit-move-error')
  error.innerHTML = ''
  loading(true)
  const id = urlParams.get('id')
  try {
    const play = {
      app: 'tictactoe/0.0.1',
      action: 'play',
      id,
      col: userMove[0],
      row: userMove[1]
    }
    const operations = [
      [
        'custom_json',
        {
          required_auths: [],
          required_posting_auths: [userData.username],
          id: 'tictactoe',
          json: JSON.stringify(play)
        }
      ]
    ]
    const tx = new hiveTx.Transaction()
    await tx.create(operations)
    const privateKey = hiveTx.PrivateKey.from(userData.key)
    tx.sign(privateKey)
    const result = await tx.broadcastNoResult()
    if (result &amp;amp;&amp;amp; result.result &amp;amp;&amp;amp; result.result.tx_id) {
      setTimeout(() =&amp;gt; getGameDetails(urlParams.get('id')), 1500)
      oldRound = round
      round = round === 'first' ? 'second' : 'first'
      toggleMoveInteractions('player-waiting')
    } else {
      error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J'
      console.error(result)
    }
  } catch (e) {
    error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J'
    console.error(e)
  }
  loading(false)
}
```
It creates a transaction with custom_json and uses `.broadcastNoResult()` method of `hiveTx` library for the fastest possible transaction broadcast. This method doesn't return the result of the transaction (but it returns the offline generated tx_id so it's possible to check for the status of the transaction later but we don't) so it may as well fail for many reasons but we assume everything is fine. In this way, the user experience is better and smoother. Because the action goes faster.
***
On the game page, the application gets the game details every 5s from the API and updates the user interface. Then calls the following function to update the board with new moves and also detects the round of play.
```
const computeMoves = () =&amp;gt; {
  if (!movesData || !gameData) {
    setTimeout(() =&amp;gt; computeMoves(), 100)
    return
  }
  clearMoves()
  for (let i = 0; i &amp;lt; movesData.length; i++) {
    const move = movesData[i]
    let mark
    if (move.player === gameData.player1) {
      mark = 'x'
    } else if (move.player === gameData.player2) {
      mark = 'o'
    } else {
      continue
    }
    placeMark(move.col, move.row, mark)
  }
  placeMark(userMove[0], userMove[1], userMove[2])
  if (movesData.length &amp;lt; 1) {
    round = gameData.starting_player
  } else if (movesData[movesData.length - 1].player === gameData.player1) {
    round = 'second'
  } else {
    round = 'first'
  }
}
```
There are many other front-end and back-end stuff which I skip the explanation because it's not a post about teaching development in any sense. I just explained the things I thought might be necessary for running the Hive applications.
***
&lt;center&gt;![town-sign-1158387_640.jpg](https://images.hive.blog/DQmW97Q9q5wLbZ9chrtsRMGvMcHZvoYVXLfsBj4G21UthyY/town-sign-1158387_640.jpg)&lt;/center&gt;

It's 2:30 AM and I'm not sure if I missed something. I hope you accept my attempt at making this tutorial. I have another project in mind so make sure to follow me.

Thank you again. Your votes, reblogs, and witness votes are much appreciated. I hope you like what I do.

&lt;sub&gt;images source: pixabay.com&lt;/sub&gt;
&lt;sub&gt;All the codes used in this project are original. Except the `rapidQueue` method (MIT license).&lt;/sub&gt;
***
The final project:
https://tic-tac-toe.mahdiyari.info/
https://gitlab.com/mahdiyari/decentralized-game-on-hive
***
Previous posts:
[part1](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-tic-tac-toe-part-1)
[part2](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-2)
[part3](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-3)
[part4](https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-4)
[part5](https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-5)&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@mahdiyari&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/making-a-decentralized-game-on-hive-last-part&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-mahdiyari-making-a-decentralized-game-on-hive-last-part').html();
      const outputElem = $('#content-mahdiyari-making-a-decentralized-game-on-hive-last-part');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part code {
    background: white;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part a:hover {
    border-bottom: 0;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part h1 {
    font-size: 2.2em;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part header small {
    color: #999;
    font-size: 50%;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-last-part&quot;&gt;Making a Decentralized Game on Hive - Last part&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@mahdiyari&quot;&gt;@mahdiyari&lt;/a&gt;
&lt;/p&gt;</content><author><name>mahdiyari</name></author><category term="howto" /><category term="nodejs" /><summary type="html">![desktop-pixabay.jpg](https://images.hive.blog/DQmah3PBKL6JDe3omk8wi2RFp3Lk2X8BZgb3FUpnkRTsfap/desktop-1245714_1280.jpg) First of all, thank you for following me and making these posts available for a bigger audience by sharing them. This post took too long but finally, it's done. I think I could make 5 posts with the content of just this yet-to-be-written post. I will make it short as possible. I was going to make a few excuses for taking it too long but TBH I could deliver it maybe 2 weeks earlier if I worked on it. Lazy me is for the blame. The game itself is not important for me, the important part was writing these posts to show how easy it is to make true decentralized applications and games. Of course, it's not for everybody. But now we have something to share with other developers who want to start a game or app. It's not perfect but it's something. Anyway, it's online and it's fully functional. You can try it with a friend on [https://tic-tac-toe.mahdiyari.info/](https://tic-tac-toe.mahdiyari.info/). Create a game and the other user can join it. Then the game should start. There is no time limit on the game. Link to the GitLab repository and the previous posts are at the end of the post. Maybe you can try running your instance of the game for the experiment! It will start syncing blocks and become identical to the official website. Now moving to the development side of things. I won't drop all the codes here because it's massive. All the codes are almost 2,000 lines. I will only explain the parts that seem necessary. *** #### Development We can use pm2 to launch our application. So let's make a config file for it. `ecosystem.config.js` ``` module.exports = { apps: [ { name: 'app-tictactoe', script: 'index.js', instances: 1, max_memory_restart: '1G', exec_mode: 'fork' }, { name: 'api-tictactoe', script: 'api/server.js', instances: 2, max_memory_restart: '1G', exec_mode: 'cluster' } ] } ``` This will launch the API in a cluster mode with 2 instances for better handling of the traffic. You can increase the number of instances up to the number of your CPU threads. **ONLY** the API. We can't run the main application in a cluster mode and it's not necessary at all. We set both scripts to use a maximum of 1GB RAM but in reality, both will use less than 40mb. It's just to be safe. I added the necessary scripts in the `package.json` for running the application. ``` &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \&quot;Error: no test specified\&quot; &amp;amp;&amp;amp; exit 1&quot;, &quot;start&quot;: &quot;pm2 start ecosystem.config.js&quot;, &quot;stop&quot;: &quot;pm2 delete ecosystem.config.js&quot;, &quot;restart&quot;: &quot;pm2 restart ecosystem.config.js&quot;, &quot;reload&quot;: &quot;pm2 reload ecosystem.config.js&quot;, &quot;logs&quot;: &quot;pm2 logs&quot; } ``` For example, for starting the app I can type `npm run start` and `npm run logs` for logs and so on. It will use the installed `pm2` with the app itself. *** For the ability to sync blocks in a row one by one, we use a queue. I call this implementation `rapidQueue`. It's in pure JS and is faster than the other methods. You can check it out [on GitLab](https://gitlab.com/mahdiyari/decentralized-game-on-hive/-/blob/master/back-end/helpers/rapidQueue.js). I set the genesis block of our game to `53,886,076` just because it was the head block at the time of launch. Every time a fresh instance of the game is installed, it will go through all the blocks one by one from the genesis block until the current head block and continue listening for the future blocks. So here it is our syncing method: `index.js` ``` const start = async () =&amp;gt; { try { await initDatabase() stream.streamBlockNumber(async blockNum =&amp;gt; { if (!blockNum) { return } if (firstRun) { firstRun = false await queueOldBlocks(blockNum) } queue.push(blockNum) }) processQueue() } catch (e) { throw new Error(e) } } ``` First, initializes database then puts into the queue not synced blocks, then puts the newly generated blocks into the back of the queue. Then call another function that will check the queue at an interval. The code below is responsible for putting not synced blocks into the queue. ``` const queueOldBlocks = async nowBlock =&amp;gt; { let oldestBlock const latestBlock = await mysql.query( 'SELECT `block_number` FROM `lastblock` WHERE `id`=1' ) if (latestBlock[0].block_number === 0) { oldestBlock = genesisBlock } else { oldestBlock = latestBlock[0].block_number } if (oldestBlock &amp;lt; nowBlock) { for (let i = oldestBlock; i &amp;lt; nowBlock; i++) { queue.push(i) } } } ``` The following code is the part that takes block numbers one by one out of the queue. It runs every 5ms to check if the current block is processed or not. If yes, goes to the next block in the queue. `queueIndex` is the counter of the currently running `processBlock()`s. Which will be a maximum of 1. ``` const intervalTime = 5 const maxI = 1 let queueIndex = 0 const processQueue = () =&amp;gt; { setInterval(() =&amp;gt; { const L = queue.length() if (queueIndex &amp;lt; maxI &amp;amp;&amp;amp; L &amp;gt; 0) { const n = maxI - queueIndex &amp;gt; L ? L : maxI - queueIndex for (let k = 0; k &amp;lt; n; k++) { const blockNum = queue.shift() processBlock(blockNum) } } }, intervalTime) } ``` You can see the counter in action: ``` const processBlock = async blockNum =&amp;gt; { if (!blockNum) { return } queueIndex++ try { const operations = await stream.getOperations(blockNum) if (operations &amp;amp;&amp;amp; operations.length &amp;gt; 0) { for (const ops of operations) { for (const op of ops) { if (op &amp;amp;&amp;amp; op[0] === 'custom_json' &amp;amp;&amp;amp; op[1].id === 'tictactoe') { await processData(op[1].json, op[1].required_posting_auths) } } } } await updateLastblock(blockNum) totalSyncedBlocks++ } catch (e) {} queueIndex-- } ``` *** The heart of the game is the `play` function. It determines the finished games and winners. It is triggered when a player plays a move. ``` const play = async (data, user) =&amp;gt; { if ( !data || !data.id || !data.col || !data.row || isNaN(data.col) || isNaN(data.row) || data.id.length !== 20 || data.col &amp;lt; 1 || data.col &amp;gt; 3 || data.row &amp;lt; 1 || data.row &amp;gt; 3 ) { return } // Validate game in database const game = await mysql.query( 'SELECT `player1`, `player2`, `starting_player` FROM `games` WHERE `game_id`= ? AND `status`= ? AND (player1=? OR player2=?)', [data.id, 'running', user, user] ) if (!game || !Array.isArray(game) || game.length &amp;lt; 1) { return } // Validate the player round let round = '' const computedMoves = new Array(9) const moves = await mysql.query( 'SELECT `player`, `col`, `row` FROM `moves` WHERE `game_id`= ? ORDER BY `id` ASC', [data.id] ) if (!moves || !Array.isArray(moves) || moves.length &amp;lt; 1) { round = game[0].starting_player } else { if (moves[moves.length - 1].player === game[0].player1) { round = 'second' } else { round = 'first' } } if (moves.length &amp;gt; 8) { return } if (round === 'first' &amp;amp;&amp;amp; game[0].player2 === user) { return } if (round === 'second' &amp;amp;&amp;amp; game[0].player1 === user) { return } // Play game and check winner await mysql.query( 'INSERT INTO `moves`(`game_id`, `player`, `col`, `row`) VALUES (?,?,?,?)', [data.id, user, data.col, data.row] ) moves.push({ player: user, col: data.col, row: data.row }) for (let i = 0; i &amp;lt; moves.length; i++) { const move = moves[i] let mark if (move.player === game[0].player1) { mark = 'x' } else if (move.player === game[0].player2) { mark = 'o' } else { continue } if (move.row === 1) { computedMoves[move.col - 1] = mark } else if (move.row === 2) { computedMoves[move.col + 2] = mark } else if (move.row === 3) { computedMoves[move.col + 5] = mark } } checkWinner(computedMoves, data.id) } ``` The `play` function validates the data, then places the played move, then checks for the game status for a possible winner or draw. The `checkWinner` function: ``` const checkWinner = async (computedMoves, id) =&amp;gt; { if (checkWinningMark(computedMoves, 'x')) { await mysql.query( 'UPDATE `games` SET `status`=?, `winner`=? WHERE `game_id`=?', ['finished', 'player1', id] ) } else if (checkWinningMark(computedMoves, 'o')) { await mysql.query( 'UPDATE `games` SET `status`=?, `winner`=? WHERE `game_id`=?', ['finished', 'player2', id] ) } else { for (let i = 0; i &amp;lt; 9; i++) { if (!computedMoves[i]) { return } } await mysql.query( 'UPDATE `games` SET `status`=?, `winner`=? WHERE `game_id`=?', ['finished', 'none', id] ) } } ``` It checks for the winning of player1 or &quot;X&quot; and then player2 or &quot;O&quot; then checks for the filled board for a draw. Then the database is updated. `checkWinningMark()` is not interesting. It just checks each row and col for a winning pattern for the provided mark. X or O. *** At the end of the file, we call the `start()` method to start the application. Then inform the user current state of sync. ``` start() console.log('Tic Tac Toe Application') console.log( 'Starting application... It is highly recommended to use a local node for syncing blocks otherwise it might take too long.' ) const interval = setInterval(() =&amp;gt; { if (queue.length() &amp;lt; 2) { clearInterval(interval) console.log('Sync completed. Application is running.') } else { console.log('Syncing blocks... Total synced blocks: ' + totalSyncedBlocks) } }, 5000) ``` With a local node, it syncs ~70 blocks per second (depends on many things). It can be boosted in certain ways but it's not necessary for this project. 70 blocks/s is still impressive enough. It all depends on the latency of the connected RPC node because the syncing is done by selecting blocks in a row one by one and waiting for the one to finish before going to the next one. *** ### Client-side There are many things on the client-side. I'm not going near front-end codes. You can always check the full code on the [GitLab repository](https://gitlab.com/mahdiyari/decentralized-game-on-hive). Our game board is designed with Canvas. I don't think it's necessary to talk about those codes. Here is the function for broadcasting a move. `js/app.js` ``` const submitMove = async () =&amp;gt; { if (!userData.authorized) { document.getElementById('login-button').click() return } if (!userMove || userMove.length &amp;lt; 2) { return } if (!urlParams.has('id')) { return } const error = document.getElementById('submit-move-error') error.innerHTML = '' loading(true) const id = urlParams.get('id') try { const play = { app: 'tictactoe/0.0.1', action: 'play', id, col: userMove[0], row: userMove[1] } const operations = [ [ 'custom_json', { required_auths: [], required_posting_auths: [userData.username], id: 'tictactoe', json: JSON.stringify(play) } ] ] const tx = new hiveTx.Transaction() await tx.create(operations) const privateKey = hiveTx.PrivateKey.from(userData.key) tx.sign(privateKey) const result = await tx.broadcastNoResult() if (result &amp;amp;&amp;amp; result.result &amp;amp;&amp;amp; result.result.tx_id) { setTimeout(() =&amp;gt; getGameDetails(urlParams.get('id')), 1500) oldRound = round round = round === 'first' ? 'second' : 'first' toggleMoveInteractions('player-waiting') } else { error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J' console.error(result) } } catch (e) { error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J' console.error(e) } loading(false) } ``` It creates a transaction with custom_json and uses `.broadcastNoResult()` method of `hiveTx` library for the fastest possible transaction broadcast. This method doesn't return the result of the transaction (but it returns the offline generated tx_id so it's possible to check for the status of the transaction later but we don't) so it may as well fail for many reasons but we assume everything is fine. In this way, the user experience is better and smoother. Because the action goes faster. *** On the game page, the application gets the game details every 5s from the API and updates the user interface. Then calls the following function to update the board with new moves and also detects the round of play. ``` const computeMoves = () =&amp;gt; { if (!movesData || !gameData) { setTimeout(() =&amp;gt; computeMoves(), 100) return } clearMoves() for (let i = 0; i &amp;lt; movesData.length; i++) { const move = movesData[i] let mark if (move.player === gameData.player1) { mark = 'x' } else if (move.player === gameData.player2) { mark = 'o' } else { continue } placeMark(move.col, move.row, mark) } placeMark(userMove[0], userMove[1], userMove[2]) if (movesData.length &amp;lt; 1) { round = gameData.starting_player } else if (movesData[movesData.length - 1].player === gameData.player1) { round = 'second' } else { round = 'first' } } ``` There are many other front-end and back-end stuff which I skip the explanation because it's not a post about teaching development in any sense. I just explained the things I thought might be necessary for running the Hive applications. *** ![town-sign-1158387_640.jpg](https://images.hive.blog/DQmW97Q9q5wLbZ9chrtsRMGvMcHZvoYVXLfsBj4G21UthyY/town-sign-1158387_640.jpg) It's 2:30 AM and I'm not sure if I missed something. I hope you accept my attempt at making this tutorial. I have another project in mind so make sure to follow me. Thank you again. Your votes, reblogs, and witness votes are much appreciated. I hope you like what I do. images source: pixabay.com All the codes used in this project are original. Except the `rapidQueue` method (MIT license). *** The final project: https://tic-tac-toe.mahdiyari.info/ https://gitlab.com/mahdiyari/decentralized-game-on-hive *** Previous posts: [part1](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-tic-tac-toe-part-1) [part2](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-2) [part3](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-3) [part4](https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-4) [part5](https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-5) See: Making a Decentralized Game on Hive - Last part by @mahdiyari</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmah3PBKL6JDe3omk8wi2RFp3Lk2X8BZgb3FUpnkRTsfap/desktop-1245714_1280.jpg" /><media:content medium="image" url="https://images.hive.blog/DQmah3PBKL6JDe3omk8wi2RFp3Lk2X8BZgb3FUpnkRTsfap/desktop-1245714_1280.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>