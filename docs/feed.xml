<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://hivedocs.info/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hivedocs.info/" rel="alternate" type="text/html" /><updated>2021-06-09T08:13:49-07:00</updated><id>https://hivedocs.info/feed.xml</id><title type="html">Hive Chain Documentation</title><subtitle>Your resource for various levels of Hive Documentation.</subtitle><author><name>site curated by: @inertia</name></author><entry><title type="html">Daily Hive Engine Snapshots</title><link href="https://hivedocs.info/howto/devops/hiveengine/2021/06/09/daily-hive-engine-snapshots.html" rel="alternate" type="text/html" title="Daily Hive Engine Snapshots" /><published>2021-06-09T07:36:06-07:00</published><updated>2021-06-09T07:36:06-07:00</updated><id>https://hivedocs.info/howto/devops/hiveengine/2021/06/09/daily-hive-engine-snapshots</id><content type="html" xml:base="https://hivedocs.info/howto/devops/hiveengine/2021/06/09/daily-hive-engine-snapshots.html">&lt;div id=&quot;content-primersion-daily-hive-engine-snapshots&quot;&gt;![wallp12.png](https://images.ecency.com/DQmRT6nLW4pqLqeR1NhGVy68HUhRMDEYCNUhFQ6R1SLT7sm/wallp12.png)

## The Why

Hive engine nodes read all transactions from the HIVE blockchain and when they discover a custom json operation with a special id (ssc-mainnet-hive), they process the transaction and add it to the hive engine sidechain. The hive engine sidechain itself is basically a big database storing all transactions and processed information, such as token balances and nft instances, inside a mongodb.
To create the hive engine sidechain completely from scratch we would have to start from the genesis block and process all transactions after that. This is a very lengthy process, because it includes millions of transactions.

That's where snapshots come into play. You simply create a snapshot of the database after block X was processed and the next time you only have to replay transactions starting from block X. The same principle applies to the HIVE blockchain itself.

So whenever something goes wrong or you want to setup a fresh node you can use the snapshot to set up your node faster.

## The What

I am running a hive engine witness node myself, which is why I need to recreate my node regularly. A few other witnesses are already providing snapshots of the hive engine sidechain regularly. I think more is better, so I decided to set up my own daily hive engine snapshots. I have integrated the snapshots into my HIVE monitor tool over here: https://primersion.com/he-snapshots

Every day at 11pm UTC a snapshot is created automatically, uploaded to https://transfer.sh and provided through my page afterwards:

![image.png](https://images.ecency.com/DQmbdCZh87hkktsYM1Sot7qBg8rDXqoWG4Do8HqDBLPxm3J/image.png)

You will find snapshots of the last 7 days (in a few days, because I only started 2 days ago) and you can download them directly by clicking on the link. After downloading the snapshot you can use it to restore the database of your hive engine node using `mongorestore --gzip --archive=&lt;path to=&quot;&quot; archive=&quot;&quot;&gt;`. Additionally you will find a checksum below the link, which you can compare with the checksum created when running `md5sum &lt;path to=&quot;&quot; archive=&quot;&quot;&gt;` on the downloaded file.

## The How

I have written a small script, which does all the work for me. All I need for it to function is a running and synced hive engine node. First I am stopping my node using `pm2 stop all`.
In a next step I am dumping the mongodb to a file including the current date and the last processed block:
```
now=`date +&quot;%m-%d-%Y&quot;`
block=`cat config.json | grep startHiveBlock | grep -Eo '[0-9]*'`
mongodump --db hsc --gzip --archive=&quot;hsc_${now}_b${block}.archive&quot;
```
When the dump is finished I start the node back up using `pm2 start app.js --no-treekill --kill-timeout 10000 --no-autorestart`.
And transfer the dump to https://transfer.sh using `curl --upload-file &quot;hsc_${now}_b${block}.archive&quot; &quot;https://transfer.sh/hsc_${now}_b${block}.archive&quot;`.

I am running the script daily at 11pm UTC using a cronjob.

That's all the magic.

---

Please support me by voting for my HIVE / Hive-Engine witness:

[HIVE](https://vote.hive.uno/?witness=primersion) (using Hivesigner)
[Hive-Engine](https://votify.now.sh/primersion) (using Votify)&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@primersion&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/daily-hive-engine-snapshots&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-primersion-daily-hive-engine-snapshots').html();
      const outputElem = $('#content-primersion-daily-hive-engine-snapshots');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-primersion-daily-hive-engine-snapshots {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-primersion-daily-hive-engine-snapshots code {
    background: white;
  }
  #content-primersion-daily-hive-engine-snapshots a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-primersion-daily-hive-engine-snapshots a:hover {
    border-bottom: 0;
  }
  #content-primersion-daily-hive-engine-snapshots h1 {
    font-size: 2.2em;
  }
  #content-primersion-daily-hive-engine-snapshots h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-primersion-daily-hive-engine-snapshots header small {
    color: #999;
    font-size: 50%;
  }
  #content-primersion-daily-hive-engine-snapshots img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://ecency.com/hive-169321/@primersion/daily-hive-engine-snapshots&quot;&gt;Daily Hive Engine Snapshots&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@primersion&quot;&gt;@primersion&lt;/a&gt;
&lt;/p&gt;

&lt;/path&gt;&lt;/path&gt;&lt;/div&gt;</content><author><name>primersion</name></author><category term="howto" /><category term="devops" /><category term="hiveengine" /><summary type="html">![wallp12.png](https://images.ecency.com/DQmRT6nLW4pqLqeR1NhGVy68HUhRMDEYCNUhFQ6R1SLT7sm/wallp12.png) ## The Why Hive engine nodes read all transactions from the HIVE blockchain and when they discover a custom json operation with a special id (ssc-mainnet-hive), they process the transaction and add it to the hive engine sidechain. The hive engine sidechain itself is basically a big database storing all transactions and processed information, such as token balances and nft instances, inside a mongodb. To create the hive engine sidechain completely from scratch we would have to start from the genesis block and process all transactions after that. This is a very lengthy process, because it includes millions of transactions. That's where snapshots come into play. You simply create a snapshot of the database after block X was processed and the next time you only have to replay transactions starting from block X. The same principle applies to the HIVE blockchain itself. So whenever something goes wrong or you want to setup a fresh node you can use the snapshot to set up your node faster. ## The What I am running a hive engine witness node myself, which is why I need to recreate my node regularly. A few other witnesses are already providing snapshots of the hive engine sidechain regularly. I think more is better, so I decided to set up my own daily hive engine snapshots. I have integrated the snapshots into my HIVE monitor tool over here: https://primersion.com/he-snapshots Every day at 11pm UTC a snapshot is created automatically, uploaded to https://transfer.sh and provided through my page afterwards: ![image.png](https://images.ecency.com/DQmbdCZh87hkktsYM1Sot7qBg8rDXqoWG4Do8HqDBLPxm3J/image.png) You will find snapshots of the last 7 days (in a few days, because I only started 2 days ago) and you can download them directly by clicking on the link. After downloading the snapshot you can use it to restore the database of your hive engine node using `mongorestore --gzip --archive=`. Additionally you will find a checksum below the link, which you can compare with the checksum created when running `md5sum ` on the downloaded file. ## The How I have written a small script, which does all the work for me. All I need for it to function is a running and synced hive engine node. First I am stopping my node using `pm2 stop all`. In a next step I am dumping the mongodb to a file including the current date and the last processed block: ``` now=`date +&quot;%m-%d-%Y&quot;` block=`cat config.json | grep startHiveBlock | grep -Eo '[0-9]*'` mongodump --db hsc --gzip --archive=&quot;hsc_${now}_b${block}.archive&quot; ``` When the dump is finished I start the node back up using `pm2 start app.js --no-treekill --kill-timeout 10000 --no-autorestart`. And transfer the dump to https://transfer.sh using `curl --upload-file &quot;hsc_${now}_b${block}.archive&quot; &quot;https://transfer.sh/hsc_${now}_b${block}.archive&quot;`. I am running the script daily at 11pm UTC using a cronjob. That's all the magic. --- Please support me by voting for my HIVE / Hive-Engine witness: [HIVE](https://vote.hive.uno/?witness=primersion) (using Hivesigner) [Hive-Engine](https://votify.now.sh/primersion) (using Votify)&amp;lt;/div&amp;gt; See: Daily Hive Engine Snapshots by @primersion</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.ecency.com/DQmRT6nLW4pqLqeR1NhGVy68HUhRMDEYCNUhFQ6R1SLT7sm/wallp12.png" /><media:content medium="image" url="https://images.ecency.com/DQmRT6nLW4pqLqeR1NhGVy68HUhRMDEYCNUhFQ6R1SLT7sm/wallp12.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Vessel Testnet Support</title><link href="https://hivedocs.info/news/vessel/testnet/2021/06/04/vessel-testnet-support.html" rel="alternate" type="text/html" title="Vessel Testnet Support" /><published>2021-06-04T20:26:39-07:00</published><updated>2021-06-04T20:26:39-07:00</updated><id>https://hivedocs.info/news/vessel/testnet/2021/06/04/vessel-testnet-support</id><content type="html" xml:base="https://hivedocs.info/news/vessel/testnet/2021/06/04/vessel-testnet-support.html">&lt;div id=&quot;content-rishi556-vessel-testnet-support&quot;&gt;Recently I updated Vessel to work with the testnet as well. Its quite nice stuff and has made my testing with the testnet a bit easier. It's pretty important to make sure what we've got work with future forks, and the testnet is a great way to do so. Nothing affecting vessel was changed so as long as you are on v0.5.0 you should be fine and not need to update, but if you'd like to checkout the testnet, you get the latest version from here: https://gitlab.syncad.com/hive/vessel/-/releases.

To get onto the testnet with vessel, all you have to do is supply it with a proper testnet node. Right now we have https://testnet.openhive.network. You can set that over on the settings page on vessel, or when first importing your account. With this instance, most accounts should already be exported with the same keys so you can just use it with no problems.


![Screen Shot 2021-06-04 at 10.21.16 PM.png](https://files.peakd.com/file/peakd-hive/rishi556/23tcJe3m31RYHtSGU6FA2ecc1E8FwXnKzjsMwPRvX71LeDjbe9ue6tWPbG6rJTzTq9tBw.png)

Switching to the testnet also gets your vessel to change its color to a lovely pink and some of the pages will show the testnet symbols instead of the mainnet one to signify that you are on it. 

I hope that this makes things easier for those of you use participate on the testnet.

I also did upgrade someguy's hivefeed-js(https://github.com/someguy123/hivefeed-js) to support the testnet as well. Just set the network to `testnet` in the config and you'll be good to go. Having more of our apps supporting the testnet will be awesome to make testing even easier and to make sure they function without problems once the fork comes around. 

&lt;hr /&gt;

Nerdier part starts here

The main change that needed to be done was just changing Hive and HBD to the proper testnet symbols(though the latest hive-js version does this automatically so if I waited could have done less work haha), that can be seen on this commit https://gitlab.syncad.com/hive/vessel/-/commit/36b366d375cffb371f04a56b97a81de9d43d4d38. It was just a simple replacement of `HIVE` to `TESTS` and `HBD` to `TBD`.

The other part was to set the chainid and prefix to the correct values, which can be seen here: https://gitlab.syncad.com/hive/vessel/-/commit/67a395539180fba62f4c849418982706e5a07c2f. @mahdiyari actually gave me a really great way on how to do this without needing user input at all. Initially I thought I would need to have user input in the chain id themselves, or check a box to signify that it's a testnet. Instead @mahdiyari proposed that I just pull the chain id and prefix right from the api node that the user supplied. That worked beautifully. 
&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@rishi556&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/vessel-testnet-support&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-rishi556-vessel-testnet-support').html();
      const outputElem = $('#content-rishi556-vessel-testnet-support');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-rishi556-vessel-testnet-support {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-rishi556-vessel-testnet-support code {
    background: white;
  }
  #content-rishi556-vessel-testnet-support a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-rishi556-vessel-testnet-support a:hover {
    border-bottom: 0;
  }
  #content-rishi556-vessel-testnet-support h1 {
    font-size: 2.2em;
  }
  #content-rishi556-vessel-testnet-support h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-rishi556-vessel-testnet-support header small {
    color: #999;
    font-size: 50%;
  }
  #content-rishi556-vessel-testnet-support img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@rishi556/vessel-testnet-support&quot;&gt;Vessel Testnet Support&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@rishi556&quot;&gt;@rishi556&lt;/a&gt;
&lt;/p&gt;</content><author><name>rishi556</name></author><category term="news" /><category term="vessel" /><category term="testnet" /><summary type="html">Recently I updated Vessel to work with the testnet as well. Its quite nice stuff and has made my testing with the testnet a bit easier. It's pretty important to make sure what we've got work with future forks, and the testnet is a great way to do so. Nothing affecting vessel was changed so as long as you are on v0.5.0 you should be fine and not need to update, but if you'd like to checkout the testnet, you get the latest version from here: https://gitlab.syncad.com/hive/vessel/-/releases. To get onto the testnet with vessel, all you have to do is supply it with a proper testnet node. Right now we have https://testnet.openhive.network. You can set that over on the settings page on vessel, or when first importing your account. With this instance, most accounts should already be exported with the same keys so you can just use it with no problems. ![Screen Shot 2021-06-04 at 10.21.16 PM.png](https://files.peakd.com/file/peakd-hive/rishi556/23tcJe3m31RYHtSGU6FA2ecc1E8FwXnKzjsMwPRvX71LeDjbe9ue6tWPbG6rJTzTq9tBw.png) Switching to the testnet also gets your vessel to change its color to a lovely pink and some of the pages will show the testnet symbols instead of the mainnet one to signify that you are on it. I hope that this makes things easier for those of you use participate on the testnet. I also did upgrade someguy's hivefeed-js(https://github.com/someguy123/hivefeed-js) to support the testnet as well. Just set the network to `testnet` in the config and you'll be good to go. Having more of our apps supporting the testnet will be awesome to make testing even easier and to make sure they function without problems once the fork comes around. Nerdier part starts here The main change that needed to be done was just changing Hive and HBD to the proper testnet symbols(though the latest hive-js version does this automatically so if I waited could have done less work haha), that can be seen on this commit https://gitlab.syncad.com/hive/vessel/-/commit/36b366d375cffb371f04a56b97a81de9d43d4d38. It was just a simple replacement of `HIVE` to `TESTS` and `HBD` to `TBD`. The other part was to set the chainid and prefix to the correct values, which can be seen here: https://gitlab.syncad.com/hive/vessel/-/commit/67a395539180fba62f4c849418982706e5a07c2f. @mahdiyari actually gave me a really great way on how to do this without needing user input at all. Initially I thought I would need to have user input in the chain id themselves, or check a box to signify that it's a testnet. Instead @mahdiyari proposed that I just pull the chain id and prefix right from the api node that the user supplied. That worked beautifully. See: Vessel Testnet Support by @rishi556</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/rishi556/23tcJe3m31RYHtSGU6FA2ecc1E8FwXnKzjsMwPRvX71LeDjbe9ue6tWPbG6rJTzTq9tBw.png" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/rishi556/23tcJe3m31RYHtSGU6FA2ecc1E8FwXnKzjsMwPRvX71LeDjbe9ue6tWPbG6rJTzTq9tBw.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">14th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/06/02/14th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="14th update of 2021 on BlockTrades work on Hive software" /><published>2021-06-02T17:21:12-07:00</published><updated>2021-06-02T17:21:12-07:00</updated><id>https://hivedocs.info/news/core/development/2021/06/02/14th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/06/02/14th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-14th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by the BlockTrades team during the last week or so:

# Hived work (blockchain node software)
We released a second and third release candidate earlier this week with several fixes and improvements for testnet-based testing:
https://gitlab.syncad.com/hive/hive/-/merge_requests/243
https://gitlab.syncad.com/hive/hive/-/merge_requests/244
https://gitlab.syncad.com/hive/hive/-/merge_requests/245

https://gitlab.syncad.com/hive/hive/-/merge_requests/250
https://gitlab.syncad.com/hive/hive/-/merge_requests/251

But we found some more issues associated with those release candidates and we also decided to reduce the vote powerup delay to one day for the testnet  (this value is configured for 30 days in the mainnet) to simplify testing scenarios where accounts stake their coins and then vote in new witnesses. So we’re about to tag a fourth release candidate for hived (probably will be tagged tomorrow). 

We’ve actually launched a new testnet with an untagged version of the planned release candidate to get the testnet jump-started quicker (we're simulating a transition of the code from HF24 rules to HF25 rules in this release and the transition test is scheduled for tomorrow so we wanted to get the testnet up as fast as possible). We haven’t tagged the new code yet as 1.25.0.rc4 because some of the automated tests failed when we changed the vote powerup delay for the testnet, but we’ll tag it after we have committed updated tests. As part of the changes to the tests, the response checking will be modified to test for the configured delay value rather than a hardcoded value, to avoid a repeat of this issue in the future.

I’ll add a link here to the new release candidate after it’s tagged.

# Hivemind (2nd layer applications + social media middleware)
Earlier this week, we merged develop branch changes to master and released a new 1.25.0 version of hivemind (so just pull from the head of the master branch to get the new version), and now we’re assisting API node operators as they upgrade to the new version. Note that the old version and the new version are broadly API compatible: most of the changes in the new release consist of bug fixes and performance improvements.

Currently the API nodes for api.hive.blog (@blocktrades), api.deathwing.me (@deathwing), and api.openhive.network (@gtg) have been updated to the new release.

Also, to eliminate the multi-day hive sync requirement for anyone setting up their API node for the first time, @gtg has provided a hivemind database dump for the new release that can be used to quickly initialize a new API node:   https://gtg.openhive.network/get/hivemind/ 

# Modular hivemind (Application framework for Hive apps)
We’ve been working on the documentation for modular hivemind’s internal architecture this week and doing individual code reviews. We have a meeting scheduled Monday to do a group code review. After that meeting, I should have a better idea as to when we can expect an initial release of the software, but from what I’ve seen so far, I’m thinking we could make it available for beta testing next month. 

 An early draft of the documentation for the architecture is here: https://gitlab.syncad.com/hive/psql_tools/-/blob/23239a592bd77b3b2cefc648e5c25880e0f76ffb/src/hive_fork/Readme.md 

# Testnet
We’re seeing more apps join in and hookup up test sites to the testnet. Note that as a regular Hive user, you can typically login with your normal credentials and test via these sites.
For example, you can login to either of these blog sites on the testnet
https://testblog.openhive.network (hive.blog-like testing site)
or
https://testnet.peakd.com/ (peakd-like testing site)

You can also browse the testnet with this block explorer: https://test.ausbit.dev/

## New testing tool for testnet
We’ve also created a new tool to convert an existing block log to a testnet block log to ease creation of more realistic “real-world” testnet-based test scenarios. The new tool is undergoing testing now.

# Tentative date for hardfork 25 is June 30th
Release candidate 4 has the hardfork scheduled for June 30th. Assuming we find no further issues by late next week, we’ll make that date official, create an official release by merging the develop branch to the master branch, and notify exchanges of the need to upgrade their wallets.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/14th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-14th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-14th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-14th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-14th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-14th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-14th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-14th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-14th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-14th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-14th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/14th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;14th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by the BlockTrades team during the last week or so: # Hived work (blockchain node software) We released a second and third release candidate earlier this week with several fixes and improvements for testnet-based testing: https://gitlab.syncad.com/hive/hive/-/merge_requests/243 https://gitlab.syncad.com/hive/hive/-/merge_requests/244 https://gitlab.syncad.com/hive/hive/-/merge_requests/245 https://gitlab.syncad.com/hive/hive/-/merge_requests/250 https://gitlab.syncad.com/hive/hive/-/merge_requests/251 But we found some more issues associated with those release candidates and we also decided to reduce the vote powerup delay to one day for the testnet (this value is configured for 30 days in the mainnet) to simplify testing scenarios where accounts stake their coins and then vote in new witnesses. So we’re about to tag a fourth release candidate for hived (probably will be tagged tomorrow). We’ve actually launched a new testnet with an untagged version of the planned release candidate to get the testnet jump-started quicker (we're simulating a transition of the code from HF24 rules to HF25 rules in this release and the transition test is scheduled for tomorrow so we wanted to get the testnet up as fast as possible). We haven’t tagged the new code yet as 1.25.0.rc4 because some of the automated tests failed when we changed the vote powerup delay for the testnet, but we’ll tag it after we have committed updated tests. As part of the changes to the tests, the response checking will be modified to test for the configured delay value rather than a hardcoded value, to avoid a repeat of this issue in the future. I’ll add a link here to the new release candidate after it’s tagged. # Hivemind (2nd layer applications + social media middleware) Earlier this week, we merged develop branch changes to master and released a new 1.25.0 version of hivemind (so just pull from the head of the master branch to get the new version), and now we’re assisting API node operators as they upgrade to the new version. Note that the old version and the new version are broadly API compatible: most of the changes in the new release consist of bug fixes and performance improvements. Currently the API nodes for api.hive.blog (@blocktrades), api.deathwing.me (@deathwing), and api.openhive.network (@gtg) have been updated to the new release. Also, to eliminate the multi-day hive sync requirement for anyone setting up their API node for the first time, @gtg has provided a hivemind database dump for the new release that can be used to quickly initialize a new API node: https://gtg.openhive.network/get/hivemind/ # Modular hivemind (Application framework for Hive apps) We’ve been working on the documentation for modular hivemind’s internal architecture this week and doing individual code reviews. We have a meeting scheduled Monday to do a group code review. After that meeting, I should have a better idea as to when we can expect an initial release of the software, but from what I’ve seen so far, I’m thinking we could make it available for beta testing next month. An early draft of the documentation for the architecture is here: https://gitlab.syncad.com/hive/psql_tools/-/blob/23239a592bd77b3b2cefc648e5c25880e0f76ffb/src/hive_fork/Readme.md # Testnet We’re seeing more apps join in and hookup up test sites to the testnet. Note that as a regular Hive user, you can typically login with your normal credentials and test via these sites. For example, you can login to either of these blog sites on the testnet https://testblog.openhive.network (hive.blog-like testing site) or https://testnet.peakd.com/ (peakd-like testing site) You can also browse the testnet with this block explorer: https://test.ausbit.dev/ ## New testing tool for testnet We’ve also created a new tool to convert an existing block log to a testnet block log to ease creation of more realistic “real-world” testnet-based test scenarios. The new tool is undergoing testing now. # Tentative date for hardfork 25 is June 30th Release candidate 4 has the hardfork scheduled for June 30th. Assuming we find no further issues by late next week, we’ll make that date official, create an official release by merging the develop branch to the master branch, and notify exchanges of the need to upgrade their wallets. See: 14th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Community Improvements, Testnet support and 15 More Updates</title><link href="https://hivedocs.info/news/projects/testnet/2021/06/01/community-improvements-testnet-support-and-15-more-updates.html" rel="alternate" type="text/html" title="Community Improvements, Testnet support and 15 More Updates" /><published>2021-06-01T06:18:18-07:00</published><updated>2021-06-01T06:18:18-07:00</updated><id>https://hivedocs.info/news/projects/testnet/2021/06/01/community-improvements-testnet-support-and-15-more-updates</id><content type="html" xml:base="https://hivedocs.info/news/projects/testnet/2021/06/01/community-improvements-testnet-support-and-15-more-updates.html">&lt;div id=&quot;content-peakd-community-improvements-testnet-support-and-15-more-updates&quot;&gt;A new release of [peakd.com](https://peakd.com) is now available. Keep reading to discover the new features and check the full list of improvements ;)

&lt;center&gt;&lt;h4&gt;The new release is now live at https://peakd.com&lt;/h4&gt;&lt;/center&gt;

![release_cover_2021_06_01.jpg](https://files.peakd.com/file/peakd-hive/peakd/23tS2bqoaD4CxPADDAxsarFCkYRHHhFubPR4eXcxdGagL2Ak7d3Lr13d4YCePLPTsnAaF.jpg)

#### 1. Default/Required Beneficiary account for Communities

A community can now define a 'default' or 'required' beneficiary for posts published in that community. This option is not supported at the chain level (or Hivemind), so keep this in mind if you want to enable it. Probvably the only community using this feature at the moment is [PhotoGames](https://peakd.com/c/hive-146701).

When this option is enabled a label will be shown on the community rules:

![image.png](https://files.peakd.com/file/peakd-hive/peakd/23ydVgLHPXNthY6xzWT8boYRB5Ka3XoP9YSx69hMpB1e7EXRd2TnQdcA7T6nMq7hKbrFy.png)

###### Introduce the '@peakd.bot' account to automatically handle posts not using the required beneficiary account

If you want to automatically mute posts not respecting the required beneficiary setting you can add the @peakd.bot account as a community moderators and it will take care of it.

![image.png](https://files.peakd.com/file/peakd-hive/peakd/23uRKjMY5AFdXPSGPeVE7SY9A3PcdrSL6YvgAjBv2aQuiGAKNMGcLBLw1bGFxdrBK34uD.png)

*This is still and experimental feature, so feel free to report any issues you notice* ;)

#### 2. Other Communities Improvements

###### Support public Templates in communities

Communities can now define public Templates (owned by the community `hive-000000` owner account) that are available to their users when they want to write a new post:

![image.png](https://files.peakd.com/file/peakd-hive/peakd/23wgaTg2AHFAUWyBNZzvWmbBdvwsv7gusdEMhFS8APfpAYPpRHMqZk6nUDLxXSF2yx45f.png)

Only templates marked as 'PUBLIC' will be available in the dropdown. You can mark a template as public on this page: https://peakd.com/me/templates.

###### Allow communities to have a Curated Collections (CCC) page

Similar to what is already available for user pages it's now possible to add a collection page to communities:


![image.png](https://files.peakd.com/file/peakd-hive/peakd/23uR9aGiUjafHdkUwL6rHt8XFUvvjdT14qvDuUyxaqc7PkNSRJ44hfd1gEBbwR7QX4Rf4.png)


###### Allow up to 20 preferred topics for communities

You can now set up to 20 preferred topics for a community

![image.png](https://files.peakd.com/file/peakd-hive/peakd/EoyVJhZbq39MxsMsupUaL1GCFwfmmpGCpHBTe6dLYKyrrYGJJJivWm9smzwTBJMd9h8.png)


#### 3. Testnet Support

This is not completely new as we have supported Testnet in the past, but we did some improvements and better support for multiple login methods. This is intended for advanced users, but if you want you can have a look here: https://testnet.peakd.com

**Important:** If you login using Hive Keychain remind to change the RPC node used to cast transactions otherwise you will cast them on the actual chain.

#### 4. Notification counter in browser tab

It's now easier to see if there are new notifications directly on the browser tab/page title:

![image.png](https://files.peakd.com/file/peakd-hive/peakd/EoCbSnqkEUmVRc7QtnbruGou1A1aaLYqC9qZ5D1hGW2H2451b5VUVtfd8NAZZhV3WPS.png)

#### 5. Image viewer for comments

Image viewer had been available for images in a post for quite some time, but now you can enjoy the same for images in the comment section. Just click on the image to see it larger ;)

#### 6. Some minor improvements and bug fixes

As always some minor improvements, updates and fixes across the website. You can check the full release notes here: **https://peakd.com/about/changelog**.

```
# Improvements and Fixes
------------------------------

[update] Better instructions for creating a curated collection
[update] Double check community required beneficiary before publishing a post
[update] Improve image hashing function to better handle edge cases
[update] Include power down amount in MAX available amount in delegation popup
[update] Stop embedded videos autoplay when opening the post in full view
[update] Exclude downvoted/muted posts from Trail view
[update] Indent sub-headers in post outline
[update] Add link to edit default beneficiaries in Settings
[update] Improve support for CCC associated templates
[update] Allow up to 20 preferred topics for communities
[update] Better handle community curator account (if set)
[fix] Improve check on max percentage set for beneficiaries
[fix] Improve HW wallet layout on smaller display
[fix] 3speak video embeds in post
[fix] Image file extension missing after upload for some file
[fix] Set the community name in browser tab title
[fix] Login with PeakLock on testnet.peakd.com is now allowed
```

---

## Support the @peakd project

Now is probably a nice time to remind you of the ways you can support the development of @peakd.

![Selection_298.png](https://files.peakd.com/file/peakd-hive/peakd/w36DQpO7-Selection_298.png)

We have a proposal on the Decentralized Hive Fund. You can review the proposal [here](/proposals/52).
If you agree to the proposal and you think the points mentioned add value to the Hive Blockchain consider supporting it using the above links or directly with **[this link](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=[52]&amp;amp;approve=true)**.

---

We also run a witness server to help produce the blocks for the Hive Blockchain. You can vote for our witness so we are in a position to process more of them.

Vote on the witness page: https://peakd.com/witnesses

- Using Keychain: You just have to click and approve the transaction
- Using HiveSigner: You'll need access to confirm the transaction with your Active Key at least

---

###### *The PeakD Team*
_About us: https://peakd.com/about_
_Join us on Discord: https://discord.gg/Fy3bca5_&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@peakd&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/community-improvements-testnet-support-and-15-more-updates&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-peakd-community-improvements-testnet-support-and-15-more-updates').html();
      const outputElem = $('#content-peakd-community-improvements-testnet-support-and-15-more-updates');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-peakd-community-improvements-testnet-support-and-15-more-updates {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-peakd-community-improvements-testnet-support-and-15-more-updates code {
    background: white;
  }
  #content-peakd-community-improvements-testnet-support-and-15-more-updates a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-peakd-community-improvements-testnet-support-and-15-more-updates a:hover {
    border-bottom: 0;
  }
  #content-peakd-community-improvements-testnet-support-and-15-more-updates h1 {
    font-size: 2.2em;
  }
  #content-peakd-community-improvements-testnet-support-and-15-more-updates h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-peakd-community-improvements-testnet-support-and-15-more-updates header small {
    color: #999;
    font-size: 50%;
  }
  #content-peakd-community-improvements-testnet-support-and-15-more-updates img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-163399/@peakd/community-improvements-testnet-support-and-15-more-updates&quot;&gt;Community Improvements, Testnet support and 15 More Updates&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@peakd&quot;&gt;@peakd&lt;/a&gt;
&lt;/p&gt;</content><author><name>peakd</name></author><category term="news" /><category term="projects" /><category term="testnet" /><summary type="html">A new release of [peakd.com](https://peakd.com) is now available. Keep reading to discover the new features and check the full list of improvements ;) The new release is now live at https://peakd.com ![release_cover_2021_06_01.jpg](https://files.peakd.com/file/peakd-hive/peakd/23tS2bqoaD4CxPADDAxsarFCkYRHHhFubPR4eXcxdGagL2Ak7d3Lr13d4YCePLPTsnAaF.jpg) #### 1. Default/Required Beneficiary account for Communities A community can now define a 'default' or 'required' beneficiary for posts published in that community. This option is not supported at the chain level (or Hivemind), so keep this in mind if you want to enable it. Probvably the only community using this feature at the moment is [PhotoGames](https://peakd.com/c/hive-146701). When this option is enabled a label will be shown on the community rules: ![image.png](https://files.peakd.com/file/peakd-hive/peakd/23ydVgLHPXNthY6xzWT8boYRB5Ka3XoP9YSx69hMpB1e7EXRd2TnQdcA7T6nMq7hKbrFy.png) ###### Introduce the '@peakd.bot' account to automatically handle posts not using the required beneficiary account If you want to automatically mute posts not respecting the required beneficiary setting you can add the @peakd.bot account as a community moderators and it will take care of it. ![image.png](https://files.peakd.com/file/peakd-hive/peakd/23uRKjMY5AFdXPSGPeVE7SY9A3PcdrSL6YvgAjBv2aQuiGAKNMGcLBLw1bGFxdrBK34uD.png) *This is still and experimental feature, so feel free to report any issues you notice* ;) #### 2. Other Communities Improvements ###### Support public Templates in communities Communities can now define public Templates (owned by the community `hive-000000` owner account) that are available to their users when they want to write a new post: ![image.png](https://files.peakd.com/file/peakd-hive/peakd/23wgaTg2AHFAUWyBNZzvWmbBdvwsv7gusdEMhFS8APfpAYPpRHMqZk6nUDLxXSF2yx45f.png) Only templates marked as 'PUBLIC' will be available in the dropdown. You can mark a template as public on this page: https://peakd.com/me/templates. ###### Allow communities to have a Curated Collections (CCC) page Similar to what is already available for user pages it's now possible to add a collection page to communities: ![image.png](https://files.peakd.com/file/peakd-hive/peakd/23uR9aGiUjafHdkUwL6rHt8XFUvvjdT14qvDuUyxaqc7PkNSRJ44hfd1gEBbwR7QX4Rf4.png) ###### Allow up to 20 preferred topics for communities You can now set up to 20 preferred topics for a community ![image.png](https://files.peakd.com/file/peakd-hive/peakd/EoyVJhZbq39MxsMsupUaL1GCFwfmmpGCpHBTe6dLYKyrrYGJJJivWm9smzwTBJMd9h8.png) #### 3. Testnet Support This is not completely new as we have supported Testnet in the past, but we did some improvements and better support for multiple login methods. This is intended for advanced users, but if you want you can have a look here: https://testnet.peakd.com **Important:** If you login using Hive Keychain remind to change the RPC node used to cast transactions otherwise you will cast them on the actual chain. #### 4. Notification counter in browser tab It's now easier to see if there are new notifications directly on the browser tab/page title: ![image.png](https://files.peakd.com/file/peakd-hive/peakd/EoCbSnqkEUmVRc7QtnbruGou1A1aaLYqC9qZ5D1hGW2H2451b5VUVtfd8NAZZhV3WPS.png) #### 5. Image viewer for comments Image viewer had been available for images in a post for quite some time, but now you can enjoy the same for images in the comment section. Just click on the image to see it larger ;) #### 6. Some minor improvements and bug fixes As always some minor improvements, updates and fixes across the website. You can check the full release notes here: **https://peakd.com/about/changelog**. ``` # Improvements and Fixes ------------------------------ [update] Better instructions for creating a curated collection [update] Double check community required beneficiary before publishing a post [update] Improve image hashing function to better handle edge cases [update] Include power down amount in MAX available amount in delegation popup [update] Stop embedded videos autoplay when opening the post in full view [update] Exclude downvoted/muted posts from Trail view [update] Indent sub-headers in post outline [update] Add link to edit default beneficiaries in Settings [update] Improve support for CCC associated templates [update] Allow up to 20 preferred topics for communities [update] Better handle community curator account (if set) [fix] Improve check on max percentage set for beneficiaries [fix] Improve HW wallet layout on smaller display [fix] 3speak video embeds in post [fix] Image file extension missing after upload for some file [fix] Set the community name in browser tab title [fix] Login with PeakLock on testnet.peakd.com is now allowed ``` --- ## Support the @peakd project Now is probably a nice time to remind you of the ways you can support the development of @peakd. ![Selection_298.png](https://files.peakd.com/file/peakd-hive/peakd/w36DQpO7-Selection_298.png) We have a proposal on the Decentralized Hive Fund. You can review the proposal [here](/proposals/52). If you agree to the proposal and you think the points mentioned add value to the Hive Blockchain consider supporting it using the above links or directly with **[this link](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=[52]&amp;amp;approve=true)**. --- We also run a witness server to help produce the blocks for the Hive Blockchain. You can vote for our witness so we are in a position to process more of them. Vote on the witness page: https://peakd.com/witnesses - Using Keychain: You just have to click and approve the transaction - Using HiveSigner: You'll need access to confirm the transaction with your Active Key at least --- ###### *The PeakD Team* _About us: https://peakd.com/about_ _Join us on Discord: https://discord.gg/Fy3bca5_ See: Community Improvements, Testnet support and 15 More Updates by @peakd</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/peakd/23tS2bqoaD4CxPADDAxsarFCkYRHHhFubPR4eXcxdGagL2Ak7d3Lr13d4YCePLPTsnAaF.jpg" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/peakd/23tS2bqoaD4CxPADDAxsarFCkYRHHhFubPR4eXcxdGagL2Ak7d3Lr13d4YCePLPTsnAaF.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How to run a witness node on the hf25 testnet</title><link href="https://hivedocs.info/howto/witness/testnet/2021/05/31/how-to-run-a-witness-node-on-the-hf25-testnet.html" rel="alternate" type="text/html" title="How to run a witness node on the hf25 testnet" /><published>2021-05-31T06:51:27-07:00</published><updated>2021-05-31T06:51:27-07:00</updated><id>https://hivedocs.info/howto/witness/testnet/2021/05/31/how-to-run-a-witness-node-on-the-hf25-testnet</id><content type="html" xml:base="https://hivedocs.info/howto/witness/testnet/2021/05/31/how-to-run-a-witness-node-on-the-hf25-testnet.html">&lt;div id=&quot;content-howo-how-to-run-a-witness-node-on-the-hf25-testnet&quot;&gt;![image.png](https://files.peakd.com/file/peakd-hive/howo/23xe7eZsnrPcykgbjNqyAudjuQ8nfGfqRzVCpTShns5vRs2J9gcknbewso9v32YFhw54x.png)

Hi ! the testnet phase for HF25 is now in full swing, here's some info on it from @gtg https://peakd.com/@gtg/hf25-public-testnet-reloaded-rc2

One important thing to understand about the testnet is much more lightweight than the main net (because the chain is brand new) so you can actually get it running on a super small machine, to prove my point I'm going to write this tutorial using the 6$ a month doplet (1 core, 25gb storage) from digitalocean. I recommend ubuntu 18.04 LTS, 20.04 is also supported by hive but it can be more tricky depending on the versions of GCC+boost+cmake that are provided with it.

If you participated in the last testnet you will find this guide very similar to the previous one https://peakd.com/hive/@howo/how-to-participate-in-the-tesntets-this-week-full-guide but I felt like making a new one was better than telling you  &quot;follow the outdated guide and at step 35 do this instead&quot; 

### step 1: Build hive or download binaries

#### download binaries

If you're on a low end hardware compiling may take a while, so it's faster to let someone compile the binaries for you so you can just run them instead.

@gtg offers pre-built binaries at https://gtg.openhive.network/get/testnet/bin/ just download both hived and cli_wallet and you're good to go:

```
mkdir programs
cd programs
wget https://gtg.openhive.network/get/testnet/bin/cli_wallet-v1.25.0rc2
wget https://gtg.openhive.network/get/testnet/bin/hived-v1.25.0rc2
chmod +x *
```

This is a hassle-free solution but binaries may not always be available and it's generally better security-wise to compile it yourself.

### build hive

If you are running on low end hardware like me, you will probably need to setup some swap to compile hive:  https://linuxize.com/post/how-to-add-swap-space-on-ubuntu-18-04/ I personally added 16GB of swap. I don't know how much is actually needed I just figured that it would be enough, feel free to tell me in the comments if you experiment with it.


Let's install the dependencies first:
```
apt-get install -y \
        autoconf \
        automake \
        autotools-dev \
        build-essential \
        cmake \
        doxygen \
        git \
        libboost-all-dev \
        libyajl-dev \
        libreadline-dev \
        libssl-dev \
        libtool \
        liblz4-tool \
        ncurses-dev \
        python3 \
        python3-dev \
        python3-jinja2 \
        python3-pip \
        libgflags-dev \
        libsnappy-dev \
        zlib1g-dev \
        libbz2-dev \
        liblz4-dev \
        libzstd-dev
```

Then get hive and compile it, change `v1.25.0rc2` to whatever is the current release tag, follow @gtg he is usually the one announcing the release notes, alternatively you can look on https://gitlab.syncad.com/hive/hive/-/tags and look at the most recent tags.  

```
git clone git@gitlab.syncad.com:hive/hive.git
cd hive
git checkout v1.25.0rc2
git submodule update --init --recursive
mkdir build
cd build

cmake -DENABLE_COVERAGE_TESTING=ON -DBUILD_HIVE_TESTNET=ON -DLOW_MEMORY_NODE=ON ..

make -j$(nproc) hived cli_wallet
```

Compiling may take a while if you are on low end hardware it could take up to a few hours if not more, I forgot to measure it when I did it myself so 🤷‍. On high end hardware you can expect 3-5 minutes.
 
## Run the node

I am using the directory structure and binary names that you get when you compile hive so straight copy paste may not work if you use binaries but everything else works the same you just have to use the right paths and right binary names.


Run the node a few seconds and then exit hived like so

`./programs/hive/hived -d testnet/`

this will create a testnet directory with the default config file.

open the config.ini file

nano testnet/config.ini

replace the config.ini with this one:

```
# tells the node which seeds he should listen to to get blocks
p2p-seed-node = testnet.openhive.network:2001

# Local http endpoint for webserver requests.
webserver-http-endpoint = 127.0.0.1:8090

# Local websocket endpoint for webserver requests.
webserver-ws-endpoint =127.0.0.1:8091

log-appender = {&quot;appender&quot;:&quot;stderr&quot;,&quot;stream&quot;:&quot;std_error&quot;}
log-logger = {&quot;name&quot;:&quot;default&quot;,&quot;level&quot;:&quot;info&quot;,&quot;appender&quot;:&quot;stderr&quot;}

backtrace = yes

plugin = webserver p2p json_rpc
plugin = database_api condenser_api

plugin = witness
plugin = rc

plugin = market_history
plugin = market_history_api

plugin = account_history_rocksdb
plugin = account_history_api

plugin = transaction_status
plugin = transaction_status_api

plugin = account_by_key
plugin = account_by_key_api

plugin = reputation
plugin = reputation_api

plugin = block_api network_broadcast_api rc_api

account-history-rocksdb-path = &quot;blockchain/account-history-rocksdb-storage&quot;

shared-file-size = 10G

shared-file-full-threshold = 9500
shared-file-scale-rate = 1000

flush-state-interval = 0

market-history-bucket-size = [15,60,300,3600,86400]
market-history-buckets-per-size = 5760

p2p-endpoint = 0.0.0.0:2001

transaction-status-block-depth = 64000
transaction-status-track-after-block = 46000000

webserver-thread-pool-size = 256
```

Then run hived again, this time we want it to stay up so setup a way for it to persist even if you log out, like screen. I personally use pm2 for the testnets just because it's convenient. This is not optimal for a production setup but it's fine for those testnets. (see https://pm2.keymetrics.io/docs/usage/quick-start/)

for the testnet I run hived like this with pm2:

pm2 start --name testnet ./programs/hived/hived -- -d testnet


It will take some time (a few minutes to a few hours) before you get your blocks.
You can look at https://test.ausbit.dev/ to see what is the head block to get a sense of how far you are.
When you are synched with the testnet and you should see messages like this:

```
3|hf23     | 1526617ms p2p_plugin.cpp:212            handle_block         ] Got 0 transactions on block 4415 by howo -- Block Time Offset: -382 ms
3|hf23     | 1532618ms p2p_plugin.cpp:212            handle_block         ] Got 0 transactions on block 4416 by howo -- Block Time Offset: -381 ms
3|hf23     | 1538612ms p2p_plugin.cpp:212            handle_block         ] Got 0 transactions on block 4417 by howo -- Block Time Offset: -387 ms
3|hf23     | 1544620ms p2p_plugin.cpp:212            handle_block         ] Got 0 transactions on block 4418 by howo -- Block Time Offset: -379 ms
3|hf23     | 1550615ms p2p_plugin.cpp:212            handle_block         ] Got 0 transactions on block 4419 by howo -- Block Time Offset: -384 ms

```

now your node is running ! So that's great, but it's not producing.

So you need to setup your witness.

## Setting up your witness 

### cli_wallet 

Open up the cli wallet:

`./programs/cli_wallet/cli_wallet --server-rpc-endpoint=&quot;ws://127.0.0.1:8091&quot;`

it'll ask for a password, so execute:

`set_password yourpassword`

then unlock it using:

`unlock yourpassword`

Now execute those commands:

import your active key to do various actions, note that the keys on the testnet are the same than the keys on main net (they have been ported) so you can just use your account  
`import_key 5JNHfZYKGaomSFvd4NUdQ9qMcEAC43kujbfjueTHpVapX1Kzq2n`

then generate keys for your witness:
`suggest_brain_key`

it'll be something like this:
```
{
  &quot;brain_priv_key&quot;: &quot;STRANGE ROADWAY TWASOME MOLER CENTIMO THOFT COMPORT VARIANT OUTSWIM EGGER SCRIBE GLAVER CROWDED DOLLIER AWNED DOPPER&quot;,
  &quot;wif_priv_key&quot;: &quot;5KJUxvUSdAV6H7LiutRJMVwEVptmoaDhM73Cg1itzYjG8zs7tWF&quot;,
  &quot;pub_key&quot;: &quot;TST71oeHrdBZEKDG1GaC75VKDaRGcXk2R8htD8J6wkP6p1zDRPzFZ&quot;
}
```
Save these for later !

Then set yourself as a witness (notice how I used the pub_key generated above)
```
update_witness &quot;yourusername&quot; &quot;http://example.org&quot; &quot;TST71oeHrdBZEKDG1GaC75VKDaRGcXk2R8htD8J6wkP6p1zDRPzFZ&quot; {&quot;account_creation_fee&quot;:&quot;0.000 TESTS&quot;,&quot;maximum_block_size&quot;:65536,&quot;hbd_interest_rate&quot;:300} true
```

then request some test hive via https://hivetestnetfaucet.org/

and power it up, this is important to do even if you already have hp. Because of the power up delay introduced in hf24, your initial HP don't have any effect:

`transfer_to_vesting &quot;yourusername&quot; &quot;yourusername&quot; &quot;10.000 TESTS&quot; true`

and finally vote for yourself so you get scheduled for blocks. If you don't have stake feel free to request some via https://hivetestnetfaucet.org/

`vote_for_witness &quot;yourusername&quot; &quot;yourusername&quot; true true`

and we are done with cli_wallet ! but not with the setup.

### final config

Open the config one final time to set yourself as a witness by adding these fields:

I use the private key that you generated with the cli above not the one that I put here. I put one here to show that you don't put quotes around the private key.
```
witness = &quot;yourusername&quot;

# WIF PRIVATE KEY to be used by one or more witnesses or miners
private-key = 5KJUxvUSdAV6H7LiutRJMVwEVptmoaDhM73Cg1itzYjG8zs7tWF
```

restart the node and you should be producing blocks, the logs should look something like this:

```
3|hf23     | 2687621ms p2p_plugin.cpp:212            handle_block         ] Got 0 transactions on block 4595 by howo -- Block Time Offset: -378 ms
3|hf23     | 2690613ms witness_plugin.cpp:343        block_production_loo ] Generated block #4596 with timestamp 2020-08-25T19:44:51 at time 2020-08-25T19:44:51
```

## Seed node

Go the extra mile and setup a seed node ! this is quite important as the testnet have very few seed nodes, so it helps a lot if you make one.

Your node is already configured to be a seed node so you just need to open the corresponding port:
(note that this command may vary depending on the firewall setup of your computer)
```
sudo iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 2001 -j ACCEPT
```

And now you can communicate the new seed node to everyone. Please post your ip as a comment of that post so that I can update this link to use your seed as well :).

Thank you for reading.

If you liked this writeup, please consider voting for @steempress it's the witness that I co-manage with @fredrikaa:
![](https://i.imgur.com/oPJ63jA.png)
&lt;center&gt;&lt;sup&gt;You can vote for our witness directly using Hivesigner &lt;a href=&quot;https://hivesigner.com/sign/account-witness-vote?witness=steempress&amp;amp;approve=1&quot;&gt;here&lt;/a&gt;.&lt;/sup&gt;&lt;/center&gt;&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@howo&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/how-to-run-a-witness-node-on-the-hf25-testnet&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-howo-how-to-run-a-witness-node-on-the-hf25-testnet').html();
      const outputElem = $('#content-howo-how-to-run-a-witness-node-on-the-hf25-testnet');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet code {
    background: white;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet a:hover {
    border-bottom: 0;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet h1 {
    font-size: 2.2em;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet header small {
    color: #999;
    font-size: 50%;
  }
  #content-howo-how-to-run-a-witness-node-on-the-hf25-testnet img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/guide/@howo/how-to-run-a-witness-node-on-the-hf25-testnet&quot;&gt;How to run a witness node on the hf25 testnet&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@howo&quot;&gt;@howo&lt;/a&gt;
&lt;/p&gt;</content><author><name>howo</name></author><category term="howto" /><category term="witness" /><category term="testnet" /><summary type="html">![image.png](https://files.peakd.com/file/peakd-hive/howo/23xe7eZsnrPcykgbjNqyAudjuQ8nfGfqRzVCpTShns5vRs2J9gcknbewso9v32YFhw54x.png) Hi ! the testnet phase for HF25 is now in full swing, here's some info on it from @gtg https://peakd.com/@gtg/hf25-public-testnet-reloaded-rc2 One important thing to understand about the testnet is much more lightweight than the main net (because the chain is brand new) so you can actually get it running on a super small machine, to prove my point I'm going to write this tutorial using the 6$ a month doplet (1 core, 25gb storage) from digitalocean. I recommend ubuntu 18.04 LTS, 20.04 is also supported by hive but it can be more tricky depending on the versions of GCC+boost+cmake that are provided with it. If you participated in the last testnet you will find this guide very similar to the previous one https://peakd.com/hive/@howo/how-to-participate-in-the-tesntets-this-week-full-guide but I felt like making a new one was better than telling you &quot;follow the outdated guide and at step 35 do this instead&quot; ### step 1: Build hive or download binaries #### download binaries If you're on a low end hardware compiling may take a while, so it's faster to let someone compile the binaries for you so you can just run them instead. @gtg offers pre-built binaries at https://gtg.openhive.network/get/testnet/bin/ just download both hived and cli_wallet and you're good to go: ``` mkdir programs cd programs wget https://gtg.openhive.network/get/testnet/bin/cli_wallet-v1.25.0rc2 wget https://gtg.openhive.network/get/testnet/bin/hived-v1.25.0rc2 chmod +x * ``` This is a hassle-free solution but binaries may not always be available and it's generally better security-wise to compile it yourself. ### build hive If you are running on low end hardware like me, you will probably need to setup some swap to compile hive: https://linuxize.com/post/how-to-add-swap-space-on-ubuntu-18-04/ I personally added 16GB of swap. I don't know how much is actually needed I just figured that it would be enough, feel free to tell me in the comments if you experiment with it. Let's install the dependencies first: ``` apt-get install -y \ autoconf \ automake \ autotools-dev \ build-essential \ cmake \ doxygen \ git \ libboost-all-dev \ libyajl-dev \ libreadline-dev \ libssl-dev \ libtool \ liblz4-tool \ ncurses-dev \ python3 \ python3-dev \ python3-jinja2 \ python3-pip \ libgflags-dev \ libsnappy-dev \ zlib1g-dev \ libbz2-dev \ liblz4-dev \ libzstd-dev ``` Then get hive and compile it, change `v1.25.0rc2` to whatever is the current release tag, follow @gtg he is usually the one announcing the release notes, alternatively you can look on https://gitlab.syncad.com/hive/hive/-/tags and look at the most recent tags. ``` git clone git@gitlab.syncad.com:hive/hive.git cd hive git checkout v1.25.0rc2 git submodule update --init --recursive mkdir build cd build cmake -DENABLE_COVERAGE_TESTING=ON -DBUILD_HIVE_TESTNET=ON -DLOW_MEMORY_NODE=ON .. make -j$(nproc) hived cli_wallet ``` Compiling may take a while if you are on low end hardware it could take up to a few hours if not more, I forgot to measure it when I did it myself so 🤷‍. On high end hardware you can expect 3-5 minutes. ## Run the node I am using the directory structure and binary names that you get when you compile hive so straight copy paste may not work if you use binaries but everything else works the same you just have to use the right paths and right binary names. Run the node a few seconds and then exit hived like so `./programs/hive/hived -d testnet/` this will create a testnet directory with the default config file. open the config.ini file nano testnet/config.ini replace the config.ini with this one: ``` # tells the node which seeds he should listen to to get blocks p2p-seed-node = testnet.openhive.network:2001 # Local http endpoint for webserver requests. webserver-http-endpoint = 127.0.0.1:8090 # Local websocket endpoint for webserver requests. webserver-ws-endpoint =127.0.0.1:8091 log-appender = {&quot;appender&quot;:&quot;stderr&quot;,&quot;stream&quot;:&quot;std_error&quot;} log-logger = {&quot;name&quot;:&quot;default&quot;,&quot;level&quot;:&quot;info&quot;,&quot;appender&quot;:&quot;stderr&quot;} backtrace = yes plugin = webserver p2p json_rpc plugin = database_api condenser_api plugin = witness plugin = rc plugin = market_history plugin = market_history_api plugin = account_history_rocksdb plugin = account_history_api plugin = transaction_status plugin = transaction_status_api plugin = account_by_key plugin = account_by_key_api plugin = reputation plugin = reputation_api plugin = block_api network_broadcast_api rc_api account-history-rocksdb-path = &quot;blockchain/account-history-rocksdb-storage&quot; shared-file-size = 10G shared-file-full-threshold = 9500 shared-file-scale-rate = 1000 flush-state-interval = 0 market-history-bucket-size = [15,60,300,3600,86400] market-history-buckets-per-size = 5760 p2p-endpoint = 0.0.0.0:2001 transaction-status-block-depth = 64000 transaction-status-track-after-block = 46000000 webserver-thread-pool-size = 256 ``` Then run hived again, this time we want it to stay up so setup a way for it to persist even if you log out, like screen. I personally use pm2 for the testnets just because it's convenient. This is not optimal for a production setup but it's fine for those testnets. (see https://pm2.keymetrics.io/docs/usage/quick-start/) for the testnet I run hived like this with pm2: pm2 start --name testnet ./programs/hived/hived -- -d testnet It will take some time (a few minutes to a few hours) before you get your blocks. You can look at https://test.ausbit.dev/ to see what is the head block to get a sense of how far you are. When you are synched with the testnet and you should see messages like this: ``` 3|hf23 | 1526617ms p2p_plugin.cpp:212 handle_block ] Got 0 transactions on block 4415 by howo -- Block Time Offset: -382 ms 3|hf23 | 1532618ms p2p_plugin.cpp:212 handle_block ] Got 0 transactions on block 4416 by howo -- Block Time Offset: -381 ms 3|hf23 | 1538612ms p2p_plugin.cpp:212 handle_block ] Got 0 transactions on block 4417 by howo -- Block Time Offset: -387 ms 3|hf23 | 1544620ms p2p_plugin.cpp:212 handle_block ] Got 0 transactions on block 4418 by howo -- Block Time Offset: -379 ms 3|hf23 | 1550615ms p2p_plugin.cpp:212 handle_block ] Got 0 transactions on block 4419 by howo -- Block Time Offset: -384 ms ``` now your node is running ! So that's great, but it's not producing. So you need to setup your witness. ## Setting up your witness ### cli_wallet Open up the cli wallet: `./programs/cli_wallet/cli_wallet --server-rpc-endpoint=&quot;ws://127.0.0.1:8091&quot;` it'll ask for a password, so execute: `set_password yourpassword` then unlock it using: `unlock yourpassword` Now execute those commands: import your active key to do various actions, note that the keys on the testnet are the same than the keys on main net (they have been ported) so you can just use your account `import_key 5JNHfZYKGaomSFvd4NUdQ9qMcEAC43kujbfjueTHpVapX1Kzq2n` then generate keys for your witness: `suggest_brain_key` it'll be something like this: ``` { &quot;brain_priv_key&quot;: &quot;STRANGE ROADWAY TWASOME MOLER CENTIMO THOFT COMPORT VARIANT OUTSWIM EGGER SCRIBE GLAVER CROWDED DOLLIER AWNED DOPPER&quot;, &quot;wif_priv_key&quot;: &quot;5KJUxvUSdAV6H7LiutRJMVwEVptmoaDhM73Cg1itzYjG8zs7tWF&quot;, &quot;pub_key&quot;: &quot;TST71oeHrdBZEKDG1GaC75VKDaRGcXk2R8htD8J6wkP6p1zDRPzFZ&quot; } ``` Save these for later ! Then set yourself as a witness (notice how I used the pub_key generated above) ``` update_witness &quot;yourusername&quot; &quot;http://example.org&quot; &quot;TST71oeHrdBZEKDG1GaC75VKDaRGcXk2R8htD8J6wkP6p1zDRPzFZ&quot; {&quot;account_creation_fee&quot;:&quot;0.000 TESTS&quot;,&quot;maximum_block_size&quot;:65536,&quot;hbd_interest_rate&quot;:300} true ``` then request some test hive via https://hivetestnetfaucet.org/ and power it up, this is important to do even if you already have hp. Because of the power up delay introduced in hf24, your initial HP don't have any effect: `transfer_to_vesting &quot;yourusername&quot; &quot;yourusername&quot; &quot;10.000 TESTS&quot; true` and finally vote for yourself so you get scheduled for blocks. If you don't have stake feel free to request some via https://hivetestnetfaucet.org/ `vote_for_witness &quot;yourusername&quot; &quot;yourusername&quot; true true` and we are done with cli_wallet ! but not with the setup. ### final config Open the config one final time to set yourself as a witness by adding these fields: I use the private key that you generated with the cli above not the one that I put here. I put one here to show that you don't put quotes around the private key. ``` witness = &quot;yourusername&quot; # WIF PRIVATE KEY to be used by one or more witnesses or miners private-key = 5KJUxvUSdAV6H7LiutRJMVwEVptmoaDhM73Cg1itzYjG8zs7tWF ``` restart the node and you should be producing blocks, the logs should look something like this: ``` 3|hf23 | 2687621ms p2p_plugin.cpp:212 handle_block ] Got 0 transactions on block 4595 by howo -- Block Time Offset: -378 ms 3|hf23 | 2690613ms witness_plugin.cpp:343 block_production_loo ] Generated block #4596 with timestamp 2020-08-25T19:44:51 at time 2020-08-25T19:44:51 ``` ## Seed node Go the extra mile and setup a seed node ! this is quite important as the testnet have very few seed nodes, so it helps a lot if you make one. Your node is already configured to be a seed node so you just need to open the corresponding port: (note that this command may vary depending on the firewall setup of your computer) ``` sudo iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 2001 -j ACCEPT ``` And now you can communicate the new seed node to everyone. Please post your ip as a comment of that post so that I can update this link to use your seed as well :). Thank you for reading. If you liked this writeup, please consider voting for @steempress it's the witness that I co-manage with @fredrikaa: ![](https://i.imgur.com/oPJ63jA.png) You can vote for our witness directly using Hivesigner here. See: How to run a witness node on the hf25 testnet by @howo</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/howo/23xe7eZsnrPcykgbjNqyAudjuQ8nfGfqRzVCpTShns5vRs2J9gcknbewso9v32YFhw54x.png" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/howo/23xe7eZsnrPcykgbjNqyAudjuQ8nfGfqRzVCpTShns5vRs2J9gcknbewso9v32YFhw54x.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive SQL is ready for the hardfork 25</title><link href="https://hivedocs.info/news/sql/database/2021/05/31/hivesql-update-hardfork25.html" rel="alternate" type="text/html" title="Hive SQL is ready for the hardfork 25" /><published>2021-05-31T06:27:45-07:00</published><updated>2021-05-31T06:27:45-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/05/31/hivesql-update-hardfork25</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/05/31/hivesql-update-hardfork25.html">&lt;div id=&quot;content-arcange-hivesql-update-hardfork25&quot;&gt;![](https://i.imgur.com/IQw9dbJ.png)

The hardfork 25 (codename Equilibrium) should be activated in a few weeks. With these harfork will come many changes in the blockchain data which must obviously be passed on to HiveSQL.

Therfore HiveSQL has undergo a lot of updates to be prepared to the new specs and configuration of the blockchain after the hardfork.

Of course, all of these changes have been implemented in such a way as to minimize the impact on users, apps and processes relying on HiveSQL, which means... they shouldn't be affected at all!

## What's new?

Here is the list of all these changes.

### 1. New Operation tables

Two new operation tables and height virtual operation tables have been created to store the new virtual operations data.

* **TxCollateralizedConverts**

The `collateralized_convert` operation is similar to the `convert` operation and instructs the blockchain to convert HIVE to HBD. The operation is performed after a 3.5 days delay, but the owner gets HBD immediately. The price risk is cushioned by extra HIVE. After actual conversion takes place the excess HIVE is returned to the owner.
    
|Column|Description|
|-|-|
|owner|The account requesting the conversion|
|requestid|A request identifier|
|amount|The amount of HIVE to convert|
|amount_symbol|HIVE|

* **TxRecurrentTransfers**

The `recurrent_transfer` operation creates/updates/removes a recurrent transfer (Transfers any liquid asset every fixed amount of time from one account to another). If the amount is set to 0, the recurrent transfer is be deleted. If there is already a recurrent transfer matching from and to, the recurrent transfer is updated.
    
|Column|Description|
|-|-|
|from|Account to transfer an asset from|
|to|Account to transfer an asset to|
|amount|The amount of asset to transfer|
|amount_symbol|The symbol of the asset to transfer|
|memo|communication that accompanies the transfer. The memo is plain-text, any encryption on the memo is up to a higher-level protocol|
|recurrence|How often will the payment be triggered (hours)|
|executions|How many times the recurrent payment will be executed|
|extensions|reserved for future use|

### 2. New Virtual Operation tables

* **VOAccountCreateds**

This virtual operation is issued each time a new account has been successfully created.

|Column|Description|
|-|-|
|new_account_name|name of the newly created account|
|creator|name of the account creator|
|initial_vesting_shares|Amount of VESTS given to the created account|
|initial_vesting_shares_symbol|VESTS|
|initial_delegation|Amount of VESTS delegated if created with account_create_with_delegation|
|initial_delegation_symbol|VESTS|

* **VOChangedRecoveryAccounts**

This virtual operation is issued when the blockchain effectively changes the recovery account of an account after it issued such a request.

|Column|Description|
|-|-|
|account|account who changed its recovery account|
|old_recovery_account|old recovery account|
|new_recovery_account|new recovery account|

* **VOCommentsVotes**

This virtual operation is issued when a vote on a post or comment becomes effective.

|Column|Description|
|-|-|
|voter|account performing the vote|
|author|author of the post or comment being voted|
|permlink|permlink of the post or comment being voted|
|weight|defines the score this vote receives, used by vote payout calc. 0 if a negative vote or changed votes|
|rshares|The number of rshares this vote is responsible for|
|total_vote_weight|the total weight of voting rewards. It is used to calculate the pro-rata share of curation payouts|
|pending_payout|potential payout of related comment at the moment of this vote|
|pending_payout_symbol|HBD|

* **VOExpiredAccountNotifications**

This virtual operation is issued when governance votes for an account have expired and are removed.

|Column|Description|
|-|-|
|account|Account for who governance votes have expired|

* **VOFailedRecurrentTransfers**

This virtual operation is issued when a recurrent transfer has failed to be executed.

|Column|Description|
|-|-|
|from|Account to transfer an asset from|
|to|Account to transfer an asset to|
|amount|The amount of asset to transfer|
|amount_symbol|The symbol of the asset to transfer|
|memo||
|consecutive_failures|How many times the recurrent payment failed to be executed|
|remaining_executions|How many times the recurrent payment should still be executed|
|deleted|Indicates that the recurrent transfer was deleted due to too many consecutive failures|

* **VOFillCollateralizedConvertRequests**

This virtual operation is issued when a HIVE to HBD conversion is completed.

|Column|Description|
|-|-|
|owner|Account requesting the conversion|
|requestid|conversion request identifier|
|amount_in|Amount of hive to be converted|
|amount_in_symbol|HIVE|
|amount_out|Amount of HBD to be received|
|amount_out_symbol|HBD|
|excess_collateral|excess HIVE returned to the owner|
|excess_collateral_symbol|HIVE|

* **VOFillRecurrentTransfers**

This virtual operation is issued when a recurrent transfer is executed.

|Column|Description|
|-|-|
|from|account sending assets|
|to|account receiving assets|
|amount|amount sent|
|amount_symbol|asset symbol|
|memo|a communication that accompanies the transfer. The memo is plain-text, any encryption on the memo is up to a higher-level protocol|
|remaining_executions|Number of remaining executions|

* **VOTransferToVestingCompleteds**

This virtual operation is issued when a power-up is finally taken into account for governance votes.

|Column|Description|
|-|-|
|from_account|account powering up HIVE|
|to_account|account receiving VESTS|
|hive_vested|amount of HIVE powered up|
|hive_vested_symbol|HIVE|
|vesting_shares_received|amount of VESTS received|
|vesting_shares_received_symbol|VESTS|

## Documentation

The HiveSQL documentation has been updated accordingly and can be viewed at https://docs.hivesql.io

## Support

If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT).

Thank you.

#### &lt;center&gt; &lt;/center&gt;
|&lt;center&gt;Support the HiveSQL proposal to keep it free for all&lt;/center&gt;|
|-|
|&lt;center&gt;[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/138)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)&lt;/center&gt;|

&lt;center&gt;

### Check out my apps and services
&lt;a href=&quot;/hive/@hive.engage/stay-connected-with-your-hive-audience-and-catch-attention&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GiNJqlm.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivebuzz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/B4UTun2.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivesql&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EPN8RW6.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/hive/@arcange/introducing-hive-account-recovery&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6TWeW7V.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hive.autoclaim&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ih2pEOw.png&quot; /&gt;&lt;/a&gt;&lt;/center&gt;
&lt;center&gt;

### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@arcange&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hivesql-update-hardfork25&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-arcange-hivesql-update-hardfork25').html();
      const outputElem = $('#content-arcange-hivesql-update-hardfork25');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-arcange-hivesql-update-hardfork25 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-arcange-hivesql-update-hardfork25 code {
    background: white;
  }
  #content-arcange-hivesql-update-hardfork25 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-arcange-hivesql-update-hardfork25 a:hover {
    border-bottom: 0;
  }
  #content-arcange-hivesql-update-hardfork25 h1 {
    font-size: 2.2em;
  }
  #content-arcange-hivesql-update-hardfork25 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-arcange-hivesql-update-hardfork25 header small {
    color: #999;
    font-size: 50%;
  }
  #content-arcange-hivesql-update-hardfork25 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@arcange/hivesql-update-hardfork25&quot;&gt;Hive SQL is ready for the hardfork 25&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@arcange&quot;&gt;@arcange&lt;/a&gt;
&lt;/p&gt;

&lt;/center&gt;&lt;/div&gt;</content><author><name>arcange</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![](https://i.imgur.com/IQw9dbJ.png) The hardfork 25 (codename Equilibrium) should be activated in a few weeks. With these harfork will come many changes in the blockchain data which must obviously be passed on to HiveSQL. Therfore HiveSQL has undergo a lot of updates to be prepared to the new specs and configuration of the blockchain after the hardfork. Of course, all of these changes have been implemented in such a way as to minimize the impact on users, apps and processes relying on HiveSQL, which means... they shouldn't be affected at all! ## What's new? Here is the list of all these changes. ### 1. New Operation tables Two new operation tables and height virtual operation tables have been created to store the new virtual operations data. * **TxCollateralizedConverts** The `collateralized_convert` operation is similar to the `convert` operation and instructs the blockchain to convert HIVE to HBD. The operation is performed after a 3.5 days delay, but the owner gets HBD immediately. The price risk is cushioned by extra HIVE. After actual conversion takes place the excess HIVE is returned to the owner. |Column|Description| |-|-| |owner|The account requesting the conversion| |requestid|A request identifier| |amount|The amount of HIVE to convert| |amount_symbol|HIVE| * **TxRecurrentTransfers** The `recurrent_transfer` operation creates/updates/removes a recurrent transfer (Transfers any liquid asset every fixed amount of time from one account to another). If the amount is set to 0, the recurrent transfer is be deleted. If there is already a recurrent transfer matching from and to, the recurrent transfer is updated. |Column|Description| |-|-| |from|Account to transfer an asset from| |to|Account to transfer an asset to| |amount|The amount of asset to transfer| |amount_symbol|The symbol of the asset to transfer| |memo|communication that accompanies the transfer. The memo is plain-text, any encryption on the memo is up to a higher-level protocol| |recurrence|How often will the payment be triggered (hours)| |executions|How many times the recurrent payment will be executed| |extensions|reserved for future use| ### 2. New Virtual Operation tables * **VOAccountCreateds** This virtual operation is issued each time a new account has been successfully created. |Column|Description| |-|-| |new_account_name|name of the newly created account| |creator|name of the account creator| |initial_vesting_shares|Amount of VESTS given to the created account| |initial_vesting_shares_symbol|VESTS| |initial_delegation|Amount of VESTS delegated if created with account_create_with_delegation| |initial_delegation_symbol|VESTS| * **VOChangedRecoveryAccounts** This virtual operation is issued when the blockchain effectively changes the recovery account of an account after it issued such a request. |Column|Description| |-|-| |account|account who changed its recovery account| |old_recovery_account|old recovery account| |new_recovery_account|new recovery account| * **VOCommentsVotes** This virtual operation is issued when a vote on a post or comment becomes effective. |Column|Description| |-|-| |voter|account performing the vote| |author|author of the post or comment being voted| |permlink|permlink of the post or comment being voted| |weight|defines the score this vote receives, used by vote payout calc. 0 if a negative vote or changed votes| |rshares|The number of rshares this vote is responsible for| |total_vote_weight|the total weight of voting rewards. It is used to calculate the pro-rata share of curation payouts| |pending_payout|potential payout of related comment at the moment of this vote| |pending_payout_symbol|HBD| * **VOExpiredAccountNotifications** This virtual operation is issued when governance votes for an account have expired and are removed. |Column|Description| |-|-| |account|Account for who governance votes have expired| * **VOFailedRecurrentTransfers** This virtual operation is issued when a recurrent transfer has failed to be executed. |Column|Description| |-|-| |from|Account to transfer an asset from| |to|Account to transfer an asset to| |amount|The amount of asset to transfer| |amount_symbol|The symbol of the asset to transfer| |memo|| |consecutive_failures|How many times the recurrent payment failed to be executed| |remaining_executions|How many times the recurrent payment should still be executed| |deleted|Indicates that the recurrent transfer was deleted due to too many consecutive failures| * **VOFillCollateralizedConvertRequests** This virtual operation is issued when a HIVE to HBD conversion is completed. |Column|Description| |-|-| |owner|Account requesting the conversion| |requestid|conversion request identifier| |amount_in|Amount of hive to be converted| |amount_in_symbol|HIVE| |amount_out|Amount of HBD to be received| |amount_out_symbol|HBD| |excess_collateral|excess HIVE returned to the owner| |excess_collateral_symbol|HIVE| * **VOFillRecurrentTransfers** This virtual operation is issued when a recurrent transfer is executed. |Column|Description| |-|-| |from|account sending assets| |to|account receiving assets| |amount|amount sent| |amount_symbol|asset symbol| |memo|a communication that accompanies the transfer. The memo is plain-text, any encryption on the memo is up to a higher-level protocol| |remaining_executions|Number of remaining executions| * **VOTransferToVestingCompleteds** This virtual operation is issued when a power-up is finally taken into account for governance votes. |Column|Description| |-|-| |from_account|account powering up HIVE| |to_account|account receiving VESTS| |hive_vested|amount of HIVE powered up| |hive_vested_symbol|HIVE| |vesting_shares_received|amount of VESTS received| |vesting_shares_received_symbol|VESTS| ## Documentation The HiveSQL documentation has been updated accordingly and can be viewed at https://docs.hivesql.io ## Support If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT). Thank you. #### |Support the HiveSQL proposal to keep it free for all| |-| |[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)[Vote for the proposal on Ecency](https://ecency.com/proposals/138)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)| ### Check out my apps and services ### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt; See: Hive SQL is ready for the hardfork 25 by @arcange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/IQw9dbJ.png" /><media:content medium="image" url="https://i.imgur.com/IQw9dbJ.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Updates to Hive.io</title><link href="https://hivedocs.info/news/projects/hive/2021/05/30/updates-to-hiveio.html" rel="alternate" type="text/html" title="Updates to Hive.io" /><published>2021-05-30T04:03:36-07:00</published><updated>2021-05-30T04:03:36-07:00</updated><id>https://hivedocs.info/news/projects/hive/2021/05/30/updates-to-hiveio</id><content type="html" xml:base="https://hivedocs.info/news/projects/hive/2021/05/30/updates-to-hiveio.html">&lt;div id=&quot;content-therealwolf-updates-to-hiveio&quot;&gt;
![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23wgiuoC5oSm54NFdpopv9SdzZjtdjhSonHUoJh6MLngntYMjXysbmrPjfVj3RHhzwTjz.png)

---


I've recently made some updates to hive.io.

This primarily includes:

- Upgraded Landing Page (https://hive.io)
- Upgraded Ecosystem Page (https://hive.io/eco)
- New Contributors Page (https://hive.io/contributors)
- New Updates Page (https://hive.io/updates)
- Upgraded Wallets Page (https://hive.io/wallets)

I want to thank @mahydiari and @good-karma for their input and feedback and ofc. everybody else who gave feedback.

There's still a bit more I've planned, mainly I want to redo the first part of the landing page (Fast, Scalable, Powerful. Hive Logo =&amp;gt; too generic, every blockchain project says that. Want to put focus on the fact that Hive made blockchain history i.e. https://twitter.com/lopp/status/1262786986013798400 and https://twitter.com/vitalikbuterin/status/1240605327122464768) but I'll need more time for planning/design.



## Contributors

I've first asked on [GitLab](https://gitlab.syncad.com/hive/hive-io/-/issues/15) who wants to be listed on there and got some fast replies, but then decided on at least adding TOP 30 Witnesses and those who are also actively working within the Hive ecosystem.

![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23z7X3CbQQda4oEQ4FuyNrxdY48L9nKiiZkg67hXJewHKFBVxiE8iAjfURNkixm6MKeRJ.png)

https://hive.io/contributors

---

Please let me know if:

- you don't want to be listed
- you want to be listed (see below)
- some data should be changed (optimally in this format https://gitlab.syncad.com/hive/hive-io/-/blob/develop/src/helpers/contributors.ts)
- you have ideas about more categories (like Core Dev, Marketing,..)

## Changing Data

Hive.io is open-source and you can also add apps/contributors yourself (technical). Checkout the Readme on GitLab: https://gitlab.syncad.com/hive/hive-io/-/blob/master/README.md

---

Have a nice Sunday!

Hive On
Wolf&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@therealwolf&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/updates-to-hiveio&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-therealwolf-updates-to-hiveio').html();
      const outputElem = $('#content-therealwolf-updates-to-hiveio');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-therealwolf-updates-to-hiveio {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-therealwolf-updates-to-hiveio code {
    background: white;
  }
  #content-therealwolf-updates-to-hiveio a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-therealwolf-updates-to-hiveio a:hover {
    border-bottom: 0;
  }
  #content-therealwolf-updates-to-hiveio h1 {
    font-size: 2.2em;
  }
  #content-therealwolf-updates-to-hiveio h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-therealwolf-updates-to-hiveio header small {
    color: #999;
    font-size: 50%;
  }
  #content-therealwolf-updates-to-hiveio img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-102930/@therealwolf/updates-to-hiveio&quot;&gt;Updates to Hive.io&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@therealwolf&quot;&gt;@therealwolf&lt;/a&gt;
&lt;/p&gt;</content><author><name>therealwolf</name></author><category term="news" /><category term="projects" /><category term="hive" /><summary type="html">![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23wgiuoC5oSm54NFdpopv9SdzZjtdjhSonHUoJh6MLngntYMjXysbmrPjfVj3RHhzwTjz.png) --- I've recently made some updates to hive.io. This primarily includes: - Upgraded Landing Page (https://hive.io) - Upgraded Ecosystem Page (https://hive.io/eco) - New Contributors Page (https://hive.io/contributors) - New Updates Page (https://hive.io/updates) - Upgraded Wallets Page (https://hive.io/wallets) I want to thank @mahydiari and @good-karma for their input and feedback and ofc. everybody else who gave feedback. There's still a bit more I've planned, mainly I want to redo the first part of the landing page (Fast, Scalable, Powerful. Hive Logo =&amp;gt; too generic, every blockchain project says that. Want to put focus on the fact that Hive made blockchain history i.e. https://twitter.com/lopp/status/1262786986013798400 and https://twitter.com/vitalikbuterin/status/1240605327122464768) but I'll need more time for planning/design. ## Contributors I've first asked on [GitLab](https://gitlab.syncad.com/hive/hive-io/-/issues/15) who wants to be listed on there and got some fast replies, but then decided on at least adding TOP 30 Witnesses and those who are also actively working within the Hive ecosystem. ![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23z7X3CbQQda4oEQ4FuyNrxdY48L9nKiiZkg67hXJewHKFBVxiE8iAjfURNkixm6MKeRJ.png) https://hive.io/contributors --- Please let me know if: - you don't want to be listed - you want to be listed (see below) - some data should be changed (optimally in this format https://gitlab.syncad.com/hive/hive-io/-/blob/develop/src/helpers/contributors.ts) - you have ideas about more categories (like Core Dev, Marketing,..) ## Changing Data Hive.io is open-source and you can also add apps/contributors yourself (technical). Checkout the Readme on GitLab: https://gitlab.syncad.com/hive/hive-io/-/blob/master/README.md --- Have a nice Sunday! Hive On Wolf See: Updates to Hive.io by @therealwolf</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/therealwolf/23wgiuoC5oSm54NFdpopv9SdzZjtdjhSonHUoJh6MLngntYMjXysbmrPjfVj3RHhzwTjz.png" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/therealwolf/23wgiuoC5oSm54NFdpopv9SdzZjtdjhSonHUoJh6MLngntYMjXysbmrPjfVj3RHhzwTjz.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">HF25 Public Testnet Reloaded (RC2)</title><link href="https://hivedocs.info/news/projects/testnet/2021/05/29/hf25-public-testnet-reloaded-rc2.html" rel="alternate" type="text/html" title="HF25 Public Testnet Reloaded (RC2)" /><published>2021-05-29T14:46:00-07:00</published><updated>2021-05-29T14:46:00-07:00</updated><id>https://hivedocs.info/news/projects/testnet/2021/05/29/hf25-public-testnet-reloaded-rc2</id><content type="html" xml:base="https://hivedocs.info/news/projects/testnet/2021/05/29/hf25-public-testnet-reloaded-rc2.html">&lt;div id=&quot;content-gtg-hf25-public-testnet-reloaded-rc2&quot;&gt;I just started brand new instance of a public Hive testnet based on `v1.25.0rc2`
https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0rc2

Re-initialization was needed due to changes in governance voting rules (rc1 would fork, because different rules impacts witness schedule):

```
witness.owner == scheduled_witness: Witness produced block at wrong time
    {&quot;block witness&quot;:&quot;gtg-rc1-10&quot;,&quot;scheduled&quot;:&quot;gtg-rc1-13&quot;,&quot;slot_num&quot;:1}
    database.cpp:4838 validate_block_header
```

Unless your account was created very recently, you should be able to participate in the testnet using your own mainnet account and keys (though please be careful, if you leak your key during testnet, your mainnet account will be compromised)

To get some tokens for testing you can use https://hivetestnetfaucet.org/ created by @howo or reach out to witnesses using your favorite communication channels such as https://openhive.chat ;-)

- Hive testnet chain-id: `18dcf0a285365fc58b71f18b3d3fec954aa0c141c44e4e5cb4cf777b9eab274e`
- Hive seed node: `p2p-seed-node = testnet.openhive.network:2001`
- API endpoint (via jussi): `https://testnet.openhive.network`
- Hive Testnet Condenser instance: https://testblog.openhive.network
- Hive Testnet Wallet instance: https://testwallet.openhive.network
- Binaries: https://gtg.openhive.network/get/testnet/bin/
- hived direct http server `http://testnet.openhive.network:8091`
- hived direct websocket server `ws://testnet.openhive.network:8090`
- hivemind server direct server `http://testnet.openhive.network:8080`

To join testnet with your hived, you need a testnet-enabled version, which you can get from here:
https://gtg.openhive.network/get/testnet/bin 
or build yourself (as usual plus `-DBUILD_HIVE_TESTNET=ON` during cmake step)

## See also
CyberBuzz Radio is LIVE: Community Q&amp;amp;A For the Upcoming Hive Blockchain Hardfork:
&lt;center&gt;https://www.youtube.com/watch?v=FtyhMAWto90&amp;amp;t=448s&lt;/center&gt;

(@hbdstabilizer as 50% beneficiary)&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@gtg&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hf25-public-testnet-reloaded-rc2&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-gtg-hf25-public-testnet-reloaded-rc2').html();
      const outputElem = $('#content-gtg-hf25-public-testnet-reloaded-rc2');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-gtg-hf25-public-testnet-reloaded-rc2 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 code {
    background: white;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 a:hover {
    border-bottom: 0;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 h1 {
    font-size: 2.2em;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 header small {
    color: #999;
    font-size: 50%;
  }
  #content-gtg-hf25-public-testnet-reloaded-rc2 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@gtg/hf25-public-testnet-reloaded-rc2&quot;&gt;HF25 Public Testnet Reloaded (RC2)&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@gtg&quot;&gt;@gtg&lt;/a&gt;
&lt;/p&gt;</content><author><name>gtg</name></author><category term="news" /><category term="projects" /><category term="testnet" /><summary type="html">I just started brand new instance of a public Hive testnet based on `v1.25.0rc2` https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0rc2 Re-initialization was needed due to changes in governance voting rules (rc1 would fork, because different rules impacts witness schedule): ``` witness.owner == scheduled_witness: Witness produced block at wrong time {&quot;block witness&quot;:&quot;gtg-rc1-10&quot;,&quot;scheduled&quot;:&quot;gtg-rc1-13&quot;,&quot;slot_num&quot;:1} database.cpp:4838 validate_block_header ``` Unless your account was created very recently, you should be able to participate in the testnet using your own mainnet account and keys (though please be careful, if you leak your key during testnet, your mainnet account will be compromised) To get some tokens for testing you can use https://hivetestnetfaucet.org/ created by @howo or reach out to witnesses using your favorite communication channels such as https://openhive.chat ;-) - Hive testnet chain-id: `18dcf0a285365fc58b71f18b3d3fec954aa0c141c44e4e5cb4cf777b9eab274e` - Hive seed node: `p2p-seed-node = testnet.openhive.network:2001` - API endpoint (via jussi): `https://testnet.openhive.network` - Hive Testnet Condenser instance: https://testblog.openhive.network - Hive Testnet Wallet instance: https://testwallet.openhive.network - Binaries: https://gtg.openhive.network/get/testnet/bin/ - hived direct http server `http://testnet.openhive.network:8091` - hived direct websocket server `ws://testnet.openhive.network:8090` - hivemind server direct server `http://testnet.openhive.network:8080` To join testnet with your hived, you need a testnet-enabled version, which you can get from here: https://gtg.openhive.network/get/testnet/bin or build yourself (as usual plus `-DBUILD_HIVE_TESTNET=ON` during cmake step) ## See also CyberBuzz Radio is LIVE: Community Q&amp;amp;A For the Upcoming Hive Blockchain Hardfork: https://www.youtube.com/watch?v=FtyhMAWto90&amp;amp;t=448s (@hbdstabilizer as 50% beneficiary) See: HF25 Public Testnet Reloaded (RC2) by @gtg</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/FtyhMAWto90/0.jpg" /><media:content medium="image" url="https://img.youtube.com/vi/FtyhMAWto90/0.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">13th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/05/25/13th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="13th update of 2021 on BlockTrades work on Hive software" /><published>2021-05-25T16:30:27-07:00</published><updated>2021-05-25T16:30:27-07:00</updated><id>https://hivedocs.info/news/core/development/2021/05/25/13th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/05/25/13th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by BlockTrades team during the last week or so:

# Hived work (blockchain node software)

We’re continuing to test and make fixes as a precursor to tagging a second release candidate for hived.

We’ve created a new python-based library currently called “testtools” for creating test scenarios for hived and hived’s CLI wallet. We’re replacing the beempy library that was previously used for this purpose in order to accelerate the speed at which the tests execute. 

For now, the primary purpose for this python library is testing hived, but it may have more general applicability as a library for communicating with hived, in which case we will rename it later to something more appropriate: 
https://gitlab.syncad.com/hive/hive/-/merge_requests/242

We created some unit-test based stress tests for the new recurrent transfers functionality, and initially we found some surprising results in terms of memory usage, but ultimately this was traced to a misconfiguration of the hived instance (it was configured with the deprecated chainbase account history plugin which is known to consume too much memory). With that plugin replaced by the rocksdb-account-history plugin, memory consumption and general performance was fine.

We also fixed some minor issues with the recurrent transfer operation: https://gitlab.syncad.com/hive/hive/-/merge_requests/246

We’ve added a few new network API calls to hived for getting peer count, getting connected peers, adding peers, and setting allowed peers. These functions were primarily added to facilitate testing scenarios (e.g. testing forking logic), but they can be useful to node operators as well: https://gitlab.syncad.com/hive/hive/-/merge_requests/244

We’ve added support for building with boost 1.70 (tested on Ubuntu 18 and 20).

We also modified the fc library to enable a simplified logging syntax. For example, instead of:
`ilog(“my variable=${my_variable}”,(“my_variable”,my_variable));`
you can simply use:
`ilog(“my variable=${my_variable}”,(my_variable));`
Note that the older syntax is still required when you need to call a function on the variable to get the value to log. The two syntaxes can be mixed-and-matched in a single log statement.

During our testing of the fix of the longstanding “duplicate operations in account history” bug, we found that this problem could also arise when the value of the last irreversible block was “undone” as part of the shutdown of hived (i.e. when a node operator presses Ctrl-C to shutdown the node). On a subsequent start, with the last irreversible block set to an earlier block, the code would re-add the operations from the already processed blocks. To fix this, we’re making sure the irreversible block number doesn’t get reverted by the database state undo operation anymore.

Once the above issue is fixed and tested in replay mode in conjunction with a full sync of hivemind, we’ll be tagging a second release candidate for the testnet (probably Thursday or Friday). Barring any unexpected issues during testnet testing, I expect that this will be our last release candidate before the official release, based on testing results so far.

# Hivemind (2nd layer applications + social media middleware)

Last week we’ve been making final fixes and doing performance tests in preparation for a new release of hivemind for API node operators later this week.

## Changing back to using pip for hivemind installation

We recently found that our current installation methodology for hivemind could lead to unexpected package versioning issues, so we’re switching back to using pip (python package installer) and pinning the versions of packages that hivemind uses.


## Performance testing and optimization for hivemind

While testing the develop branch of hivemind on our production API node (https://api.hive.blog), we noticed a slowdown in performance of the query `bridge_get_ranked_post_by_created_for_tag` (went from average of 64ms to nearly 2s average time). 

This problem was ultimately traced down to a lack of sufficient statistics being accumulated for the tags_ids column in the hive_posts table. The collected statistics weren’t sufficient to model the probability distribution of the tags used by posts, which resulted in the query planner selecting an under-performing query plan.

What’s interesting here is that this was a latent performance issue that could have potentially occurred on any given API node if it collected an unlucky statistical set (the problem wasn’t really a master vs develop branch issue). We fixed the issue by increasing the statistics collected for this column from 100 to 1000: 
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/503

## Hivemind memory consumption

We’re still researching potential ways to decrease the amount of memory consumed by the hivemind sync process over time. We’ve reduced memory consumption some, but more looks possible.

## Postgres 13 vs Postgres 10 for hivemind

During our search for a possible solution to the above problem (before we realized increasing statistics was the best solution), we also tried updating our SQL database from postgres 10 with postgres 13, to see if it would select a better query plan. 

The database upgrade had no impact on the above problem, but we found another slowdown during hive sync (the indexer that adds data from the blockchain to the database) tied to postgres 13. This problem occurs because the postgres13 planner incorrectly estimates the costs of updating rshare totals during ‘live sync’ and decides to do a just-in-time (jit) optimization which adds 100ms to the query time. 

We confirmed this was the issue by increasing the threshold cost required before the planner was allowed to employ jit optimization (effectively disabling jit usage in the query). In this scenario, performance was just slightly better for postgres 13 than for 10. Once we move to 13, we’ll need to select a long term solution for this issue (either improve the cost estimation or just disable jit for this query), but that’s an issue for a later day.

## Functional testing and fixes for hivemind

While working on fixes to community-related API calls, we also improved mock testing capabilities to verify the changes (mock testing allows us to generate “fake” data for testing purposes into an existing hivemind data set).
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/496

https://gitlab.syncad.com/hive/hivemind/-/merge_requests/499
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/501


# Modular hivemind (Application framework for Hive apps)

We’re currently building a sample application with the prototype for our modular hivemind framework that will support the account history API. Hopefully we’ll be able to perform a full test of this sample application by sometime next week.

# Condenser wallet

We’ve been doing some condenser wallet testing and bug fixing. We fixed a bug in the new feature by @quochuy that generates a CSV file with a user’s transaction history. The fix has been deployed to https://wallet.hive.blog.
https://gitlab.syncad.com/hive/wallet/-/merge_requests/106

# Testnet

We’ve had a few brave souls do some testing with the testnet, but I’d like to see a lot more, especially from users supporting Hive API libraries and Hive-based apps. 

But everyone is welcome to play around on the testnet and try to break things. As a regular Hive user, you can login with your normal credentials via:
https://testblog.openhive.network (hive.blog-like testing site)
or
https://testnet.peakd.com/ (peakd-like testing site)

You can also browse the testnet with this block explorer: https://test.ausbit.dev/ 

Going forward, the testnet should be the preferred vehicle for initial testing of Hive apps. And testing new features now, before the hardfork, helps us to identify areas where we may want to make changes to API responses, etc, before there’s an “official” API response that must then be changed later.

# Planned date for hardfork 25

I’m still projecting the hardfork will be in the last week of June.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/13th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/13th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;13th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by BlockTrades team during the last week or so: # Hived work (blockchain node software) We’re continuing to test and make fixes as a precursor to tagging a second release candidate for hived. We’ve created a new python-based library currently called “testtools” for creating test scenarios for hived and hived’s CLI wallet. We’re replacing the beempy library that was previously used for this purpose in order to accelerate the speed at which the tests execute. For now, the primary purpose for this python library is testing hived, but it may have more general applicability as a library for communicating with hived, in which case we will rename it later to something more appropriate: https://gitlab.syncad.com/hive/hive/-/merge_requests/242 We created some unit-test based stress tests for the new recurrent transfers functionality, and initially we found some surprising results in terms of memory usage, but ultimately this was traced to a misconfiguration of the hived instance (it was configured with the deprecated chainbase account history plugin which is known to consume too much memory). With that plugin replaced by the rocksdb-account-history plugin, memory consumption and general performance was fine. We also fixed some minor issues with the recurrent transfer operation: https://gitlab.syncad.com/hive/hive/-/merge_requests/246 We’ve added a few new network API calls to hived for getting peer count, getting connected peers, adding peers, and setting allowed peers. These functions were primarily added to facilitate testing scenarios (e.g. testing forking logic), but they can be useful to node operators as well: https://gitlab.syncad.com/hive/hive/-/merge_requests/244 We’ve added support for building with boost 1.70 (tested on Ubuntu 18 and 20). We also modified the fc library to enable a simplified logging syntax. For example, instead of: `ilog(“my variable=${my_variable}”,(“my_variable”,my_variable));` you can simply use: `ilog(“my variable=${my_variable}”,(my_variable));` Note that the older syntax is still required when you need to call a function on the variable to get the value to log. The two syntaxes can be mixed-and-matched in a single log statement. During our testing of the fix of the longstanding “duplicate operations in account history” bug, we found that this problem could also arise when the value of the last irreversible block was “undone” as part of the shutdown of hived (i.e. when a node operator presses Ctrl-C to shutdown the node). On a subsequent start, with the last irreversible block set to an earlier block, the code would re-add the operations from the already processed blocks. To fix this, we’re making sure the irreversible block number doesn’t get reverted by the database state undo operation anymore. Once the above issue is fixed and tested in replay mode in conjunction with a full sync of hivemind, we’ll be tagging a second release candidate for the testnet (probably Thursday or Friday). Barring any unexpected issues during testnet testing, I expect that this will be our last release candidate before the official release, based on testing results so far. # Hivemind (2nd layer applications + social media middleware) Last week we’ve been making final fixes and doing performance tests in preparation for a new release of hivemind for API node operators later this week. ## Changing back to using pip for hivemind installation We recently found that our current installation methodology for hivemind could lead to unexpected package versioning issues, so we’re switching back to using pip (python package installer) and pinning the versions of packages that hivemind uses. ## Performance testing and optimization for hivemind While testing the develop branch of hivemind on our production API node (https://api.hive.blog), we noticed a slowdown in performance of the query `bridge_get_ranked_post_by_created_for_tag` (went from average of 64ms to nearly 2s average time). This problem was ultimately traced down to a lack of sufficient statistics being accumulated for the tags_ids column in the hive_posts table. The collected statistics weren’t sufficient to model the probability distribution of the tags used by posts, which resulted in the query planner selecting an under-performing query plan. What’s interesting here is that this was a latent performance issue that could have potentially occurred on any given API node if it collected an unlucky statistical set (the problem wasn’t really a master vs develop branch issue). We fixed the issue by increasing the statistics collected for this column from 100 to 1000: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/503 ## Hivemind memory consumption We’re still researching potential ways to decrease the amount of memory consumed by the hivemind sync process over time. We’ve reduced memory consumption some, but more looks possible. ## Postgres 13 vs Postgres 10 for hivemind During our search for a possible solution to the above problem (before we realized increasing statistics was the best solution), we also tried updating our SQL database from postgres 10 with postgres 13, to see if it would select a better query plan. The database upgrade had no impact on the above problem, but we found another slowdown during hive sync (the indexer that adds data from the blockchain to the database) tied to postgres 13. This problem occurs because the postgres13 planner incorrectly estimates the costs of updating rshare totals during ‘live sync’ and decides to do a just-in-time (jit) optimization which adds 100ms to the query time. We confirmed this was the issue by increasing the threshold cost required before the planner was allowed to employ jit optimization (effectively disabling jit usage in the query). In this scenario, performance was just slightly better for postgres 13 than for 10. Once we move to 13, we’ll need to select a long term solution for this issue (either improve the cost estimation or just disable jit for this query), but that’s an issue for a later day. ## Functional testing and fixes for hivemind While working on fixes to community-related API calls, we also improved mock testing capabilities to verify the changes (mock testing allows us to generate “fake” data for testing purposes into an existing hivemind data set). https://gitlab.syncad.com/hive/hivemind/-/merge_requests/496 https://gitlab.syncad.com/hive/hivemind/-/merge_requests/499 https://gitlab.syncad.com/hive/hivemind/-/merge_requests/501 # Modular hivemind (Application framework for Hive apps) We’re currently building a sample application with the prototype for our modular hivemind framework that will support the account history API. Hopefully we’ll be able to perform a full test of this sample application by sometime next week. # Condenser wallet We’ve been doing some condenser wallet testing and bug fixing. We fixed a bug in the new feature by @quochuy that generates a CSV file with a user’s transaction history. The fix has been deployed to https://wallet.hive.blog. https://gitlab.syncad.com/hive/wallet/-/merge_requests/106 # Testnet We’ve had a few brave souls do some testing with the testnet, but I’d like to see a lot more, especially from users supporting Hive API libraries and Hive-based apps. But everyone is welcome to play around on the testnet and try to break things. As a regular Hive user, you can login with your normal credentials via: https://testblog.openhive.network (hive.blog-like testing site) or https://testnet.peakd.com/ (peakd-like testing site) You can also browse the testnet with this block explorer: https://test.ausbit.dev/ Going forward, the testnet should be the preferred vehicle for initial testing of Hive apps. And testing new features now, before the hardfork, helps us to identify areas where we may want to make changes to API responses, etc, before there’s an “official” API response that must then be changed later. # Planned date for hardfork 25 I’m still projecting the hardfork will be in the last week of June. See: 13th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive core developer meeting #24</title><link href="https://hivedocs.info/news/core/development/2021/05/25/hive-core-developer-meeting-24.html" rel="alternate" type="text/html" title="Hive core developer meeting #24" /><published>2021-05-25T10:03:27-07:00</published><updated>2021-05-25T10:03:27-07:00</updated><id>https://hivedocs.info/news/core/development/2021/05/25/hive-core-developer-meeting-24</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/05/25/hive-core-developer-meeting-24.html">&lt;div id=&quot;content-howo-hive-core-developer-meeting-24&quot;&gt;https://www.youtube.com/watch?v=pxUvrI0pyPs

Hi, 

This meeting was very focused on the testnet and it's operation and what was needed, if you are reading this and are a dapp creator, please test your app against the new testnet, or even better create a testnet version of your app, this testnet will keep on running after testing is over and if you are missing a tool to deploy your app, please tell us which.

meeting tl;dr:

### Dev sync

you should listen to that part

### Dynamic RC costs

We discussed a few solutions we have in mind to make RC costs more in line with the actual cost of an operation on the chain

### vop for instant hbd conversion when transferring hive to the dhf

Not discussed, postponed to a later meeting.


### support for new consensus changes in related libraries, who's down to do it ?

I volunteered to do it in hive-js, we need to speak with other maintainers to see who will do what.

### How is the public testing going for the  account expiration due to lack of governance activity ?

We realized the expiration was set to 20 days which is too much time, so we will soon update the testnet with a new version that includes some fixes and lowers it.



### have front ends been updated to include notifications about account expiration or at least presenting the expiration date ?

So far, no.

### What about testing recurrent transfer/proposal update publicly ? Best by using 3rd party libraries wrapping direct blockchain operations

That has been tested on my own testnets, but not on that testnet, I'm gonna run some tests on it later this week 

### We did internally test creating max. number of recurrent transfers for 10% accounts: 120000*255. Results show dramatic memory allocation (under investigation). Changes are here:
https://gitlab.syncad.com/hive/hive/-/tree/km_operation_tests_recurrent

We talked a bunch on this, the expected memory consumption was 8gb but ended up being 40 gb, we are not sure what is causing it but it could be that it's the nature of the testing environment that caused it and it wouldn't be reproduced in the real world, we are still investigating that part.

### Anyone [outside of Blocktrades group] tested new HBD conversion operation ?

No

### Anyone [outside of Blocktrades group] tested/analyzed new author/curator rewarding ?

No

^ on these last discussion points, there are a bunch of discussions on the gitlab issue that you can read here: https://gitlab.syncad.com/hive/tasks_without_projects_yet/-/issues/39

Have a nice day

@howo&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@howo&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-core-developer-meeting-24&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-howo-hive-core-developer-meeting-24').html();
      const outputElem = $('#content-howo-hive-core-developer-meeting-24');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-howo-hive-core-developer-meeting-24 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-howo-hive-core-developer-meeting-24 code {
    background: white;
  }
  #content-howo-hive-core-developer-meeting-24 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-howo-hive-core-developer-meeting-24 a:hover {
    border-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-24 h1 {
    font-size: 2.2em;
  }
  #content-howo-hive-core-developer-meeting-24 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-24 header small {
    color: #999;
    font-size: 50%;
  }
  #content-howo-hive-core-developer-meeting-24 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/meeting/@howo/hive-core-developer-meeting-24&quot;&gt;Hive core developer meeting #24&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@howo&quot;&gt;@howo&lt;/a&gt;
&lt;/p&gt;</content><author><name>howo</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">https://www.youtube.com/watch?v=pxUvrI0pyPs Hi, This meeting was very focused on the testnet and it's operation and what was needed, if you are reading this and are a dapp creator, please test your app against the new testnet, or even better create a testnet version of your app, this testnet will keep on running after testing is over and if you are missing a tool to deploy your app, please tell us which. meeting tl;dr: ### Dev sync you should listen to that part ### Dynamic RC costs We discussed a few solutions we have in mind to make RC costs more in line with the actual cost of an operation on the chain ### vop for instant hbd conversion when transferring hive to the dhf Not discussed, postponed to a later meeting. ### support for new consensus changes in related libraries, who's down to do it ? I volunteered to do it in hive-js, we need to speak with other maintainers to see who will do what. ### How is the public testing going for the account expiration due to lack of governance activity ? We realized the expiration was set to 20 days which is too much time, so we will soon update the testnet with a new version that includes some fixes and lowers it. ### have front ends been updated to include notifications about account expiration or at least presenting the expiration date ? So far, no. ### What about testing recurrent transfer/proposal update publicly ? Best by using 3rd party libraries wrapping direct blockchain operations That has been tested on my own testnets, but not on that testnet, I'm gonna run some tests on it later this week ### We did internally test creating max. number of recurrent transfers for 10% accounts: 120000*255. Results show dramatic memory allocation (under investigation). Changes are here: https://gitlab.syncad.com/hive/hive/-/tree/km_operation_tests_recurrent We talked a bunch on this, the expected memory consumption was 8gb but ended up being 40 gb, we are not sure what is causing it but it could be that it's the nature of the testing environment that caused it and it wouldn't be reproduced in the real world, we are still investigating that part. ### Anyone [outside of Blocktrades group] tested new HBD conversion operation ? No ### Anyone [outside of Blocktrades group] tested/analyzed new author/curator rewarding ? No ^ on these last discussion points, there are a bunch of discussions on the gitlab issue that you can read here: https://gitlab.syncad.com/hive/tasks_without_projects_yet/-/issues/39 Have a nice day @howo See: Hive core developer meeting #24 by @howo</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>