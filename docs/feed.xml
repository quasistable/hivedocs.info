<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://hivedocs.info/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hivedocs.info/" rel="alternate" type="text/html" /><updated>2021-03-13T11:55:05-08:00</updated><id>https://hivedocs.info/feed.xml</id><title type="html">Hive Chain Documentation</title><subtitle>Your resource for various levels of Hive Documentation.</subtitle><author><name>site curated by: @inertia</name></author><entry><title type="html">7th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/03/11/7th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="7th update of 2021 on BlockTrades work on Hive software" /><published>2021-03-11T12:25:42-08:00</published><updated>2021-03-11T12:25:42-08:00</updated><id>https://hivedocs.info/news/core/development/2021/03/11/7th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/03/11/7th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-7th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;Below is a brief list of Hive-related programming issues worked on by BlockTrades team during last week or so:

# Hived work (blockchain node software)

## SQL account history plugin for hived

We made some fixes to the SQL account history plugin to enable proper operation with hivemind sync process:
https://gitlab.syncad.com/hive/hive/-/merge_requests/173
https://gitlab.syncad.com/hive/hive/-/commits/bw_live_postgres_dump/
https://gitlab.syncad.com/hive/hive/-/merge_requests/177

 We still have one fix to avoid a potential foreign key violation during live sync (probably will be finished tomorrow).

## HF25 changes (these are described in detail in our [Hive roadmap post](https://hive.blog/hive-139531/@blocktrades/roadmap-for-hive-related-work-by-blocktrades-in-the-next-6-months))

We made some fixes and improvements to the code that handles expiration of governance votes (votes for witnesses and Hive Fund proposals): 
https://gitlab.syncad.com/hive/hive/-/merge_requests/174

We started work on voting window changes for HF25. We expect to finish implementation tomorrow, then we can begin testing.

## Miscellaneous hived changes

We made a fix related to removal of expired Hive Fund proposals: https://gitlab.syncad.com/hive/hive/-/merge_requests/176

We finished review of @howo merge requests. Two have been merged to develop and one is still under review:
https://gitlab.syncad.com/hive/hive/-/merge_requests/162
https://gitlab.syncad.com/hive/hive/-/merge_requests/169

We also fixed an intermittent issue with hived shutdown:
https://gitlab.syncad.com/hive/hive/-/merge_requests/157

We added some virtual ops to report various changes in state (mainly accounting-related) that weren’t previously reported: 
https://gitlab.syncad.com/hive/hive/-/merge_requests/167

Some changes to cleanup compile process: https://gitlab.syncad.com/hive/hive/-/merge_requests/172
Fix for proper testnet operation: https://gitlab.syncad.com/hive/hive/-/merge_requests/175

# Hivemind (2nd layer applications + social media middleware)

Fixed a problem in master branch that caused issues when upgrading an existing hivemind database: 
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/483

Fixed an issue with git version reporting: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/479

Added a comand-line option to log the time required for hive server to process API requests:
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/481

Some new tests for bridge API calls:
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/477

# Postgres extension for fork handling for Modular hivemind

One of the key challenges for modular hivemind (the upcoming 2nd layer application framework) is automated support of fork handling. Automated fork-handling will simplify design of 2nd layer apps so that they don't need to worry about fork-handling logic. 

Currently we’re experimenting with the use of a C-based postgres extension to help accomplish this task (we’re referring to this as the SQL change-audit extension). 

Last week we tested the prototype’s ability to recover the original state of an updated record in the database. Below are links to where this work is going on in the repo:
https://gitlab.syncad.com/hive/psql_tools/-/blob/mi_hive_fork_plugin/README.md
https://gitlab.syncad.com/hive/psql_tools/-/commits/mi_hive_fork_plugin&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/7th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-7th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-7th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-7th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-7th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-7th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-7th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-7th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-7th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-7th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-7th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/7th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;7th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">Below is a brief list of Hive-related programming issues worked on by BlockTrades team during last week or so: # Hived work (blockchain node software) ## SQL account history plugin for hived We made some fixes to the SQL account history plugin to enable proper operation with hivemind sync process: https://gitlab.syncad.com/hive/hive/-/merge_requests/173 https://gitlab.syncad.com/hive/hive/-/commits/bw_live_postgres_dump/ https://gitlab.syncad.com/hive/hive/-/merge_requests/177 We still have one fix to avoid a potential foreign key violation during live sync (probably will be finished tomorrow). ## HF25 changes (these are described in detail in our [Hive roadmap post](https://hive.blog/hive-139531/@blocktrades/roadmap-for-hive-related-work-by-blocktrades-in-the-next-6-months)) We made some fixes and improvements to the code that handles expiration of governance votes (votes for witnesses and Hive Fund proposals): https://gitlab.syncad.com/hive/hive/-/merge_requests/174 We started work on voting window changes for HF25. We expect to finish implementation tomorrow, then we can begin testing. ## Miscellaneous hived changes We made a fix related to removal of expired Hive Fund proposals: https://gitlab.syncad.com/hive/hive/-/merge_requests/176 We finished review of @howo merge requests. Two have been merged to develop and one is still under review: https://gitlab.syncad.com/hive/hive/-/merge_requests/162 https://gitlab.syncad.com/hive/hive/-/merge_requests/169 We also fixed an intermittent issue with hived shutdown: https://gitlab.syncad.com/hive/hive/-/merge_requests/157 We added some virtual ops to report various changes in state (mainly accounting-related) that weren’t previously reported: https://gitlab.syncad.com/hive/hive/-/merge_requests/167 Some changes to cleanup compile process: https://gitlab.syncad.com/hive/hive/-/merge_requests/172 Fix for proper testnet operation: https://gitlab.syncad.com/hive/hive/-/merge_requests/175 # Hivemind (2nd layer applications + social media middleware) Fixed a problem in master branch that caused issues when upgrading an existing hivemind database: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/483 Fixed an issue with git version reporting: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/479 Added a comand-line option to log the time required for hive server to process API requests: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/481 Some new tests for bridge API calls: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/477 # Postgres extension for fork handling for Modular hivemind One of the key challenges for modular hivemind (the upcoming 2nd layer application framework) is automated support of fork handling. Automated fork-handling will simplify design of 2nd layer apps so that they don't need to worry about fork-handling logic. Currently we’re experimenting with the use of a C-based postgres extension to help accomplish this task (we’re referring to this as the SQL change-audit extension). Last week we tested the prototype’s ability to recover the original state of an updated record in the database. Below are links to where this work is going on in the repo: https://gitlab.syncad.com/hive/psql_tools/-/blob/mi_hive_fork_plugin/README.md https://gitlab.syncad.com/hive/psql_tools/-/commits/mi_hive_fork_plugin See: 7th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive Account Recovery Update</title><link href="https://hivedocs.info/tools/2021/03/09/hive-account-recovery-update.html" rel="alternate" type="text/html" title="Hive Account Recovery Update" /><published>2021-03-09T10:19:12-08:00</published><updated>2021-03-09T10:19:12-08:00</updated><id>https://hivedocs.info/tools/2021/03/09/hive-account-recovery-update</id><content type="html" xml:base="https://hivedocs.info/tools/2021/03/09/hive-account-recovery-update.html">&lt;div id=&quot;content-arcange-hive-account-recovery-update&quot;&gt;&lt;center&gt;![](https://i.imgur.com/cBnUxCk.png)&lt;/center&gt;

Several months ago, I introduced Hive Recovery, a service that runs continuously and autonomously to help you recover your account if it were to be compromised.

For more information, I invite you to read the [introduction post](/hive/@arcange/introducing-hive-account-recovery).

Currently, many users have decided to define @hive.recovery as their recovery account and to date, none have yet had to use its services to recover it, which in itself is a good thing.

### One service with several working pieces

The services provided by @hive.recovery consist of two components:

1. The front-end

The front-end is a static HTML page that helps users to configure @hive.recovery as their recovery account. The front-end also helps to request @hive.recovery to initiate the recovery process

2. The back-end

The back-end is a javascript service running on a server that, upon request will verify the identity of an account and initiate the recovery process.

### Front-end improvements

I recently had to provide assistance to users who wanted to change their recovery account. No major issue, but it made me realize that there was still room for improvement, especially on the user interface part.

#### 1. Better error and edge case management

I first improved the error handling and fixed some small bugs regarding their notification.

I also added additional validations, among them the verification of the user's HIVE balance because the change request requires to have at least 0.001 HIVE available.

#### 2. New password and keys generator

I took the opportunity to add a feature intended for the recovery process itself: the possibility of generating a new password and keys.

Indeed, the recovery process requires you to provide your recovery account with the public owner key from a new password and keys set you previously generated for your account.

But to generate this new password and keys set, it was necessary to use an external service, and first to know where to find such a service. This is no longer necessary since this functionality is now directly integrated into the site.

![](https://i.imgur.com/cYYj2De.png)

If you do not have already generated a new password and keys set, you can do it by clicking the &quot;Generate new Password and Keys&quot; button. It will display a new dialog with a new randomly generated password and its related keys.

![](https://i.imgur.com/lFGHHr0.png)

After confirming you have saved your new credentials and clicked on &quot;Continue&quot;, it will automatically copy your new public owner key into the appropriate input field.

Of course, none of the displayed data is stored or transmitted. You can audit the source code that has been updated on [github](https://github.com/VIM-Arcange/hive-Recovery).

The [Hive Recovery User Guide](/hive/@hive.recovery/userguide), which contains all the details about this service has also been updated.

Little things that make your life easier.

---
&lt;center&gt;

### Check out my apps and services
&lt;a href=&quot;/hive/@hive.engage/stay-connected-with-your-hive-audience-and-catch-attention&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GiNJqlm.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivebuzz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/B4UTun2.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivesql&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EPN8RW6.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/hive/@arcange/introducing-hive-account-recovery&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6TWeW7V.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hive.autoclaim&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ih2pEOw.png&quot; /&gt;&lt;/a&gt;&lt;/center&gt;
&lt;center&gt;

### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@arcange&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-account-recovery-update&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-arcange-hive-account-recovery-update').html();
      const outputElem = $('#content-arcange-hive-account-recovery-update');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-arcange-hive-account-recovery-update {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-arcange-hive-account-recovery-update code {
    background: white;
  }
  #content-arcange-hive-account-recovery-update a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-arcange-hive-account-recovery-update a:hover {
    border-bottom: 0;
  }
  #content-arcange-hive-account-recovery-update h1 {
    font-size: 2.2em;
  }
  #content-arcange-hive-account-recovery-update h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-arcange-hive-account-recovery-update header small {
    color: #999;
    font-size: 50%;
  }
  #content-arcange-hive-account-recovery-update img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@arcange/hive-account-recovery-update&quot;&gt;Hive Account Recovery Update&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@arcange&quot;&gt;@arcange&lt;/a&gt;
&lt;/p&gt;

&lt;/center&gt;&lt;/div&gt;</content><author><name>arcange</name></author><category term="tools" /><summary type="html">![](https://i.imgur.com/cBnUxCk.png) Several months ago, I introduced Hive Recovery, a service that runs continuously and autonomously to help you recover your account if it were to be compromised. For more information, I invite you to read the [introduction post](/hive/@arcange/introducing-hive-account-recovery). Currently, many users have decided to define @hive.recovery as their recovery account and to date, none have yet had to use its services to recover it, which in itself is a good thing. ### One service with several working pieces The services provided by @hive.recovery consist of two components: 1. The front-end The front-end is a static HTML page that helps users to configure @hive.recovery as their recovery account. The front-end also helps to request @hive.recovery to initiate the recovery process 2. The back-end The back-end is a javascript service running on a server that, upon request will verify the identity of an account and initiate the recovery process. ### Front-end improvements I recently had to provide assistance to users who wanted to change their recovery account. No major issue, but it made me realize that there was still room for improvement, especially on the user interface part. #### 1. Better error and edge case management I first improved the error handling and fixed some small bugs regarding their notification. I also added additional validations, among them the verification of the user's HIVE balance because the change request requires to have at least 0.001 HIVE available. #### 2. New password and keys generator I took the opportunity to add a feature intended for the recovery process itself: the possibility of generating a new password and keys. Indeed, the recovery process requires you to provide your recovery account with the public owner key from a new password and keys set you previously generated for your account. But to generate this new password and keys set, it was necessary to use an external service, and first to know where to find such a service. This is no longer necessary since this functionality is now directly integrated into the site. ![](https://i.imgur.com/cYYj2De.png) If you do not have already generated a new password and keys set, you can do it by clicking the &quot;Generate new Password and Keys&quot; button. It will display a new dialog with a new randomly generated password and its related keys. ![](https://i.imgur.com/lFGHHr0.png) After confirming you have saved your new credentials and clicked on &quot;Continue&quot;, it will automatically copy your new public owner key into the appropriate input field. Of course, none of the displayed data is stored or transmitted. You can audit the source code that has been updated on [github](https://github.com/VIM-Arcange/hive-Recovery). The [Hive Recovery User Guide](/hive/@hive.recovery/userguide), which contains all the details about this service has also been updated. Little things that make your life easier. --- ### Check out my apps and services ### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt; See: Hive Account Recovery Update by @arcange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/cBnUxCk.png" /><media:content medium="image" url="https://i.imgur.com/cBnUxCk.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">6th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/03/02/6th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="6th update of 2021 on BlockTrades work on Hive software" /><published>2021-03-02T15:26:51-08:00</published><updated>2021-03-02T15:26:51-08:00</updated><id>https://hivedocs.info/news/core/development/2021/03/02/6th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/03/02/6th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-6th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;# Hived work (blockchain node software)


## SQL account history plugin

In the last week or so, we continued our work on the SQL account history plugin. 

Don’t be confused by the name of this plugin: while it can and will function as a very fast replacement for the rocksdb account history plugin, its primary purpose is to lay the foundation for “modular hivemind” (an application framework for 2nd layer applications).

We added support for resuming a hived replay configured with the SQL account history plugin. This support is also necessary for enabling the use of this plugin when operated in conjunction with a hivemind running in “live sync” mode. 

The SQL account history plugin also now populates the database with block and transaction signatures needed for get_block api calls.

Finally, we added code to drop/restore the SQL indexes associated with the account history data to enable faster hived replays (this can be useful, for example, if no hivemind sync is happening at the same time).

## Other work on hived

We reviewed recent changes in the hived code, which resulted in some code fixes and code reformats and new unit tests. We also did some preliminary reviews of current merge requests for hived.

# Modular Hivemind (2nd layer application framework)

## Syncing hivemind from SQL account history plugin databases

Hivemind can now run an “initial sync” directly from the postgres data generated by the SQL account history plugin. We repeated the “initial sync” of hivemind that died near the end during our previous test (running for 49.58M blocks) and confirmed that it takes just under 46 hours (just under two days). For comparison, a hivemind sync using the old “pull” process with all our other recent optimizations still took 61.2 hours.

The final database size for this test was: SQL account history-generated data (~1.1 TB) + hivemind sync-generated data (~0.5 TB) for a total size of 1.6 TB. 

## Experimenting with Postgres extensions for fork handling

One of the key challenges for modular hivemind is automated support of fork handling, to remove this burden from 2nd layer applications. Currently we’re experimenting with the use of C-based postgres extensions to help accomplish this task.

## Miscellaneous changes to hive sync

We eliminated use of some SQL constructs in hivemind sync that obtained exclusive locks on tables and therefore prevented database dumps from being run concurrently with a hivemind sync. Without this change, a hivemind server operator would need to temporarily disable his hivemind server in order to make a database backup.

## Official hivemind release v1.24.2

We completed testing of the develop branch, then merged all our latest work on hivemind to the master branch, tagged it as v1.24.2. 

We notified all API node operators that they should upgrade to v1.24.2 as soon as practical, as it contains not only optimizations and the exclusive lock fix, but also various bugfixes related to hivemind indexing and API responses.


# Condenser (https://hive.blog code base)

We finished fixing condenser bugs related to the follows, mutes, and decentralized lists, and deployed a new version of hive.blog with the fixes. At this point, we’ve completed and tested all work on decentralized lists.

# Plans for next week

On hived side, we’ll continue working on changes for HF25 (vote expiration for governance changes, curation vote window changes, merge request review, etc). Depending on how much time we have, we may take a look at the HBD interest code, now that witnesses are experimenting with enabling HBD interest payments. I’ve also considered adding a mechanism for helping to maintain the HBD peg if we have time. I’ll write a post about it if we make enough progress on other fronts in the next week or so that it seems feasible to fit the enhanced pegging mechanism into HF25.

For modular hivemind, we’ll continue to explore ways to automate fork-handling.

On the optimization front, we’re experimenting with python profiling to see if we can further reduce the time for a hivemind initial sync from SQL account history data. For a visualization tool, we’re using kcachegrind.

We also want to look at combining the process of replaying hived with the SQL account history plugin (which takes about 11 hours) while running a hivemind sync simultaneously (which takes 46 hours). Currently these process are running sequentially, which takes 11 + 46 = 57 hours. 

By running them concurrently, I believe we can reduce the overall time to nearly just the time of the hivemind sync (i.e. 46 hours currently). As a reminder, previously this process took 17 hours for a hived replay with rockdsb account history + about 96 hours for a hivemind sync, before we began optimizations of sync time.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/6th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-6th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-6th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-6th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-6th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-6th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-6th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-6th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-6th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-6th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-6th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/6th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;6th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html"># Hived work (blockchain node software) ## SQL account history plugin In the last week or so, we continued our work on the SQL account history plugin. Don’t be confused by the name of this plugin: while it can and will function as a very fast replacement for the rocksdb account history plugin, its primary purpose is to lay the foundation for “modular hivemind” (an application framework for 2nd layer applications). We added support for resuming a hived replay configured with the SQL account history plugin. This support is also necessary for enabling the use of this plugin when operated in conjunction with a hivemind running in “live sync” mode. The SQL account history plugin also now populates the database with block and transaction signatures needed for get_block api calls. Finally, we added code to drop/restore the SQL indexes associated with the account history data to enable faster hived replays (this can be useful, for example, if no hivemind sync is happening at the same time). ## Other work on hived We reviewed recent changes in the hived code, which resulted in some code fixes and code reformats and new unit tests. We also did some preliminary reviews of current merge requests for hived. # Modular Hivemind (2nd layer application framework) ## Syncing hivemind from SQL account history plugin databases Hivemind can now run an “initial sync” directly from the postgres data generated by the SQL account history plugin. We repeated the “initial sync” of hivemind that died near the end during our previous test (running for 49.58M blocks) and confirmed that it takes just under 46 hours (just under two days). For comparison, a hivemind sync using the old “pull” process with all our other recent optimizations still took 61.2 hours. The final database size for this test was: SQL account history-generated data (~1.1 TB) + hivemind sync-generated data (~0.5 TB) for a total size of 1.6 TB. ## Experimenting with Postgres extensions for fork handling One of the key challenges for modular hivemind is automated support of fork handling, to remove this burden from 2nd layer applications. Currently we’re experimenting with the use of C-based postgres extensions to help accomplish this task. ## Miscellaneous changes to hive sync We eliminated use of some SQL constructs in hivemind sync that obtained exclusive locks on tables and therefore prevented database dumps from being run concurrently with a hivemind sync. Without this change, a hivemind server operator would need to temporarily disable his hivemind server in order to make a database backup. ## Official hivemind release v1.24.2 We completed testing of the develop branch, then merged all our latest work on hivemind to the master branch, tagged it as v1.24.2. We notified all API node operators that they should upgrade to v1.24.2 as soon as practical, as it contains not only optimizations and the exclusive lock fix, but also various bugfixes related to hivemind indexing and API responses. # Condenser (https://hive.blog code base) We finished fixing condenser bugs related to the follows, mutes, and decentralized lists, and deployed a new version of hive.blog with the fixes. At this point, we’ve completed and tested all work on decentralized lists. # Plans for next week On hived side, we’ll continue working on changes for HF25 (vote expiration for governance changes, curation vote window changes, merge request review, etc). Depending on how much time we have, we may take a look at the HBD interest code, now that witnesses are experimenting with enabling HBD interest payments. I’ve also considered adding a mechanism for helping to maintain the HBD peg if we have time. I’ll write a post about it if we make enough progress on other fronts in the next week or so that it seems feasible to fit the enhanced pegging mechanism into HF25. For modular hivemind, we’ll continue to explore ways to automate fork-handling. On the optimization front, we’re experimenting with python profiling to see if we can further reduce the time for a hivemind initial sync from SQL account history data. For a visualization tool, we’re using kcachegrind. We also want to look at combining the process of replaying hived with the SQL account history plugin (which takes about 11 hours) while running a hivemind sync simultaneously (which takes 46 hours). Currently these process are running sequentially, which takes 11 + 46 = 57 hours. By running them concurrently, I believe we can reduce the overall time to nearly just the time of the hivemind sync (i.e. 46 hours currently). As a reminder, previously this process took 17 hours for a hived replay with rockdsb account history + about 96 hours for a hivemind sync, before we began optimizations of sync time. See: 6th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">JavaScript library for Ledger Nano S HIVE application</title><link href="https://hivedocs.info/howto/nano/nodejs/wallet/2021/03/02/javascript-library-for-ledger-nano-s-hive-application.html" rel="alternate" type="text/html" title="JavaScript library for Ledger Nano S HIVE application" /><published>2021-03-02T11:17:12-08:00</published><updated>2021-03-02T11:17:12-08:00</updated><id>https://hivedocs.info/howto/nano/nodejs/wallet/2021/03/02/javascript-library-for-ledger-nano-s-hive-application</id><content type="html" xml:base="https://hivedocs.info/howto/nano/nodejs/wallet/2021/03/02/javascript-library-for-ledger-nano-s-hive-application.html">&lt;div id=&quot;content-engrave-javascript-library-for-ledger-nano-s-hive-application&quot;&gt;![Incoming HIVE Ledger wallet](https://files.peakd.com/file/peakd-hive/engrave/EowF9ezqJkPjHhLKMx9NjA82sqpuhKVddGJHDgbd5zyo9TsVhKtGc1714xmomVXPeLL)


It's been a couple of months since @netuoso [published the initial version of the Hive Ledger App](https://hive.blog/hive-139531/@netuoso/hive-application-for-the-ledger-nano-s-x-hardware-wallet). In order to get official support from Ledger (i.e. the possibility to install it from Ledger Live), we need to meet several requirements. And I'm trying to fulfill them all so we could benefit from the hardware wallet support.

# Code review

First, we need to make sure that the application is stable and secure. I already made a preliminary review of the app and created a Pull Request with some fixes. The next step will be to review the code from a security perspective, following the guidelines provided by Ledger. This requires a bit more work and knowledge than validating transactions serialization etc, but we will get there.

 * https://github.com/netuoso/ledger-app-hive/pull/5/

# Javascript library

To simplify communication with the ledger app, I created a JavaScript/Typescript library. It's really easy to use it with NodeJS. The library covers every functionality supported by the app.

Example usage:

```typescript
import Hive from '@engrave/ledger-app-hive';
import TransportNodeHid from '@ledgerhq/hw-transport-node-hid';
import Transport from '@ledgerhq/hw-transport';

( async () =&amp;gt; {

    console.log('Unlock your ledger....');
    const transport = await TransportNodeHid.create();
    console.log(`Established connection with Ledger Nano S`);

    try {
        const hive = new Hive(transport);
        const {version, arbitraryData} = await hive.getAppConfiguration();
        console.log(&quot;Current version:&quot;, version);
        console.log(&quot;Arbitary data enabled:&quot;, arbitraryData);

        const publicKey = await hive.getPublicKey(`48'/13'/0'/0'/0'`);
        console.log(&quot;Public key:&quot;, publicKey);
    } catch (e) {
        console.error(e);
    }
    finally {
        transport.close();
    }

})();
```

## API

 * [getAppConfiguration](#getappconfiguration)
 * [getPublicKey](#getpublickey)
 * [signTransaction](#signtransaction) 

### getAppConfiguration

Get current configuration for HIVE App installed on a Ledger.

```typescript
async getAppConfiguration(): Promise&amp;lt;{version: string, arbitraryData: boolean}&amp;gt;
```

### getPublicKey

Retrieve public key from specified BIP32 path. You can set an additional parameter `confirm: boolean` which will ask the user to confirm the Public Key on his Ledger before returning it. 

```typescript
async getPublicKey(path: string, confirm?: boolean): Promise&amp;lt;{publicKey: string}&amp;gt; {
```

### signTransaction

Sign basic transactions with the specified key path. This method will return signed transactions (a transaction with additional `signatures` property). Please note that extensions are not yet supported for most transactions and operations (except `beneficiaries` for `comment_options`). 

```typescript
async signTransaction(tx: Transaction, path: string): Promise&lt;SignedTransaction&gt;
```

Please be aware that the current implementation of the HIVE Ledger App does not support multisig. This could be also a cool feature and we might add it someday. For now, let's focus on publishing it.

The library is open-source and available on Gitlab and NPM:
 * https://gitlab.com/engrave/ledger/ledger-app-hive

# Ledger Companion App

To prove that the application is working correctly, Ledger requires a sample Companion App. 

I prepared an initial design for a new wallet app and will start developing it soon. The plan is to make it as a wallet targeted at large stakeholders willing to invest in HIVE. It will be focused on governance (voting for witnesses and proposals) and the most significant chain news.

![It will be possible to create a new Hive account directly from app](https://files.peakd.com/file/peakd-hive/engrave/23wWk6s648pDWBsa1JoJunzjwiXRo9f49h5gbvBg2q65FmshLwjh7mpbHEcrqHRdQmJAg)

![Hive Ledger will display all significant parameters of your account](https://files.peakd.com/file/peakd-hive/engrave/23vsBhgnPDwTJcjG9YXJp5qfx6828bE9xVTzR6HsZW6XEskYJBs1bZoG99HkjsHBiau1W)

![It will be possible to vote on witnesses and perform other governance actions](https://files.peakd.com/file/peakd-hive/engrave/23wWnW3EENBacfW6UgsUncKqKVHKiQXRRNftBf1qpAp9GvXMJWu9x7ihqNU1wPktLyhdE)

Follow me to be up to date with incoming development updates!

***

&lt;center&gt;

**Click on the image to vote for @engrave witness:**

[![banner_engrave 100.png](https://images.hive.blog/DQmUghvic5TCPPvVkB4iB7eXmgQ3RQ4L8jkVizvuCBW8RMT/banner_engrave%20100.png)](https://hivesigner.com/sign/account-witness-vote?witness=engrave&amp;amp;approve=1)


&lt;/center&gt;
&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@engrave&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/javascript-library-for-ledger-nano-s-hive-application&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-engrave-javascript-library-for-ledger-nano-s-hive-application').html();
      const outputElem = $('#content-engrave-javascript-library-for-ledger-nano-s-hive-application');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-engrave-javascript-library-for-ledger-nano-s-hive-application {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-engrave-javascript-library-for-ledger-nano-s-hive-application code {
    background: white;
  }
  #content-engrave-javascript-library-for-ledger-nano-s-hive-application a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-engrave-javascript-library-for-ledger-nano-s-hive-application a:hover {
    border-bottom: 0;
  }
  #content-engrave-javascript-library-for-ledger-nano-s-hive-application h1 {
    font-size: 2.2em;
  }
  #content-engrave-javascript-library-for-ledger-nano-s-hive-application h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-engrave-javascript-library-for-ledger-nano-s-hive-application header small {
    color: #999;
    font-size: 50%;
  }
  #content-engrave-javascript-library-for-ledger-nano-s-hive-application img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@engrave/javascript-library-for-ledger-nano-s-hive-application&quot;&gt;JavaScript library for Ledger Nano S HIVE application&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@engrave&quot;&gt;@engrave&lt;/a&gt;
&lt;/p&gt;

&lt;/SignedTransaction&gt;&lt;/div&gt;</content><author><name>engrave</name></author><category term="howto" /><category term="nano" /><category term="nodejs" /><category term="wallet" /><summary type="html">![Incoming HIVE Ledger wallet](https://files.peakd.com/file/peakd-hive/engrave/EowF9ezqJkPjHhLKMx9NjA82sqpuhKVddGJHDgbd5zyo9TsVhKtGc1714xmomVXPeLL) It's been a couple of months since @netuoso [published the initial version of the Hive Ledger App](https://hive.blog/hive-139531/@netuoso/hive-application-for-the-ledger-nano-s-x-hardware-wallet). In order to get official support from Ledger (i.e. the possibility to install it from Ledger Live), we need to meet several requirements. And I'm trying to fulfill them all so we could benefit from the hardware wallet support. # Code review First, we need to make sure that the application is stable and secure. I already made a preliminary review of the app and created a Pull Request with some fixes. The next step will be to review the code from a security perspective, following the guidelines provided by Ledger. This requires a bit more work and knowledge than validating transactions serialization etc, but we will get there. * https://github.com/netuoso/ledger-app-hive/pull/5/ # Javascript library To simplify communication with the ledger app, I created a JavaScript/Typescript library. It's really easy to use it with NodeJS. The library covers every functionality supported by the app. Example usage: ```typescript import Hive from '@engrave/ledger-app-hive'; import TransportNodeHid from '@ledgerhq/hw-transport-node-hid'; import Transport from '@ledgerhq/hw-transport'; ( async () =&amp;gt; { console.log('Unlock your ledger....'); const transport = await TransportNodeHid.create(); console.log(`Established connection with Ledger Nano S`); try { const hive = new Hive(transport); const {version, arbitraryData} = await hive.getAppConfiguration(); console.log(&quot;Current version:&quot;, version); console.log(&quot;Arbitary data enabled:&quot;, arbitraryData); const publicKey = await hive.getPublicKey(`48'/13'/0'/0'/0'`); console.log(&quot;Public key:&quot;, publicKey); } catch (e) { console.error(e); } finally { transport.close(); } })(); ``` ## API * [getAppConfiguration](#getappconfiguration) * [getPublicKey](#getpublickey) * [signTransaction](#signtransaction) ### getAppConfiguration Get current configuration for HIVE App installed on a Ledger. ```typescript async getAppConfiguration(): Promise&amp;lt;{version: string, arbitraryData: boolean}&amp;gt; ``` ### getPublicKey Retrieve public key from specified BIP32 path. You can set an additional parameter `confirm: boolean` which will ask the user to confirm the Public Key on his Ledger before returning it. ```typescript async getPublicKey(path: string, confirm?: boolean): Promise&amp;lt;{publicKey: string}&amp;gt; { ``` ### signTransaction Sign basic transactions with the specified key path. This method will return signed transactions (a transaction with additional `signatures` property). Please note that extensions are not yet supported for most transactions and operations (except `beneficiaries` for `comment_options`). ```typescript async signTransaction(tx: Transaction, path: string): Promise ``` Please be aware that the current implementation of the HIVE Ledger App does not support multisig. This could be also a cool feature and we might add it someday. For now, let's focus on publishing it. The library is open-source and available on Gitlab and NPM: * https://gitlab.com/engrave/ledger/ledger-app-hive # Ledger Companion App To prove that the application is working correctly, Ledger requires a sample Companion App. I prepared an initial design for a new wallet app and will start developing it soon. The plan is to make it as a wallet targeted at large stakeholders willing to invest in HIVE. It will be focused on governance (voting for witnesses and proposals) and the most significant chain news. ![It will be possible to create a new Hive account directly from app](https://files.peakd.com/file/peakd-hive/engrave/23wWk6s648pDWBsa1JoJunzjwiXRo9f49h5gbvBg2q65FmshLwjh7mpbHEcrqHRdQmJAg) ![Hive Ledger will display all significant parameters of your account](https://files.peakd.com/file/peakd-hive/engrave/23vsBhgnPDwTJcjG9YXJp5qfx6828bE9xVTzR6HsZW6XEskYJBs1bZoG99HkjsHBiau1W) ![It will be possible to vote on witnesses and perform other governance actions](https://files.peakd.com/file/peakd-hive/engrave/23wWnW3EENBacfW6UgsUncKqKVHKiQXRRNftBf1qpAp9GvXMJWu9x7ihqNU1wPktLyhdE) Follow me to be up to date with incoming development updates! *** **Click on the image to vote for @engrave witness:** [![banner_engrave 100.png](https://images.hive.blog/DQmUghvic5TCPPvVkB4iB7eXmgQ3RQ4L8jkVizvuCBW8RMT/banner_engrave%20100.png)](https://hivesigner.com/sign/account-witness-vote?witness=engrave&amp;amp;approve=1) &amp;lt;/div&amp;gt; See: JavaScript library for Ledger Nano S HIVE application by @engrave</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/engrave/EowF9ezqJkPjHhLKMx9NjA82sqpuhKVddGJHDgbd5zyo9TsVhKtGc1714xmomVXPeLL" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/engrave/EowF9ezqJkPjHhLKMx9NjA82sqpuhKVddGJHDgbd5zyo9TsVhKtGc1714xmomVXPeLL" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hivesigner SDK rewritten in typescript</title><link href="https://hivedocs.info/news/nodejs/hivesigner/2021/02/27/hivesigner-sdk-rewritten-in-typescript.html" rel="alternate" type="text/html" title="Hivesigner SDK rewritten in typescript" /><published>2021-02-27T21:38:21-08:00</published><updated>2021-02-27T21:38:21-08:00</updated><id>https://hivedocs.info/news/nodejs/hivesigner/2021/02/27/hivesigner-sdk-rewritten-in-typescript</id><content type="html" xml:base="https://hivedocs.info/news/nodejs/hivesigner/2021/02/27/hivesigner-sdk-rewritten-in-typescript.html">&lt;div id=&quot;content-good-karma-hivesigner-sdk-rewritten-in-typescript&quot;&gt;Few days ago we have published new version of Hivesigner javascript SDK which is completely rewritten in Typescript with proper types, additional improvements on promises and written tests.

![hivesigner-development-secure-way-to-sign-in-blockchain](https://images.ecency.com/p/Y2iXpRRkNSnseh3NuL6KUBitJTXrc5K2vbTzBseGEENcE)  

Typescript implementation is clean and helps you to identify type of each parameters. If you are JS developer, you probably love this update because it helps you to write less buggy code. We have also written some tests to make sure each new update into library passes those tests. 

As a part of this update to `hivesigner`, we made minor changes into `hive-uri` package as well, which removes dependencies to old dsteem library.

New version of `hivesigner` package is x4 times smaller in size which means less addition to your website bundle, faster download for entire app in general. Shortly after release, we have made some improvements and better browser support, size x2 times smaller from legacy, still great. **Please note, however due to typescript change, you might have to check how you import library into your apps.**

![hivesigner-package-size](https://images.ecency.com/DQmVHtnik5iTniaH5k2ivQKcFkKZNMQAWVLHrKY5QtNcrhw/image.png)

Try new version `hivesigner@3.2.5` and let us know how it works on your apps. https://www.npmjs.com/package/hivesigner

If you are using `hive-uri` in your apps, consider updating that library as well. https://www.npmjs.com/package/hive-uri

Next in line is to optimise and finalise Hivesigner UI (website) changes and release update to website which will improve user experience.

## Support Hivesigner  
 
- [Read details of Hivesigner proposal](https://ecency.com/hive/@good-karma/hivesigner-ongoing-development-and-improvement)  
 
&lt;center&gt;  
[`Hivesigner proposal`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B88%5D&amp;amp;approve=true) | [`Hivesearcher proposal`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B114%5D&amp;amp;approve=true)  
[![Vote for @good-karma as a witness](https://images.ecency.com/p/o1AJ9qDyyJNSpZWhUgGYc3MngFqoAN2qn9AiTn8UpLP6Qb5TL?format=match&amp;amp;mode=fit)](https://hivesigner.com/sign/account-witness-vote?witness=good-karma&amp;amp;approve=1)  
&lt;/center&gt;&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@good-karma&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hivesigner-sdk-rewritten-in-typescript&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-good-karma-hivesigner-sdk-rewritten-in-typescript').html();
      const outputElem = $('#content-good-karma-hivesigner-sdk-rewritten-in-typescript');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-good-karma-hivesigner-sdk-rewritten-in-typescript {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-good-karma-hivesigner-sdk-rewritten-in-typescript code {
    background: white;
  }
  #content-good-karma-hivesigner-sdk-rewritten-in-typescript a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-good-karma-hivesigner-sdk-rewritten-in-typescript a:hover {
    border-bottom: 0;
  }
  #content-good-karma-hivesigner-sdk-rewritten-in-typescript h1 {
    font-size: 2.2em;
  }
  #content-good-karma-hivesigner-sdk-rewritten-in-typescript h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-good-karma-hivesigner-sdk-rewritten-in-typescript header small {
    color: #999;
    font-size: 50%;
  }
  #content-good-karma-hivesigner-sdk-rewritten-in-typescript img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://ecency.com/hive-139531/@good-karma/hivesigner-sdk-rewritten-in-typescript&quot;&gt;Hivesigner SDK rewritten in typescript&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@good-karma&quot;&gt;@good-karma&lt;/a&gt;
&lt;/p&gt;</content><author><name>good-karma</name></author><category term="news" /><category term="nodejs" /><category term="hivesigner" /><summary type="html">Few days ago we have published new version of Hivesigner javascript SDK which is completely rewritten in Typescript with proper types, additional improvements on promises and written tests. ![hivesigner-development-secure-way-to-sign-in-blockchain](https://images.ecency.com/p/Y2iXpRRkNSnseh3NuL6KUBitJTXrc5K2vbTzBseGEENcE) Typescript implementation is clean and helps you to identify type of each parameters. If you are JS developer, you probably love this update because it helps you to write less buggy code. We have also written some tests to make sure each new update into library passes those tests. As a part of this update to `hivesigner`, we made minor changes into `hive-uri` package as well, which removes dependencies to old dsteem library. New version of `hivesigner` package is x4 times smaller in size which means less addition to your website bundle, faster download for entire app in general. Shortly after release, we have made some improvements and better browser support, size x2 times smaller from legacy, still great. **Please note, however due to typescript change, you might have to check how you import library into your apps.** ![hivesigner-package-size](https://images.ecency.com/DQmVHtnik5iTniaH5k2ivQKcFkKZNMQAWVLHrKY5QtNcrhw/image.png) Try new version `hivesigner@3.2.5` and let us know how it works on your apps. https://www.npmjs.com/package/hivesigner If you are using `hive-uri` in your apps, consider updating that library as well. https://www.npmjs.com/package/hive-uri Next in line is to optimise and finalise Hivesigner UI (website) changes and release update to website which will improve user experience. ## Support Hivesigner - [Read details of Hivesigner proposal](https://ecency.com/hive/@good-karma/hivesigner-ongoing-development-and-improvement) [`Hivesigner proposal`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B88%5D&amp;amp;approve=true) | [`Hivesearcher proposal`](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=%5B114%5D&amp;amp;approve=true) [![Vote for @good-karma as a witness](https://images.ecency.com/p/o1AJ9qDyyJNSpZWhUgGYc3MngFqoAN2qn9AiTn8UpLP6Qb5TL?format=match&amp;amp;mode=fit)](https://hivesigner.com/sign/account-witness-vote?witness=good-karma&amp;amp;approve=1) See: Hivesigner SDK rewritten in typescript by @good-karma</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.ecency.com/DQmVHtnik5iTniaH5k2ivQKcFkKZNMQAWVLHrKY5QtNcrhw/image.png" /><media:content medium="image" url="https://images.ecency.com/DQmVHtnik5iTniaH5k2ivQKcFkKZNMQAWVLHrKY5QtNcrhw/image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive Devportal Update: SDK References, Python Tutorials</title><link href="https://hivedocs.info/news/documentation/2021/02/27/hive-devportal-update-sdk-references-python-tutorials.html" rel="alternate" type="text/html" title="Hive Devportal Update: SDK References, Python Tutorials" /><published>2021-02-27T12:13:12-08:00</published><updated>2021-02-27T12:13:12-08:00</updated><id>https://hivedocs.info/news/documentation/2021/02/27/hive-devportal-update-sdk-references-python-tutorials</id><content type="html" xml:base="https://hivedocs.info/news/documentation/2021/02/27/hive-devportal-update-sdk-references-python-tutorials.html">&lt;div id=&quot;content-inertia-hive-devportal-update-sdk-references-python-tutorials&quot;&gt;&lt;div class=&quot;pull-right&quot;&gt;
  &lt;img src=&quot;https://developers.hive.io/images/honey-comb-92.png&quot; /&gt;
&lt;/div&gt;

My proposal got approved this week, so I've been able to dedicate serious time to documentation.

##### SDK References

&lt;center&gt;&lt;img src=&quot;https://files.peakd.com/file/peakd-hive/inertia/se3yfj4k-image.png&quot; /&gt;&lt;/center&gt;

&lt;sup&gt;See: &lt;a href=&quot;https://developers.hive.io/apidefinitions/#database_api.list_escrows&quot;&gt;database_api.list_escrows&lt;/a&gt;&lt;/sup&gt;

We already have what amounts to a master list of API methods on the devportal, called API Definitions.  It's grouped by namespaces and functionality.  You can use this list to figure out what parameters are available for the SDK (software development kit) that you use.

From the standpoint of documentation, I'm referring to an SDK as a module, library, or dependency in your project that connects to the API for you.

Knowing the methods names and operations doesn't always correlate to the same method in your favorite SDK.  So I've added links from the API Definitions that points to a method in the SDK's documentation.

In addition to the methods you can call, the API Definitions also list the operations you can execute on the blockchain:

&lt;center&gt;&lt;img src=&quot;https://files.peakd.com/file/peakd-hive/inertia/VjfLDBS6-image.png&quot; /&gt;&lt;/center&gt;

&lt;sup&gt;See: &lt;a href=&quot;http://developers.hive.io/apidefinitions/#broadcast_ops_vote&quot;&gt;vote_operation&lt;/a&gt;&lt;/sup&gt;

As you can see, even more tools are available for operations like voting, primarily because the additional tools like hive-keychain and hivesigner.js perform these operations in the browser.

Related refs: [00c2fc45](https://gitlab.syncad.com/hive/devportal/-/commit/00c2fc45eb860c4f4574ce4817e387680ba06a9d), [45bc486d](https://gitlab.syncad.com/hive/devportal/-/commit/45bc486d5afdd93beec7170d4a617e2b4ddb42f7)

##### Python Tutorials

Previously, I did an audit on the Javascript Tutorials.  In the next update, I also have the Python Tutorials fully reviewed.  This process takes a while and I'm about one third of the way through, at the moment.

#### Tintoy

Because we don't have a testnet at the moment, it's important for developers to be able to deploy their own local testnet if they want to try out certain tutorials.

Of course, they can always just point their copy of the tutorial to the mainnet.  But it's nice to have the option of running a local testnet.

I've been maintaining the [testnet setup tutorials](https://developers.hive.io/search/?q=testnet) with that in mind, but if you have docker configured, you can deploy your local testnet using the following command:

```bash
docker run -d -P inertia/tintoy:latest
```

As it relates to the devportal, [tintoy](https://hub.docker.com/r/inertia/tintoy) can be an important tool for exploring Hive capabilities, so I've been maintaining the docker image on an ongoing basis by refreshing the image when there are major changes to `hived`.  Big thanks to @someguy123 for providing [hive-docker](https://github.com/Someguy123/hive-docker), which is key to allowing me to maintain the tintoy docker images.

---

If you'd like to vote for my current proposal:

[https://hivesigner.com/sign/update-proposal-votes?proposal_ids=[151]&amp;amp;approve=true](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=[151]&amp;amp;approve=true)

---

Also see: https://peakd.com/proposals/inertia&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@inertia&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-devportal-update-sdk-references-python-tutorials&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-inertia-hive-devportal-update-sdk-references-python-tutorials').html();
      const outputElem = $('#content-inertia-hive-devportal-update-sdk-references-python-tutorials');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-inertia-hive-devportal-update-sdk-references-python-tutorials {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-inertia-hive-devportal-update-sdk-references-python-tutorials code {
    background: white;
  }
  #content-inertia-hive-devportal-update-sdk-references-python-tutorials a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-inertia-hive-devportal-update-sdk-references-python-tutorials a:hover {
    border-bottom: 0;
  }
  #content-inertia-hive-devportal-update-sdk-references-python-tutorials h1 {
    font-size: 2.2em;
  }
  #content-inertia-hive-devportal-update-sdk-references-python-tutorials h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-inertia-hive-devportal-update-sdk-references-python-tutorials header small {
    color: #999;
    font-size: 50%;
  }
  #content-inertia-hive-devportal-update-sdk-references-python-tutorials img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@inertia/hive-devportal-update-sdk-references-python-tutorials&quot;&gt;Hive Devportal Update: SDK References, Python Tutorials&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@inertia&quot;&gt;@inertia&lt;/a&gt;
&lt;/p&gt;</content><author><name>inertia</name></author><category term="news" /><category term="documentation" /><summary type="html">My proposal got approved this week, so I've been able to dedicate serious time to documentation. ##### SDK References See: database_api.list_escrows We already have what amounts to a master list of API methods on the devportal, called API Definitions. It's grouped by namespaces and functionality. You can use this list to figure out what parameters are available for the SDK (software development kit) that you use. From the standpoint of documentation, I'm referring to an SDK as a module, library, or dependency in your project that connects to the API for you. Knowing the methods names and operations doesn't always correlate to the same method in your favorite SDK. So I've added links from the API Definitions that points to a method in the SDK's documentation. In addition to the methods you can call, the API Definitions also list the operations you can execute on the blockchain: See: vote_operation As you can see, even more tools are available for operations like voting, primarily because the additional tools like hive-keychain and hivesigner.js perform these operations in the browser. Related refs: [00c2fc45](https://gitlab.syncad.com/hive/devportal/-/commit/00c2fc45eb860c4f4574ce4817e387680ba06a9d), [45bc486d](https://gitlab.syncad.com/hive/devportal/-/commit/45bc486d5afdd93beec7170d4a617e2b4ddb42f7) ##### Python Tutorials Previously, I did an audit on the Javascript Tutorials. In the next update, I also have the Python Tutorials fully reviewed. This process takes a while and I'm about one third of the way through, at the moment. #### Tintoy Because we don't have a testnet at the moment, it's important for developers to be able to deploy their own local testnet if they want to try out certain tutorials. Of course, they can always just point their copy of the tutorial to the mainnet. But it's nice to have the option of running a local testnet. I've been maintaining the [testnet setup tutorials](https://developers.hive.io/search/?q=testnet) with that in mind, but if you have docker configured, you can deploy your local testnet using the following command: ```bash docker run -d -P inertia/tintoy:latest ``` As it relates to the devportal, [tintoy](https://hub.docker.com/r/inertia/tintoy) can be an important tool for exploring Hive capabilities, so I've been maintaining the docker image on an ongoing basis by refreshing the image when there are major changes to `hived`. Big thanks to @someguy123 for providing [hive-docker](https://github.com/Someguy123/hive-docker), which is key to allowing me to maintain the tintoy docker images. --- If you'd like to vote for my current proposal: [https://hivesigner.com/sign/update-proposal-votes?proposal_ids=[151]&amp;amp;approve=true](https://hivesigner.com/sign/update-proposal-votes?proposal_ids=[151]&amp;amp;approve=true) --- Also see: https://peakd.com/proposals/inertia See: Hive Devportal Update: SDK References, Python Tutorials by @inertia</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://developers.hive.io/images/honey-comb-92.png" /><media:content medium="image" url="https://developers.hive.io/images/honey-comb-92.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">JSON DOCTOR - An open source tool for broadcasting custom_json operations on hive</title><link href="https://hivedocs.info/tools/2021/02/24/json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive.html" rel="alternate" type="text/html" title="JSON DOCTOR - An open source tool for broadcasting custom_json operations on hive" /><published>2021-02-24T09:16:51-08:00</published><updated>2021-02-24T09:16:51-08:00</updated><id>https://hivedocs.info/tools/2021/02/24/json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive</id><content type="html" xml:base="https://hivedocs.info/tools/2021/02/24/json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive.html">&lt;div id=&quot;content-ali-h-json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive&quot;&gt;Would like to share one of my open source tools I developed a few months back. I usually have these sudden ideas out of nowhere about some ***possibly useful*** fun tools and projects. Most of the time it just stays in my *mind palace*.. uhm, but well, sometimes they are lucky &amp;amp; get turned into the ***indefinite unfinished projects***.

Anyways here's something that I've developed which could be useful for some individuals that like to mess &amp;amp; experiment with custom_jsons..

&lt;center&gt;[![image.png](https://files.peakd.com/file/peakd-hive/ali-h/VVQn7BFt-image.png)](https://jsondoctor.github.io/)&lt;/center&gt;

**JSON Doctor** is a simple, open source tool that allows you to broadcast custom_json operations on hive blockchain.

Website: https://jsondoctor.github.io/
Source Code: https://github.com/ali-h/jsonDoctor

Custom JSONs are awesome, they can be used to store data on blockchain to build a 2nd layer d-app. 

Since they are mostly used in development cases there isn't a single UI (in my knowledge) that lets you broadcast a ***&quot;custom&quot; json***, so to even learn about it you have to write some code, import some library to work with. So here I have a front-end that can be used to broadcast any valid JSON on the blockchain with active/posting authority.

You can use it with ***Hive Keychain*** or entering your private key (not suggested). It also has some JSON templates to play with which includes hive-engine and blog operations (follow/unfollow). 

This can also act like your gateway to interact with 2nd layers when a certain front-end is down or not accessible. For Example Transferring Hive-Engine tokens.

&lt;center&gt;![image.png](https://files.peakd.com/file/peakd-hive/ali-h/slvzmQ85-image.png)&lt;/center&gt;

I got with this really techy kinda theme, don't know how it came to my mind but I like like it! *I like raw themes*.

&lt;center&gt;![image.png](https://files.peakd.com/file/peakd-hive/ali-h/Lkq2138n-image.png)&lt;/center&gt;

There are also some options like changing the Auth type &amp;amp; RPC endpoint. It has a Log window that logs every change and transaction status.

&lt;center&gt;~ Full Page ~
&lt;center&gt;![image.png](https://files.peakd.com/file/peakd-hive/ali-h/aYpQrNYI-image.png)&lt;/center&gt;&lt;/center&gt;

---

I usually use it when I'm testing a script that streams blockchain for specific custom JSONs, it helps avoid writing and running a separate script to broadcast.

I had plans to include a json stream too but got very busy with other ~ ***side projects*** ~ so skipped on further development. maybe sometime later. If you've got something to include please [fork the GitHub repository](https://github.com/jsondoctor/jsondoctor.github.io/network/members) and open a PR. Thanks a lot! Feedback is appreciated.

## Contact me ^^
[Hive Profile](https://hive.blog/@ali-h)
[GitHub Profile](https://github.com/ali-h)
[Discord: Ali H#7057](https://discord.com/app)&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@ali-h&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-ali-h-json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive').html();
      const outputElem = $('#content-ali-h-json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-ali-h-json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-ali-h-json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive code {
    background: white;
  }
  #content-ali-h-json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-ali-h-json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive a:hover {
    border-bottom: 0;
  }
  #content-ali-h-json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive h1 {
    font-size: 2.2em;
  }
  #content-ali-h-json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-ali-h-json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive header small {
    color: #999;
    font-size: 50%;
  }
  #content-ali-h-json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@ali-h/json-doctor-an-open-source-tool-for-broadcasting-customjson-operations-on-hive&quot;&gt;JSON DOCTOR - An open source tool for broadcasting custom_json operations on hive&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@ali-h&quot;&gt;@ali-h&lt;/a&gt;
&lt;/p&gt;</content><author><name>ali-h</name></author><category term="tools" /><summary type="html">Would like to share one of my open source tools I developed a few months back. I usually have these sudden ideas out of nowhere about some ***possibly useful*** fun tools and projects. Most of the time it just stays in my *mind palace*.. uhm, but well, sometimes they are lucky &amp;amp; get turned into the ***indefinite unfinished projects***. Anyways here's something that I've developed which could be useful for some individuals that like to mess &amp;amp; experiment with custom_jsons.. [![image.png](https://files.peakd.com/file/peakd-hive/ali-h/VVQn7BFt-image.png)](https://jsondoctor.github.io/) **JSON Doctor** is a simple, open source tool that allows you to broadcast custom_json operations on hive blockchain. Website: https://jsondoctor.github.io/ Source Code: https://github.com/ali-h/jsonDoctor Custom JSONs are awesome, they can be used to store data on blockchain to build a 2nd layer d-app. Since they are mostly used in development cases there isn't a single UI (in my knowledge) that lets you broadcast a ***&quot;custom&quot; json***, so to even learn about it you have to write some code, import some library to work with. So here I have a front-end that can be used to broadcast any valid JSON on the blockchain with active/posting authority. You can use it with ***Hive Keychain*** or entering your private key (not suggested). It also has some JSON templates to play with which includes hive-engine and blog operations (follow/unfollow). This can also act like your gateway to interact with 2nd layers when a certain front-end is down or not accessible. For Example Transferring Hive-Engine tokens. ![image.png](https://files.peakd.com/file/peakd-hive/ali-h/slvzmQ85-image.png) I got with this really techy kinda theme, don't know how it came to my mind but I like like it! *I like raw themes*. ![image.png](https://files.peakd.com/file/peakd-hive/ali-h/Lkq2138n-image.png) There are also some options like changing the Auth type &amp;amp; RPC endpoint. It has a Log window that logs every change and transaction status. ~ Full Page ~ ![image.png](https://files.peakd.com/file/peakd-hive/ali-h/aYpQrNYI-image.png) --- I usually use it when I'm testing a script that streams blockchain for specific custom JSONs, it helps avoid writing and running a separate script to broadcast. I had plans to include a json stream too but got very busy with other ~ ***side projects*** ~ so skipped on further development. maybe sometime later. If you've got something to include please [fork the GitHub repository](https://github.com/jsondoctor/jsondoctor.github.io/network/members) and open a PR. Thanks a lot! Feedback is appreciated. ## Contact me ^^ [Hive Profile](https://hive.blog/@ali-h) [GitHub Profile](https://github.com/ali-h) [Discord: Ali H#7057](https://discord.com/app) See: JSON DOCTOR - An open source tool for broadcasting custom_json operations on hive by @ali-h</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/ali-h/VVQn7BFt-image.png" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/ali-h/VVQn7BFt-image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">5th update on BlockTrades’ Hive development progress</title><link href="https://hivedocs.info/news/core/development/2021/02/19/5th-update-on-blocktrades-hive-development-progress.html" rel="alternate" type="text/html" title="5th update on BlockTrades’ Hive development progress" /><published>2021-02-19T16:04:00-08:00</published><updated>2021-02-19T16:04:00-08:00</updated><id>https://hivedocs.info/news/core/development/2021/02/19/5th-update-on-blocktrades-hive-development-progress</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/02/19/5th-update-on-blocktrades-hive-development-progress.html">&lt;div id=&quot;content-blocktrades-5th-update-on-blocktrades-hive-development-progress&quot;&gt;# SQL account history plugin for modular hivemind

Lately our blockchain work has focused on the SQL account history plugin that injects operations, transactions, and block data into a PostgresSQL database (for use by modular hivemind apps such as wallets, games, etc).

We’ve been testing and fixing bugs related to this hived plugin and the associated hivemind sync. As mentioned last time, a replay of hived into hivemind takes 11 hours (as opposed to the 15 hours required by the rocksdb-based plugin, so we already have a decent win on replay time). 

We ran a hivemind sync using this data and it completed in 46 hours (just under 2 days), but unfortunately we had a fail near the end of the sync (probably due to use of a different hived to supply some dynamic API data not yet provided by the plugin), so we still don’t have definitive data on the speed of a full hivemind sync using this method, but I wouldn’t be surprised if we cut the time in half for a full hivemind sync (i.e. from 4 days down to 2 days or even less) by the time we’re done. I say this because we’ve found that the hivemind sync using this method is currently CPU bound (with about 2/3 of CPU being used by the python-based hivemind indexer and 1/3 being used by postgres), so I think we will be able to reduce the 46 hours after we’ve profiled the python code (and maybe the SQL code as well). My best guess right now is that we're CPU bound due to some data transformation prior to writing the data to the database.

# Performance results for SQL account history plugin

We’ve run some performance benchmarks using the new SQL account history plugin (versus the rocksdb account history plugin) with excellent performance gains resulting:

API call:  
`{&quot;jsonrpc&quot;:&quot;2.0&quot;, &quot;method&quot;:&quot;account_history_api.get_ops_in_block&quot;, &quot;params&quot;:{&quot;block_num&quot;:2889020,&quot;only_virtual&quot;:false}, &quot;id&quot;:1}`
ah-rocksdb: ranges from 26s to 64s
ah-sql: 0.9s

API call:
`{&quot;jsonrpc&quot;:&quot;2.0&quot;, &quot;method&quot;:&quot;account_history_api.get_account_history&quot;, &quot;params&quot;:{&quot;account&quot;:&quot;abit&quot;, &quot;start&quot;:125000, &quot;limit&quot;:1000}, &quot;id&quot;:1}`
ah-rocksdb: ranges from 0.3s to 1.2s
ah-sql: 0.03s

API call:
`{&quot;jsonrpc&quot;:&quot;2.0&quot;, &quot;method&quot;:&quot;account_history_api.enum_virtual_ops&quot;, &quot;params&quot;:{&quot;block_range_begin&quot;: 4000000, &quot;block_range_end&quot;: 4020000 }, &quot;id&quot;:1} `
ah-rocksdb: ranges from 36s to 45s
ah-sql: 0.8s

These gains are good enough that we should be able to eliminate the artificial 2000 operation lookback limit currently set on the get_account_history API call when filtering for specific operation types (assuming the node is configured to serve the data from the ah-sql plugin instead of the ah-rocksdb plugin, of course).

# Progress on modular hivemind

Now while the above sync and API response times represent substantial performance gains, that’s not the primary goal of this work. The primary goal is to support the creation of 2nd layer app development using “modular hivemind” deployments, allowing for the creation of unique hive-based apps that can scale to large numbers of users with real-time responsiveness.

The first step in the development of the modular hivemind technology was to validate swapping to a model where we directly inject blockchain data into hivemind’s PostgresSQL database, and as we can see from the benchmark data above, this work is going well. We’ve proved it has better performance and we were also able to switch from “pulling” the data from hived to having hived push the data to us using the existing hivemind indexer code with minor modifications.

The next step is a bit more challenging, design-wise: we plan to add support automatic handling of forks in the hivemind sync process. This will allow for modular hivemind apps to serve up data from the current headblock without any additional delay and cleanly revert whenever a micro-fork occurs (currently 2nd layer apps either have to accept a delay penalty or risk the chance for error if they don’t properly revert the state of their internal data in the case of a micro-fork). Modular hivemind application will gain a built-in micro-fork handler that automatically executes to undo the effects of blocks from the previous fork and replay blocks from the new fork in the case of a fork, eliminating the need for their developers to manually write code for fork handling. We’re currently looking into various algorithms for this fork handling logic and next we’ll be experimenting with some prototype implementations.

# Hivemind-based account history API

We also recently completed a python-based account history API that reuses the SQL queries that we developed for the hived SQL account history plugin (this could be used, for example, to reduce API loading on a hived instance). The performance of this API was roughly comparable to that of the ah-sql plugin, but preliminary performance tests show it a little slower (maybe 30% in some cases), probably due to more overhead during data conversions. Still this could be an acceptable tradeoff in some situations and we haven't done any tests in high load situations, where hivemind may perform better than hived.

# Hivemind API (2nd layer microservice for social media apps)

We fixed bugs and created new tests related to the follow code and decentralized lists and merged them to the develop branch (https://gitlab.syncad.com/hive/hivemind/-/merge_requests/396). 

We also merged in a few more remaining optimizations to hivemind queries: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/470

And created some more tests for community API calls: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/466

# Condenser and wallet (https://hive.blog)

We made one change to fix a bug related to decentralized lists:  https://gitlab.syncad.com/hive/condenser/-/merge_requests/209

We completed a preliminary review of vision (ecency code base) versus condesner (hive.blog code base). In general the vision code looks more up-to-date in terms of web technologies and libraries used, and the code is cleaner overall, but the vision code currently relies on too much closed-source APIs to operate it easily as a white-labeled application yet. So before we begin contributing to this work, we’re awaiting changes from @good-karma team.

# Near-term work plans and work in progress

We’ll continue working on modular hivemind code, with an emphasis in the next cycle on design of micro-fork handling logic. We’ll also continue tests and optimization of SQL account history plugin and hivemind sync process.

We began testing the current head of develop branch of hivemind (this contains follows and decentralized list fixes) on api.hive.blog today. If it performs well, we’ll merge it to master on Monday so that other API node operators can deploy it.

I’ve also given some thought in the last week to ways to improve the upward side of the HBD peg (when HBD goes above $1 USD).  I have one idea that looks relatively simple to implement that could probably be fit into HF25. I’ll write more about it later in a separate post in the Hive Improvements community so that there can be some discussion about the economic considerations involved.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/5th-update-on-blocktrades-hive-development-progress&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-5th-update-on-blocktrades-hive-development-progress').html();
      const outputElem = $('#content-blocktrades-5th-update-on-blocktrades-hive-development-progress');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-5th-update-on-blocktrades-hive-development-progress {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-5th-update-on-blocktrades-hive-development-progress code {
    background: white;
  }
  #content-blocktrades-5th-update-on-blocktrades-hive-development-progress a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-5th-update-on-blocktrades-hive-development-progress a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-5th-update-on-blocktrades-hive-development-progress h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-5th-update-on-blocktrades-hive-development-progress h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-5th-update-on-blocktrades-hive-development-progress header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-5th-update-on-blocktrades-hive-development-progress img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/5th-update-on-blocktrades-hive-development-progress&quot;&gt;5th update on BlockTrades' Hive development progress&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html"># SQL account history plugin for modular hivemind Lately our blockchain work has focused on the SQL account history plugin that injects operations, transactions, and block data into a PostgresSQL database (for use by modular hivemind apps such as wallets, games, etc). We’ve been testing and fixing bugs related to this hived plugin and the associated hivemind sync. As mentioned last time, a replay of hived into hivemind takes 11 hours (as opposed to the 15 hours required by the rocksdb-based plugin, so we already have a decent win on replay time). We ran a hivemind sync using this data and it completed in 46 hours (just under 2 days), but unfortunately we had a fail near the end of the sync (probably due to use of a different hived to supply some dynamic API data not yet provided by the plugin), so we still don’t have definitive data on the speed of a full hivemind sync using this method, but I wouldn’t be surprised if we cut the time in half for a full hivemind sync (i.e. from 4 days down to 2 days or even less) by the time we’re done. I say this because we’ve found that the hivemind sync using this method is currently CPU bound (with about 2/3 of CPU being used by the python-based hivemind indexer and 1/3 being used by postgres), so I think we will be able to reduce the 46 hours after we’ve profiled the python code (and maybe the SQL code as well). My best guess right now is that we're CPU bound due to some data transformation prior to writing the data to the database. # Performance results for SQL account history plugin We’ve run some performance benchmarks using the new SQL account history plugin (versus the rocksdb account history plugin) with excellent performance gains resulting: API call: `{&quot;jsonrpc&quot;:&quot;2.0&quot;, &quot;method&quot;:&quot;account_history_api.get_ops_in_block&quot;, &quot;params&quot;:{&quot;block_num&quot;:2889020,&quot;only_virtual&quot;:false}, &quot;id&quot;:1}` ah-rocksdb: ranges from 26s to 64s ah-sql: 0.9s API call: `{&quot;jsonrpc&quot;:&quot;2.0&quot;, &quot;method&quot;:&quot;account_history_api.get_account_history&quot;, &quot;params&quot;:{&quot;account&quot;:&quot;abit&quot;, &quot;start&quot;:125000, &quot;limit&quot;:1000}, &quot;id&quot;:1}` ah-rocksdb: ranges from 0.3s to 1.2s ah-sql: 0.03s API call: `{&quot;jsonrpc&quot;:&quot;2.0&quot;, &quot;method&quot;:&quot;account_history_api.enum_virtual_ops&quot;, &quot;params&quot;:{&quot;block_range_begin&quot;: 4000000, &quot;block_range_end&quot;: 4020000 }, &quot;id&quot;:1} ` ah-rocksdb: ranges from 36s to 45s ah-sql: 0.8s These gains are good enough that we should be able to eliminate the artificial 2000 operation lookback limit currently set on the get_account_history API call when filtering for specific operation types (assuming the node is configured to serve the data from the ah-sql plugin instead of the ah-rocksdb plugin, of course). # Progress on modular hivemind Now while the above sync and API response times represent substantial performance gains, that’s not the primary goal of this work. The primary goal is to support the creation of 2nd layer app development using “modular hivemind” deployments, allowing for the creation of unique hive-based apps that can scale to large numbers of users with real-time responsiveness. The first step in the development of the modular hivemind technology was to validate swapping to a model where we directly inject blockchain data into hivemind’s PostgresSQL database, and as we can see from the benchmark data above, this work is going well. We’ve proved it has better performance and we were also able to switch from “pulling” the data from hived to having hived push the data to us using the existing hivemind indexer code with minor modifications. The next step is a bit more challenging, design-wise: we plan to add support automatic handling of forks in the hivemind sync process. This will allow for modular hivemind apps to serve up data from the current headblock without any additional delay and cleanly revert whenever a micro-fork occurs (currently 2nd layer apps either have to accept a delay penalty or risk the chance for error if they don’t properly revert the state of their internal data in the case of a micro-fork). Modular hivemind application will gain a built-in micro-fork handler that automatically executes to undo the effects of blocks from the previous fork and replay blocks from the new fork in the case of a fork, eliminating the need for their developers to manually write code for fork handling. We’re currently looking into various algorithms for this fork handling logic and next we’ll be experimenting with some prototype implementations. # Hivemind-based account history API We also recently completed a python-based account history API that reuses the SQL queries that we developed for the hived SQL account history plugin (this could be used, for example, to reduce API loading on a hived instance). The performance of this API was roughly comparable to that of the ah-sql plugin, but preliminary performance tests show it a little slower (maybe 30% in some cases), probably due to more overhead during data conversions. Still this could be an acceptable tradeoff in some situations and we haven't done any tests in high load situations, where hivemind may perform better than hived. # Hivemind API (2nd layer microservice for social media apps) We fixed bugs and created new tests related to the follow code and decentralized lists and merged them to the develop branch (https://gitlab.syncad.com/hive/hivemind/-/merge_requests/396). We also merged in a few more remaining optimizations to hivemind queries: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/470 And created some more tests for community API calls: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/466 # Condenser and wallet (https://hive.blog) We made one change to fix a bug related to decentralized lists: https://gitlab.syncad.com/hive/condenser/-/merge_requests/209 We completed a preliminary review of vision (ecency code base) versus condesner (hive.blog code base). In general the vision code looks more up-to-date in terms of web technologies and libraries used, and the code is cleaner overall, but the vision code currently relies on too much closed-source APIs to operate it easily as a white-labeled application yet. So before we begin contributing to this work, we’re awaiting changes from @good-karma team. # Near-term work plans and work in progress We’ll continue working on modular hivemind code, with an emphasis in the next cycle on design of micro-fork handling logic. We’ll also continue tests and optimization of SQL account history plugin and hivemind sync process. We began testing the current head of develop branch of hivemind (this contains follows and decentralized list fixes) on api.hive.blog today. If it performs well, we’ll merge it to master on Monday so that other API node operators can deploy it. I’ve also given some thought in the last week to ways to improve the upward side of the HBD peg (when HBD goes above $1 USD). I have one idea that looks relatively simple to implement that could probably be fit into HF25. I’ll write more about it later in a separate post in the Hive Improvements community so that there can be some discussion about the economic considerations involved. See: 5th update on BlockTrades' Hive development progress by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">My new contributions to the Hive Condenser and Wallet apps.</title><link href="https://hivedocs.info/news/nodejs/condenser/2021/02/16/my-new-contributions-to-the-hive-condenser-and-wallet-apps.html" rel="alternate" type="text/html" title="My new contributions to the Hive Condenser and Wallet apps." /><published>2021-02-16T21:42:03-08:00</published><updated>2021-02-16T21:42:03-08:00</updated><id>https://hivedocs.info/news/nodejs/condenser/2021/02/16/my-new-contributions-to-the-hive-condenser-and-wallet-apps</id><content type="html" xml:base="https://hivedocs.info/news/nodejs/condenser/2021/02/16/my-new-contributions-to-the-hive-condenser-and-wallet-apps.html">&lt;div id=&quot;content-quochuy-my-new-contributions-to-the-hive-condenser-and-wallet-apps&quot;&gt;## Context
I have been involved (voluntarily) with the development of the Condenser &amp;amp; Wallet apps (that are powering https://hive.blog and https://wallet.hive.blog) for quite a while now. There are other great frontends to Hive out there such as https://peakd.com and https://ecency.com but I have always been more or less faithful with the Condenser.

This is a regular report on my new contributions. Some of the new work below might still be in test and not yet deployed.

## Delegation revoke bug fix
@ausbitbank raised this wallet issue where clicking on the `revoke` button on the delegation list on the wallet won't do anything. There was a typo in the code which was causing the feature fail to retrieve username of the delegator.
Merge request: https://gitlab.syncad.com/hive/wallet/-/merge_requests/95

## Redirect some URLS from Condenser to Wallet.
Another @ausbitbank request. The Condenser used to handle the `transfers` and `witnesses` pages, however, for security reasons, the Condenser was split into a second app, the Wallet. This new request was to redirect the URLs from the condenser to the wallet instead of erroring.

Merge request: https://gitlab.syncad.com/hive/condenser/-/merge_requests/207

## Alternate post author:
@themarkymark requested porting feature implemented on @peakd to the Condenser. Once this feature is deployed, you will be able to create a new post and specify the username of an author if it is different from the account you are using to submit the post.

![Alternate post author](https://images.hive.blog/DQmf2gw6tVD8jL4h5n5NhMj4VeEUBfm5Md3MpUTEDioE7nj/Screen%20Shot%202021-02-17%20at%202.38.47%20pm.jpg)

Merge request: https://gitlab.syncad.com/hive/condenser/-/merge_requests/208

---

**Vote for my witness**
[![Support @quochuy Witness.jpg](https://images.hive.blog/DQmecYTZemY8SwU6rrg7awhpNRBsehUp7ivk9RGyZsUUpVw/quochuy-hive-witness.jpg)](https://hivesigner.com/sign/account-witness-vote?witness=quochuy&amp;amp;approve=1)
On Hive, Witnesses are playing the important role of providing a performant and safe network for all of us. You have the power to choose 30 trusty witnesses to package transactions and sign the blocks that will go in the Hive blockchain. [Vote for me via HiveSigner](https://hivesigner.com/sign/account-witness-vote?witness=quochuy&amp;amp;approve=1) to support my work for the community.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@quochuy&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/my-new-contributions-to-the-hive-condenser-and-wallet-apps&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-quochuy-my-new-contributions-to-the-hive-condenser-and-wallet-apps').html();
      const outputElem = $('#content-quochuy-my-new-contributions-to-the-hive-condenser-and-wallet-apps');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-quochuy-my-new-contributions-to-the-hive-condenser-and-wallet-apps {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-quochuy-my-new-contributions-to-the-hive-condenser-and-wallet-apps code {
    background: white;
  }
  #content-quochuy-my-new-contributions-to-the-hive-condenser-and-wallet-apps a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-quochuy-my-new-contributions-to-the-hive-condenser-and-wallet-apps a:hover {
    border-bottom: 0;
  }
  #content-quochuy-my-new-contributions-to-the-hive-condenser-and-wallet-apps h1 {
    font-size: 2.2em;
  }
  #content-quochuy-my-new-contributions-to-the-hive-condenser-and-wallet-apps h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-quochuy-my-new-contributions-to-the-hive-condenser-and-wallet-apps header small {
    color: #999;
    font-size: 50%;
  }
  #content-quochuy-my-new-contributions-to-the-hive-condenser-and-wallet-apps img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@quochuy/my-new-contributions-to-the-hive-condenser-and-wallet-apps&quot;&gt;My new contributions to the Hive Condenser and Wallet apps.&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@quochuy&quot;&gt;@quochuy&lt;/a&gt;
&lt;/p&gt;</content><author><name>quochuy</name></author><category term="news" /><category term="nodejs" /><category term="condenser" /><summary type="html">## Context I have been involved (voluntarily) with the development of the Condenser &amp;amp; Wallet apps (that are powering https://hive.blog and https://wallet.hive.blog) for quite a while now. There are other great frontends to Hive out there such as https://peakd.com and https://ecency.com but I have always been more or less faithful with the Condenser. This is a regular report on my new contributions. Some of the new work below might still be in test and not yet deployed. ## Delegation revoke bug fix @ausbitbank raised this wallet issue where clicking on the `revoke` button on the delegation list on the wallet won't do anything. There was a typo in the code which was causing the feature fail to retrieve username of the delegator. Merge request: https://gitlab.syncad.com/hive/wallet/-/merge_requests/95 ## Redirect some URLS from Condenser to Wallet. Another @ausbitbank request. The Condenser used to handle the `transfers` and `witnesses` pages, however, for security reasons, the Condenser was split into a second app, the Wallet. This new request was to redirect the URLs from the condenser to the wallet instead of erroring. Merge request: https://gitlab.syncad.com/hive/condenser/-/merge_requests/207 ## Alternate post author: @themarkymark requested porting feature implemented on @peakd to the Condenser. Once this feature is deployed, you will be able to create a new post and specify the username of an author if it is different from the account you are using to submit the post. ![Alternate post author](https://images.hive.blog/DQmf2gw6tVD8jL4h5n5NhMj4VeEUBfm5Md3MpUTEDioE7nj/Screen%20Shot%202021-02-17%20at%202.38.47%20pm.jpg) Merge request: https://gitlab.syncad.com/hive/condenser/-/merge_requests/208 --- **Vote for my witness** [![Support @quochuy Witness.jpg](https://images.hive.blog/DQmecYTZemY8SwU6rrg7awhpNRBsehUp7ivk9RGyZsUUpVw/quochuy-hive-witness.jpg)](https://hivesigner.com/sign/account-witness-vote?witness=quochuy&amp;amp;approve=1) On Hive, Witnesses are playing the important role of providing a performant and safe network for all of us. You have the power to choose 30 trusty witnesses to package transactions and sign the blocks that will go in the Hive blockchain. [Vote for me via HiveSigner](https://hivesigner.com/sign/account-witness-vote?witness=quochuy&amp;amp;approve=1) to support my work for the community. See: My new contributions to the Hive Condenser and Wallet apps. by @quochuy</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmf2gw6tVD8jL4h5n5NhMj4VeEUBfm5Md3MpUTEDioE7nj/Screen%20Shot%202021-02-17%20at%202.38.47%20pm.jpg" /><media:content medium="image" url="https://images.hive.blog/DQmf2gw6tVD8jL4h5n5NhMj4VeEUBfm5Md3MpUTEDioE7nj/Screen%20Shot%202021-02-17%20at%202.38.47%20pm.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">4th update of 2021 on our Hive software work</title><link href="https://hivedocs.info/news/core/development/2021/02/06/4th-update-of-2021-on-our-hive-software-work.html" rel="alternate" type="text/html" title="4th update of 2021 on our Hive software work" /><published>2021-02-06T14:45:39-08:00</published><updated>2021-02-06T14:45:39-08:00</updated><id>https://hivedocs.info/news/core/development/2021/02/06/4th-update-of-2021-on-our-hive-software-work</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/02/06/4th-update-of-2021-on-our-hive-software-work.html">&lt;div id=&quot;content-blocktrades-4th-update-of-2021-on-our-hive-software-work&quot;&gt;# Hived work (blockchain node software)

Lately our blockchain work has focused on the hived plugin that injects operations, transactions, and block data into a PostgresSQL database (for use by modular hivemind apps such as wallets, games, etc). We’ve made solid progress since my last report on the this plugin.

We’ve never had a really great name for this plugin, but we may end up calling it the “SQL account history plugin” since it can, as a side benefit, effectively replace the rocksdb-based account history plugin. This is because this week we added API calls to the hived plugin so it that can serve up this postgres-stored data the same way that the rocksdb account history plugin does. In other words, a hived node operator can make use of this plugin even if they don’t operate a hivemind node, they just need to spin up a postgres database (although I still expect performance advantages for adding hivemind to the mix, as I discuss further below).

Performance was one of the primary drivers for this work, and performance results so far have been as good as I anticipated (but surprising to some of our more pessimistic devs). All API performance tests done so far show it to be equal or better in performance to the existing rocksdb plugin. 

The new plugin should really shine when it comes to operation history requests where filtering based on operation type is desirable (previously performance issues forced us to place limits on what a single API call of this type could request, and I hope we’ll be able to eliminate this limitation).

I believe we will be able to achieve even better results when we implement the account history API on hivemind itself rather than via hived, where I think serialization issues still slow down the results quite a lot on large data requests. For larger result queries, I think we could easily reduce response latency by 4x or more and these new calls should also be less costly in terms of CPU loading.

Both the hived-based API and the hivemind-based API will employ the same SQL queries, so we’ll be able to re-use much of this week’s work on the hived plugin when implementing account history API support inside hivemind.

## Some benchmark results from the SQL account history plugin

A full reindex of hived for 49 million blocks while running the SQL account history plugin took around 11 hours (as opposed to 15 hours for the rocksdb-based account history plugin). While this performance is already fairly impressive, there’s a reasonable chance we can still improve on this, with the absolute lower bound being the time required by a consensus-only replay (6 hours). 

It’s also important to note that while we’re comparing the re-index time to that of the old account history plugin as an example benchmark, one of primary goal for this work is to speedup the reindex time of hivemind (and other modular hivemind variants), which currently takes too long (~4 days).

So an even more interesting benchmark will be to compare how much faster hivemind reindexing will be using the SQL account history plugin. In the past week we completed the work in hivemind to swap away from pulling the hived data directly from hived to using the data pushed by the hived plugin, so we’ll be performing a full hivemind re-index on a Postgres database that has been pre-populated with 49M blocks worth of operations. It’s hard to predict exactly how long this new re-index process will take yet, but I’m very optimistic about the results.

The SQL account history plugin currently generates 967GB of storage when we run the 49M block reindex. This is more than 2x the size of rocksdb-based storage, but the data is being stored in more desirable forms that can be served up faster during API calls, and with much less CPU loading. This is also a bit of an unfair comparison, as we’re including data here on the SQL account history plugin side that previously had to also be stored in the hivemind database. 

We still don’t know what the final size of hivemind will be with this new data introduced, other than the upper cap at the current block height should be around 1.5TB. I expect to have an initial answer on this in the coming week after we complete the full hivemind sync test.

## Other work on hived

* We have one dev assigned to working on incorporating the accounting virtual ops code from the BlockTrades version of the hived code. That work will likely be completed in the coming week.

* We performed a preliminary review of the current state of the SMT code. Unfortunately, we found that the code was far from in a complete state (not only is much of it untested, there’s a fair amount that hasn’t yet been implemented). We have a partially complete report on the state of the C++ code for SMTs, if there’s any developers that would like to review it.

* We’re creating a new wallet_bridge_api_plugin to reduce future headaches associated with upgrading the command-line interface wallet when we make updates to hived’s API.

# Hivemind (2nd layer microservice for social media apps)

As mentioned above, we completed the work for enabling a hivemind sync operation to be performed from injected operations data instead of pulling the data from hived. We’re currently running functional and performance tests on this code.

We made another improvement to the speed of the hivemind initial sync process (we added threading support to the post initial sync process, just before “live sync” begins), but we had to fight our way through a few errors that this created along the way.

We also fixed a constraint problem that could occur when upgrading an existing hivemind database to use the latest code.

We’re currently fixing bugs related to the follow code and decentralized lists. A big part of this work is creating a comprehensive set of tests for both the old and new features. I expect we will complete that work this week. Next we will merge the current development branch of hivemind into the master branch and make an official Hivemind release for deployment by Hive API node operators (these are the node operators that serve up Hive data to the frontend applications).


There’s a known issue with testing system when it comes to measuring the performance of individual API calls, but we expect to fix it in the upcoming week. We’ve temporarily disabled the performance measurement code in the meantime to avoid false positive test fails.

# Condenser and wallet (https://hive.blog)

We completed testing and deployed new versions of hive.blog and the web wallet with the latest changes from our team and @quochuy.

I’ve also assigned a couple of UI devs to compare/contrast the current state and functionality of the code bases for ecency and hive.blog. 

# Near-term work plans and work in progress

On the hived side, we will continue to work on the governance changes discussed in our six-month roadmap post. With regards to the modular hivemind plugin, we have a few ideas we plan to try to further speedup the re-indexing process.

On hivemind side, we’ll continue work on tests and documentation and preparing the next release of hivemind after the follows code passes all the new tests.

We’ll also be continuing our work on modular hivemind. So far, I’m very pleased with our progress on this project and I’m optimistic about its use as a foundation for a smart-contract platform and other 2nd layer apps.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/4th-update-of-2021-on-our-hive-software-work&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-4th-update-of-2021-on-our-hive-software-work').html();
      const outputElem = $('#content-blocktrades-4th-update-of-2021-on-our-hive-software-work');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-4th-update-of-2021-on-our-hive-software-work {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-4th-update-of-2021-on-our-hive-software-work code {
    background: white;
  }
  #content-blocktrades-4th-update-of-2021-on-our-hive-software-work a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-4th-update-of-2021-on-our-hive-software-work a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-4th-update-of-2021-on-our-hive-software-work h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-4th-update-of-2021-on-our-hive-software-work h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-4th-update-of-2021-on-our-hive-software-work header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-4th-update-of-2021-on-our-hive-software-work img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive/@blocktrades/4th-update-of-2021-on-our-hive-software-work&quot;&gt;4th update of 2021 on our Hive software work&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html"># Hived work (blockchain node software) Lately our blockchain work has focused on the hived plugin that injects operations, transactions, and block data into a PostgresSQL database (for use by modular hivemind apps such as wallets, games, etc). We’ve made solid progress since my last report on the this plugin. We’ve never had a really great name for this plugin, but we may end up calling it the “SQL account history plugin” since it can, as a side benefit, effectively replace the rocksdb-based account history plugin. This is because this week we added API calls to the hived plugin so it that can serve up this postgres-stored data the same way that the rocksdb account history plugin does. In other words, a hived node operator can make use of this plugin even if they don’t operate a hivemind node, they just need to spin up a postgres database (although I still expect performance advantages for adding hivemind to the mix, as I discuss further below). Performance was one of the primary drivers for this work, and performance results so far have been as good as I anticipated (but surprising to some of our more pessimistic devs). All API performance tests done so far show it to be equal or better in performance to the existing rocksdb plugin. The new plugin should really shine when it comes to operation history requests where filtering based on operation type is desirable (previously performance issues forced us to place limits on what a single API call of this type could request, and I hope we’ll be able to eliminate this limitation). I believe we will be able to achieve even better results when we implement the account history API on hivemind itself rather than via hived, where I think serialization issues still slow down the results quite a lot on large data requests. For larger result queries, I think we could easily reduce response latency by 4x or more and these new calls should also be less costly in terms of CPU loading. Both the hived-based API and the hivemind-based API will employ the same SQL queries, so we’ll be able to re-use much of this week’s work on the hived plugin when implementing account history API support inside hivemind. ## Some benchmark results from the SQL account history plugin A full reindex of hived for 49 million blocks while running the SQL account history plugin took around 11 hours (as opposed to 15 hours for the rocksdb-based account history plugin). While this performance is already fairly impressive, there’s a reasonable chance we can still improve on this, with the absolute lower bound being the time required by a consensus-only replay (6 hours). It’s also important to note that while we’re comparing the re-index time to that of the old account history plugin as an example benchmark, one of primary goal for this work is to speedup the reindex time of hivemind (and other modular hivemind variants), which currently takes too long (~4 days). So an even more interesting benchmark will be to compare how much faster hivemind reindexing will be using the SQL account history plugin. In the past week we completed the work in hivemind to swap away from pulling the hived data directly from hived to using the data pushed by the hived plugin, so we’ll be performing a full hivemind re-index on a Postgres database that has been pre-populated with 49M blocks worth of operations. It’s hard to predict exactly how long this new re-index process will take yet, but I’m very optimistic about the results. The SQL account history plugin currently generates 967GB of storage when we run the 49M block reindex. This is more than 2x the size of rocksdb-based storage, but the data is being stored in more desirable forms that can be served up faster during API calls, and with much less CPU loading. This is also a bit of an unfair comparison, as we’re including data here on the SQL account history plugin side that previously had to also be stored in the hivemind database. We still don’t know what the final size of hivemind will be with this new data introduced, other than the upper cap at the current block height should be around 1.5TB. I expect to have an initial answer on this in the coming week after we complete the full hivemind sync test. ## Other work on hived * We have one dev assigned to working on incorporating the accounting virtual ops code from the BlockTrades version of the hived code. That work will likely be completed in the coming week. * We performed a preliminary review of the current state of the SMT code. Unfortunately, we found that the code was far from in a complete state (not only is much of it untested, there’s a fair amount that hasn’t yet been implemented). We have a partially complete report on the state of the C++ code for SMTs, if there’s any developers that would like to review it. * We’re creating a new wallet_bridge_api_plugin to reduce future headaches associated with upgrading the command-line interface wallet when we make updates to hived’s API. # Hivemind (2nd layer microservice for social media apps) As mentioned above, we completed the work for enabling a hivemind sync operation to be performed from injected operations data instead of pulling the data from hived. We’re currently running functional and performance tests on this code. We made another improvement to the speed of the hivemind initial sync process (we added threading support to the post initial sync process, just before “live sync” begins), but we had to fight our way through a few errors that this created along the way. We also fixed a constraint problem that could occur when upgrading an existing hivemind database to use the latest code. We’re currently fixing bugs related to the follow code and decentralized lists. A big part of this work is creating a comprehensive set of tests for both the old and new features. I expect we will complete that work this week. Next we will merge the current development branch of hivemind into the master branch and make an official Hivemind release for deployment by Hive API node operators (these are the node operators that serve up Hive data to the frontend applications). There’s a known issue with testing system when it comes to measuring the performance of individual API calls, but we expect to fix it in the upcoming week. We’ve temporarily disabled the performance measurement code in the meantime to avoid false positive test fails. # Condenser and wallet (https://hive.blog) We completed testing and deployed new versions of hive.blog and the web wallet with the latest changes from our team and @quochuy. I’ve also assigned a couple of UI devs to compare/contrast the current state and functionality of the code bases for ecency and hive.blog. # Near-term work plans and work in progress On the hived side, we will continue to work on the governance changes discussed in our six-month roadmap post. With regards to the modular hivemind plugin, we have a few ideas we plan to try to further speedup the re-indexing process. On hivemind side, we’ll continue work on tests and documentation and preparing the next release of hivemind after the follows code passes all the new tests. We’ll also be continuing our work on modular hivemind. So far, I’m very pleased with our progress on this project and I’m optimistic about its use as a foundation for a smart-contract platform and other 2nd layer apps. See: 4th update of 2021 on our Hive software work by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>