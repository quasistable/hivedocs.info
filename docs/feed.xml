<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://hivedocs.info/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hivedocs.info/" rel="alternate" type="text/html" /><updated>2021-05-27T10:32:47-07:00</updated><id>https://hivedocs.info/feed.xml</id><title type="html">Hive Chain Documentation</title><subtitle>Your resource for various levels of Hive Documentation.</subtitle><author><name>site curated by: @inertia</name></author><entry><title type="html">13th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/sql/database/2021/05/25/13th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="13th update of 2021 on BlockTrades work on Hive software" /><published>2021-05-25T16:30:27-07:00</published><updated>2021-05-25T16:30:27-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/05/25/13th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/05/25/13th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by BlockTrades team during the last week or so:

# Hived work (blockchain node software)

We’re continuing to test and make fixes as a precursor to tagging a second release candidate for hived.

We’ve created a new python-based library currently called “testtools” for creating test scenarios for hived and hived’s CLI wallet. We’re replacing the beempy library that was previously used for this purpose in order to accelerate the speed at which the tests execute. 

For now, the primary purpose for this python library is testing hived, but it may have more general applicability as a library for communicating with hived, in which case we will rename it later to something more appropriate: 
https://gitlab.syncad.com/hive/hive/-/merge_requests/242

We created some unit-test based stress tests for the new recurrent transfers functionality, and initially we found some surprising results in terms of memory usage, but ultimately this was traced to a misconfiguration of the hived instance (it was configured with the deprecated chainbase account history plugin which is known to consume too much memory). With that plugin replaced by the rocksdb-account-history plugin, memory consumption and general performance was fine.

We also fixed some minor issues with the recurrent transfer operation: https://gitlab.syncad.com/hive/hive/-/merge_requests/246

We’ve added a few new network API calls to hived for getting peer count, getting connected peers, adding peers, and setting allowed peers. These functions were primarily added to facilitate testing scenarios (e.g. testing forking logic), but they can be useful to node operators as well: https://gitlab.syncad.com/hive/hive/-/merge_requests/244

We’ve added support for building with boost 1.70 (tested on Ubuntu 18 and 20).

We also modified the fc library to enable a simplified logging syntax. For example, instead of:
`ilog(“my variable=${my_variable}”,(“my_variable”,my_variable));`
you can simply use:
`ilog(“my variable=${my_variable}”,(my_variable));`
Note that the older syntax is still required when you need to call a function on the variable to get the value to log. The two syntaxes can be mixed-and-matched in a single log statement.

During our testing of the fix of the longstanding “duplicate operations in account history” bug, we found that this problem could also arise when the value of the last irreversible block was “undone” as part of the shutdown of hived (i.e. when a node operator presses Ctrl-C to shutdown the node). On a subsequent start, with the last irreversible block set to an earlier block, the code would re-add the operations from the already processed blocks. To fix this, we’re making sure the irreversible block number doesn’t get reverted by the database state undo operation anymore.

Once the above issue is fixed and tested in replay mode in conjunction with a full sync of hivemind, we’ll be tagging a second release candidate for the testnet (probably Thursday or Friday). Barring any unexpected issues during testnet testing, I expect that this will be our last release candidate before the official release, based on testing results so far.

# Hivemind (2nd layer applications + social media middleware)

Last week we’ve been making final fixes and doing performance tests in preparation for a new release of hivemind for API node operators later this week.

## Changing back to using pip for hivemind installation

We recently found that our current installation methodology for hivemind could lead to unexpected package versioning issues, so we’re switching back to using pip (python package installer) and pinning the versions of packages that hivemind uses.


## Performance testing and optimization for hivemind

While testing the develop branch of hivemind on our production API node (https://api.hive.blog), we noticed a slowdown in performance of the query `bridge_get_ranked_post_by_created_for_tag` (went from average of 64ms to nearly 2s average time). 

This problem was ultimately traced down to a lack of sufficient statistics being accumulated for the tags_ids column in the hive_posts table. The collected statistics weren’t sufficient to model the probability distribution of the tags used by posts, which resulted in the query planner selecting an under-performing query plan.

What’s interesting here is that this was a latent performance issue that could have potentially occurred on any given API node if it collected an unlucky statistical set (the problem wasn’t really a master vs develop branch issue). We fixed the issue by increasing the statistics collected for this column from 100 to 1000: 
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/503

## Hivemind memory consumption

We’re still researching potential ways to decrease the amount of memory consumed by the hivemind sync process over time. We’ve reduced memory consumption some, but more looks possible.

## Postgres 13 vs Postgres 10 for hivemind

During our search for a possible solution to the above problem (before we realized increasing statistics was the best solution), we also tried updating our SQL database from postgres 10 with postgres 13, to see if it would select a better query plan. 

The database upgrade had no impact on the above problem, but we found another slowdown during hive sync (the indexer that adds data from the blockchain to the database) tied to postgres 13. This problem occurs because the postgres13 planner incorrectly estimates the costs of updating rshare totals during ‘live sync’ and decides to do a just-in-time (jit) optimization which adds 100ms to the query time. 

We confirmed this was the issue by increasing the threshold cost required before the planner was allowed to employ jit optimization (effectively disabling jit usage in the query). In this scenario, performance was just slightly better for postgres 13 than for 10. Once we move to 13, we’ll need to select a long term solution for this issue (either improve the cost estimation or just disable jit for this query), but that’s an issue for a later day.

## Functional testing and fixes for hivemind

While working on fixes to community-related API calls, we also improved mock testing capabilities to verify the changes (mock testing allows us to generate “fake” data for testing purposes into an existing hivemind data set).
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/496

https://gitlab.syncad.com/hive/hivemind/-/merge_requests/499
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/501


# Modular hivemind (Application framework for Hive apps)

We’re currently building a sample application with the prototype for our modular hivemind framework that will support the account history API. Hopefully we’ll be able to perform a full test of this sample application by sometime next week.

# Condenser wallet

We’ve been doing some condenser wallet testing and bug fixing. We fixed a bug in the new feature by @quochuy that generates a CSV file with a user’s transaction history. The fix has been deployed to https://wallet.hive.blog.
https://gitlab.syncad.com/hive/wallet/-/merge_requests/106

# Testnet

We’ve had a few brave souls do some testing with the testnet, but I’d like to see a lot more, especially from users supporting Hive API libraries and Hive-based apps. 

But everyone is welcome to play around on the testnet and try to break things. As a regular Hive user, you can login with your normal credentials via:
https://testblog.openhive.network (hive.blog-like testing site)
or
https://testnet.peakd.com/ (peakd-like testing site)

You can also browse the testnet with this block explorer: https://test.ausbit.dev/ 

Going forward, the testnet should be the preferred vehicle for initial testing of Hive apps. And testing new features now, before the hardfork, helps us to identify areas where we may want to make changes to API responses, etc, before there’s an “official” API response that must then be changed later.

# Planned date for hardfork 25

I’m still projecting the hardfork will be in the last week of June.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/13th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-13th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/13th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;13th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by BlockTrades team during the last week or so: # Hived work (blockchain node software) We’re continuing to test and make fixes as a precursor to tagging a second release candidate for hived. We’ve created a new python-based library currently called “testtools” for creating test scenarios for hived and hived’s CLI wallet. We’re replacing the beempy library that was previously used for this purpose in order to accelerate the speed at which the tests execute. For now, the primary purpose for this python library is testing hived, but it may have more general applicability as a library for communicating with hived, in which case we will rename it later to something more appropriate: https://gitlab.syncad.com/hive/hive/-/merge_requests/242 We created some unit-test based stress tests for the new recurrent transfers functionality, and initially we found some surprising results in terms of memory usage, but ultimately this was traced to a misconfiguration of the hived instance (it was configured with the deprecated chainbase account history plugin which is known to consume too much memory). With that plugin replaced by the rocksdb-account-history plugin, memory consumption and general performance was fine. We also fixed some minor issues with the recurrent transfer operation: https://gitlab.syncad.com/hive/hive/-/merge_requests/246 We’ve added a few new network API calls to hived for getting peer count, getting connected peers, adding peers, and setting allowed peers. These functions were primarily added to facilitate testing scenarios (e.g. testing forking logic), but they can be useful to node operators as well: https://gitlab.syncad.com/hive/hive/-/merge_requests/244 We’ve added support for building with boost 1.70 (tested on Ubuntu 18 and 20). We also modified the fc library to enable a simplified logging syntax. For example, instead of: `ilog(“my variable=${my_variable}”,(“my_variable”,my_variable));` you can simply use: `ilog(“my variable=${my_variable}”,(my_variable));` Note that the older syntax is still required when you need to call a function on the variable to get the value to log. The two syntaxes can be mixed-and-matched in a single log statement. During our testing of the fix of the longstanding “duplicate operations in account history” bug, we found that this problem could also arise when the value of the last irreversible block was “undone” as part of the shutdown of hived (i.e. when a node operator presses Ctrl-C to shutdown the node). On a subsequent start, with the last irreversible block set to an earlier block, the code would re-add the operations from the already processed blocks. To fix this, we’re making sure the irreversible block number doesn’t get reverted by the database state undo operation anymore. Once the above issue is fixed and tested in replay mode in conjunction with a full sync of hivemind, we’ll be tagging a second release candidate for the testnet (probably Thursday or Friday). Barring any unexpected issues during testnet testing, I expect that this will be our last release candidate before the official release, based on testing results so far. # Hivemind (2nd layer applications + social media middleware) Last week we’ve been making final fixes and doing performance tests in preparation for a new release of hivemind for API node operators later this week. ## Changing back to using pip for hivemind installation We recently found that our current installation methodology for hivemind could lead to unexpected package versioning issues, so we’re switching back to using pip (python package installer) and pinning the versions of packages that hivemind uses. ## Performance testing and optimization for hivemind While testing the develop branch of hivemind on our production API node (https://api.hive.blog), we noticed a slowdown in performance of the query `bridge_get_ranked_post_by_created_for_tag` (went from average of 64ms to nearly 2s average time). This problem was ultimately traced down to a lack of sufficient statistics being accumulated for the tags_ids column in the hive_posts table. The collected statistics weren’t sufficient to model the probability distribution of the tags used by posts, which resulted in the query planner selecting an under-performing query plan. What’s interesting here is that this was a latent performance issue that could have potentially occurred on any given API node if it collected an unlucky statistical set (the problem wasn’t really a master vs develop branch issue). We fixed the issue by increasing the statistics collected for this column from 100 to 1000: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/503 ## Hivemind memory consumption We’re still researching potential ways to decrease the amount of memory consumed by the hivemind sync process over time. We’ve reduced memory consumption some, but more looks possible. ## Postgres 13 vs Postgres 10 for hivemind During our search for a possible solution to the above problem (before we realized increasing statistics was the best solution), we also tried updating our SQL database from postgres 10 with postgres 13, to see if it would select a better query plan. The database upgrade had no impact on the above problem, but we found another slowdown during hive sync (the indexer that adds data from the blockchain to the database) tied to postgres 13. This problem occurs because the postgres13 planner incorrectly estimates the costs of updating rshare totals during ‘live sync’ and decides to do a just-in-time (jit) optimization which adds 100ms to the query time. We confirmed this was the issue by increasing the threshold cost required before the planner was allowed to employ jit optimization (effectively disabling jit usage in the query). In this scenario, performance was just slightly better for postgres 13 than for 10. Once we move to 13, we’ll need to select a long term solution for this issue (either improve the cost estimation or just disable jit for this query), but that’s an issue for a later day. ## Functional testing and fixes for hivemind While working on fixes to community-related API calls, we also improved mock testing capabilities to verify the changes (mock testing allows us to generate “fake” data for testing purposes into an existing hivemind data set). https://gitlab.syncad.com/hive/hivemind/-/merge_requests/496 https://gitlab.syncad.com/hive/hivemind/-/merge_requests/499 https://gitlab.syncad.com/hive/hivemind/-/merge_requests/501 # Modular hivemind (Application framework for Hive apps) We’re currently building a sample application with the prototype for our modular hivemind framework that will support the account history API. Hopefully we’ll be able to perform a full test of this sample application by sometime next week. # Condenser wallet We’ve been doing some condenser wallet testing and bug fixing. We fixed a bug in the new feature by @quochuy that generates a CSV file with a user’s transaction history. The fix has been deployed to https://wallet.hive.blog. https://gitlab.syncad.com/hive/wallet/-/merge_requests/106 # Testnet We’ve had a few brave souls do some testing with the testnet, but I’d like to see a lot more, especially from users supporting Hive API libraries and Hive-based apps. But everyone is welcome to play around on the testnet and try to break things. As a regular Hive user, you can login with your normal credentials via: https://testblog.openhive.network (hive.blog-like testing site) or https://testnet.peakd.com/ (peakd-like testing site) You can also browse the testnet with this block explorer: https://test.ausbit.dev/ Going forward, the testnet should be the preferred vehicle for initial testing of Hive apps. And testing new features now, before the hardfork, helps us to identify areas where we may want to make changes to API responses, etc, before there’s an “official” API response that must then be changed later. # Planned date for hardfork 25 I’m still projecting the hardfork will be in the last week of June. See: 13th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive core developer meeting #24</title><link href="https://hivedocs.info/news/core/development/2021/05/25/hive-core-developer-meeting-24.html" rel="alternate" type="text/html" title="Hive core developer meeting #24" /><published>2021-05-25T10:03:27-07:00</published><updated>2021-05-25T10:03:27-07:00</updated><id>https://hivedocs.info/news/core/development/2021/05/25/hive-core-developer-meeting-24</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/05/25/hive-core-developer-meeting-24.html">&lt;div id=&quot;content-howo-hive-core-developer-meeting-24&quot;&gt;https://www.youtube.com/watch?v=pxUvrI0pyPs

Hi, 

This meeting was very focused on the testnet and it's operation and what was needed, if you are reading this and are a dapp creator, please test your app against the new testnet, or even better create a testnet version of your app, this testnet will keep on running after testing is over and if you are missing a tool to deploy your app, please tell us which.

meeting tl;dr:

### Dev sync

you should listen to that part

### Dynamic RC costs

We discussed a few solutions we have in mind to make RC costs more in line with the actual cost of an operation on the chain

### vop for instant hbd conversion when transferring hive to the dhf

Not discussed, postponed to a later meeting.


### support for new consensus changes in related libraries, who's down to do it ?

I volunteered to do it in hive-js, we need to speak with other maintainers to see who will do what.

### How is the public testing going for the  account expiration due to lack of governance activity ?

We realized the expiration was set to 20 days which is too much time, so we will soon update the testnet with a new version that includes some fixes and lowers it.



### have front ends been updated to include notifications about account expiration or at least presenting the expiration date ?

So far, no.

### What about testing recurrent transfer/proposal update publicly ? Best by using 3rd party libraries wrapping direct blockchain operations

That has been tested on my own testnets, but not on that testnet, I'm gonna run some tests on it later this week 

### We did internally test creating max. number of recurrent transfers for 10% accounts: 120000*255. Results show dramatic memory allocation (under investigation). Changes are here:
https://gitlab.syncad.com/hive/hive/-/tree/km_operation_tests_recurrent

We talked a bunch on this, the expected memory consumption was 8gb but ended up being 40 gb, we are not sure what is causing it but it could be that it's the nature of the testing environment that caused it and it wouldn't be reproduced in the real world, we are still investigating that part.

### Anyone [outside of Blocktrades group] tested new HBD conversion operation ?

No

### Anyone [outside of Blocktrades group] tested/analyzed new author/curator rewarding ?

No

^ on these last discussion points, there are a bunch of discussions on the gitlab issue that you can read here: https://gitlab.syncad.com/hive/tasks_without_projects_yet/-/issues/39

Have a nice day

@howo&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@howo&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-core-developer-meeting-24&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-howo-hive-core-developer-meeting-24').html();
      const outputElem = $('#content-howo-hive-core-developer-meeting-24');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-howo-hive-core-developer-meeting-24 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-howo-hive-core-developer-meeting-24 code {
    background: white;
  }
  #content-howo-hive-core-developer-meeting-24 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-howo-hive-core-developer-meeting-24 a:hover {
    border-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-24 h1 {
    font-size: 2.2em;
  }
  #content-howo-hive-core-developer-meeting-24 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-24 header small {
    color: #999;
    font-size: 50%;
  }
  #content-howo-hive-core-developer-meeting-24 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/meeting/@howo/hive-core-developer-meeting-24&quot;&gt;Hive core developer meeting #24&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@howo&quot;&gt;@howo&lt;/a&gt;
&lt;/p&gt;</content><author><name>howo</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">https://www.youtube.com/watch?v=pxUvrI0pyPs Hi, This meeting was very focused on the testnet and it's operation and what was needed, if you are reading this and are a dapp creator, please test your app against the new testnet, or even better create a testnet version of your app, this testnet will keep on running after testing is over and if you are missing a tool to deploy your app, please tell us which. meeting tl;dr: ### Dev sync you should listen to that part ### Dynamic RC costs We discussed a few solutions we have in mind to make RC costs more in line with the actual cost of an operation on the chain ### vop for instant hbd conversion when transferring hive to the dhf Not discussed, postponed to a later meeting. ### support for new consensus changes in related libraries, who's down to do it ? I volunteered to do it in hive-js, we need to speak with other maintainers to see who will do what. ### How is the public testing going for the account expiration due to lack of governance activity ? We realized the expiration was set to 20 days which is too much time, so we will soon update the testnet with a new version that includes some fixes and lowers it. ### have front ends been updated to include notifications about account expiration or at least presenting the expiration date ? So far, no. ### What about testing recurrent transfer/proposal update publicly ? Best by using 3rd party libraries wrapping direct blockchain operations That has been tested on my own testnets, but not on that testnet, I'm gonna run some tests on it later this week ### We did internally test creating max. number of recurrent transfers for 10% accounts: 120000*255. Results show dramatic memory allocation (under investigation). Changes are here: https://gitlab.syncad.com/hive/hive/-/tree/km_operation_tests_recurrent We talked a bunch on this, the expected memory consumption was 8gb but ended up being 40 gb, we are not sure what is causing it but it could be that it's the nature of the testing environment that caused it and it wouldn't be reproduced in the real world, we are still investigating that part. ### Anyone [outside of Blocktrades group] tested new HBD conversion operation ? No ### Anyone [outside of Blocktrades group] tested/analyzed new author/curator rewarding ? No ^ on these last discussion points, there are a bunch of discussions on the gitlab issue that you can read here: https://gitlab.syncad.com/hive/tasks_without_projects_yet/-/issues/39 Have a nice day @howo See: Hive core developer meeting #24 by @howo</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">The HiveSQL documentation is now available</title><link href="https://hivedocs.info/news/sql/database/2021/05/25/hivesql-documentation.html" rel="alternate" type="text/html" title="The HiveSQL documentation is now available" /><published>2021-05-25T05:52:09-07:00</published><updated>2021-05-25T05:52:09-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/05/25/hivesql-documentation</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/05/25/hivesql-documentation.html">&lt;div id=&quot;content-arcange-hivesql-documentation&quot;&gt;![](https://i.imgur.com/rq7Ab3K.png)

Promises are made to be kept! HiveSQL's proposal mentioned the creation of documentation and tutorials. Here is finally the culmination of a long work that I undertook several weeks ago: the [HiveSQL documentation](https://docs.hivesql.io).

After many tests with different documentation solutions, my choice finally fell on gitbooks which, in my opinion, offer a lot of flexibility, both in terms of content editing and maintenance.

TL;DR: HiveSQL documentation can be found at **https://docs.hivesql.io**

### What's in it?

First, there is general information on 
* what is HiveSQL.
* how to access it.
* how to get support. 

Things that current HiveSQL users are already used to.

You will then find more technical information such as: 
* a [database diagram](https://docs.hivesql.io/technical-informations/database-diagram)
* an exhaustive list of all available tables
* a description for each table's column

Yes, you read it well: for all operations, virtual operations and state tables, each column of each table is described. This should interest many developers, even if they do not use Hiveql.

The documentation describes:
* [Operations](https://docs.hivesql.io/technical-informations/operations)
* [Virtual Operations](https://docs.hivesql.io/technical-informations/virtual-operations)
* [State tables](https://docs.hivesql.io/technical-informations/state-tables) like Accounts and Comments

It also describes how to use HiveSQL exclusive features like [Full-Text Search](https://docs.hivesql.io/technical-informations/full-text-search) and [Language Detection](https://docs.hivesql.io/technical-informations/language-detection).

The documentation also contains various tutorials for developers, notably PHP, Python, Ruby and even for Microsoft Excel users. More to come.

### Other Resources

I also searched the blockchain to find the various posts that have been written about HiveSQL. So I grouped the links to these different posts on a resource page to make it easier for you to find them. 

If you have made a post that deserves to appear there, do not hesitate to contact me as well.

### What's next?

There is still room to improve this documentation. I am thinking about examples of complex queries, more detailed information on the blockchain content and operations.

Some of the tutorials provided are quite rudimentary. I plan to improve them too. Do not hesitate to contact me if you want to add your contribution.

But I first wish to have your feedback on its current state before going further.

Feel free to use the HiveSQL [Discord](https://discord.gg/kyEFDfT) channel to report typos or make suggestions.

### One last word

Thank you to @inertia for the amazing work he did with the [Hive Developer Documentation](https://developers.hive.io) from which I borrowed a few sentences.

I truly believe that both documentations are complementary resources and that they will help everyone, developers and non-developers, to understand the content and organization of our blockchain.

The HiveSQL Documentation is available at **https://docs.hivesql.io**

---
#### &lt;center&gt; Support our proposals&lt;/center&gt;
|HiveSQL (to keep it free for all)|HiveBuzz (to keep it entertaining)|
|-|-|
|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/138)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/147)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/147)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22147%22%5D&amp;amp;approve=true)|

&lt;center&gt;
### Check out my apps and services
&lt;a href=&quot;/hive/@hive.engage/stay-connected-with-your-hive-audience-and-catch-attention&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GiNJqlm.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivebuzz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/B4UTun2.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivesql&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EPN8RW6.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/hive/@arcange/introducing-hive-account-recovery&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6TWeW7V.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hive.autoclaim&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ih2pEOw.png&quot; /&gt;&lt;/a&gt;&lt;/center&gt;
&lt;center&gt;

### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@arcange&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hivesql-documentation&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-arcange-hivesql-documentation').html();
      const outputElem = $('#content-arcange-hivesql-documentation');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-arcange-hivesql-documentation {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-arcange-hivesql-documentation code {
    background: white;
  }
  #content-arcange-hivesql-documentation a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-arcange-hivesql-documentation a:hover {
    border-bottom: 0;
  }
  #content-arcange-hivesql-documentation h1 {
    font-size: 2.2em;
  }
  #content-arcange-hivesql-documentation h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-arcange-hivesql-documentation header small {
    color: #999;
    font-size: 50%;
  }
  #content-arcange-hivesql-documentation img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@arcange/hivesql-documentation&quot;&gt;The HiveSQL documentation is now available&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@arcange&quot;&gt;@arcange&lt;/a&gt;
&lt;/p&gt;

&lt;/center&gt;&lt;/div&gt;</content><author><name>arcange</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![](https://i.imgur.com/rq7Ab3K.png) Promises are made to be kept! HiveSQL's proposal mentioned the creation of documentation and tutorials. Here is finally the culmination of a long work that I undertook several weeks ago: the [HiveSQL documentation](https://docs.hivesql.io). After many tests with different documentation solutions, my choice finally fell on gitbooks which, in my opinion, offer a lot of flexibility, both in terms of content editing and maintenance. TL;DR: HiveSQL documentation can be found at **https://docs.hivesql.io** ### What's in it? First, there is general information on * what is HiveSQL. * how to access it. * how to get support. Things that current HiveSQL users are already used to. You will then find more technical information such as: * a [database diagram](https://docs.hivesql.io/technical-informations/database-diagram) * an exhaustive list of all available tables * a description for each table's column Yes, you read it well: for all operations, virtual operations and state tables, each column of each table is described. This should interest many developers, even if they do not use Hiveql. The documentation describes: * [Operations](https://docs.hivesql.io/technical-informations/operations) * [Virtual Operations](https://docs.hivesql.io/technical-informations/virtual-operations) * [State tables](https://docs.hivesql.io/technical-informations/state-tables) like Accounts and Comments It also describes how to use HiveSQL exclusive features like [Full-Text Search](https://docs.hivesql.io/technical-informations/full-text-search) and [Language Detection](https://docs.hivesql.io/technical-informations/language-detection). The documentation also contains various tutorials for developers, notably PHP, Python, Ruby and even for Microsoft Excel users. More to come. ### Other Resources I also searched the blockchain to find the various posts that have been written about HiveSQL. So I grouped the links to these different posts on a resource page to make it easier for you to find them. If you have made a post that deserves to appear there, do not hesitate to contact me as well. ### What's next? There is still room to improve this documentation. I am thinking about examples of complex queries, more detailed information on the blockchain content and operations. Some of the tutorials provided are quite rudimentary. I plan to improve them too. Do not hesitate to contact me if you want to add your contribution. But I first wish to have your feedback on its current state before going further. Feel free to use the HiveSQL [Discord](https://discord.gg/kyEFDfT) channel to report typos or make suggestions. ### One last word Thank you to @inertia for the amazing work he did with the [Hive Developer Documentation](https://developers.hive.io) from which I borrowed a few sentences. I truly believe that both documentations are complementary resources and that they will help everyone, developers and non-developers, to understand the content and organization of our blockchain. The HiveSQL Documentation is available at **https://docs.hivesql.io** --- #### Support our proposals |HiveSQL (to keep it free for all)|HiveBuzz (to keep it entertaining)| |-|-| |[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)[Vote for the proposal on Ecency](https://ecency.com/proposals/138)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/147)[Vote for the proposal on Ecency](https://ecency.com/proposals/147)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22147%22%5D&amp;amp;approve=true)| ### Check out my apps and services ### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)&amp;lt;/div&amp;gt; See: The HiveSQL documentation is now available by @arcange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/rq7Ab3K.png" /><media:content medium="image" url="https://i.imgur.com/rq7Ab3K.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">12th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/sql/database/2021/05/17/12th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="12th update of 2021 on BlockTrades work on Hive software" /><published>2021-05-17T16:04:24-07:00</published><updated>2021-05-17T16:04:24-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/05/17/12th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/05/17/12th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by the BlockTrades team during the last week:

# Hived work (blockchain node software)

This week we’ve been testing the first release candidate for hardfork 25.  In addition to manual testing of node operation, we're also writing a few more tests to test consensus changes under stress conditions.

Although we haven’t found any bugs in the new consensus changes yet, we have made several fixes to long-standing bugs that we found as part of our manual node testing. Most of the bugs are related to startup issues and confusing log messages that might mislead a node operator:

* We fixed an error message that erroneously reported that a peer node was on an irreversible fork when it most likely was just ahead of the user’s node.
* We fixed a long-standing error that could cause a crash at startup if a node started receiving API requests before the node had fully initialized.
* hived now reports the peer count in warning messages when the blockchain thread is warning that it hasn’t received any transactions or blocks from the P2P thread in the last 30 seconds.
* Hived now delays connecting to seed nodes until the P2P network is initialized and ready to process peer requests. This prevent seed nodes from disconnecting because the user's node doesn't respond to them in a timely manner.
* ulog messages are now logged to stderr (console) for the node. Ulog messages are used by the P2P thread to report important issues that should be seen by node operators. In particular, the user now receives a console warning when the node startup is delayed while the P2P thread is trying to get access to the P2P port from the operating system (when a node is shutdown via Ctrl-C, the OS may take up to 1 minute to release the port, delaying recapture of the port when the node is restarted).

We’ve also updated hived nodes to begin reporting the Hive chainid of BEEABODE at startup (as a temporary measure, the node used to report a chainid of 0 at startup, then swap to reporting BEEABODE after they hit the genesis fork for Hive). 

For the initial release of hardfork 25, hived nodes will still continue to allow connections from nodes with chainid of 0, despite reporting the new chainid, but after all Hive nodes have updated to the hardfork 25 code, we’ll change the code to reject connections from older nodes.

## Second release candidate for hived soon

We’ll likely be publishing a second release candidate of hived in the next couple of days that contains the diagnostics and fixes discussed above (those changes have already been merged into the develop branch, so you can get them now for testing), plus one or two more small improvements that are still pending review.

# Hivemind (2nd layer applications + social media middleware)

We’re continuing to work on a few hivemind tests, running performance tests, and preparing database migration scripts in preparation for a new hivemind release (should be sometime this week).

# Modular hivemind (framework for hive applications)

We still didn’t have time to make the changes for the sql serializer last week due to the time spent fixing the various issues discussed in this post, but we will likely? complete that work in the coming week. Then we’ll be able to do a full performance test of the sql serializer in combination with a full sync of hivemind.

In the meantime, we’re doing preparatory work to create an example modular hivemind-based application that just supports the account history API.

# Condenser (code base for https://hive.blog)

We’re testing condenser code against the testnet. We had some problems with condenser being able to broadcast transactions to the testnest which were ultimately traced to condenser using an older version of the hive-js package. It’s being updated currently and testing will continue. The same change will also be applied to the condenser wallet.

# Hived testnet

We launched and began testing the new public testnet based on release candidate 1. 

We’ve also setup an API node configured to draw data from the testnet. This API node should be used by Hive applications to begin adding code changes to support new features added by the hardfork, such as vote expiration reporting.

If you want to add a node to the public testnet, use this seednode:
`p2p-seed-node = testnet.openhive.network:2001`

To use the API node for the testnet:

API endpoint via jussi:  https://testnet.openhive.network
hived direct http server:  http://testnet.openhive.network:8091
hived direct websocket server:  ws://testnet.openhive.network:8090
hivemind server direct server:  http://testnet.openhive.network:8080 

As mentioned previously, we’ve begun testing this testnet API node with condenser. You can visit it here: https://testblog.openhive.network 

 We will also setup a block explorer and a condenser-based wallet for the testnet soon.
Update: @ausbitbank added block explorer for testnet https://test.ausbit.dev/

We plan to leave this testnet running as a permanent testnet that apps can use to test against prior to making changes to their app operating on the mainnet. So Hive app devs are strongly urged to take advantage of this opportunity. As a side note, when doing so, please make sure to use the latest version of hive-js to make sure it's compatible with the testnet API node. We've also tested beempy successfully against the testnet API node.

# Planned date for hardfork 25

I’m still projecting the hardfork will be in the latter part of June, probably in the last week.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/12th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-12th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/12th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;12th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by the BlockTrades team during the last week: # Hived work (blockchain node software) This week we’ve been testing the first release candidate for hardfork 25. In addition to manual testing of node operation, we're also writing a few more tests to test consensus changes under stress conditions. Although we haven’t found any bugs in the new consensus changes yet, we have made several fixes to long-standing bugs that we found as part of our manual node testing. Most of the bugs are related to startup issues and confusing log messages that might mislead a node operator: * We fixed an error message that erroneously reported that a peer node was on an irreversible fork when it most likely was just ahead of the user’s node. * We fixed a long-standing error that could cause a crash at startup if a node started receiving API requests before the node had fully initialized. * hived now reports the peer count in warning messages when the blockchain thread is warning that it hasn’t received any transactions or blocks from the P2P thread in the last 30 seconds. * Hived now delays connecting to seed nodes until the P2P network is initialized and ready to process peer requests. This prevent seed nodes from disconnecting because the user's node doesn't respond to them in a timely manner. * ulog messages are now logged to stderr (console) for the node. Ulog messages are used by the P2P thread to report important issues that should be seen by node operators. In particular, the user now receives a console warning when the node startup is delayed while the P2P thread is trying to get access to the P2P port from the operating system (when a node is shutdown via Ctrl-C, the OS may take up to 1 minute to release the port, delaying recapture of the port when the node is restarted). We’ve also updated hived nodes to begin reporting the Hive chainid of BEEABODE at startup (as a temporary measure, the node used to report a chainid of 0 at startup, then swap to reporting BEEABODE after they hit the genesis fork for Hive). For the initial release of hardfork 25, hived nodes will still continue to allow connections from nodes with chainid of 0, despite reporting the new chainid, but after all Hive nodes have updated to the hardfork 25 code, we’ll change the code to reject connections from older nodes. ## Second release candidate for hived soon We’ll likely be publishing a second release candidate of hived in the next couple of days that contains the diagnostics and fixes discussed above (those changes have already been merged into the develop branch, so you can get them now for testing), plus one or two more small improvements that are still pending review. # Hivemind (2nd layer applications + social media middleware) We’re continuing to work on a few hivemind tests, running performance tests, and preparing database migration scripts in preparation for a new hivemind release (should be sometime this week). # Modular hivemind (framework for hive applications) We still didn’t have time to make the changes for the sql serializer last week due to the time spent fixing the various issues discussed in this post, but we will likely? complete that work in the coming week. Then we’ll be able to do a full performance test of the sql serializer in combination with a full sync of hivemind. In the meantime, we’re doing preparatory work to create an example modular hivemind-based application that just supports the account history API. # Condenser (code base for https://hive.blog) We’re testing condenser code against the testnet. We had some problems with condenser being able to broadcast transactions to the testnest which were ultimately traced to condenser using an older version of the hive-js package. It’s being updated currently and testing will continue. The same change will also be applied to the condenser wallet. # Hived testnet We launched and began testing the new public testnet based on release candidate 1. We’ve also setup an API node configured to draw data from the testnet. This API node should be used by Hive applications to begin adding code changes to support new features added by the hardfork, such as vote expiration reporting. If you want to add a node to the public testnet, use this seednode: `p2p-seed-node = testnet.openhive.network:2001` To use the API node for the testnet: API endpoint via jussi:  https://testnet.openhive.network hived direct http server:  http://testnet.openhive.network:8091 hived direct websocket server: ws://testnet.openhive.network:8090 hivemind server direct server:  http://testnet.openhive.network:8080 As mentioned previously, we’ve begun testing this testnet API node with condenser. You can visit it here: https://testblog.openhive.network We will also setup a block explorer and a condenser-based wallet for the testnet soon. Update: @ausbitbank added block explorer for testnet https://test.ausbit.dev/ We plan to leave this testnet running as a permanent testnet that apps can use to test against prior to making changes to their app operating on the mainnet. So Hive app devs are strongly urged to take advantage of this opportunity. As a side note, when doing so, please make sure to use the latest version of hive-js to make sure it's compatible with the testnet API node. We've also tested beempy successfully against the testnet API node. # Planned date for hardfork 25 I’m still projecting the hardfork will be in the latter part of June, probably in the last week. See: 12th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">HiveSQL Upate - New Virtual Operation tables</title><link href="https://hivedocs.info/news/sql/database/2021/05/17/hivesql-upate-20210517.html" rel="alternate" type="text/html" title="HiveSQL Upate - New Virtual Operation tables" /><published>2021-05-17T07:53:39-07:00</published><updated>2021-05-17T07:53:39-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/05/17/hivesql-upate-20210517</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/05/17/hivesql-upate-20210517.html">&lt;div id=&quot;content-arcange-hivesql-upate-20210517&quot;&gt;![](https://i.imgur.com/FE9D32t.png)

I am finalizing a consequent work I started weeks ago to create the HiveSQL documentation, which should be available soon. While performing this job, I realized that the database was missing a few Virtual Operations tables. Therefore, I hastened to add them so that the database content is as complete as possible.

### What new?

Two new tables are now available:
 
**VOClearNullAccountBalances**

This table contains virtual operations created by the blockchain when the @null account balances need to be zeroed.

|Column|Description|
|-|-|
|total_cleared|a JSON array with the assets that have been burned|

**VOSPSConverts**

This table contains virtual operations issued when a Proposals Fund (DHF) conversion from HIVE to HBD occurs.

|Column|Description|
|-|-|
|fund_account|DHF account|
|hive_amount_in|amount of HIVE burned|
|hbd_amount_out|amount of HBD created|

**VODelayedVotings**

This table contains virtual operations issued when newly powered up VESTS (Hive Power) become counted towards witnesses and DHF proposals votes (after a 30 days delay is complete - HF24).

|Column|Description|
|-|-|
|voter|account who performed a power-up and whose votes will be impacted|
|votes|amount of additional VESTS to take into account for votes|

### What else?

**&lt;div class=&quot;phishy&quot;&gt;I made a major change&lt;/div&gt;** to the `TxCustoms` table which contains all the `custom_json` operation broadcasted to the blockchain.

Its `json_metadata` column has been renamed to `json` to match the blockchain field name (and because it does not contain &quot;metadata&quot;).

However, in order not to break (d)Apps and processes that currently use `json_metadata`, **the two column [names] will stay available for another month**. This will give applications ample time to adapt. After that, `json_metadata` will be permanently removed.


## Support

If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT).

Thank you for reading.

---
**Let's keep HiveSQL free to use - Support its proposals**!
|HiveSQL|HiveBuzz|
|-|-|
|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/138)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/147)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/147)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22147%22%5D&amp;amp;approve=true)|

---
&lt;center&gt;

### Check out my apps and services
&lt;a href=&quot;/hive/@hive.engage/stay-connected-with-your-hive-audience-and-catch-attention&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GiNJqlm.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivebuzz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/B4UTun2.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivesql&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EPN8RW6.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/hive/@arcange/introducing-hive-account-recovery&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6TWeW7V.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hive.autoclaim&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ih2pEOw.png&quot; /&gt;&lt;/a&gt;&lt;/center&gt;
&lt;center&gt;

### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)
&lt;/center&gt;&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@arcange&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hivesql-upate-20210517&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-arcange-hivesql-upate-20210517').html();
      const outputElem = $('#content-arcange-hivesql-upate-20210517');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-arcange-hivesql-upate-20210517 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-arcange-hivesql-upate-20210517 code {
    background: white;
  }
  #content-arcange-hivesql-upate-20210517 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-arcange-hivesql-upate-20210517 a:hover {
    border-bottom: 0;
  }
  #content-arcange-hivesql-upate-20210517 h1 {
    font-size: 2.2em;
  }
  #content-arcange-hivesql-upate-20210517 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-arcange-hivesql-upate-20210517 header small {
    color: #999;
    font-size: 50%;
  }
  #content-arcange-hivesql-upate-20210517 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@arcange/hivesql-upate-20210517&quot;&gt;HiveSQL Upate - New Virtual Operation tables&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@arcange&quot;&gt;@arcange&lt;/a&gt;
&lt;/p&gt;</content><author><name>arcange</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![](https://i.imgur.com/FE9D32t.png) I am finalizing a consequent work I started weeks ago to create the HiveSQL documentation, which should be available soon. While performing this job, I realized that the database was missing a few Virtual Operations tables. Therefore, I hastened to add them so that the database content is as complete as possible. ### What new? Two new tables are now available: **VOClearNullAccountBalances** This table contains virtual operations created by the blockchain when the @null account balances need to be zeroed. |Column|Description| |-|-| |total_cleared|a JSON array with the assets that have been burned| **VOSPSConverts** This table contains virtual operations issued when a Proposals Fund (DHF) conversion from HIVE to HBD occurs. |Column|Description| |-|-| |fund_account|DHF account| |hive_amount_in|amount of HIVE burned| |hbd_amount_out|amount of HBD created| **VODelayedVotings** This table contains virtual operations issued when newly powered up VESTS (Hive Power) become counted towards witnesses and DHF proposals votes (after a 30 days delay is complete - HF24). |Column|Description| |-|-| |voter|account who performed a power-up and whose votes will be impacted| |votes|amount of additional VESTS to take into account for votes| ### What else? **I made a major change** to the `TxCustoms` table which contains all the `custom_json` operation broadcasted to the blockchain. Its `json_metadata` column has been renamed to `json` to match the blockchain field name (and because it does not contain &quot;metadata&quot;). However, in order not to break (d)Apps and processes that currently use `json_metadata`, **the two column [names] will stay available for another month**. This will give applications ample time to adapt. After that, `json_metadata` will be permanently removed. ## Support If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT). Thank you for reading. --- **Let's keep HiveSQL free to use - Support its proposals**! |HiveSQL|HiveBuzz| |-|-| |[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)[Vote for the proposal on Ecency](https://ecency.com/proposals/138)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/147)[Vote for the proposal on Ecency](https://ecency.com/proposals/147)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22147%22%5D&amp;amp;approve=true)| --- ### Check out my apps and services ### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1) See: HiveSQL Upate - New Virtual Operation tables by @arcange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/FE9D32t.png" /><media:content medium="image" url="https://i.imgur.com/FE9D32t.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Making a Decentralized Game on Hive - Last part</title><link href="https://hivedocs.info/howto/nodejs/2021/05/14/making-a-decentralized-game-on-hive-last-part.html" rel="alternate" type="text/html" title="Making a Decentralized Game on Hive - Last part" /><published>2021-05-14T15:17:36-07:00</published><updated>2021-05-14T15:17:36-07:00</updated><id>https://hivedocs.info/howto/nodejs/2021/05/14/making-a-decentralized-game-on-hive-last-part</id><content type="html" xml:base="https://hivedocs.info/howto/nodejs/2021/05/14/making-a-decentralized-game-on-hive-last-part.html">&lt;div id=&quot;content-mahdiyari-making-a-decentralized-game-on-hive-last-part&quot;&gt;&lt;center&gt;![desktop-pixabay.jpg](https://images.hive.blog/DQmah3PBKL6JDe3omk8wi2RFp3Lk2X8BZgb3FUpnkRTsfap/desktop-1245714_1280.jpg)&lt;/center&gt;
First of all, thank you for following me and making these posts available for a bigger audience by sharing them.

This post took too long but finally, it's done. I think I could make 5 posts with the content of just this yet-to-be-written post. I will make it short as possible. I was going to make a few excuses for taking it too long but TBH I could deliver it maybe 2 weeks earlier if I worked on it. Lazy me is for the blame.

The game itself is not important for me, the important part was writing these posts to show how easy it is to make true decentralized applications and games. Of course, it's not for everybody. But now we have something to share with other developers who want to start a game or app. It's not perfect but it's something.

Anyway, it's online and it's fully functional. You can try it with a friend on [https://tic-tac-toe.mahdiyari.info/](https://tic-tac-toe.mahdiyari.info/). Create a game and the other user can join it. Then the game should start. There is no time limit on the game.

Link to the GitLab repository and the previous posts are at the end of the post. Maybe you can try running your instance of the game for the experiment! It will start syncing blocks and become identical to the official website.

Now moving to the development side of things. I won't drop all the codes here because it's massive. All the codes are almost 2,000 lines. I will only explain the parts that seem necessary.
***
#### Development
We can use pm2 to launch our application. So let's make a config file for it.
`ecosystem.config.js`
```
module.exports = {
  apps: [
    {
      name: 'app-tictactoe',
      script: 'index.js',
      instances: 1,
      max_memory_restart: '1G',
      exec_mode: 'fork'
    },
    {
      name: 'api-tictactoe',
      script: 'api/server.js',
      instances: 2,
      max_memory_restart: '1G',
      exec_mode: 'cluster'
    }
  ]
}
```
This will launch the API in a cluster mode with 2 instances for better handling of the traffic. You can increase the number of instances up to the number of your CPU threads. **ONLY** the API. We can't run the main application in a cluster mode and it's not necessary at all. We set both scripts to use a maximum of 1GB RAM but in reality, both will use less than 40mb. It's just to be safe.

I added the necessary scripts in the `package.json` for running the application.
```
&quot;scripts&quot;: {
    &quot;test&quot;: &quot;echo \&quot;Error: no test specified\&quot; &amp;amp;&amp;amp; exit 1&quot;,
    &quot;start&quot;: &quot;pm2 start ecosystem.config.js&quot;,
    &quot;stop&quot;: &quot;pm2 delete ecosystem.config.js&quot;,
    &quot;restart&quot;: &quot;pm2 restart ecosystem.config.js&quot;,
    &quot;reload&quot;: &quot;pm2 reload ecosystem.config.js&quot;,
    &quot;logs&quot;: &quot;pm2 logs&quot;
  }
```
For example, for starting the app I can type `npm run start` and `npm run logs` for logs and so on. It will use the installed `pm2` with the app itself.
***
For the ability to sync blocks in a row one by one, we use a queue. I call this implementation `rapidQueue`. It's in pure JS and is faster than the other methods. You can check it out [on GitLab](https://gitlab.com/mahdiyari/decentralized-game-on-hive/-/blob/master/back-end/helpers/rapidQueue.js).

I set the genesis block of our game to `53,886,076` just because it was the head block at the time of launch. Every time a fresh instance of the game is installed, it will go through all the blocks one by one from the genesis block until the current head block and continue listening for the future blocks.

So here it is our syncing method:
`index.js`
```
const start = async () =&amp;gt; {
  try {
    await initDatabase()
    stream.streamBlockNumber(async blockNum =&amp;gt; {
      if (!blockNum) {
        return
      }
      if (firstRun) {
        firstRun = false
        await queueOldBlocks(blockNum)
      }
      queue.push(blockNum)
    })
    processQueue()
  } catch (e) {
    throw new Error(e)
  }
}
```
First, initializes database then puts into the queue not synced blocks, then puts the newly generated blocks into the back of the queue. Then call another function that will check the queue at an interval.

The code below is responsible for putting not synced blocks into the queue.
```
const queueOldBlocks = async nowBlock =&amp;gt; {
  let oldestBlock
  const latestBlock = await mysql.query(
    'SELECT `block_number` FROM `lastblock` WHERE `id`=1'
  )
  if (latestBlock[0].block_number === 0) {
    oldestBlock = genesisBlock
  } else {
    oldestBlock = latestBlock[0].block_number
  }
  if (oldestBlock &amp;lt; nowBlock) {
    for (let i = oldestBlock; i &amp;lt; nowBlock; i++) {
      queue.push(i)
    }
  }
}
```
The following code is the part that takes block numbers one by one out of the queue. It runs every 5ms to check if the current block is processed or not. If yes, goes to the next block in the queue. `queueIndex` is the counter of the currently running `processBlock()`s. Which will be a maximum of 1.
```
const intervalTime = 5
const maxI = 1
let queueIndex = 0
const processQueue = () =&amp;gt; {
  setInterval(() =&amp;gt; {
    const L = queue.length()
    if (queueIndex &amp;lt; maxI &amp;amp;&amp;amp; L &amp;gt; 0) {
      const n = maxI - queueIndex &amp;gt; L ? L : maxI - queueIndex
      for (let k = 0; k &amp;lt; n; k++) {
        const blockNum = queue.shift()
        processBlock(blockNum)
      }
    }
  }, intervalTime)
}
```
You can see the counter in action:
```
const processBlock = async blockNum =&amp;gt; {
  if (!blockNum) {
    return
  }
  queueIndex++
  try {
    const operations = await stream.getOperations(blockNum)
    if (operations &amp;amp;&amp;amp; operations.length &amp;gt; 0) {
      for (const ops of operations) {
        for (const op of ops) {
          if (op &amp;amp;&amp;amp; op[0] === 'custom_json' &amp;amp;&amp;amp; op[1].id === 'tictactoe') {
            await processData(op[1].json, op[1].required_posting_auths)
          }
        }
      }
    }
    await updateLastblock(blockNum)
    totalSyncedBlocks++
  } catch (e) {}
  queueIndex--
}
```
***
The heart of the game is the `play` function. It determines the finished games and winners. It is triggered when a player plays a move.
```
const play = async (data, user) =&amp;gt; {
  if (
    !data ||
    !data.id ||
    !data.col ||
    !data.row ||
    isNaN(data.col) ||
    isNaN(data.row) ||
    data.id.length !== 20 ||
    data.col &amp;lt; 1 ||
    data.col &amp;gt; 3 ||
    data.row &amp;lt; 1 ||
    data.row &amp;gt; 3
  ) {
    return
  }
  // Validate game in database
  const game = await mysql.query(
    'SELECT `player1`, `player2`, `starting_player` FROM `games` WHERE `game_id`= ? AND `status`= ? AND (player1=? OR player2=?)',
    [data.id, 'running', user, user]
  )
  if (!game || !Array.isArray(game) || game.length &amp;lt; 1) {
    return
  }
  // Validate the player round
  let round = ''
  const computedMoves = new Array(9)
  const moves = await mysql.query(
    'SELECT `player`, `col`, `row` FROM `moves` WHERE `game_id`= ? ORDER BY `id` ASC',
    [data.id]
  )
  if (!moves || !Array.isArray(moves) || moves.length &amp;lt; 1) {
    round = game[0].starting_player
  } else {
    if (moves[moves.length - 1].player === game[0].player1) {
      round = 'second'
    } else {
      round = 'first'
    }
  }
  if (moves.length &amp;gt; 8) {
    return
  }
  if (round === 'first' &amp;amp;&amp;amp; game[0].player2 === user) {
    return
  }
  if (round === 'second' &amp;amp;&amp;amp; game[0].player1 === user) {
    return
  }
  // Play game and check winner
  await mysql.query(
    'INSERT INTO `moves`(`game_id`, `player`, `col`, `row`) VALUES (?,?,?,?)',
    [data.id, user, data.col, data.row]
  )
  moves.push({ player: user, col: data.col, row: data.row })
  for (let i = 0; i &amp;lt; moves.length; i++) {
    const move = moves[i]
    let mark
    if (move.player === game[0].player1) {
      mark = 'x'
    } else if (move.player === game[0].player2) {
      mark = 'o'
    } else {
      continue
    }
    if (move.row === 1) {
      computedMoves[move.col - 1] = mark
    } else if (move.row === 2) {
      computedMoves[move.col + 2] = mark
    } else if (move.row === 3) {
      computedMoves[move.col + 5] = mark
    }
  }
  checkWinner(computedMoves, data.id)
}
```
The `play` function validates the data, then places the played move, then checks for the game status for a possible winner or draw.
The `checkWinner` function:
```
const checkWinner = async (computedMoves, id) =&amp;gt; {
  if (checkWinningMark(computedMoves, 'x')) {
    await mysql.query(
      'UPDATE `games` SET `status`=?, `winner`=? WHERE `game_id`=?',
      ['finished', 'player1', id]
    )
  } else if (checkWinningMark(computedMoves, 'o')) {
    await mysql.query(
      'UPDATE `games` SET `status`=?, `winner`=? WHERE `game_id`=?',
      ['finished', 'player2', id]
    )
  } else {
    for (let i = 0; i &amp;lt; 9; i++) {
      if (!computedMoves[i]) {
        return
      }
    }
    await mysql.query(
      'UPDATE `games` SET `status`=?, `winner`=? WHERE `game_id`=?',
      ['finished', 'none', id]
    )
  }
}
```
It checks for the winning of player1 or &quot;X&quot; and then player2 or &quot;O&quot; then checks for the filled board for a draw. Then the database is updated.
`checkWinningMark()` is not interesting. It just checks each row and col for a winning pattern for the provided mark. X or O.
***
At the end of the file, we call the `start()` method to start the application. Then inform the user current state of sync.
```
start()
console.log('Tic Tac Toe Application')
console.log(
  'Starting application... It is highly recommended to use a local node for syncing blocks otherwise it might take too long.'
)
const interval = setInterval(() =&amp;gt; {
  if (queue.length() &amp;lt; 2) {
    clearInterval(interval)
    console.log('Sync completed. Application is running.')
  } else {
    console.log('Syncing blocks... Total synced blocks: ' + totalSyncedBlocks)
  }
}, 5000)
```
With a local node, it syncs ~70 blocks per second (depends on many things). It can be boosted in certain ways but it's not necessary for this project. 70 blocks/s is still impressive enough. It all depends on the latency of the connected RPC node because the syncing is done by selecting blocks in a row one by one and waiting for the one to finish before going to the next one.
***
### Client-side
There are many things on the client-side. I'm not going near front-end codes. You can always check the full code on the [GitLab repository](https://gitlab.com/mahdiyari/decentralized-game-on-hive).

Our game board is designed with Canvas. I don't think it's necessary to talk about those codes.

Here is the function for broadcasting a move.
`js/app.js`
```
const submitMove = async () =&amp;gt; {
  if (!userData.authorized) {
    document.getElementById('login-button').click()
    return
  }
  if (!userMove || userMove.length &amp;lt; 2) {
    return
  }
  if (!urlParams.has('id')) {
    return
  }
  const error = document.getElementById('submit-move-error')
  error.innerHTML = ''
  loading(true)
  const id = urlParams.get('id')
  try {
    const play = {
      app: 'tictactoe/0.0.1',
      action: 'play',
      id,
      col: userMove[0],
      row: userMove[1]
    }
    const operations = [
      [
        'custom_json',
        {
          required_auths: [],
          required_posting_auths: [userData.username],
          id: 'tictactoe',
          json: JSON.stringify(play)
        }
      ]
    ]
    const tx = new hiveTx.Transaction()
    await tx.create(operations)
    const privateKey = hiveTx.PrivateKey.from(userData.key)
    tx.sign(privateKey)
    const result = await tx.broadcastNoResult()
    if (result &amp;amp;&amp;amp; result.result &amp;amp;&amp;amp; result.result.tx_id) {
      setTimeout(() =&amp;gt; getGameDetails(urlParams.get('id')), 1500)
      oldRound = round
      round = round === 'first' ? 'second' : 'first'
      toggleMoveInteractions('player-waiting')
    } else {
      error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J'
      console.error(result)
    }
  } catch (e) {
    error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J'
    console.error(e)
  }
  loading(false)
}
```
It creates a transaction with custom_json and uses `.broadcastNoResult()` method of `hiveTx` library for the fastest possible transaction broadcast. This method doesn't return the result of the transaction (but it returns the offline generated tx_id so it's possible to check for the status of the transaction later but we don't) so it may as well fail for many reasons but we assume everything is fine. In this way, the user experience is better and smoother. Because the action goes faster.
***
On the game page, the application gets the game details every 5s from the API and updates the user interface. Then calls the following function to update the board with new moves and also detects the round of play.
```
const computeMoves = () =&amp;gt; {
  if (!movesData || !gameData) {
    setTimeout(() =&amp;gt; computeMoves(), 100)
    return
  }
  clearMoves()
  for (let i = 0; i &amp;lt; movesData.length; i++) {
    const move = movesData[i]
    let mark
    if (move.player === gameData.player1) {
      mark = 'x'
    } else if (move.player === gameData.player2) {
      mark = 'o'
    } else {
      continue
    }
    placeMark(move.col, move.row, mark)
  }
  placeMark(userMove[0], userMove[1], userMove[2])
  if (movesData.length &amp;lt; 1) {
    round = gameData.starting_player
  } else if (movesData[movesData.length - 1].player === gameData.player1) {
    round = 'second'
  } else {
    round = 'first'
  }
}
```
There are many other front-end and back-end stuff which I skip the explanation because it's not a post about teaching development in any sense. I just explained the things I thought might be necessary for running the Hive applications.
***
&lt;center&gt;![town-sign-1158387_640.jpg](https://images.hive.blog/DQmW97Q9q5wLbZ9chrtsRMGvMcHZvoYVXLfsBj4G21UthyY/town-sign-1158387_640.jpg)&lt;/center&gt;

It's 2:30 AM and I'm not sure if I missed something. I hope you accept my attempt at making this tutorial. I have another project in mind so make sure to follow me.

Thank you again. Your votes, reblogs, and witness votes are much appreciated. I hope you like what I do.

&lt;sub&gt;images source: pixabay.com&lt;/sub&gt;
&lt;sub&gt;All the codes used in this project are original. Except the `rapidQueue` method (MIT license).&lt;/sub&gt;
***
The final project:
https://tic-tac-toe.mahdiyari.info/
https://gitlab.com/mahdiyari/decentralized-game-on-hive
***
Previous posts:
[part1](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-tic-tac-toe-part-1)
[part2](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-2)
[part3](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-3)
[part4](https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-4)
[part5](https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-5)&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@mahdiyari&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/making-a-decentralized-game-on-hive-last-part&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-mahdiyari-making-a-decentralized-game-on-hive-last-part').html();
      const outputElem = $('#content-mahdiyari-making-a-decentralized-game-on-hive-last-part');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part code {
    background: white;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part a:hover {
    border-bottom: 0;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part h1 {
    font-size: 2.2em;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part header small {
    color: #999;
    font-size: 50%;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-last-part img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-last-part&quot;&gt;Making a Decentralized Game on Hive - Last part&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@mahdiyari&quot;&gt;@mahdiyari&lt;/a&gt;
&lt;/p&gt;</content><author><name>mahdiyari</name></author><category term="howto" /><category term="nodejs" /><summary type="html">![desktop-pixabay.jpg](https://images.hive.blog/DQmah3PBKL6JDe3omk8wi2RFp3Lk2X8BZgb3FUpnkRTsfap/desktop-1245714_1280.jpg) First of all, thank you for following me and making these posts available for a bigger audience by sharing them. This post took too long but finally, it's done. I think I could make 5 posts with the content of just this yet-to-be-written post. I will make it short as possible. I was going to make a few excuses for taking it too long but TBH I could deliver it maybe 2 weeks earlier if I worked on it. Lazy me is for the blame. The game itself is not important for me, the important part was writing these posts to show how easy it is to make true decentralized applications and games. Of course, it's not for everybody. But now we have something to share with other developers who want to start a game or app. It's not perfect but it's something. Anyway, it's online and it's fully functional. You can try it with a friend on [https://tic-tac-toe.mahdiyari.info/](https://tic-tac-toe.mahdiyari.info/). Create a game and the other user can join it. Then the game should start. There is no time limit on the game. Link to the GitLab repository and the previous posts are at the end of the post. Maybe you can try running your instance of the game for the experiment! It will start syncing blocks and become identical to the official website. Now moving to the development side of things. I won't drop all the codes here because it's massive. All the codes are almost 2,000 lines. I will only explain the parts that seem necessary. *** #### Development We can use pm2 to launch our application. So let's make a config file for it. `ecosystem.config.js` ``` module.exports = { apps: [ { name: 'app-tictactoe', script: 'index.js', instances: 1, max_memory_restart: '1G', exec_mode: 'fork' }, { name: 'api-tictactoe', script: 'api/server.js', instances: 2, max_memory_restart: '1G', exec_mode: 'cluster' } ] } ``` This will launch the API in a cluster mode with 2 instances for better handling of the traffic. You can increase the number of instances up to the number of your CPU threads. **ONLY** the API. We can't run the main application in a cluster mode and it's not necessary at all. We set both scripts to use a maximum of 1GB RAM but in reality, both will use less than 40mb. It's just to be safe. I added the necessary scripts in the `package.json` for running the application. ``` &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \&quot;Error: no test specified\&quot; &amp;amp;&amp;amp; exit 1&quot;, &quot;start&quot;: &quot;pm2 start ecosystem.config.js&quot;, &quot;stop&quot;: &quot;pm2 delete ecosystem.config.js&quot;, &quot;restart&quot;: &quot;pm2 restart ecosystem.config.js&quot;, &quot;reload&quot;: &quot;pm2 reload ecosystem.config.js&quot;, &quot;logs&quot;: &quot;pm2 logs&quot; } ``` For example, for starting the app I can type `npm run start` and `npm run logs` for logs and so on. It will use the installed `pm2` with the app itself. *** For the ability to sync blocks in a row one by one, we use a queue. I call this implementation `rapidQueue`. It's in pure JS and is faster than the other methods. You can check it out [on GitLab](https://gitlab.com/mahdiyari/decentralized-game-on-hive/-/blob/master/back-end/helpers/rapidQueue.js). I set the genesis block of our game to `53,886,076` just because it was the head block at the time of launch. Every time a fresh instance of the game is installed, it will go through all the blocks one by one from the genesis block until the current head block and continue listening for the future blocks. So here it is our syncing method: `index.js` ``` const start = async () =&amp;gt; { try { await initDatabase() stream.streamBlockNumber(async blockNum =&amp;gt; { if (!blockNum) { return } if (firstRun) { firstRun = false await queueOldBlocks(blockNum) } queue.push(blockNum) }) processQueue() } catch (e) { throw new Error(e) } } ``` First, initializes database then puts into the queue not synced blocks, then puts the newly generated blocks into the back of the queue. Then call another function that will check the queue at an interval. The code below is responsible for putting not synced blocks into the queue. ``` const queueOldBlocks = async nowBlock =&amp;gt; { let oldestBlock const latestBlock = await mysql.query( 'SELECT `block_number` FROM `lastblock` WHERE `id`=1' ) if (latestBlock[0].block_number === 0) { oldestBlock = genesisBlock } else { oldestBlock = latestBlock[0].block_number } if (oldestBlock &amp;lt; nowBlock) { for (let i = oldestBlock; i &amp;lt; nowBlock; i++) { queue.push(i) } } } ``` The following code is the part that takes block numbers one by one out of the queue. It runs every 5ms to check if the current block is processed or not. If yes, goes to the next block in the queue. `queueIndex` is the counter of the currently running `processBlock()`s. Which will be a maximum of 1. ``` const intervalTime = 5 const maxI = 1 let queueIndex = 0 const processQueue = () =&amp;gt; { setInterval(() =&amp;gt; { const L = queue.length() if (queueIndex &amp;lt; maxI &amp;amp;&amp;amp; L &amp;gt; 0) { const n = maxI - queueIndex &amp;gt; L ? L : maxI - queueIndex for (let k = 0; k &amp;lt; n; k++) { const blockNum = queue.shift() processBlock(blockNum) } } }, intervalTime) } ``` You can see the counter in action: ``` const processBlock = async blockNum =&amp;gt; { if (!blockNum) { return } queueIndex++ try { const operations = await stream.getOperations(blockNum) if (operations &amp;amp;&amp;amp; operations.length &amp;gt; 0) { for (const ops of operations) { for (const op of ops) { if (op &amp;amp;&amp;amp; op[0] === 'custom_json' &amp;amp;&amp;amp; op[1].id === 'tictactoe') { await processData(op[1].json, op[1].required_posting_auths) } } } } await updateLastblock(blockNum) totalSyncedBlocks++ } catch (e) {} queueIndex-- } ``` *** The heart of the game is the `play` function. It determines the finished games and winners. It is triggered when a player plays a move. ``` const play = async (data, user) =&amp;gt; { if ( !data || !data.id || !data.col || !data.row || isNaN(data.col) || isNaN(data.row) || data.id.length !== 20 || data.col &amp;lt; 1 || data.col &amp;gt; 3 || data.row &amp;lt; 1 || data.row &amp;gt; 3 ) { return } // Validate game in database const game = await mysql.query( 'SELECT `player1`, `player2`, `starting_player` FROM `games` WHERE `game_id`= ? AND `status`= ? AND (player1=? OR player2=?)', [data.id, 'running', user, user] ) if (!game || !Array.isArray(game) || game.length &amp;lt; 1) { return } // Validate the player round let round = '' const computedMoves = new Array(9) const moves = await mysql.query( 'SELECT `player`, `col`, `row` FROM `moves` WHERE `game_id`= ? ORDER BY `id` ASC', [data.id] ) if (!moves || !Array.isArray(moves) || moves.length &amp;lt; 1) { round = game[0].starting_player } else { if (moves[moves.length - 1].player === game[0].player1) { round = 'second' } else { round = 'first' } } if (moves.length &amp;gt; 8) { return } if (round === 'first' &amp;amp;&amp;amp; game[0].player2 === user) { return } if (round === 'second' &amp;amp;&amp;amp; game[0].player1 === user) { return } // Play game and check winner await mysql.query( 'INSERT INTO `moves`(`game_id`, `player`, `col`, `row`) VALUES (?,?,?,?)', [data.id, user, data.col, data.row] ) moves.push({ player: user, col: data.col, row: data.row }) for (let i = 0; i &amp;lt; moves.length; i++) { const move = moves[i] let mark if (move.player === game[0].player1) { mark = 'x' } else if (move.player === game[0].player2) { mark = 'o' } else { continue } if (move.row === 1) { computedMoves[move.col - 1] = mark } else if (move.row === 2) { computedMoves[move.col + 2] = mark } else if (move.row === 3) { computedMoves[move.col + 5] = mark } } checkWinner(computedMoves, data.id) } ``` The `play` function validates the data, then places the played move, then checks for the game status for a possible winner or draw. The `checkWinner` function: ``` const checkWinner = async (computedMoves, id) =&amp;gt; { if (checkWinningMark(computedMoves, 'x')) { await mysql.query( 'UPDATE `games` SET `status`=?, `winner`=? WHERE `game_id`=?', ['finished', 'player1', id] ) } else if (checkWinningMark(computedMoves, 'o')) { await mysql.query( 'UPDATE `games` SET `status`=?, `winner`=? WHERE `game_id`=?', ['finished', 'player2', id] ) } else { for (let i = 0; i &amp;lt; 9; i++) { if (!computedMoves[i]) { return } } await mysql.query( 'UPDATE `games` SET `status`=?, `winner`=? WHERE `game_id`=?', ['finished', 'none', id] ) } } ``` It checks for the winning of player1 or &quot;X&quot; and then player2 or &quot;O&quot; then checks for the filled board for a draw. Then the database is updated. `checkWinningMark()` is not interesting. It just checks each row and col for a winning pattern for the provided mark. X or O. *** At the end of the file, we call the `start()` method to start the application. Then inform the user current state of sync. ``` start() console.log('Tic Tac Toe Application') console.log( 'Starting application... It is highly recommended to use a local node for syncing blocks otherwise it might take too long.' ) const interval = setInterval(() =&amp;gt; { if (queue.length() &amp;lt; 2) { clearInterval(interval) console.log('Sync completed. Application is running.') } else { console.log('Syncing blocks... Total synced blocks: ' + totalSyncedBlocks) } }, 5000) ``` With a local node, it syncs ~70 blocks per second (depends on many things). It can be boosted in certain ways but it's not necessary for this project. 70 blocks/s is still impressive enough. It all depends on the latency of the connected RPC node because the syncing is done by selecting blocks in a row one by one and waiting for the one to finish before going to the next one. *** ### Client-side There are many things on the client-side. I'm not going near front-end codes. You can always check the full code on the [GitLab repository](https://gitlab.com/mahdiyari/decentralized-game-on-hive). Our game board is designed with Canvas. I don't think it's necessary to talk about those codes. Here is the function for broadcasting a move. `js/app.js` ``` const submitMove = async () =&amp;gt; { if (!userData.authorized) { document.getElementById('login-button').click() return } if (!userMove || userMove.length &amp;lt; 2) { return } if (!urlParams.has('id')) { return } const error = document.getElementById('submit-move-error') error.innerHTML = '' loading(true) const id = urlParams.get('id') try { const play = { app: 'tictactoe/0.0.1', action: 'play', id, col: userMove[0], row: userMove[1] } const operations = [ [ 'custom_json', { required_auths: [], required_posting_auths: [userData.username], id: 'tictactoe', json: JSON.stringify(play) } ] ] const tx = new hiveTx.Transaction() await tx.create(operations) const privateKey = hiveTx.PrivateKey.from(userData.key) tx.sign(privateKey) const result = await tx.broadcastNoResult() if (result &amp;amp;&amp;amp; result.result &amp;amp;&amp;amp; result.result.tx_id) { setTimeout(() =&amp;gt; getGameDetails(urlParams.get('id')), 1500) oldRound = round round = round === 'first' ? 'second' : 'first' toggleMoveInteractions('player-waiting') } else { error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J' console.error(result) } } catch (e) { error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J' console.error(e) } loading(false) } ``` It creates a transaction with custom_json and uses `.broadcastNoResult()` method of `hiveTx` library for the fastest possible transaction broadcast. This method doesn't return the result of the transaction (but it returns the offline generated tx_id so it's possible to check for the status of the transaction later but we don't) so it may as well fail for many reasons but we assume everything is fine. In this way, the user experience is better and smoother. Because the action goes faster. *** On the game page, the application gets the game details every 5s from the API and updates the user interface. Then calls the following function to update the board with new moves and also detects the round of play. ``` const computeMoves = () =&amp;gt; { if (!movesData || !gameData) { setTimeout(() =&amp;gt; computeMoves(), 100) return } clearMoves() for (let i = 0; i &amp;lt; movesData.length; i++) { const move = movesData[i] let mark if (move.player === gameData.player1) { mark = 'x' } else if (move.player === gameData.player2) { mark = 'o' } else { continue } placeMark(move.col, move.row, mark) } placeMark(userMove[0], userMove[1], userMove[2]) if (movesData.length &amp;lt; 1) { round = gameData.starting_player } else if (movesData[movesData.length - 1].player === gameData.player1) { round = 'second' } else { round = 'first' } } ``` There are many other front-end and back-end stuff which I skip the explanation because it's not a post about teaching development in any sense. I just explained the things I thought might be necessary for running the Hive applications. *** ![town-sign-1158387_640.jpg](https://images.hive.blog/DQmW97Q9q5wLbZ9chrtsRMGvMcHZvoYVXLfsBj4G21UthyY/town-sign-1158387_640.jpg) It's 2:30 AM and I'm not sure if I missed something. I hope you accept my attempt at making this tutorial. I have another project in mind so make sure to follow me. Thank you again. Your votes, reblogs, and witness votes are much appreciated. I hope you like what I do. images source: pixabay.com All the codes used in this project are original. Except the `rapidQueue` method (MIT license). *** The final project: https://tic-tac-toe.mahdiyari.info/ https://gitlab.com/mahdiyari/decentralized-game-on-hive *** Previous posts: [part1](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-tic-tac-toe-part-1) [part2](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-2) [part3](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-3) [part4](https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-4) [part5](https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-5) See: Making a Decentralized Game on Hive - Last part by @mahdiyari</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmah3PBKL6JDe3omk8wi2RFp3Lk2X8BZgb3FUpnkRTsfap/desktop-1245714_1280.jpg" /><media:content medium="image" url="https://images.hive.blog/DQmah3PBKL6JDe3omk8wi2RFp3Lk2X8BZgb3FUpnkRTsfap/desktop-1245714_1280.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">HiveSQL Upate - Changes to the Internal Market tables</title><link href="https://hivedocs.info/news/sql/database/2021/05/14/hivesql-upate-20210514.html" rel="alternate" type="text/html" title="HiveSQL Upate - Changes to the Internal Market tables" /><published>2021-05-14T06:47:57-07:00</published><updated>2021-05-14T06:47:57-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/05/14/hivesql-upate-20210514</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/05/14/hivesql-upate-20210514.html">&lt;div id=&quot;content-arcange-hivesql-upate-20210514&quot;&gt;![](https://i.imgur.com/E2xbX8S.png)

I am actively continuing the work of [reorganizing the HiveSQL database](/hive-139531/@arcange/hivesql-update-20210511) that I started a few days ago. Lately, I tackled the tables related to the internal market.

There are two operations associated with it: the creation of orders (buy or sell) and their cancellation. However, until now, these two operations were grouped together in a single table, which could cause confusion, but also wasted storage resources.

### What changed?

* A new `TxLimitOrdersCancels` table has been created and cancel orders have been moved from the table `TxLimitOrders` to `TxLimitOrdersCancels`
* The table `TxLimitOrders` (purged from the cancel orders) has been renamed to `TxLimitOrdersCreates`
  
Therefore, we now have two new tables available:

**TxLimitOrdersCreates**

This table contains operations broadcasted to the blockchain when users want to buy or sell assets on the internal market.

|Column|Description|
|-|-|
|owner|account who filled a limit order|
|orderid|an order ID defined by the owner. It must be unique|
|amount_to_sell|amount of asset|
|amount_to_sell_symbol|symbol of the asset|
|min_to_receive|The target asset expected price (limit_order_create operation)|
|min_to_receive_symbol|The target asset expected symbol (limit_order_create only)|
|exchange_rate|The target asset expected price (limit_order_create2 operation)|
fill_or_kill|flag to specify if the order should be killed (removed) from the order book if it cannot be filled|
|expiration|expiration time for the order|

**TxLimitOrdersCancels**

This table contains operations broadcasted to the blockchain when users want to cancel orders created on the internal market.

|Column|Description|
|-|-|
|owner|account who filled a limit order|
|orderid|an order ID defined by the owner|

## Support

If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT).

Thank you for reading.

---
**Let's keep HiveSQL free to use - Support its proposals**!
|HiveSQL|HiveBuzz|
|-|-|
|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/138)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/147)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/147)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22147%22%5D&amp;amp;approve=true)|

---
&lt;center&gt;

### Check out my apps and services
&lt;a href=&quot;/hive/@hive.engage/stay-connected-with-your-hive-audience-and-catch-attention&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GiNJqlm.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivebuzz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/B4UTun2.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivesql&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EPN8RW6.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/hive/@arcange/introducing-hive-account-recovery&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6TWeW7V.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hive.autoclaim&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ih2pEOw.png&quot; /&gt;&lt;/a&gt;&lt;/center&gt;
&lt;center&gt;

### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)
&lt;/center&gt;&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@arcange&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hivesql-upate-20210514&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-arcange-hivesql-upate-20210514').html();
      const outputElem = $('#content-arcange-hivesql-upate-20210514');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-arcange-hivesql-upate-20210514 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-arcange-hivesql-upate-20210514 code {
    background: white;
  }
  #content-arcange-hivesql-upate-20210514 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-arcange-hivesql-upate-20210514 a:hover {
    border-bottom: 0;
  }
  #content-arcange-hivesql-upate-20210514 h1 {
    font-size: 2.2em;
  }
  #content-arcange-hivesql-upate-20210514 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-arcange-hivesql-upate-20210514 header small {
    color: #999;
    font-size: 50%;
  }
  #content-arcange-hivesql-upate-20210514 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@arcange/hivesql-upate-20210514&quot;&gt;HiveSQL Upate - Changes to the Internal Market tables&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@arcange&quot;&gt;@arcange&lt;/a&gt;
&lt;/p&gt;</content><author><name>arcange</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![](https://i.imgur.com/E2xbX8S.png) I am actively continuing the work of [reorganizing the HiveSQL database](/hive-139531/@arcange/hivesql-update-20210511) that I started a few days ago. Lately, I tackled the tables related to the internal market. There are two operations associated with it: the creation of orders (buy or sell) and their cancellation. However, until now, these two operations were grouped together in a single table, which could cause confusion, but also wasted storage resources. ### What changed? * A new `TxLimitOrdersCancels` table has been created and cancel orders have been moved from the table `TxLimitOrders` to `TxLimitOrdersCancels` * The table `TxLimitOrders` (purged from the cancel orders) has been renamed to `TxLimitOrdersCreates` Therefore, we now have two new tables available: **TxLimitOrdersCreates** This table contains operations broadcasted to the blockchain when users want to buy or sell assets on the internal market. |Column|Description| |-|-| |owner|account who filled a limit order| |orderid|an order ID defined by the owner. It must be unique| |amount_to_sell|amount of asset| |amount_to_sell_symbol|symbol of the asset| |min_to_receive|The target asset expected price (limit_order_create operation)| |min_to_receive_symbol|The target asset expected symbol (limit_order_create only)| |exchange_rate|The target asset expected price (limit_order_create2 operation)| fill_or_kill|flag to specify if the order should be killed (removed) from the order book if it cannot be filled| |expiration|expiration time for the order| **TxLimitOrdersCancels** This table contains operations broadcasted to the blockchain when users want to cancel orders created on the internal market. |Column|Description| |-|-| |owner|account who filled a limit order| |orderid|an order ID defined by the owner| ## Support If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT). Thank you for reading. --- **Let's keep HiveSQL free to use - Support its proposals**! |HiveSQL|HiveBuzz| |-|-| |[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)[Vote for the proposal on Ecency](https://ecency.com/proposals/138)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/147)[Vote for the proposal on Ecency](https://ecency.com/proposals/147)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22147%22%5D&amp;amp;approve=true)| --- ### Check out my apps and services ### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1) See: HiveSQL Upate - Changes to the Internal Market tables by @arcange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/E2xbX8S.png" /><media:content medium="image" url="https://i.imgur.com/E2xbX8S.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">HF25 Public Testnet (RC1)</title><link href="https://hivedocs.info/news/projects/testnet/2021/05/13/hf25-public-testnet-rc1.html" rel="alternate" type="text/html" title="HF25 Public Testnet (RC1)" /><published>2021-05-13T04:17:42-07:00</published><updated>2021-05-13T04:17:42-07:00</updated><id>https://hivedocs.info/news/projects/testnet/2021/05/13/hf25-public-testnet-rc1</id><content type="html" xml:base="https://hivedocs.info/news/projects/testnet/2021/05/13/hf25-public-testnet-rc1.html">&lt;div id=&quot;content-gtg-hf25-public-testnet-rc1&quot;&gt;This is a back-of-the-envelope-notes kind of a thread, so don't expect high quality write-ups here.
For this reason 50% beneficiary for top level post and 100% of my comments here are going to be set to @hbd.funder
I encourage all who comment to do the same so we can push up the most relevant content while giving profits for entire platform as a side effect.

Although, of course it is meant to be very useful for all that wish to participate in testing the brand new Hive.

On Wednesday I've started a public Hive testnet based on `v1.25.0rc1`
https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0rc1

Many thanks to @inertia for his tinman, that let me easily import mainnet accounts with their original keys, which in turn makes it much, much easier for every Hive user to participate in testing.

For now it's just a seed node with default Hive testnet chain-id, but of course it's going to be powered by many other usual components such as hivemind, jussi (and thus fully featured API node), condenser, block explorer, etc.

Anyone can run their own testnet instance and/or join this public one.

`p2p-seed-node = testnet.openhive.network`

###### Bonus: a piece of art
&lt;center&gt;![Frunk Full of Hive](https://images.hive.blog/DQmaKfQSrzQZFXt4hbNTwc3TD26wAjMxt5x1Ww6nMTY6Zfc/image.png)&lt;/center&gt;&lt;sup&gt;Handcrafted Hive logo courtesy of @thenoy, background courtesy of Elon Musk and Franz von Holzhausen ;-)
&lt;/sup&gt;

Stay tuned for updates and upgrades.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@gtg&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hf25-public-testnet-rc1&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-gtg-hf25-public-testnet-rc1').html();
      const outputElem = $('#content-gtg-hf25-public-testnet-rc1');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-gtg-hf25-public-testnet-rc1 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-gtg-hf25-public-testnet-rc1 code {
    background: white;
  }
  #content-gtg-hf25-public-testnet-rc1 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-gtg-hf25-public-testnet-rc1 a:hover {
    border-bottom: 0;
  }
  #content-gtg-hf25-public-testnet-rc1 h1 {
    font-size: 2.2em;
  }
  #content-gtg-hf25-public-testnet-rc1 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-gtg-hf25-public-testnet-rc1 header small {
    color: #999;
    font-size: 50%;
  }
  #content-gtg-hf25-public-testnet-rc1 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@gtg/hf25-public-testnet-rc1&quot;&gt;HF25 Public Testnet (RC1)&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@gtg&quot;&gt;@gtg&lt;/a&gt;
&lt;/p&gt;</content><author><name>gtg</name></author><category term="news" /><category term="projects" /><category term="testnet" /><summary type="html">This is a back-of-the-envelope-notes kind of a thread, so don't expect high quality write-ups here. For this reason 50% beneficiary for top level post and 100% of my comments here are going to be set to @hbd.funder I encourage all who comment to do the same so we can push up the most relevant content while giving profits for entire platform as a side effect. Although, of course it is meant to be very useful for all that wish to participate in testing the brand new Hive. On Wednesday I've started a public Hive testnet based on `v1.25.0rc1` https://gitlab.syncad.com/hive/hive/-/tags/v1.25.0rc1 Many thanks to @inertia for his tinman, that let me easily import mainnet accounts with their original keys, which in turn makes it much, much easier for every Hive user to participate in testing. For now it's just a seed node with default Hive testnet chain-id, but of course it's going to be powered by many other usual components such as hivemind, jussi (and thus fully featured API node), condenser, block explorer, etc. Anyone can run their own testnet instance and/or join this public one. `p2p-seed-node = testnet.openhive.network` ###### Bonus: a piece of art ![Frunk Full of Hive](https://images.hive.blog/DQmaKfQSrzQZFXt4hbNTwc3TD26wAjMxt5x1Ww6nMTY6Zfc/image.png)Handcrafted Hive logo courtesy of @thenoy, background courtesy of Elon Musk and Franz von Holzhausen ;-) Stay tuned for updates and upgrades. See: HF25 Public Testnet (RC1) by @gtg</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmaKfQSrzQZFXt4hbNTwc3TD26wAjMxt5x1Ww6nMTY6Zfc/image.png" /><media:content medium="image" url="https://images.hive.blog/DQmaKfQSrzQZFXt4hbNTwc3TD26wAjMxt5x1Ww6nMTY6Zfc/image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">HiveSQL Upate - Database maintenance and new Account Recovery Tables</title><link href="https://hivedocs.info/news/sql/database/2021/05/11/hivesql-update-20210511.html" rel="alternate" type="text/html" title="HiveSQL Upate - Database maintenance and new Account Recovery Tables" /><published>2021-05-11T06:48:15-07:00</published><updated>2021-05-11T06:48:15-07:00</updated><id>https://hivedocs.info/news/sql/database/2021/05/11/hivesql-update-20210511</id><content type="html" xml:base="https://hivedocs.info/news/sql/database/2021/05/11/hivesql-update-20210511.html">&lt;div id=&quot;content-arcange-hivesql-update-20210511&quot;&gt;![](https://i.imgur.com/E2xbX8S.png)

As you know, the account recovery process is something I have [worked](/hive-139531/@arcange/hive-account-recovery-major-update-and-new-user-interface) on and [written](/hive-139531/@arcange/account-recovery-about-trusting-and-not-being-trusted) a lot about recently. 

This allowed me to better understand the related transactions recorded in the blockchain. I also noticed that the related tables in HiveSQL were not that well organized (some early days errors)

So I took advantage of the HiveSQL reorganization work that I am currently carrying out to make some modifications.

### What changed?

* The table `TxAccountChangeRecovers` has been renamed to `TxAccountRecoveryChanges`
* The content of the table `TxAccountRecovers` has been split into `TxAccountRecoveryRequests` and `TxAccountRecoveryConfirms`.

Therefore, we now have three new tables available:

**TxAccountRecoveryChanges**

This table contains operations broadcasted to the blockchain when users want to change their Recovery Account.

|Column|Description|
|-|-|
|account_to_recover|the account that wants to change its Recovery Account|
|new_recovery_account|the new Recovery Account|

**TxAccountRecoveryRequests**

This operation is broadcasted to the blockchain by the Account Recovery of an account that has been hacked to initiate the recovery process

|Column|Description|
|-|-|
|recovery_account|username of the Recovery Account|
|account_to_recover|username of the account to recover|
|new_owner_authority|new public owner key provided by the account to recover to the recovery account|

**TxAccountRecoveryConfirms**

This table contains operations broadcasted to the blockchain by the hacked account's owner to confirm the account recovery request sent by its Recovery Account.

|Column|Description|
|-|-|
|account_to_recover|username of the account to recover|
|new_owner_authority|new public owner key provided by the account to recover to the recovery account|
|recent_owner_authority|a public owner key of the account to recover before it was last changed|

## What's next?

This first change should make it easier to find information relating to the account recovery process. 

As indicated at the beginning of this post, I have embarked on a work of reorganizing and improving the database. So expect to see more posts on this subject in the coming days.

## Support

If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT).

Thank you for reading.

---
**Let's keep HiveSQL free to use - Support its proposals**!
|HiveSQL|HiveBuzz|
|-|-|
|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/138)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/147)&lt;br /&gt;[Vote for the proposal on Ecency](https://ecency.com/proposals/147)&lt;br /&gt;[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22147%22%5D&amp;amp;approve=true)|

---
&lt;center&gt;

### Check out my apps and services
&lt;a href=&quot;/hive/@hive.engage/stay-connected-with-your-hive-audience-and-catch-attention&quot;&gt;&lt;img src=&quot;https://i.imgur.com/GiNJqlm.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivebuzz&quot;&gt;&lt;img src=&quot;https://i.imgur.com/B4UTun2.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hivesql&quot;&gt;&lt;img src=&quot;https://i.imgur.com/EPN8RW6.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/hive/@arcange/introducing-hive-account-recovery&quot;&gt;&lt;img src=&quot;https://i.imgur.com/6TWeW7V.png&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;/@hive.autoclaim&quot;&gt;&lt;img src=&quot;https://i.imgur.com/ih2pEOw.png&quot; /&gt;&lt;/a&gt;&lt;/center&gt;
&lt;center&gt;

### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1)
&lt;/center&gt;&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@arcange&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hivesql-update-20210511&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-arcange-hivesql-update-20210511').html();
      const outputElem = $('#content-arcange-hivesql-update-20210511');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-arcange-hivesql-update-20210511 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-arcange-hivesql-update-20210511 code {
    background: white;
  }
  #content-arcange-hivesql-update-20210511 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-arcange-hivesql-update-20210511 a:hover {
    border-bottom: 0;
  }
  #content-arcange-hivesql-update-20210511 h1 {
    font-size: 2.2em;
  }
  #content-arcange-hivesql-update-20210511 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-arcange-hivesql-update-20210511 header small {
    color: #999;
    font-size: 50%;
  }
  #content-arcange-hivesql-update-20210511 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@arcange/hivesql-update-20210511&quot;&gt;HiveSQL Upate - Database maintenance and new Account Recovery Tables&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@arcange&quot;&gt;@arcange&lt;/a&gt;
&lt;/p&gt;</content><author><name>arcange</name></author><category term="news" /><category term="sql" /><category term="database" /><summary type="html">![](https://i.imgur.com/E2xbX8S.png) As you know, the account recovery process is something I have [worked](/hive-139531/@arcange/hive-account-recovery-major-update-and-new-user-interface) on and [written](/hive-139531/@arcange/account-recovery-about-trusting-and-not-being-trusted) a lot about recently. This allowed me to better understand the related transactions recorded in the blockchain. I also noticed that the related tables in HiveSQL were not that well organized (some early days errors) So I took advantage of the HiveSQL reorganization work that I am currently carrying out to make some modifications. ### What changed? * The table `TxAccountChangeRecovers` has been renamed to `TxAccountRecoveryChanges` * The content of the table `TxAccountRecovers` has been split into `TxAccountRecoveryRequests` and `TxAccountRecoveryConfirms`. Therefore, we now have three new tables available: **TxAccountRecoveryChanges** This table contains operations broadcasted to the blockchain when users want to change their Recovery Account. |Column|Description| |-|-| |account_to_recover|the account that wants to change its Recovery Account| |new_recovery_account|the new Recovery Account| **TxAccountRecoveryRequests** This operation is broadcasted to the blockchain by the Account Recovery of an account that has been hacked to initiate the recovery process |Column|Description| |-|-| |recovery_account|username of the Recovery Account| |account_to_recover|username of the account to recover| |new_owner_authority|new public owner key provided by the account to recover to the recovery account| **TxAccountRecoveryConfirms** This table contains operations broadcasted to the blockchain by the hacked account's owner to confirm the account recovery request sent by its Recovery Account. |Column|Description| |-|-| |account_to_recover|username of the account to recover| |new_owner_authority|new public owner key provided by the account to recover to the recovery account| |recent_owner_authority|a public owner key of the account to recover before it was last changed| ## What's next? This first change should make it easier to find information relating to the account recovery process. As indicated at the beginning of this post, I have embarked on a work of reorganizing and improving the database. So expect to see more posts on this subject in the coming days. ## Support If you have any questions or remarks, support is provided on the [HiveSQL Discord Channel](https://discord.gg/kyEFDfT). Thank you for reading. --- **Let's keep HiveSQL free to use - Support its proposals**! |HiveSQL|HiveBuzz| |-|-| |[Vote for the proposal on PeakD](https://peakd.com/me/proposals/138)[Vote for the proposal on Ecency](https://ecency.com/proposals/138)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22138%22%5D&amp;amp;approve=true)|[Vote for the proposal on PeakD](https://peakd.com/me/proposals/147)[Vote for the proposal on Ecency](https://ecency.com/proposals/147)[Vote for the proposal using HiveSigner](https://hivesigner.com/sign/update_proposal_votes?proposal_ids=%5B%22147%22%5D&amp;amp;approve=true)| --- ### Check out my apps and services ### [Vote for me as a witness ![](https://i.imgur.com/2bi4SnT.png)](https://hivesigner.com/sign/account-witness-vote?witness=arcange&amp;amp;approve=1) See: HiveSQL Upate - Database maintenance and new Account Recovery Tables by @arcange</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/E2xbX8S.png" /><media:content medium="image" url="https://i.imgur.com/E2xbX8S.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">11th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/05/10/11th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="11th update of 2021 on BlockTrades work on Hive software" /><published>2021-05-10T14:27:30-07:00</published><updated>2021-05-10T14:27:30-07:00</updated><id>https://hivedocs.info/news/core/development/2021/05/10/11th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/05/10/11th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-11th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png)

Below is a list of Hive-related programming issues worked on by the BlockTrades team during the last week:

# Hived work (blockchain node software)

Last week we’ve been focused on testing hived in preparation for a final feature freeze and fixing bugs as we find them. So far most of the bugs we’ve found are very old bugs that have been around for many years.

We fixed two bugs we found and discussed in last weeks report:
1. Better warnings and less cpu-loading when node gets no peers at startup
https://gitlab.syncad.com/hive/hive/-/merge_requests/220
2. Fix to beem to fix update_proposals test
https://gitlab.syncad.com/hive/beem/-/merge_requests/6

During benchmarking of hivemind sync on two similarly configured systems, we found one system was syncing much slower than the other one. After a fair amount of debugging effort, we ultimately were able to trace this back to intermittent errors on one of the disks in the raid array where hived stored it’s data, but more interestingly, this also exposed an error that was introduced over 5 years ago (ie. when this code was in the BitShares graphene repo).

This bug caused incoming blocks that are not yet linkable to the node’s head block to be discarded instead of being kept for future usage, once intervening blocks were received.

On normally functioning hardware, this was no big deal, but in the case where disk IO performance was strained (in this case due to intermittent disk errors), this error led to the node often dropping peers and generally straining to keep in sync with the rest of the p2p network. 

Note that this is a practical real world problem, not just a theoretical one, as we believe this problem led to one commonly used exchange having problems maintaining their Hive wallet open for deposits. At the time, the problem was resolved by convincing the exchange to move their Hive wallet to another computer, but it’s obviously better to have Hive nodes more resistant to such issues.

We fixed this bug in these two merge requests:
https://gitlab.syncad.com/hive/hive/-/merge_requests/226
https://gitlab.syncad.com/hive/hive/-/merge_requests/227

As part of the above work, we had to dive pretty deep into profiling the performance of hived when processing transactions and blocks, and we identified several places where we would like to improve performance in the future, after the hard fork is completed. The majority of such changes can be released at any time, as they don’t require consensus changes.

To facilitate our profiling work, we also made changes to how timestamps are represented in hived logs. By default, timestamps are now stored as UTC times with milliseconds resolution in files and seconds resolution on the console, with the option to store the timestamps with microseconds resolution when needed for profiling: https://gitlab.syncad.com/hive/hive/-/merge_requests/229

We added a script that automatically code-generates the get_config api call, so that when new parameters are added to the blockchain, these parameters are automatically added to the output of this call. This script is executed by CMAKE at build time. https://gitlab.syncad.com/hive/hive/-/merge_requests/211

We fixed several longstanding errors with the account history plugin:
Under rare circumstances, the account history plugin could include duplicate records of an operation in an account’s history as a result of microforks because the notification of last irreversible block was sent to the plugin too early:
https://gitlab.syncad.com/hive/hive/-/merge_requests/205
The wrong number of operations could be returned by get_account_history because of miscounting of effective_comment_vote_operation:
https://gitlab.syncad.com/hive/hive/-/merge_requests/225

We also reviewed and merged in @howo’s changes for recurrent transfers today:
https://gitlab.syncad.com/hive/hive/-/merge_requests/150

Finally, we reviewed and approved @howo’s proposed implementation for resource credit (RC) delegations: https://gitlab.syncad.com/hive/hive/-/issues/152 We will be able to incorporate this change after the hardfork, as it doesn’t require any consensus changes.

# Hivemind (2nd layer applications + social media middleware)

Our work in hivemind last week has also revolved around testing performance and fixing bugs.

We ran full hivemind syncs to test the new code that deep cleans the dictionaries to cut a few gigabytes of memory from hivemind’s memory footprint. The new code worked well, and without any apparent performance problems, but we’ll need to repeat the tests again to obtain final performance numbers, as we got distracted by the hived performance issue we found during this testing (discussed earlier in hived section of this post).

We made several fixes to hivemind:
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/493
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/494
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/496

We found another issue with hivemind that is still under investigation, so we’re not quite ready to make a new release candidate for hivemind yet, but I’m hopeful we’ll still be able to do so by the end of this week as originally planned. The timeframe will be tight, as we still need to merge in several of the above changes to the develop branch and do real-world performance testing on api.hive.blog.

# Modular hivemind (framework for hive applications)

During documentation and discussion of the fork resolution code for hive using SQL shadow tables, some concerns were raised about issues where a modular-Hive based application could hold a transaction open, preventing the fork-resolving code from swapping to a new fork, so we’re looking at various ways to manage this issue.

We didn’t have time to make the changes for the sql serializer last week due to the time spent fixing the various issues discussed in this post, but we will likely complete that work in the coming week. Then we’ll be able to do a full performance test of the sql serializer in combination with a full sync of hivemind.

# Condenser (code base for https://hive.blog)

We incorporated several fixes to condenser and deployed them on hive.blog:
Search fix by @quochuy: https://gitlab.syncad.com/hive/condenser/-/merge_requests/246
Iframe fix by @mahdiyari: https://gitlab.syncad.com/hive/condenser/-/merge_requests/249
Fix for 3speak.tv domain by @jes2850: https://gitlab.syncad.com/hive/condenser/-/merge_requests/251
Api node selection fix by @jes2850: https://gitlab.syncad.com/hive/condenser/-/merge_requests/254

# Hived testnet

We’re planning to launch an updated testnet on Wednesday with the latest fixes to hived discussed above. We’ll be tagging this version of hived as an official release candidate.

That will be followed by the launch of an API node configured to draw data from the testnet (probably on Thursday). This API node will allow Hive applications to begin adding code changes to support new features added by the hardfork, such as vote expiration reporting.

# Planned date for hardfork 25

Based on our testing experience so far, I’m currently projecting the hardfork will be in the latter part of June (about a week or so past my earlier “best case” projection).

Assuming no major problems are discovered in the coming week with the release candidate, we’ll next begin notifying exchanges in order to give them 30 days notice which should be plenty of time to update their wallets before the hardfork.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/11th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-11th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-11th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-11th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-11th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-11th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-11th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-11th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-11th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-11th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-11th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/11th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;11th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">![blocktrades update.png](https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png) Below is a list of Hive-related programming issues worked on by the BlockTrades team during the last week: # Hived work (blockchain node software) Last week we’ve been focused on testing hived in preparation for a final feature freeze and fixing bugs as we find them. So far most of the bugs we’ve found are very old bugs that have been around for many years. We fixed two bugs we found and discussed in last weeks report: 1. Better warnings and less cpu-loading when node gets no peers at startup https://gitlab.syncad.com/hive/hive/-/merge_requests/220 2. Fix to beem to fix update_proposals test https://gitlab.syncad.com/hive/beem/-/merge_requests/6 During benchmarking of hivemind sync on two similarly configured systems, we found one system was syncing much slower than the other one. After a fair amount of debugging effort, we ultimately were able to trace this back to intermittent errors on one of the disks in the raid array where hived stored it’s data, but more interestingly, this also exposed an error that was introduced over 5 years ago (ie. when this code was in the BitShares graphene repo). This bug caused incoming blocks that are not yet linkable to the node’s head block to be discarded instead of being kept for future usage, once intervening blocks were received. On normally functioning hardware, this was no big deal, but in the case where disk IO performance was strained (in this case due to intermittent disk errors), this error led to the node often dropping peers and generally straining to keep in sync with the rest of the p2p network. Note that this is a practical real world problem, not just a theoretical one, as we believe this problem led to one commonly used exchange having problems maintaining their Hive wallet open for deposits. At the time, the problem was resolved by convincing the exchange to move their Hive wallet to another computer, but it’s obviously better to have Hive nodes more resistant to such issues. We fixed this bug in these two merge requests: https://gitlab.syncad.com/hive/hive/-/merge_requests/226 https://gitlab.syncad.com/hive/hive/-/merge_requests/227 As part of the above work, we had to dive pretty deep into profiling the performance of hived when processing transactions and blocks, and we identified several places where we would like to improve performance in the future, after the hard fork is completed. The majority of such changes can be released at any time, as they don’t require consensus changes. To facilitate our profiling work, we also made changes to how timestamps are represented in hived logs. By default, timestamps are now stored as UTC times with milliseconds resolution in files and seconds resolution on the console, with the option to store the timestamps with microseconds resolution when needed for profiling: https://gitlab.syncad.com/hive/hive/-/merge_requests/229 We added a script that automatically code-generates the get_config api call, so that when new parameters are added to the blockchain, these parameters are automatically added to the output of this call. This script is executed by CMAKE at build time. https://gitlab.syncad.com/hive/hive/-/merge_requests/211 We fixed several longstanding errors with the account history plugin: Under rare circumstances, the account history plugin could include duplicate records of an operation in an account’s history as a result of microforks because the notification of last irreversible block was sent to the plugin too early: https://gitlab.syncad.com/hive/hive/-/merge_requests/205 The wrong number of operations could be returned by get_account_history because of miscounting of effective_comment_vote_operation: https://gitlab.syncad.com/hive/hive/-/merge_requests/225 We also reviewed and merged in @howo’s changes for recurrent transfers today: https://gitlab.syncad.com/hive/hive/-/merge_requests/150 Finally, we reviewed and approved @howo’s proposed implementation for resource credit (RC) delegations: https://gitlab.syncad.com/hive/hive/-/issues/152 We will be able to incorporate this change after the hardfork, as it doesn’t require any consensus changes. # Hivemind (2nd layer applications + social media middleware) Our work in hivemind last week has also revolved around testing performance and fixing bugs. We ran full hivemind syncs to test the new code that deep cleans the dictionaries to cut a few gigabytes of memory from hivemind’s memory footprint. The new code worked well, and without any apparent performance problems, but we’ll need to repeat the tests again to obtain final performance numbers, as we got distracted by the hived performance issue we found during this testing (discussed earlier in hived section of this post). We made several fixes to hivemind: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/493 https://gitlab.syncad.com/hive/hivemind/-/merge_requests/494 https://gitlab.syncad.com/hive/hivemind/-/merge_requests/496 We found another issue with hivemind that is still under investigation, so we’re not quite ready to make a new release candidate for hivemind yet, but I’m hopeful we’ll still be able to do so by the end of this week as originally planned. The timeframe will be tight, as we still need to merge in several of the above changes to the develop branch and do real-world performance testing on api.hive.blog. # Modular hivemind (framework for hive applications) During documentation and discussion of the fork resolution code for hive using SQL shadow tables, some concerns were raised about issues where a modular-Hive based application could hold a transaction open, preventing the fork-resolving code from swapping to a new fork, so we’re looking at various ways to manage this issue. We didn’t have time to make the changes for the sql serializer last week due to the time spent fixing the various issues discussed in this post, but we will likely complete that work in the coming week. Then we’ll be able to do a full performance test of the sql serializer in combination with a full sync of hivemind. # Condenser (code base for https://hive.blog) We incorporated several fixes to condenser and deployed them on hive.blog: Search fix by @quochuy: https://gitlab.syncad.com/hive/condenser/-/merge_requests/246 Iframe fix by @mahdiyari: https://gitlab.syncad.com/hive/condenser/-/merge_requests/249 Fix for 3speak.tv domain by @jes2850: https://gitlab.syncad.com/hive/condenser/-/merge_requests/251 Api node selection fix by @jes2850: https://gitlab.syncad.com/hive/condenser/-/merge_requests/254 # Hived testnet We’re planning to launch an updated testnet on Wednesday with the latest fixes to hived discussed above. We’ll be tagging this version of hived as an official release candidate. That will be followed by the launch of an API node configured to draw data from the testnet (probably on Thursday). This API node will allow Hive applications to begin adding code changes to support new features added by the hardfork, such as vote expiration reporting. # Planned date for hardfork 25 Based on our testing experience so far, I’m currently projecting the hardfork will be in the latter part of June (about a week or so past my earlier “best case” projection). Assuming no major problems are discovered in the coming week with the release candidate, we’ll next begin notifying exchanges in order to give them 30 days notice which should be plenty of time to update their wallets before the hardfork. See: 11th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" /><media:content medium="image" url="https://images.hive.blog/DQmSihw8Kz4U7TuCQa98DDdCzqbqPFRumuVWAbareiYZW1Z/blocktrades%20update.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>