<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://hivedocs.info/feed.xml" rel="self" type="application/atom+xml" /><link href="https://hivedocs.info/" rel="alternate" type="text/html" /><updated>2021-04-23T11:11:45-07:00</updated><id>https://hivedocs.info/feed.xml</id><title type="html">Hive Chain Documentation</title><subtitle>Your resource for various levels of Hive Documentation.</subtitle><author><name>site curated by: @inertia</name></author><entry><title type="html">My new contributions to the Hive Condenser and Wallet apps.</title><link href="https://hivedocs.info/news/nodejs/condenser/2021/04/22/6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps.html" rel="alternate" type="text/html" title="My new contributions to the Hive Condenser and Wallet apps." /><published>2021-04-22T05:59:18-07:00</published><updated>2021-04-22T05:59:18-07:00</updated><id>https://hivedocs.info/news/nodejs/condenser/2021/04/22/6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps</id><content type="html" xml:base="https://hivedocs.info/news/nodejs/condenser/2021/04/22/6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps.html">&lt;div id=&quot;content-quochuy-6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps&quot;&gt;## Context
I have been involved (voluntarily) with the development of the Condenser &amp;amp; Wallet apps (that are powering https://hive.blog and https://wallet.hive.blog) for quite a while now. There are other great frontends to Hive out there such as https://peakd.com and https://ecency.com but I have always been more or less faithful with the Condenser.

This is a regular report on my new contributions. Some of the new work below might still be in test and not yet deployed.

## Add highlight syntax to code blocks in blog posts
There was [a request for syntax highlighting](https://gitlab.syncad.com/hive/condenser/-/issues/115) on posts. We indeed have some developers sharing code on the platform. So I tested integrating PrismJS and HighlightJS. I picked HighlightJS due to the way it works nicely with the Condenser.

However, there were some concerns that HighlightJS package is 270KB+ which might be a problem for mobile phone users on a slow bandwidth. So this change might not get approved for deployment to production. See my next contribution below instead.

![Syntax Highlighter](https://gitlab.syncad.com/hive/condenser/uploads/f5417cdefb5d92bdca036ab9c1d83992/Screen_Shot_2021-04-15_at_2.47.54_pm.jpg)

Merge request: https://gitlab.syncad.com/hive/condenser/-/merge_requests/234

## Supporting GitHub's GIST embeds
@good-karma suggested that instead of highlighting syntax, we could simply add support for [GIST](http://gist.github.com/) embedded views. [GIST is a tool allowing you to share code snippets or data excerpts](http://gist.github.com/). It also has syntax highlighting so integrating it to the Condenser is lightweight.

There is one downside to the method though: old posts not using GIST won't have their code highlighted.

![GitHub GIST embeds](https://gitlab.syncad.com/hive/condenser/uploads/45a0e2fb10e2f634c871cfdedd2c5e6e/Screen_Shot_2021-04-17_at_9.19.56_pm.jpg)

Merge request: https://gitlab.syncad.com/hive/condenser/-/merge_requests/238

Thank you @mahdiyari for helping with testing

## Display votes value breakdown
Aren't you sometimes curious as to what is the $ contribution of a vote on your post? This little change adds vote value to the voter list of a post.

![Votes value breakdown](https://gitlab.syncad.com/hive/condenser/uploads/b0cb8b7e54df71129624613193e8411e/Screen_Shot_2021-04-22_at_10.34.52_pm.jpg)

Merge request: https://gitlab.syncad.com/hive/condenser/-/merge_requests/242

---

**Vote for my witness**
[![Support @quochuy Witness.jpg](https://images.hive.blog/DQmecYTZemY8SwU6rrg7awhpNRBsehUp7ivk9RGyZsUUpVw/quochuy-hive-witness.jpg)](https://hivesigner.com/sign/account-witness-vote?witness=quochuy&amp;amp;approve=1)
On Hive, Witnesses are playing the important role of providing a performant and safe network for all of us. You have the power to choose 30 trusty witnesses to package transactions and sign the blocks that will go in the Hive blockchain. [Vote for me via HiveSigner](https://hivesigner.com/sign/account-witness-vote?witness=quochuy&amp;amp;approve=1) to support my work for the community.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@quochuy&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-quochuy-6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps').html();
      const outputElem = $('#content-quochuy-6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-quochuy-6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-quochuy-6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps code {
    background: white;
  }
  #content-quochuy-6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-quochuy-6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps a:hover {
    border-bottom: 0;
  }
  #content-quochuy-6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps h1 {
    font-size: 2.2em;
  }
  #content-quochuy-6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-quochuy-6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps header small {
    color: #999;
    font-size: 50%;
  }
  #content-quochuy-6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@quochuy/6cv6sw-my-new-contributions-to-the-hive-condenser-and-wallet-apps&quot;&gt;My new contributions to the Hive Condenser and Wallet apps.&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@quochuy&quot;&gt;@quochuy&lt;/a&gt;
&lt;/p&gt;</content><author><name>quochuy</name></author><category term="news" /><category term="nodejs" /><category term="condenser" /><summary type="html">## Context I have been involved (voluntarily) with the development of the Condenser &amp;amp; Wallet apps (that are powering https://hive.blog and https://wallet.hive.blog) for quite a while now. There are other great frontends to Hive out there such as https://peakd.com and https://ecency.com but I have always been more or less faithful with the Condenser. This is a regular report on my new contributions. Some of the new work below might still be in test and not yet deployed. ## Add highlight syntax to code blocks in blog posts There was [a request for syntax highlighting](https://gitlab.syncad.com/hive/condenser/-/issues/115) on posts. We indeed have some developers sharing code on the platform. So I tested integrating PrismJS and HighlightJS. I picked HighlightJS due to the way it works nicely with the Condenser. However, there were some concerns that HighlightJS package is 270KB+ which might be a problem for mobile phone users on a slow bandwidth. So this change might not get approved for deployment to production. See my next contribution below instead. ![Syntax Highlighter](https://gitlab.syncad.com/hive/condenser/uploads/f5417cdefb5d92bdca036ab9c1d83992/Screen_Shot_2021-04-15_at_2.47.54_pm.jpg) Merge request: https://gitlab.syncad.com/hive/condenser/-/merge_requests/234 ## Supporting GitHub's GIST embeds @good-karma suggested that instead of highlighting syntax, we could simply add support for [GIST](http://gist.github.com/) embedded views. [GIST is a tool allowing you to share code snippets or data excerpts](http://gist.github.com/). It also has syntax highlighting so integrating it to the Condenser is lightweight. There is one downside to the method though: old posts not using GIST won't have their code highlighted. ![GitHub GIST embeds](https://gitlab.syncad.com/hive/condenser/uploads/45a0e2fb10e2f634c871cfdedd2c5e6e/Screen_Shot_2021-04-17_at_9.19.56_pm.jpg) Merge request: https://gitlab.syncad.com/hive/condenser/-/merge_requests/238 Thank you @mahdiyari for helping with testing ## Display votes value breakdown Aren't you sometimes curious as to what is the $ contribution of a vote on your post? This little change adds vote value to the voter list of a post. ![Votes value breakdown](https://gitlab.syncad.com/hive/condenser/uploads/b0cb8b7e54df71129624613193e8411e/Screen_Shot_2021-04-22_at_10.34.52_pm.jpg) Merge request: https://gitlab.syncad.com/hive/condenser/-/merge_requests/242 --- **Vote for my witness** [![Support @quochuy Witness.jpg](https://images.hive.blog/DQmecYTZemY8SwU6rrg7awhpNRBsehUp7ivk9RGyZsUUpVw/quochuy-hive-witness.jpg)](https://hivesigner.com/sign/account-witness-vote?witness=quochuy&amp;amp;approve=1) On Hive, Witnesses are playing the important role of providing a performant and safe network for all of us. You have the power to choose 30 trusty witnesses to package transactions and sign the blocks that will go in the Hive blockchain. [Vote for me via HiveSigner](https://hivesigner.com/sign/account-witness-vote?witness=quochuy&amp;amp;approve=1) to support my work for the community. See: My new contributions to the Hive Condenser and Wallet apps. by @quochuy</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://gitlab.syncad.com/hive/condenser/uploads/f5417cdefb5d92bdca036ab9c1d83992/Screen_Shot_2021-04-15_at_2.47.54_pm.jpg" /><media:content medium="image" url="https://gitlab.syncad.com/hive/condenser/uploads/f5417cdefb5d92bdca036ab9c1d83992/Screen_Shot_2021-04-15_at_2.47.54_pm.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Tin Toy - HF25 on a Local Testnet</title><link href="https://hivedocs.info/tools/docker/testnet/2021/04/15/tin-toy-hf26-on-a-local-testnet.html" rel="alternate" type="text/html" title="Tin Toy - HF25 on a Local Testnet" /><published>2021-04-15T00:20:51-07:00</published><updated>2021-04-15T00:20:51-07:00</updated><id>https://hivedocs.info/tools/docker/testnet/2021/04/15/tin-toy-hf26-on-a-local-testnet</id><content type="html" xml:base="https://hivedocs.info/tools/docker/testnet/2021/04/15/tin-toy-hf26-on-a-local-testnet.html">&lt;div id=&quot;content-inertia-tin-toy-hf26-on-a-local-testnet&quot;&gt;&lt;div class=&quot;pull-right&quot;&gt;
  &lt;img src=&quot;https://i.imgur.com/FkZIVUu.jpg&quot; /&gt;
&lt;/div&gt;

One of the tools I maintain is Tin Toy.  It's a docker image for running a tiny Hive testnet on your local computer.

With it, you can point your application and test new functionality, without having to broadcast to the mainnet.

I just did a refresh on the `develop` branch so you can try out the next hardfork, HF25.

It's also a tool that comes in handy for me, when I'm doing [documentation](https://peakd.com/c/hive-139531/search?q=devportal), because it helps me find new functionality and create tutorials.  You'll find that anytime the devportal mentions a testnet, it's going to recommend tintoy.  And so for this reason, I feel like this is time well spent when researching and improving the devportal.

To try out the hived 1.26.0, right now:

```bash
docker run -d -p 8090:8090 inertia/tintoy:develop
```

Then point your app API endpoint at `http://127.0.0.1:8080`

--- 

Tin Toy - A tiny Hive testnet based on [tinman](https://gitlab.syncad.com/hive/tinman)

# Quickstart

```bash
docker run -d -p 8090:8090 inertia/tintoy:latest
```

Using `-p 8090:8090` will expose json-rpc.

... or ...

```bash
docker run -d -P inertia/tintoy:latest
```

Using `-P` will expose all of the ports, ephemerally (see below).

If you want to modify the scripts before deploying:

```bash
git clone https://gist.github.com/b88e7bfff8862858e54c59392e2bce20.git tintoy
cd tintoy
docker build -t myname/tintoy:mybranch .
docker run -d -P myname/tintoy:mybranch
```

For example, you can modify the first line of `Dockerfile` to switch versions of `hived`.

Tin Toy uses:

```Dockerfile
FROM hiveio/hive:latest
```

But you can switch to any branch and try it out.  Suggested branches to try can be found in [hive/activity](https://gitlab.syncad.com/hive/hive/activity).

Say we want to take a look at a branch like `develop`.  Change the first line of the `Dockerfile` to:

```Dockerfile
FROM hiveio/hive:develop
```

Then build and run.

# Shell In

* Use `docker ps` to get the name of the existing container.
* Use the command `docker exec -it &lt;container name=&quot;&quot;&gt; /bin/bash` to get a bash shell in the container.

# How to Use

Once the docker container has fully deployed, you'll have access to various port.  Internally, the docker container responds to:

| Port | Purpose   |
|------|-----------|
| 2001 | p2p       |
| 8090 | jussi json-rpc |
| 8091 | hived json-rpc |
| 8092 | hivemind json-rpc |
| 5000 | tinman server (if enabled) |

If you launched with `-P` (ephemeral ports enabled), you can get a list of ports:

```bash
docker ps
```

Which might return something like:

```
CONTAINER ID        IMAGE                   COMMAND                  CREATED             STATUS              PORTS                                                                                                NAMES
290810dba18e        inertia/tintoy:latest   &quot;/bin/sh -c /app/boo…&quot;   5 minutes ago       Up 5 minutes        0.0.0.0:32832-&amp;gt;2001/tcp, 0.0.0.0:32831-&amp;gt;8080/tcp, 0.0.0.0:32830-&amp;gt;8090/tcp, 0.0.0.0:32829-&amp;gt;8091/tcp   tintoy
```

## Default Secret Key

Normally, the secret key for a testnet is kept secret.  But for a local testnet, there's no reason to keep it a secret.  For tintoy, the default secret key is set in the `Dockerfile`:

```bash
ENV SHARED_SECRET tintoy
```

Which means, if you want to derive the private keys for `tnman`, you could use the following command:

```bash
get_dev_key tintoy owner-tnman active-tnman posting-tnman memo-tnman | jq
```

```json
[
  {
    &quot;private_key&quot;: &quot;5K5kjWq8pY23YptZaiEkiiaKi1wafufj63nzAtaDu1epVXw9fvz&quot;,
    &quot;public_key&quot;: &quot;TST7uubH7SpknapasQTzW1rFho3LUn1pFmdR7X4f1cHmK22aTJYm3&quot;,
    &quot;account_name&quot;: &quot;owner-tnman&quot;
  },
  {
    &quot;private_key&quot;: &quot;5K3NwkFwCnsSfJNACw1qm3zzojWBtP8k4rTb2kbLQ4DDR6TgGnw&quot;,
    &quot;public_key&quot;: &quot;TST4w9GXogQtqPprzPhp7WKZPPKWXv4KvqqMMgd5agJQCDtYLBJwA&quot;,
    &quot;account_name&quot;: &quot;active-tnman&quot;
  },
  {
    &quot;private_key&quot;: &quot;5Jrdrbt5xfjVeHfHd5JMiJy1FfrGtuieRvzr9WFYhcdHpjgfwPY&quot;,
    &quot;public_key&quot;: &quot;TST883nSqJL5KbVgfdV44snPPDTStQQxfR7vj8XttsZo25sXvHAnQ&quot;,
    &quot;account_name&quot;: &quot;posting-tnman&quot;
  },
  {
    &quot;private_key&quot;: &quot;5KB3ddeh5o3WghSM3qQaUthxVt7QZWfNYCoiAW3XYfeDki1oH9z&quot;,
    &quot;public_key&quot;: &quot;TST56jtUgZrajuBUgdECYaew6cebjSbKWVdtCKkc4xxLAFZQ9f8A9&quot;,
    &quot;account_name&quot;: &quot;memo-tnman&quot;
  }
]
```

Every account on the testnet uses `tnman` as their account authority.  Using this account, you can sign any transaction for any account.

## Snapshot Refresh

Occasionally, it's a good idea to refresh the `sample-snapshot.json` file.  This process is usually only required to be performed by the repo maintainer, but if you want to do it yourself, here are the steps:

1. Install `tinman` by following that product's [README.md](https://gitlab.syncad.com/hive/tinman#installation).
2. Next, [generate a new snapshot](https://gitlab.syncad.com/hive/tinman#taking-a-snapshot).
  * Example: `tinman snapshot -s https://anyx.io -o - | pv &amp;gt; snapshot.json`
3. Once we have our new snapshot, create a sample, overwriting the previous one.
  * Example: `tinman sample -i snapshot.json -o sample-snapshot.json`
4. Delete (or move) `snapshot.json` (we don't need it anymore now that we have `sample-snapshot.json`).
&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@inertia&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/tin-toy-hf26-on-a-local-testnet&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-inertia-tin-toy-hf26-on-a-local-testnet').html();
      const outputElem = $('#content-inertia-tin-toy-hf26-on-a-local-testnet');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-inertia-tin-toy-hf26-on-a-local-testnet {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-inertia-tin-toy-hf26-on-a-local-testnet code {
    background: white;
  }
  #content-inertia-tin-toy-hf26-on-a-local-testnet a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-inertia-tin-toy-hf26-on-a-local-testnet a:hover {
    border-bottom: 0;
  }
  #content-inertia-tin-toy-hf26-on-a-local-testnet h1 {
    font-size: 2.2em;
  }
  #content-inertia-tin-toy-hf26-on-a-local-testnet h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-inertia-tin-toy-hf26-on-a-local-testnet header small {
    color: #999;
    font-size: 50%;
  }
  #content-inertia-tin-toy-hf26-on-a-local-testnet img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@inertia/tin-toy-hf26-on-a-local-testnet&quot;&gt;Tin Toy - HF25 on a Local Testnet&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@inertia&quot;&gt;@inertia&lt;/a&gt;
&lt;/p&gt;

&lt;/container&gt;&lt;/div&gt;</content><author><name>inertia</name></author><category term="tools" /><category term="docker" /><category term="testnet" /><summary type="html">One of the tools I maintain is Tin Toy. It's a docker image for running a tiny Hive testnet on your local computer. With it, you can point your application and test new functionality, without having to broadcast to the mainnet. I just did a refresh on the `develop` branch so you can try out the next hardfork, HF25. It's also a tool that comes in handy for me, when I'm doing [documentation](https://peakd.com/c/hive-139531/search?q=devportal), because it helps me find new functionality and create tutorials. You'll find that anytime the devportal mentions a testnet, it's going to recommend tintoy. And so for this reason, I feel like this is time well spent when researching and improving the devportal. To try out the hived 1.26.0, right now: ```bash docker run -d -p 8090:8090 inertia/tintoy:develop ``` Then point your app API endpoint at `http://127.0.0.1:8080` --- Tin Toy - A tiny Hive testnet based on [tinman](https://gitlab.syncad.com/hive/tinman) # Quickstart ```bash docker run -d -p 8090:8090 inertia/tintoy:latest ``` Using `-p 8090:8090` will expose json-rpc. ... or ... ```bash docker run -d -P inertia/tintoy:latest ``` Using `-P` will expose all of the ports, ephemerally (see below). If you want to modify the scripts before deploying: ```bash git clone https://gist.github.com/b88e7bfff8862858e54c59392e2bce20.git tintoy cd tintoy docker build -t myname/tintoy:mybranch . docker run -d -P myname/tintoy:mybranch ``` For example, you can modify the first line of `Dockerfile` to switch versions of `hived`. Tin Toy uses: ```Dockerfile FROM hiveio/hive:latest ``` But you can switch to any branch and try it out. Suggested branches to try can be found in [hive/activity](https://gitlab.syncad.com/hive/hive/activity). Say we want to take a look at a branch like `develop`. Change the first line of the `Dockerfile` to: ```Dockerfile FROM hiveio/hive:develop ``` Then build and run. # Shell In * Use `docker ps` to get the name of the existing container. * Use the command `docker exec -it /bin/bash` to get a bash shell in the container. # How to Use Once the docker container has fully deployed, you'll have access to various port. Internally, the docker container responds to: | Port | Purpose | |------|-----------| | 2001 | p2p | | 8090 | jussi json-rpc | | 8091 | hived json-rpc | | 8092 | hivemind json-rpc | | 5000 | tinman server (if enabled) | If you launched with `-P` (ephemeral ports enabled), you can get a list of ports: ```bash docker ps ``` Which might return something like: ``` CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 290810dba18e inertia/tintoy:latest &quot;/bin/sh -c /app/boo…&quot; 5 minutes ago Up 5 minutes 0.0.0.0:32832-&amp;gt;2001/tcp, 0.0.0.0:32831-&amp;gt;8080/tcp, 0.0.0.0:32830-&amp;gt;8090/tcp, 0.0.0.0:32829-&amp;gt;8091/tcp tintoy ``` ## Default Secret Key Normally, the secret key for a testnet is kept secret. But for a local testnet, there's no reason to keep it a secret. For tintoy, the default secret key is set in the `Dockerfile`: ```bash ENV SHARED_SECRET tintoy ``` Which means, if you want to derive the private keys for `tnman`, you could use the following command: ```bash get_dev_key tintoy owner-tnman active-tnman posting-tnman memo-tnman | jq ``` ```json [ { &quot;private_key&quot;: &quot;5K5kjWq8pY23YptZaiEkiiaKi1wafufj63nzAtaDu1epVXw9fvz&quot;, &quot;public_key&quot;: &quot;TST7uubH7SpknapasQTzW1rFho3LUn1pFmdR7X4f1cHmK22aTJYm3&quot;, &quot;account_name&quot;: &quot;owner-tnman&quot; }, { &quot;private_key&quot;: &quot;5K3NwkFwCnsSfJNACw1qm3zzojWBtP8k4rTb2kbLQ4DDR6TgGnw&quot;, &quot;public_key&quot;: &quot;TST4w9GXogQtqPprzPhp7WKZPPKWXv4KvqqMMgd5agJQCDtYLBJwA&quot;, &quot;account_name&quot;: &quot;active-tnman&quot; }, { &quot;private_key&quot;: &quot;5Jrdrbt5xfjVeHfHd5JMiJy1FfrGtuieRvzr9WFYhcdHpjgfwPY&quot;, &quot;public_key&quot;: &quot;TST883nSqJL5KbVgfdV44snPPDTStQQxfR7vj8XttsZo25sXvHAnQ&quot;, &quot;account_name&quot;: &quot;posting-tnman&quot; }, { &quot;private_key&quot;: &quot;5KB3ddeh5o3WghSM3qQaUthxVt7QZWfNYCoiAW3XYfeDki1oH9z&quot;, &quot;public_key&quot;: &quot;TST56jtUgZrajuBUgdECYaew6cebjSbKWVdtCKkc4xxLAFZQ9f8A9&quot;, &quot;account_name&quot;: &quot;memo-tnman&quot; } ] ``` Every account on the testnet uses `tnman` as their account authority. Using this account, you can sign any transaction for any account. ## Snapshot Refresh Occasionally, it's a good idea to refresh the `sample-snapshot.json` file. This process is usually only required to be performed by the repo maintainer, but if you want to do it yourself, here are the steps: 1. Install `tinman` by following that product's [README.md](https://gitlab.syncad.com/hive/tinman#installation). 2. Next, [generate a new snapshot](https://gitlab.syncad.com/hive/tinman#taking-a-snapshot). * Example: `tinman snapshot -s https://anyx.io -o - | pv &amp;gt; snapshot.json` 3. Once we have our new snapshot, create a sample, overwriting the previous one. * Example: `tinman sample -i snapshot.json -o sample-snapshot.json` 4. Delete (or move) `snapshot.json` (we don't need it anymore now that we have `sample-snapshot.json`). &amp;lt;/div&amp;gt; See: Tin Toy - HF25 on a Local Testnet by @inertia</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://i.imgur.com/FkZIVUu.jpg" /><media:content medium="image" url="https://i.imgur.com/FkZIVUu.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Hive core developer meeting #21</title><link href="https://hivedocs.info/news/core/development/2021/04/13/hive-core-developer-meeting-21.html" rel="alternate" type="text/html" title="Hive core developer meeting #21" /><published>2021-04-13T06:12:39-07:00</published><updated>2021-04-13T06:12:39-07:00</updated><id>https://hivedocs.info/news/core/development/2021/04/13/hive-core-developer-meeting-21</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/04/13/hive-core-developer-meeting-21.html">&lt;div id=&quot;content-howo-hive-core-developer-meeting-21&quot;&gt;https://www.youtube.com/watch?v=2tOH_yCANCo


2:47 - Intro(Howo)
3:34 - (Blocktrades) - changes and future planning
8:53 - RC plugin
10:40 - Usage of memory
15:33 - incoming RC delegation api feature
17:08 - json operation limit per block
21:46 - Testnet + Bug bounty
22:54 - Hive stem hackathon
26:01 - test voice on another platform like jitsi and stop paying zoom fees
26:53 - move the meeting ahead by few hours
29:18 - Soft cap hf25 or hf26
31:00 - Max curation rewards on top of author rewards
33:15 : Review Issues on gitlab

If you're listening to the whole thing, please post timestamps as a comment, the first one to do so (and correctly) will get a 100% upvote from me :)

# meeting tl;dr:

## Dev sync

As usual it's better to listen to this part

## RC delegations

@blocktrades and team are concerned about some design decisions (operations in a non consensus plugin), after some offline discussions we realized that it was fine, we were just not aligned on semantics. 

Then there are some memory concerns (a lot of new data is stored). I will be running some tests this week to build a million delegations and see the memory impact it would have on nodes, it shouldn't cost more than a extra gig of ram. So I'll be building a test to monitor this. 

Also while we were discussing offline, we realized that rc delegates were non consensus meaning that it could be rolled out without a hard fork, and ultimately decided to push them to hf25.1, the reasoning being that there is no reason to risk the health of the chain making a big release when we can release hf25 and then a bit later release hf25.1 with rc delegations. I know it will come as a disapointment to some, but one of the core principles of the dev team is risk averse and if we can avoid a risk / spread it over multiple smaller releases, we will do it.

## Incoming rc delegations index

Us implementing the index or not will depend on the result from the memory cost of the rc plugin, but it may have to be done via L2

## Increase custom json operation limit per block

Would be a problem as we go into the middle of 2021 with a lot of applications relying on it, it's actually not a problem, as the limit is &quot;per account per block&quot; and not &quot;per block&quot;. 

## Testnet setup + date (?) + bug bounty ?

Testnet will be setup by voluntary witnesses (most likely myself), date is still kinda undetermined, but could be as early as the end of the week, the &quot;human&quot; cost of organizing a bug bounty was deemed to big compared to the benefits it brings.

## HiveStem hackathon on core dev things ?

We figured that it would be interesting to let people hack on hivemind, so I will be creating a guide on how to setup a dev hivemind environment so participants can participate on it if they want (things like communities, sorting algorithms etc) 

## Test another platform like jitsi and stop paying zoom fees

We'll need to see with @roelandp who currently pays for the account and @crimsonclad who manages the stream but we are inclined to use any platform really.

## Move the meeting ahead by a few hours

There is a bit of wiggle room (1/2 hours early, an hour after), we'll run a poll with current regular participants to see what would fit them best.

## soft cap in hf25 or hf26

https://gitlab.syncad.com/hive/hive/-/issues/140 we will roll out a fix on hf25, it's a very small change but an important one for hive -&amp;gt; hbd conversions.

## from @guiltyparties: 
`Review of open issues on gitlab (who, when, ...). Some are 1 year old.`
```
The possibility for authors/dapps to set a) max accepted rewards to author AND b) max accepted rewards to curator ---- both values required or set to default. Usecase: dapp wants to limit rewards for posts through it to 1$ for authors but to $10 for curators.
```

I think it would be possible to get close to that output via beneficiaries and max payout, I can't remember if curation rewards are before or after beneficiaries (before would make more sense) so let's say you want 1$ to the author and 10$ to curators, you can set the max reward to 20$, and a 90% beneficiary to @null, that way when it's computed you get:

50% of the reward goes to curators = 10$, out of the remaining 10$ for the author 9$ goes to @null, and 1$ goes to the author. 

Something to play around with, but I think this can be done purely using the existing chain functionalities.

##  from @arcange:

`Review of open issues on gitlab (who, when, ...). Some are 1 year old.` 

Some discussion regarding on who's responsibility it falls to follow up with open tickets and who should close tickets, better to listen to this part. 

Then we reviewed and closed https://gitlab.syncad.com/hive/hive/-/issues/61 and https://gitlab.syncad.com/hive/hive/-/issues/14


# Support what I'm doing 

If you like what I'm doing, please consider voting on my new proposal:
https://peakd.com/proposals/167
[hivesigner](https://hivesigner.com/import?redirect=%2Fsign%2Fupdate-proposal-votes%3Fproposal_ids%3D%255B167%255D%26approve%3Dtrue&amp;amp;authority=active)&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@howo&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/hive-core-developer-meeting-21&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-howo-hive-core-developer-meeting-21').html();
      const outputElem = $('#content-howo-hive-core-developer-meeting-21');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-howo-hive-core-developer-meeting-21 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-howo-hive-core-developer-meeting-21 code {
    background: white;
  }
  #content-howo-hive-core-developer-meeting-21 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-howo-hive-core-developer-meeting-21 a:hover {
    border-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-21 h1 {
    font-size: 2.2em;
  }
  #content-howo-hive-core-developer-meeting-21 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-howo-hive-core-developer-meeting-21 header small {
    color: #999;
    font-size: 50%;
  }
  #content-howo-hive-core-developer-meeting-21 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/meeting/@howo/hive-core-developer-meeting-21&quot;&gt;Hive core developer meeting #21&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@howo&quot;&gt;@howo&lt;/a&gt;
&lt;/p&gt;</content><author><name>howo</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">https://www.youtube.com/watch?v=2tOH_yCANCo 2:47 - Intro(Howo) 3:34 - (Blocktrades) - changes and future planning 8:53 - RC plugin 10:40 - Usage of memory 15:33 - incoming RC delegation api feature 17:08 - json operation limit per block 21:46 - Testnet + Bug bounty 22:54 - Hive stem hackathon 26:01 - test voice on another platform like jitsi and stop paying zoom fees 26:53 - move the meeting ahead by few hours 29:18 - Soft cap hf25 or hf26 31:00 - Max curation rewards on top of author rewards 33:15 : Review Issues on gitlab If you're listening to the whole thing, please post timestamps as a comment, the first one to do so (and correctly) will get a 100% upvote from me :) # meeting tl;dr: ## Dev sync As usual it's better to listen to this part ## RC delegations @blocktrades and team are concerned about some design decisions (operations in a non consensus plugin), after some offline discussions we realized that it was fine, we were just not aligned on semantics. Then there are some memory concerns (a lot of new data is stored). I will be running some tests this week to build a million delegations and see the memory impact it would have on nodes, it shouldn't cost more than a extra gig of ram. So I'll be building a test to monitor this. Also while we were discussing offline, we realized that rc delegates were non consensus meaning that it could be rolled out without a hard fork, and ultimately decided to push them to hf25.1, the reasoning being that there is no reason to risk the health of the chain making a big release when we can release hf25 and then a bit later release hf25.1 with rc delegations. I know it will come as a disapointment to some, but one of the core principles of the dev team is risk averse and if we can avoid a risk / spread it over multiple smaller releases, we will do it. ## Incoming rc delegations index Us implementing the index or not will depend on the result from the memory cost of the rc plugin, but it may have to be done via L2 ## Increase custom json operation limit per block Would be a problem as we go into the middle of 2021 with a lot of applications relying on it, it's actually not a problem, as the limit is &quot;per account per block&quot; and not &quot;per block&quot;. ## Testnet setup + date (?) + bug bounty ? Testnet will be setup by voluntary witnesses (most likely myself), date is still kinda undetermined, but could be as early as the end of the week, the &quot;human&quot; cost of organizing a bug bounty was deemed to big compared to the benefits it brings. ## HiveStem hackathon on core dev things ? We figured that it would be interesting to let people hack on hivemind, so I will be creating a guide on how to setup a dev hivemind environment so participants can participate on it if they want (things like communities, sorting algorithms etc) ## Test another platform like jitsi and stop paying zoom fees We'll need to see with @roelandp who currently pays for the account and @crimsonclad who manages the stream but we are inclined to use any platform really. ## Move the meeting ahead by a few hours There is a bit of wiggle room (1/2 hours early, an hour after), we'll run a poll with current regular participants to see what would fit them best. ## soft cap in hf25 or hf26 https://gitlab.syncad.com/hive/hive/-/issues/140 we will roll out a fix on hf25, it's a very small change but an important one for hive -&amp;gt; hbd conversions. ## from @guiltyparties: `Review of open issues on gitlab (who, when, ...). Some are 1 year old.` ``` The possibility for authors/dapps to set a) max accepted rewards to author AND b) max accepted rewards to curator ---- both values required or set to default. Usecase: dapp wants to limit rewards for posts through it to 1$ for authors but to $10 for curators. ``` I think it would be possible to get close to that output via beneficiaries and max payout, I can't remember if curation rewards are before or after beneficiaries (before would make more sense) so let's say you want 1$ to the author and 10$ to curators, you can set the max reward to 20$, and a 90% beneficiary to @null, that way when it's computed you get: 50% of the reward goes to curators = 10$, out of the remaining 10$ for the author 9$ goes to @null, and 1$ goes to the author. Something to play around with, but I think this can be done purely using the existing chain functionalities. ## from @arcange: `Review of open issues on gitlab (who, when, ...). Some are 1 year old.` Some discussion regarding on who's responsibility it falls to follow up with open tickets and who should close tickets, better to listen to this part. Then we reviewed and closed https://gitlab.syncad.com/hive/hive/-/issues/61 and https://gitlab.syncad.com/hive/hive/-/issues/14 # Support what I'm doing If you like what I'm doing, please consider voting on my new proposal: https://peakd.com/proposals/167 [hivesigner](https://hivesigner.com/import?redirect=%2Fsign%2Fupdate-proposal-votes%3Fproposal_ids%3D%255B167%255D%26approve%3Dtrue&amp;amp;authority=active) See: Hive core developer meeting #21 by @howo</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://img.youtube.com/vi/2tOH_yCANCo/0.jpg" /><media:content medium="image" url="https://img.youtube.com/vi/2tOH_yCANCo/0.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">My new contributions to the Hive Condenser and Wallet apps.</title><link href="https://hivedocs.info/news/nodejs/condenser/2021/04/13/5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps.html" rel="alternate" type="text/html" title="My new contributions to the Hive Condenser and Wallet apps." /><published>2021-04-13T00:27:24-07:00</published><updated>2021-04-13T00:27:24-07:00</updated><id>https://hivedocs.info/news/nodejs/condenser/2021/04/13/5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps</id><content type="html" xml:base="https://hivedocs.info/news/nodejs/condenser/2021/04/13/5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps.html">&lt;div id=&quot;content-quochuy-5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps&quot;&gt;## Context
I have been involved (voluntarily) with the development of the Condenser &amp;amp; Wallet apps (that are powering https://hive.blog and https://wallet.hive.blog) for quite a while now. There are other great frontends to Hive out there such as https://peakd.com and https://ecency.com but I have always been more or less faithful with the Condenser.

This is a regular report on my new contributions. Some of the new work below might still be in test and not yet deployed.

## Sanitize input fields
I noticed that when creating a new community, users were allowed to use HTML code. Although the HTML is not interpreted it is still displayed (encoded) on the screen which looks bad. Apparently, there is no sanitising code of user input for those fields. This code change adds input sanitisation at creation and content filtering at display to clean up existing data.

Merge request: https://gitlab.syncad.com/hive/condenser/-/merge_requests/232

## Modifying the community selection on post creation
Myself and other users have often accidentally posted our content in the wrong community because we forgot to select the right one when creating the post. Currently the community selection process is not very obvious. For this change what I've done is:
- create an actually community selector drop down menu in the post editing form
- move it to the bottom right next to the `Post` button

![Community selector](https://gitlab.syncad.com/hive/condenser/uploads/2c64f4229ba3743c83cf0afcb37f9d91/Screen_Shot_2021-04-09_at_4.51.17_pm.jpg)

To change community, you don't have to go back to browse through them anymore, the menu should make it easier.
![Community selector](https://gitlab.syncad.com/hive/condenser/uploads/00cc3a8373a5914ee8dc506928e7af4a/Screen_Shot_2021-04-09_at_5.07.49_pm.jpg)

---

**Vote for my witness**
[![Support @quochuy Witness.jpg](https://images.hive.blog/DQmecYTZemY8SwU6rrg7awhpNRBsehUp7ivk9RGyZsUUpVw/quochuy-hive-witness.jpg)](https://hivesigner.com/sign/account-witness-vote?witness=quochuy&amp;amp;approve=1)
On Hive, Witnesses are playing the important role of providing a performant and safe network for all of us. You have the power to choose 30 trusty witnesses to package transactions and sign the blocks that will go in the Hive blockchain. [Vote for me via HiveSigner](https://hivesigner.com/sign/account-witness-vote?witness=quochuy&amp;amp;approve=1) to support my work for the community.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@quochuy&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-quochuy-5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps').html();
      const outputElem = $('#content-quochuy-5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-quochuy-5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-quochuy-5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps code {
    background: white;
  }
  #content-quochuy-5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-quochuy-5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps a:hover {
    border-bottom: 0;
  }
  #content-quochuy-5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps h1 {
    font-size: 2.2em;
  }
  #content-quochuy-5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-quochuy-5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps header small {
    color: #999;
    font-size: 50%;
  }
  #content-quochuy-5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@quochuy/5ps1ah-my-new-contributions-to-the-hive-condenser-and-wallet-apps&quot;&gt;My new contributions to the Hive Condenser and Wallet apps.&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@quochuy&quot;&gt;@quochuy&lt;/a&gt;
&lt;/p&gt;</content><author><name>quochuy</name></author><category term="news" /><category term="nodejs" /><category term="condenser" /><summary type="html">## Context I have been involved (voluntarily) with the development of the Condenser &amp;amp; Wallet apps (that are powering https://hive.blog and https://wallet.hive.blog) for quite a while now. There are other great frontends to Hive out there such as https://peakd.com and https://ecency.com but I have always been more or less faithful with the Condenser. This is a regular report on my new contributions. Some of the new work below might still be in test and not yet deployed. ## Sanitize input fields I noticed that when creating a new community, users were allowed to use HTML code. Although the HTML is not interpreted it is still displayed (encoded) on the screen which looks bad. Apparently, there is no sanitising code of user input for those fields. This code change adds input sanitisation at creation and content filtering at display to clean up existing data. Merge request: https://gitlab.syncad.com/hive/condenser/-/merge_requests/232 ## Modifying the community selection on post creation Myself and other users have often accidentally posted our content in the wrong community because we forgot to select the right one when creating the post. Currently the community selection process is not very obvious. For this change what I've done is: - create an actually community selector drop down menu in the post editing form - move it to the bottom right next to the `Post` button ![Community selector](https://gitlab.syncad.com/hive/condenser/uploads/2c64f4229ba3743c83cf0afcb37f9d91/Screen_Shot_2021-04-09_at_4.51.17_pm.jpg) To change community, you don't have to go back to browse through them anymore, the menu should make it easier. ![Community selector](https://gitlab.syncad.com/hive/condenser/uploads/00cc3a8373a5914ee8dc506928e7af4a/Screen_Shot_2021-04-09_at_5.07.49_pm.jpg) --- **Vote for my witness** [![Support @quochuy Witness.jpg](https://images.hive.blog/DQmecYTZemY8SwU6rrg7awhpNRBsehUp7ivk9RGyZsUUpVw/quochuy-hive-witness.jpg)](https://hivesigner.com/sign/account-witness-vote?witness=quochuy&amp;amp;approve=1) On Hive, Witnesses are playing the important role of providing a performant and safe network for all of us. You have the power to choose 30 trusty witnesses to package transactions and sign the blocks that will go in the Hive blockchain. [Vote for me via HiveSigner](https://hivesigner.com/sign/account-witness-vote?witness=quochuy&amp;amp;approve=1) to support my work for the community. See: My new contributions to the Hive Condenser and Wallet apps. by @quochuy</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://gitlab.syncad.com/hive/condenser/uploads/2c64f4229ba3743c83cf0afcb37f9d91/Screen_Shot_2021-04-09_at_4.51.17_pm.jpg" /><media:content medium="image" url="https://gitlab.syncad.com/hive/condenser/uploads/2c64f4229ba3743c83cf0afcb37f9d91/Screen_Shot_2021-04-09_at_4.51.17_pm.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Google Analytics Reports for Hive.io (~150k Unique Users)</title><link href="https://hivedocs.info/news/projects/hive/2021/04/12/google-analytics-reports-for-hiveio-150k-unique-users.html" rel="alternate" type="text/html" title="Google Analytics Reports for Hive.io (~150k Unique Users)" /><published>2021-04-12T09:55:03-07:00</published><updated>2021-04-12T09:55:03-07:00</updated><id>https://hivedocs.info/news/projects/hive/2021/04/12/google-analytics-reports-for-hiveio-150k-unique-users</id><content type="html" xml:base="https://hivedocs.info/news/projects/hive/2021/04/12/google-analytics-reports-for-hiveio-150k-unique-users.html">&lt;div id=&quot;content-therealwolf-google-analytics-reports-for-hiveio-150k-unique-users&quot;&gt;Here is some interesting data of [hive.io](https://hive.io) generated by Google Analytics.

I've used the default reports. If there's something missing, let me know. 🤓

---

### Audience Overview: From Launch to Now

![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23w3EdUkxfqvkLNhcRgnmyxupsbw9HMZcgkSuZC1B4HGuryyG122xRVyXvjDRsECmaGKn.png)

---

### Audience Overview: From January 1st 2021 to Now

![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23w3EdV44J4b3A8gmvZHQnW4k6EPczP2XxbErNDSPvKHzr3oShaBVXEyxvcCkRScYMfSt.png)

---

### Acquisition Overview: From Launch to Now

![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23wXQcbnv22zmRWEJ6B3kdvvqgv2X4mBFXie74hcLMPyaRJnwxJw9CFqtfhoub3LSgyLp.png)

---

### Acquisition Overview: From January 1st 2021 to Now

![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23wgoGyNRnEGJV9oQ4XPbrJQguTFkJncPm8W47SZNLp4S6jSyCdpd6PqXPShRBm8K3yMn.png)

---

### Behaviors Overview: From Launch to Now

![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23wN1x5oUHJ9HbD9TvqjTBBBXVRaAzoKnXY9DJWF8wYtLbLVf4mq1q8gWtZaagNNAgCrx.png)

---

### Behaviors Overview: From January 1st 2021 to Now

![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23wCdNcCaGFEQrmwMVqXt8juJucpmMoZ3BwLjmax7mz1sJmKrjZQU59oPnXfKUJd7Gt28.png)

---

### Footnote

I know that some people are not impressed by the design of Hive.io. And that's fine. Still, looking back, I'm somewhat proud that I was able to create it in a span of days under pressure for it to be ready for Launch on March 25th 2020. (this ofc. goes for **everyone** who collaborated in the launch) Especially considering that I had to come up with a theme and sexy catchphrase.

&amp;gt; Fast.
&amp;gt; Scalable.
&amp;gt; Powerful.
&amp;gt; The Blockchain for Web 3.0

![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/EoibUABQD1YoMsK3va1ySF1QjsorKyh42LGaUJX8PXimvyhKK4brFCX84BoycGetQpU.png)

Now, I'm not sure whether it's actually the best way to describe Hive, considering that tech will always advance and Hive lacks behind in some aspects, and our most powerful attribute/strength is the tight-knit community. So maybe it's time for some change.

Since the website is owned by the community, you can simply submit ideas yourself on Gitlab: https://gitlab.syncad.com/hive/hive-io. Or if that's too troublesome, just comment below. This goes for everything on the website ofc.

Note: I'm not hosting hive.io nor am I &quot;in charge&quot; of Hive. Just a community developer.
&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@therealwolf&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/google-analytics-reports-for-hiveio-150k-unique-users&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-therealwolf-google-analytics-reports-for-hiveio-150k-unique-users').html();
      const outputElem = $('#content-therealwolf-google-analytics-reports-for-hiveio-150k-unique-users');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-therealwolf-google-analytics-reports-for-hiveio-150k-unique-users {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-therealwolf-google-analytics-reports-for-hiveio-150k-unique-users code {
    background: white;
  }
  #content-therealwolf-google-analytics-reports-for-hiveio-150k-unique-users a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-therealwolf-google-analytics-reports-for-hiveio-150k-unique-users a:hover {
    border-bottom: 0;
  }
  #content-therealwolf-google-analytics-reports-for-hiveio-150k-unique-users h1 {
    font-size: 2.2em;
  }
  #content-therealwolf-google-analytics-reports-for-hiveio-150k-unique-users h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-therealwolf-google-analytics-reports-for-hiveio-150k-unique-users header small {
    color: #999;
    font-size: 50%;
  }
  #content-therealwolf-google-analytics-reports-for-hiveio-150k-unique-users img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-102930/@therealwolf/google-analytics-reports-for-hiveio-150k-unique-users&quot;&gt;Google Analytics Reports for Hive.io (~150k Unique Users)&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@therealwolf&quot;&gt;@therealwolf&lt;/a&gt;
&lt;/p&gt;</content><author><name>therealwolf</name></author><category term="news" /><category term="projects" /><category term="hive" /><summary type="html">Here is some interesting data of [hive.io](https://hive.io) generated by Google Analytics. I've used the default reports. If there's something missing, let me know. 🤓 --- ### Audience Overview: From Launch to Now ![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23w3EdUkxfqvkLNhcRgnmyxupsbw9HMZcgkSuZC1B4HGuryyG122xRVyXvjDRsECmaGKn.png) --- ### Audience Overview: From January 1st 2021 to Now ![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23w3EdV44J4b3A8gmvZHQnW4k6EPczP2XxbErNDSPvKHzr3oShaBVXEyxvcCkRScYMfSt.png) --- ### Acquisition Overview: From Launch to Now ![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23wXQcbnv22zmRWEJ6B3kdvvqgv2X4mBFXie74hcLMPyaRJnwxJw9CFqtfhoub3LSgyLp.png) --- ### Acquisition Overview: From January 1st 2021 to Now ![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23wgoGyNRnEGJV9oQ4XPbrJQguTFkJncPm8W47SZNLp4S6jSyCdpd6PqXPShRBm8K3yMn.png) --- ### Behaviors Overview: From Launch to Now ![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23wN1x5oUHJ9HbD9TvqjTBBBXVRaAzoKnXY9DJWF8wYtLbLVf4mq1q8gWtZaagNNAgCrx.png) --- ### Behaviors Overview: From January 1st 2021 to Now ![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/23wCdNcCaGFEQrmwMVqXt8juJucpmMoZ3BwLjmax7mz1sJmKrjZQU59oPnXfKUJd7Gt28.png) --- ### Footnote I know that some people are not impressed by the design of Hive.io. And that's fine. Still, looking back, I'm somewhat proud that I was able to create it in a span of days under pressure for it to be ready for Launch on March 25th 2020. (this ofc. goes for **everyone** who collaborated in the launch) Especially considering that I had to come up with a theme and sexy catchphrase. &amp;gt; Fast. &amp;gt; Scalable. &amp;gt; Powerful. &amp;gt; The Blockchain for Web 3.0 ![image.png](https://files.peakd.com/file/peakd-hive/therealwolf/EoibUABQD1YoMsK3va1ySF1QjsorKyh42LGaUJX8PXimvyhKK4brFCX84BoycGetQpU.png) Now, I'm not sure whether it's actually the best way to describe Hive, considering that tech will always advance and Hive lacks behind in some aspects, and our most powerful attribute/strength is the tight-knit community. So maybe it's time for some change. Since the website is owned by the community, you can simply submit ideas yourself on Gitlab: https://gitlab.syncad.com/hive/hive-io. Or if that's too troublesome, just comment below. This goes for everything on the website ofc. Note: I'm not hosting hive.io nor am I &quot;in charge&quot; of Hive. Just a community developer. See: Google Analytics Reports for Hive.io (~150k Unique Users) by @therealwolf</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/therealwolf/23w3EdUkxfqvkLNhcRgnmyxupsbw9HMZcgkSuZC1B4HGuryyG122xRVyXvjDRsECmaGKn.png" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/therealwolf/23w3EdUkxfqvkLNhcRgnmyxupsbw9HMZcgkSuZC1B4HGuryyG122xRVyXvjDRsECmaGKn.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How to setup a Hivemind Dev Environment</title><link href="https://hivedocs.info/howto/hivemind/2021/04/12/how-to-setup-a-hivemind-dev-environment.html" rel="alternate" type="text/html" title="How to setup a Hivemind Dev Environment" /><published>2021-04-12T08:00:30-07:00</published><updated>2021-04-12T08:00:30-07:00</updated><id>https://hivedocs.info/howto/hivemind/2021/04/12/how-to-setup-a-hivemind-dev-environment</id><content type="html" xml:base="https://hivedocs.info/howto/hivemind/2021/04/12/how-to-setup-a-hivemind-dev-environment.html">&lt;div id=&quot;content-deathwing-how-to-setup-a-hivemind-dev-environment&quot;&gt;
![image.png](https://files.peakd.com/file/peakd-hive/deathwing/23tbMTX77iKs3vk3Z3ST8kik2wiZYMhjovCQnPAJ2rER2tFCQ7jaSJrPkC124YF3Yyhpp.png)

---

#### Preface

This tutorial assumes that you have a server with hived installed and synced. As well as a server capable of running [Hivemind](https://gitlab.syncad.com/hive/hivemind). (preferably Ubuntu 20.04)

If you would like to run a production environment Hivemind, please run a docker container. It is a lot easier to set up and the potential of something going wrong is a lot less than manual setup. (Also recommended)

#### Getting Started

First of all, you would need to install PostgreSQL 12, since that is what we're using for Hivemind at the moment, as well as the main requirements for Hivemind.

`apt install postgresql git python3 python3-dev build-essential libpq-dev libxml2-dev libxslt1-dev libldap2-dev libsasl2-dev libffi-dev`

After the installation is complete, you will need to go into postgres. (This is similar to MySQL -uroot)

`sudo -u postgres psql`

then, create the database user.

`create user hive with password 'hive';`


![image.png](https://files.peakd.com/file/peakd-hive/deathwing/23tRxJBSsvGs8kKGcrU1f7twSivSfs2bybmpEHkRHNHKcxhEuQf7g8byrCoxdzoremfnC.png)

Next step, create the database.

`create database hive;`


![image.png](https://files.peakd.com/file/peakd-hive/deathwing/23tkjayTiHw8sVBiXwXn72naK4FB3DfoVXehYyHvZa6MTPiMDzmjfEWKRcJM7Sqv7KVak.png)


By default, a database is owned by user `postgres` you will need to change this to the user that you will be using for your Hivemind instance, so in this case, `hive`.

`alter database hive owner to hive;`

![image.png](https://files.peakd.com/file/peakd-hive/deathwing/23tkk3PMDiaaspZsH4fWxMfteMsqcmqw1P3uyzrLZTXnBJQ1AsnKpbEcq3KU5Jc8mMrXv.png)

Next, you will need to set up an intarray extension in the database `hive`.

`\c hive`
`create extension intarray;`

Type `\q` to exit postgres and return to terminal.

The next step is to clone the repository for Hivemind.

Use `git clone https://gitlab.syncad.com/hive/hivemind.git`

Next, `cd` into the hivemind directory and installing prerequisites. (if you'd like to run tests)

`cd hivemind`
`git submodule update --init --recursive`

Next step is to start building and installing hivemind.

`python3 setup.py build`
`python3 setup.py install`


![image.png](https://files.peakd.com/file/peakd-hive/deathwing/23tRxSJgh4nF3dtPYtJVzn4m6LGzgQ8X4H67gWiX3eS6iqH6zm9B1gZXkjgveEBq3zz6x.png)

After the build has been successfully completed, export the database information and node information.

`export DATABASE_URL=postgresql://hive:hive@localhost:5432/hive` (hive:hive is user:password).
`export STEEMD_URL='{&quot;default&quot;:&quot;http://apinode:8091&quot;}'`

After everything is set up, you can run Hivemind with `hive sync`.


![image.png](https://files.peakd.com/file/peakd-hive/deathwing/EoATUJKgNA7LDETYTfJJtdz53dwoquqYmG2wQpZhjFTThuhPqjVFsg3bWc9TPZrHWrg.png)

![image.png](https://files.peakd.com/file/peakd-hive/deathwing/23tRxSKeYEg9BZPnmwFsbrzwSVWwuFH8W4An6HnM1Qqm4Wsy4RyWNdhuzMWhG1d6Vfpm2.png)



If your set up was correct and your node is a private, preferably local node, your hivemind instance will start syncing. Just so you know the syncing process can take several days.

To start the server (for incoming calls) you can use `hive server`.


![image.png](https://files.peakd.com/file/peakd-hive/deathwing/EoATVNbcYtNqDHp9cACh9dHq3zj8bzUnYD5HvYmqjGj1UeZxr5mPQkkJrPNpKh1ufJL.png)
&lt;sub&gt;As this is a test instance, it is not fully synced. So a fully synced hivemind will look different, especially *database_head_block* :)&lt;/sub&gt;

#### The End

Please don't forget that this is not recommended for use in production environments, please use Docker in that scenario.

Also, if this helped you and you have an extra witness vote, I'd like to remind you that I am a witness! You are more than welcome to vote for my witness [here](https://peakd.com/me/witnesses).

&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@deathwing&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/how-to-setup-a-hivemind-dev-environment&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-deathwing-how-to-setup-a-hivemind-dev-environment').html();
      const outputElem = $('#content-deathwing-how-to-setup-a-hivemind-dev-environment');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-deathwing-how-to-setup-a-hivemind-dev-environment {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-deathwing-how-to-setup-a-hivemind-dev-environment code {
    background: white;
  }
  #content-deathwing-how-to-setup-a-hivemind-dev-environment a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-deathwing-how-to-setup-a-hivemind-dev-environment a:hover {
    border-bottom: 0;
  }
  #content-deathwing-how-to-setup-a-hivemind-dev-environment h1 {
    font-size: 2.2em;
  }
  #content-deathwing-how-to-setup-a-hivemind-dev-environment h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-deathwing-how-to-setup-a-hivemind-dev-environment header small {
    color: #999;
    font-size: 50%;
  }
  #content-deathwing-how-to-setup-a-hivemind-dev-environment img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/hive-139531/@deathwing/how-to-setup-a-hivemind-dev-environment&quot;&gt;How to setup a Hivemind Dev Environment&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@deathwing&quot;&gt;@deathwing&lt;/a&gt;
&lt;/p&gt;</content><author><name>deathwing</name></author><category term="howto" /><category term="hivemind" /><summary type="html">![image.png](https://files.peakd.com/file/peakd-hive/deathwing/23tbMTX77iKs3vk3Z3ST8kik2wiZYMhjovCQnPAJ2rER2tFCQ7jaSJrPkC124YF3Yyhpp.png) --- #### Preface This tutorial assumes that you have a server with hived installed and synced. As well as a server capable of running [Hivemind](https://gitlab.syncad.com/hive/hivemind). (preferably Ubuntu 20.04) If you would like to run a production environment Hivemind, please run a docker container. It is a lot easier to set up and the potential of something going wrong is a lot less than manual setup. (Also recommended) #### Getting Started First of all, you would need to install PostgreSQL 12, since that is what we're using for Hivemind at the moment, as well as the main requirements for Hivemind. `apt install postgresql git python3 python3-dev build-essential libpq-dev libxml2-dev libxslt1-dev libldap2-dev libsasl2-dev libffi-dev` After the installation is complete, you will need to go into postgres. (This is similar to MySQL -uroot) `sudo -u postgres psql` then, create the database user. `create user hive with password 'hive';` ![image.png](https://files.peakd.com/file/peakd-hive/deathwing/23tRxJBSsvGs8kKGcrU1f7twSivSfs2bybmpEHkRHNHKcxhEuQf7g8byrCoxdzoremfnC.png) Next step, create the database. `create database hive;` ![image.png](https://files.peakd.com/file/peakd-hive/deathwing/23tkjayTiHw8sVBiXwXn72naK4FB3DfoVXehYyHvZa6MTPiMDzmjfEWKRcJM7Sqv7KVak.png) By default, a database is owned by user `postgres` you will need to change this to the user that you will be using for your Hivemind instance, so in this case, `hive`. `alter database hive owner to hive;` ![image.png](https://files.peakd.com/file/peakd-hive/deathwing/23tkk3PMDiaaspZsH4fWxMfteMsqcmqw1P3uyzrLZTXnBJQ1AsnKpbEcq3KU5Jc8mMrXv.png) Next, you will need to set up an intarray extension in the database `hive`. `\c hive` `create extension intarray;` Type `\q` to exit postgres and return to terminal. The next step is to clone the repository for Hivemind. Use `git clone https://gitlab.syncad.com/hive/hivemind.git` Next, `cd` into the hivemind directory and installing prerequisites. (if you'd like to run tests) `cd hivemind` `git submodule update --init --recursive` Next step is to start building and installing hivemind. `python3 setup.py build` `python3 setup.py install` ![image.png](https://files.peakd.com/file/peakd-hive/deathwing/23tRxSJgh4nF3dtPYtJVzn4m6LGzgQ8X4H67gWiX3eS6iqH6zm9B1gZXkjgveEBq3zz6x.png) After the build has been successfully completed, export the database information and node information. `export DATABASE_URL=postgresql://hive:hive@localhost:5432/hive` (hive:hive is user:password). `export STEEMD_URL='{&quot;default&quot;:&quot;http://apinode:8091&quot;}'` After everything is set up, you can run Hivemind with `hive sync`. ![image.png](https://files.peakd.com/file/peakd-hive/deathwing/EoATUJKgNA7LDETYTfJJtdz53dwoquqYmG2wQpZhjFTThuhPqjVFsg3bWc9TPZrHWrg.png) ![image.png](https://files.peakd.com/file/peakd-hive/deathwing/23tRxSKeYEg9BZPnmwFsbrzwSVWwuFH8W4An6HnM1Qqm4Wsy4RyWNdhuzMWhG1d6Vfpm2.png) If your set up was correct and your node is a private, preferably local node, your hivemind instance will start syncing. Just so you know the syncing process can take several days. To start the server (for incoming calls) you can use `hive server`. ![image.png](https://files.peakd.com/file/peakd-hive/deathwing/EoATVNbcYtNqDHp9cACh9dHq3zj8bzUnYD5HvYmqjGj1UeZxr5mPQkkJrPNpKh1ufJL.png) As this is a test instance, it is not fully synced. So a fully synced hivemind will look different, especially *database_head_block* :) #### The End Please don't forget that this is not recommended for use in production environments, please use Docker in that scenario. Also, if this helped you and you have an extra witness vote, I'd like to remind you that I am a witness! You are more than welcome to vote for my witness [here](https://peakd.com/me/witnesses). See: How to setup a Hivemind Dev Environment by @deathwing</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/deathwing/23tbMTX77iKs3vk3Z3ST8kik2wiZYMhjovCQnPAJ2rER2tFCQ7jaSJrPkC124YF3Yyhpp.png" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/deathwing/23tbMTX77iKs3vk3Z3ST8kik2wiZYMhjovCQnPAJ2rER2tFCQ7jaSJrPkC124YF3Yyhpp.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Making a Decentralized Game on Hive - Part 5</title><link href="https://hivedocs.info/howto/nodejs/2021/04/11/making-a-decentralized-game-on-hive-part-5.html" rel="alternate" type="text/html" title="Making a Decentralized Game on Hive - Part 5" /><published>2021-04-11T10:06:57-07:00</published><updated>2021-04-11T10:06:57-07:00</updated><id>https://hivedocs.info/howto/nodejs/2021/04/11/making-a-decentralized-game-on-hive-part-5</id><content type="html" xml:base="https://hivedocs.info/howto/nodejs/2021/04/11/making-a-decentralized-game-on-hive-part-5.html">&lt;div id=&quot;content-mahdiyari-making-a-decentralized-game-on-hive-part-5&quot;&gt;&lt;center&gt;![game-pixabay.jpg](https://images.hive.blog/DQmSeL2wLvGPWHqcLVX4ZtfhqidWhj4GVNiVDC2LsHX6jNX/game-4648923_1280.jpg)&lt;/center&gt;
Games are fun and most people like to play different kinds of games. I'm not sure about the game we are building. Whether it be fun or not, the purpose of this project is the tutorial. To have a step-by-step guide that developers can use as a reference in building apps on Hive.

Check out previous posts:

***
#### Building the transactions
We will build the back-end for the front-end that we built in the previous post. All goes into `js/app.js`.
```
const random = (length = 20) =&amp;gt; {
  const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'
  let str = ''
  for (let i = 0; i &amp;lt; length; i++) {
    str += chars.charAt(Math.floor(Math.random() * chars.length))
  }
  return str
}
```
A simple function to generate a random string. We will use the random string for the game_id.
***
```
const createGame = async () =&amp;gt; {
  const button = document.getElementById('create-game-btn')
  button.setAttribute('disabled', 'true')
  const errorOutput = document.getElementById('create-game-error')
  const successOutput = document.getElementById('create-game-success')
  errorOutput.innerHTML = ''
  successOutput.innerHTML = ''
  try {
    const game = {
      app: 'tictactoe/0.0.1',
      action: 'create_game',
      id: random(20),
      starting_player: document.getElementById('starting-player').value
    }
    const operations = [
      [
        'custom_json',
        {
          required_auths: [],
          required_posting_auths: [userData.username],
          id: 'tictactoe',
          json: JSON.stringify(game)
        }
      ]
    ]
    const tx = new hiveTx.Transaction()
    await tx.create(operations)
    const privateKey = hiveTx.PrivateKey.from(userData.key)
    tx.sign(privateKey)
    const result = await tx.broadcast()
    if (result &amp;amp;&amp;amp; result.result &amp;amp;&amp;amp; result.result.block_num) {
      successOutput.innerHTML =
        'Success! &lt;a href=&quot;link to game&quot;&gt;Click to see&lt;/a&gt;'
    } else {
      errorOutput.innerHTML =
        'Error! Check console for details. Press Ctrl+Shift+J'
      console.error(result)
    }
  } catch (e) {
    errorOutput.innerHTML =
      'Error! Check console for details. Press Ctrl+Shift+J'
    console.error(e)
  }
  button.removeAttribute('disabled')
}
```
We create the transaction by using the [hive-tx](https://www.npmjs.com/package/hive-tx) library then sign and broadcast it. We put the game link in the success message and show it to the user.

Now users can create the game and see the list of games. We create the `game.html` page for users to play the game.
***
#### Game page
We can add the game board, moves history, and the game stats like the winner, player1, and player2. I think we can make this page accessible by the game_id, like `/game.html?id=game_id_here`. Let's create the easier parts first.

`game.html`: We use the head from `index.html` and the same navbar code.
```
&amp;lt;!DOCTYPE html&amp;gt;
&lt;html lang=&quot;en&quot;&gt;

&lt;head&gt;
  &lt;meta charset=&quot;UTF-8&quot; /&gt;
  &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot; /&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;
  &lt;meta name=&quot;description&quot; content=&quot;A decentralized game on hive blockchain&quot; /&gt;
  &lt;title&gt;Tic-Tac-Toe on Hive blockchain&lt;/title&gt;
  &lt;link href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/css/bootstrap.min.css&quot; rel=&quot;stylesheet&quot; integrity=&quot;sha384-BmbxuPwQa2lc/FVzBcNJ7UAyJxM6wuqIj61tLrc4wSX0szH/Ev+nYRRuWlolflfl&quot; crossorigin=&quot;anonymous&quot; /&gt;
  &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/js/bootstrap.bundle.min.js&quot; integrity=&quot;sha384-b5kHyXgcpbZJO/tY9Ul7kGkf1S0CWuKcCD38l8YkeH8z8QjE0GmW1gYU5S9FOnJ0&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-tx/dist/hive-tx.min.js&quot;&gt;&lt;/script&gt;
  &lt;link rel=&quot;stylesheet&quot; href=&quot;css/style.css&quot; /&gt;
&lt;/head&gt;

&lt;body&gt;
  &lt;nav class=&quot;navbar navbar-expand navbar-dark bg-dark&quot;&gt;
    &lt;div class=&quot;container-fluid&quot;&gt;
      &lt;a class=&quot;navbar-brand&quot; href=&quot;#&quot;&gt;Tic-Tac-Toe&lt;/a&gt;
      &lt;ul class=&quot;navbar-nav&quot;&gt;
        &lt;li class=&quot;nav-item&quot;&gt;
          &lt;a class=&quot;nav-link&quot; href=&quot;#&quot; data-bs-toggle=&quot;modal&quot; data-bs-target=&quot;#login-modal&quot; id=&quot;login-button&quot;&gt;
            Login
          &lt;/a&gt;
        &lt;li class=&quot;nav-item dropdown&quot; id=&quot;logout-menu&quot; style=&quot;display: none;&quot;&gt;
          &lt;a class=&quot;nav-link dropdown-toggle&quot; href=&quot;#&quot; id=&quot;username-button&quot; role=&quot;button&quot; data-bs-toggle=&quot;dropdown&quot; aria-expanded=&quot;false&quot;&gt;&lt;/a&gt;
          &lt;ul class=&quot;dropdown-menu dropdown-menu-end&quot; aria-labelledby=&quot;username-button&quot;&gt;
            &lt;li&gt;&lt;a class=&quot;dropdown-item&quot; href=&quot;#&quot; onclick=&quot;logout()&quot;&gt;Logout&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/div&gt;
  &lt;/nav&gt;
  &lt;!-- Login Modal --&gt;
  &lt;div class=&quot;modal fade&quot; id=&quot;login-modal&quot; tabindex=&quot;-1&quot; aria-labelledby=&quot;login-modal-title&quot; aria-hidden=&quot;true&quot;&gt;
    &lt;div class=&quot;modal-dialog&quot;&gt;
      &lt;div class=&quot;modal-content&quot;&gt;
        &lt;div class=&quot;modal-header&quot;&gt;
          &lt;h5 class=&quot;modal-title&quot; id=&quot;login-modal-title&quot;&gt;Login&lt;/h5&gt;
          &lt;button type=&quot;button&quot; class=&quot;btn-close&quot; data-bs-dismiss=&quot;modal&quot; aria-label=&quot;Close&quot;&gt;&lt;/button&gt;
        &lt;/div&gt;
        &lt;div class=&quot;modal-body&quot;&gt;
          &lt;form onsubmit=&quot;login(); return false&quot;&gt;
            &lt;div class=&quot;mb-3&quot;&gt;
              &lt;label for=&quot;username&quot; class=&quot;form-label&quot;&gt;Username:&lt;/label&gt;
              &lt;div class=&quot;input-group mb-3&quot;&gt;
                &lt;span class=&quot;input-group-text&quot;&gt;@&lt;/span&gt;
                &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;username&quot; aria-label=&quot;username&quot; id=&quot;username&quot; required=&quot;&quot; /&gt;
              &lt;/div&gt;
              &lt;div class=&quot;form-text&quot;&gt;Your Hive username. Lowercase.&lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&quot;mb-3&quot;&gt;
              &lt;label for=&quot;posting-key&quot; class=&quot;form-label&quot;&gt;Posting key:&lt;/label&gt;
              &lt;input type=&quot;password&quot; class=&quot;form-control&quot; id=&quot;posting-key&quot; placeholder=&quot;Private posting key&quot; required=&quot;&quot; /&gt;
              &lt;div class=&quot;form-text&quot;&gt;Your key will never leave your browser.&lt;/div&gt;
            &lt;/div&gt;
            &lt;p id=&quot;login-error&quot;&gt;&lt;/p&gt;
            &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot; id=&quot;login-form-btn&quot;&gt;Login&lt;/button&gt;
            &lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot; data-bs-dismiss=&quot;modal&quot;&gt;Close&lt;/button&gt;
          &lt;/form&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;!-- Modal end --&gt;

  &lt;script src=&quot;js/app.js&quot;&gt;&lt;/script&gt;
&lt;/body&gt;

&lt;/html&gt;
```
Since we use `app.js` here too, we have to modify 2 lines in `app.js`:
```
// Run the script only in homepage
if (!window.location.pathname.match(/game.html$/)) {
  loadTheGames()
  setInterval(() =&amp;gt; loadTheGames(), 5000)
}
```
In the above code, we can define which scripts to run on the homepage and which run on the game page.

We need an API for retrieving the game details by game_id. Let's set that up in the back-end.
`api/game.js`:
```
const mysql = require('../helpers/mysql')
const express = require('express')
const router = express.Router()

router.get('/game/:id', async (req, res) =&amp;gt; {
  try {
    const id = req.params.id
    if (!id || id.length !== 20 || !id.match(/^[a-zA-Z0-9]+$/)) {
      return res.json({
        id: 0,
        error: 'Wrong id.'
      })
    }
    const game = await mysql.query(
      'SELECT `game_id`, `player1`, `player2`, `starting_player`, `status`, `winner` FROM `games`' +
        'WHERE `game_id`=?',
      [id]
    )
    if (!game || !Array.isArray(game) || game.length &amp;lt; 1) {
      return res.json({
        id: 1,
        game: []
      })
    }
    return res.json({
      id: 1,
      game
    })
  } catch (e) {
    return res.json({
      id: 0,
      error: 'Unexpected error.'
    })
  }
})

module.exports = router
```
The above code is similar to the other APIs we set up. Nothing new here. Now we can show the game details on the game.html page.

```
const getGameDetails = async (id) =&amp;gt; {
  const data = await APICall('/game/' + id)
  if (data &amp;amp;&amp;amp; data.id === 0) {
    document.getElementById('details-error').innerHTML = data.error
  } else if (data &amp;amp;&amp;amp; data.id === 1) {
    const game = data.game[0]
    document.getElementById('game-details').innerHTML = `&lt;tr&gt;
    &lt;td&gt;${game.player1}&lt;/td&gt;
    &lt;td&gt;${game.player2}&lt;/td&gt;
    &lt;td&gt;${game.starting_player}&lt;/td&gt;
    &lt;td&gt;${game.status}&lt;/td&gt;
    &lt;td&gt;${game.winner}&lt;/td&gt;
    &lt;/tr&gt;`
    if (game.player1 === userData.username) {
      document.getElementById('req-message-1').style.display = 'block'
      document.getElementById('req-message-2').style.display = 'none'
    }
  }
}
```
And running the above function:
```
const queryString = window.location.search
const urlParams = new URLSearchParams(queryString)

// Run the script only in homepage
if (!window.location.pathname.match(/game.html$/)) {
  loadTheGames()
  setInterval(() =&amp;gt; loadTheGames(), 5000)
} else {
  // Run the script only in game page
  if (urlParams.has('id')) {
    getGameDetails(urlParams.get('id'))
  }
}
```
We get the `id` from the page URL and use it in the API call. Then display the data in an HTML table.
```
&lt;table class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Player1&lt;/th&gt;
      &lt;th&gt;Player2&lt;/th&gt;
      &lt;th&gt;Starting player&lt;/th&gt;
      &lt;th&gt;Status&lt;/th&gt;
      &lt;th&gt;Winner&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody id=&quot;game-details&quot;&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
```
***
We can get the join requests from API and show them beside the game so player1 can accept one of the coming requests and start the game.
A simple HTML table:
```
&lt;table class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Player&lt;/th&gt;
      &lt;th&gt;Status&lt;/th&gt;
      &lt;th&gt;Action&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody id=&quot;request-list&quot;&gt;&lt;/tbody&gt;
&lt;/table&gt;
```
And the API call:
```
const getRequests = async (id, creator = false) =&amp;gt; {
  const data = await APICall('/requests/' + id)
  if (data &amp;amp;&amp;amp; data.id === 0) {
    document.getElementById('requests-error').innerHTML = data.error
  } else if (data &amp;amp;&amp;amp; data.id === 1) {
    let temp = ''
    for (let i = 0; i &amp;lt; data.requests.length; i++) {
      const request = data.requests[i]
      temp += `&lt;tr&gt;
        &lt;td&gt;${request.player}&lt;/td&gt;
        &lt;td&gt;${request.status}&lt;/td&gt;`
      if (creator) {
        // Add an Accept button if the visitor is player1 (creator)
        temp += `&lt;td&gt;
          &lt;button class=&quot;btn btn-primary&quot; onclick=&quot;acceptRequest(${id}, ${request.player})&quot;&gt;
            Accept
          &lt;/button&gt;
        &lt;/td&gt;`
      } else {
        temp += '&lt;td&gt;---&lt;/td&gt;'
      }
      temp += '&lt;/tr&gt;'
    }
    if (data.requests.length &amp;lt; 1) {
      temp = 'None'
    }
    document.getElementById('request-list').innerHTML = temp
  }
}
```
We can call the `getRequests` function inside the `getGameDetails` function because we can know when the user (visitor) is the creator of the game aka player1. Then show them an `Accept` button based on that so the player1 can accept the request.
```
const getGameDetails = async (id) =&amp;gt; {
  ... // skipped unchanged lines
    if (game.player1 === userData.username) {
      document.getElementById('req-message-1').style.display = 'block'
      document.getElementById('req-message-2').style.display = 'none'
      getRequests(id, true)
    } else {
      getRequests(id, false)
    }
  }
}
```

Also, let's make both functions run with an interval to auto-update the data.
```
// Run the script only in homepage
if (!window.location.pathname.match(/game.html$/)) {
  loadTheGames()
  setInterval(() =&amp;gt; loadTheGames(), 5000)
} else {
  // Run the script only in game page
  if (urlParams.has('id')) {
    getGameDetails(urlParams.get('id'))
    setInterval(() =&amp;gt; getGameDetails(urlParams.get('id')), 5000)
  }
}
```
***
We added the `accept` button so let's add its function and transaction too.
```
const acceptRequest = async (id, player) =&amp;gt; {
  const success = document.getElementById('requests-success')
  const error = document.getElementById('requests-error')
  if (!userData.username) {
    return
  }
  try {
    const accept = {
      app: 'tictactoe/0.0.1',
      action: 'accept_request',
      id,
      player
    }
    const operations = [
      [
        'custom_json',
        {
          required_auths: [],
          required_posting_auths: [userData.username],
          id: 'tictactoe',
          json: JSON.stringify(accept)
        }
      ]
    ]
    const tx = new hiveTx.Transaction()
    await tx.create(operations)
    const privateKey = hiveTx.PrivateKey.from(userData.key)
    tx.sign(privateKey)
    const result = await tx.broadcast()
    if (result &amp;amp;&amp;amp; result.result &amp;amp;&amp;amp; result.result.block_num) {
      success.innerHTML = 'Success! Game started.'
    } else {
      error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J'
      console.error(result)
    }
  } catch (e) {
    error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J'
    console.error(e)
  }
}
```
***
Now let's add a button for other users to join the game.
```
&lt;button id=&quot;join-btn&quot; class=&quot;btn btn-primary&quot; onclick=&quot;joinGame()&quot;&gt;Join the game&lt;/button&gt;
```
And build the transaction for it:
```
const joinGame = async (gameId) =&amp;gt; {
  const success = document.getElementById('join-success')
  const error = document.getElementById('join-error')
  if (!urlParams.has('id')) {
    return
  }
  const id = urlParams.get('id')
  try {
    const joinReq = {
      app: 'tictactoe/0.0.1',
      action: 'request_join',
      id
    }
    const operations = [
      [
        'custom_json',
        {
          required_auths: [],
          required_posting_auths: [userData.username],
          id: 'tictactoe',
          json: JSON.stringify(joinReq)
        }
      ]
    ]
    const tx = new hiveTx.Transaction()
    await tx.create(operations)
    const privateKey = hiveTx.PrivateKey.from(userData.key)
    tx.sign(privateKey)
    const result = await tx.broadcast()
    if (result &amp;amp;&amp;amp; result.result &amp;amp;&amp;amp; result.result.block_num) {
      success.innerHTML = 'Success! Your request submitted.'
    } else {
      error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J'
      console.error(result)
    }
  } catch (e) {
    error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J'
    console.error(e)
  }
}
```
***
## Next part
We finally finished most of the functions needed for starting the game. I think the only remaining challenge is the gameplay. We can use Canvas for the front-end graphical gameplay. I already built a project with Canvas but there is nothing easy about coding. It's still a challenge.

Let me list the remaining tasks:
- Gameplay front-end
- Gameplay back-end
- resync method for the database
- Front-end polishing

We are getting to the end of this project and I think we can finish it in the next post and finally play this boring game at least once.

Making tutorials and coding at the same time is really hard and tiring. I might continue writing this kind of series for different projects if there is enough interest but the target audience is too small. So let me know in the comments what you think.

I wouldn't mind building an interesting app or game which can be some kind of tutorial too.

TBH after writing the above line I wanted to remove it. Let's see what happens.

Thanks for reading. Make sure to follow me and share the post. Upvote if you like and leave a comment.


Enjoy the cat.
&lt;center&gt;![cat-pixabay.jpg](https://images.hive.blog/DQmSnpWeu5yxjzddzEavE4c61BkweaXrEJepuv4LHyMKpg1/cat-4611189_1280.jpg)
&lt;/center&gt;
&lt;sub&gt;Images source: pixabay.com&lt;/sub&gt;
***
[GitLab](https://gitlab.com/mahdiyari/decentralized-game-on-hive)
[Part 1](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-tic-tac-toe-part-1)
[Part 2](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-2)
[Part 3](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-3)
[Part 4](https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-4)
***
**Vote for my witness:**
- https://wallet.hive.blog/~witnesses
- https://peakd.com/witnesses
- https://ecency.com/witnesses&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@mahdiyari&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/making-a-decentralized-game-on-hive-part-5&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-mahdiyari-making-a-decentralized-game-on-hive-part-5').html();
      const outputElem = $('#content-mahdiyari-making-a-decentralized-game-on-hive-part-5');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-5 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-5 code {
    background: white;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-5 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-5 a:hover {
    border-bottom: 0;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-5 h1 {
    font-size: 2.2em;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-5 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-5 header small {
    color: #999;
    font-size: 50%;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-5 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-5&quot;&gt;Making a Decentralized Game on Hive - Part 5&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@mahdiyari&quot;&gt;@mahdiyari&lt;/a&gt;
&lt;/p&gt;</content><author><name>mahdiyari</name></author><category term="howto" /><category term="nodejs" /><summary type="html">![game-pixabay.jpg](https://images.hive.blog/DQmSeL2wLvGPWHqcLVX4ZtfhqidWhj4GVNiVDC2LsHX6jNX/game-4648923_1280.jpg) Games are fun and most people like to play different kinds of games. I'm not sure about the game we are building. Whether it be fun or not, the purpose of this project is the tutorial. To have a step-by-step guide that developers can use as a reference in building apps on Hive. Check out previous posts: *** #### Building the transactions We will build the back-end for the front-end that we built in the previous post. All goes into `js/app.js`. ``` const random = (length = 20) =&amp;gt; { const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789' let str = '' for (let i = 0; i &amp;lt; length; i++) { str += chars.charAt(Math.floor(Math.random() * chars.length)) } return str } ``` A simple function to generate a random string. We will use the random string for the game_id. *** ``` const createGame = async () =&amp;gt; { const button = document.getElementById('create-game-btn') button.setAttribute('disabled', 'true') const errorOutput = document.getElementById('create-game-error') const successOutput = document.getElementById('create-game-success') errorOutput.innerHTML = '' successOutput.innerHTML = '' try { const game = { app: 'tictactoe/0.0.1', action: 'create_game', id: random(20), starting_player: document.getElementById('starting-player').value } const operations = [ [ 'custom_json', { required_auths: [], required_posting_auths: [userData.username], id: 'tictactoe', json: JSON.stringify(game) } ] ] const tx = new hiveTx.Transaction() await tx.create(operations) const privateKey = hiveTx.PrivateKey.from(userData.key) tx.sign(privateKey) const result = await tx.broadcast() if (result &amp;amp;&amp;amp; result.result &amp;amp;&amp;amp; result.result.block_num) { successOutput.innerHTML = 'Success! Click to see' } else { errorOutput.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J' console.error(result) } } catch (e) { errorOutput.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J' console.error(e) } button.removeAttribute('disabled') } ``` We create the transaction by using the [hive-tx](https://www.npmjs.com/package/hive-tx) library then sign and broadcast it. We put the game link in the success message and show it to the user. Now users can create the game and see the list of games. We create the `game.html` page for users to play the game. *** #### Game page We can add the game board, moves history, and the game stats like the winner, player1, and player2. I think we can make this page accessible by the game_id, like `/game.html?id=game_id_here`. Let's create the easier parts first. `game.html`: We use the head from `index.html` and the same navbar code. ``` &amp;lt;!DOCTYPE html&amp;gt; Tic-Tac-Toe on Hive blockchain Tic-Tac-Toe Login Logout Login Username: @ Your Hive username. Lowercase. Posting key: Your key will never leave your browser. Login Close ``` Since we use `app.js` here too, we have to modify 2 lines in `app.js`: ``` // Run the script only in homepage if (!window.location.pathname.match(/game.html$/)) { loadTheGames() setInterval(() =&amp;gt; loadTheGames(), 5000) } ``` In the above code, we can define which scripts to run on the homepage and which run on the game page. We need an API for retrieving the game details by game_id. Let's set that up in the back-end. `api/game.js`: ``` const mysql = require('../helpers/mysql') const express = require('express') const router = express.Router() router.get('/game/:id', async (req, res) =&amp;gt; { try { const id = req.params.id if (!id || id.length !== 20 || !id.match(/^[a-zA-Z0-9]+$/)) { return res.json({ id: 0, error: 'Wrong id.' }) } const game = await mysql.query( 'SELECT `game_id`, `player1`, `player2`, `starting_player`, `status`, `winner` FROM `games`' + 'WHERE `game_id`=?', [id] ) if (!game || !Array.isArray(game) || game.length &amp;lt; 1) { return res.json({ id: 1, game: [] }) } return res.json({ id: 1, game }) } catch (e) { return res.json({ id: 0, error: 'Unexpected error.' }) } }) module.exports = router ``` The above code is similar to the other APIs we set up. Nothing new here. Now we can show the game details on the game.html page. ``` const getGameDetails = async (id) =&amp;gt; { const data = await APICall('/game/' + id) if (data &amp;amp;&amp;amp; data.id === 0) { document.getElementById('details-error').innerHTML = data.error } else if (data &amp;amp;&amp;amp; data.id === 1) { const game = data.game[0] document.getElementById('game-details').innerHTML = ` ${game.player1} ${game.player2} ${game.starting_player} ${game.status} ${game.winner} ` if (game.player1 === userData.username) { document.getElementById('req-message-1').style.display = 'block' document.getElementById('req-message-2').style.display = 'none' } } } ``` And running the above function: ``` const queryString = window.location.search const urlParams = new URLSearchParams(queryString) // Run the script only in homepage if (!window.location.pathname.match(/game.html$/)) { loadTheGames() setInterval(() =&amp;gt; loadTheGames(), 5000) } else { // Run the script only in game page if (urlParams.has('id')) { getGameDetails(urlParams.get('id')) } } ``` We get the `id` from the page URL and use it in the API call. Then display the data in an HTML table. ``` Player1 Player2 Starting player Status Winner ``` *** We can get the join requests from API and show them beside the game so player1 can accept one of the coming requests and start the game. A simple HTML table: ``` Player Status Action ``` And the API call: ``` const getRequests = async (id, creator = false) =&amp;gt; { const data = await APICall('/requests/' + id) if (data &amp;amp;&amp;amp; data.id === 0) { document.getElementById('requests-error').innerHTML = data.error } else if (data &amp;amp;&amp;amp; data.id === 1) { let temp = '' for (let i = 0; i &amp;lt; data.requests.length; i++) { const request = data.requests[i] temp += ` ${request.player} ${request.status}` if (creator) { // Add an Accept button if the visitor is player1 (creator) temp += ` Accept ` } else { temp += '---' } temp += '' } if (data.requests.length &amp;lt; 1) { temp = 'None' } document.getElementById('request-list').innerHTML = temp } } ``` We can call the `getRequests` function inside the `getGameDetails` function because we can know when the user (visitor) is the creator of the game aka player1. Then show them an `Accept` button based on that so the player1 can accept the request. ``` const getGameDetails = async (id) =&amp;gt; { ... // skipped unchanged lines if (game.player1 === userData.username) { document.getElementById('req-message-1').style.display = 'block' document.getElementById('req-message-2').style.display = 'none' getRequests(id, true) } else { getRequests(id, false) } } } ``` Also, let's make both functions run with an interval to auto-update the data. ``` // Run the script only in homepage if (!window.location.pathname.match(/game.html$/)) { loadTheGames() setInterval(() =&amp;gt; loadTheGames(), 5000) } else { // Run the script only in game page if (urlParams.has('id')) { getGameDetails(urlParams.get('id')) setInterval(() =&amp;gt; getGameDetails(urlParams.get('id')), 5000) } } ``` *** We added the `accept` button so let's add its function and transaction too. ``` const acceptRequest = async (id, player) =&amp;gt; { const success = document.getElementById('requests-success') const error = document.getElementById('requests-error') if (!userData.username) { return } try { const accept = { app: 'tictactoe/0.0.1', action: 'accept_request', id, player } const operations = [ [ 'custom_json', { required_auths: [], required_posting_auths: [userData.username], id: 'tictactoe', json: JSON.stringify(accept) } ] ] const tx = new hiveTx.Transaction() await tx.create(operations) const privateKey = hiveTx.PrivateKey.from(userData.key) tx.sign(privateKey) const result = await tx.broadcast() if (result &amp;amp;&amp;amp; result.result &amp;amp;&amp;amp; result.result.block_num) { success.innerHTML = 'Success! Game started.' } else { error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J' console.error(result) } } catch (e) { error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J' console.error(e) } } ``` *** Now let's add a button for other users to join the game. ``` Join the game ``` And build the transaction for it: ``` const joinGame = async (gameId) =&amp;gt; { const success = document.getElementById('join-success') const error = document.getElementById('join-error') if (!urlParams.has('id')) { return } const id = urlParams.get('id') try { const joinReq = { app: 'tictactoe/0.0.1', action: 'request_join', id } const operations = [ [ 'custom_json', { required_auths: [], required_posting_auths: [userData.username], id: 'tictactoe', json: JSON.stringify(joinReq) } ] ] const tx = new hiveTx.Transaction() await tx.create(operations) const privateKey = hiveTx.PrivateKey.from(userData.key) tx.sign(privateKey) const result = await tx.broadcast() if (result &amp;amp;&amp;amp; result.result &amp;amp;&amp;amp; result.result.block_num) { success.innerHTML = 'Success! Your request submitted.' } else { error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J' console.error(result) } } catch (e) { error.innerHTML = 'Error! Check console for details. Press Ctrl+Shift+J' console.error(e) } } ``` *** ## Next part We finally finished most of the functions needed for starting the game. I think the only remaining challenge is the gameplay. We can use Canvas for the front-end graphical gameplay. I already built a project with Canvas but there is nothing easy about coding. It's still a challenge. Let me list the remaining tasks: - Gameplay front-end - Gameplay back-end - resync method for the database - Front-end polishing We are getting to the end of this project and I think we can finish it in the next post and finally play this boring game at least once. Making tutorials and coding at the same time is really hard and tiring. I might continue writing this kind of series for different projects if there is enough interest but the target audience is too small. So let me know in the comments what you think. I wouldn't mind building an interesting app or game which can be some kind of tutorial too. TBH after writing the above line I wanted to remove it. Let's see what happens. Thanks for reading. Make sure to follow me and share the post. Upvote if you like and leave a comment. Enjoy the cat. ![cat-pixabay.jpg](https://images.hive.blog/DQmSnpWeu5yxjzddzEavE4c61BkweaXrEJepuv4LHyMKpg1/cat-4611189_1280.jpg) Images source: pixabay.com *** [GitLab](https://gitlab.com/mahdiyari/decentralized-game-on-hive) [Part 1](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-tic-tac-toe-part-1) [Part 2](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-2) [Part 3](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-3) [Part 4](https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-4) *** **Vote for my witness:** - https://wallet.hive.blog/~witnesses - https://peakd.com/witnesses - https://ecency.com/witnesses See: Making a Decentralized Game on Hive - Part 5 by @mahdiyari</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmSeL2wLvGPWHqcLVX4ZtfhqidWhj4GVNiVDC2LsHX6jNX/game-4648923_1280.jpg" /><media:content medium="image" url="https://images.hive.blog/DQmSeL2wLvGPWHqcLVX4ZtfhqidWhj4GVNiVDC2LsHX6jNX/game-4648923_1280.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">8th update of 2021 on BlockTrades work on Hive software</title><link href="https://hivedocs.info/news/core/development/2021/04/06/8th-update-of-2021-on-blocktrades-work-on-hive-software.html" rel="alternate" type="text/html" title="8th update of 2021 on BlockTrades work on Hive software" /><published>2021-04-06T17:42:57-07:00</published><updated>2021-04-06T17:42:57-07:00</updated><id>https://hivedocs.info/news/core/development/2021/04/06/8th-update-of-2021-on-blocktrades-work-on-hive-software</id><content type="html" xml:base="https://hivedocs.info/news/core/development/2021/04/06/8th-update-of-2021-on-blocktrades-work-on-hive-software.html">&lt;div id=&quot;content-blocktrades-8th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;Below is a list of some Hive-related programming issues worked on by BlockTrades team during the past few weeks:

# Hived work (blockchain node software)

## Code cleanup and investigation of support for Ubuntu 20

Separate from our hardfork 25 changes, we’ve been doing some general code cleanup to make the code more maintainable, and we also started a task to get the code to compile cleanly under Ubuntu 20 without requiring “fiddling” with the build process.

## HF25 changes (these are described in detail in our Hive roadmap post)

### Expiration of old governance votes
We’ve completed and written tests for all changes related to handling expiration of governance votes (votes for witnesses and Hive Fund proposals).

### Curation rewards calculation changes

We completed analysis and implementation of voting window curation changes for HF25. We’re also writing some tests for the curation calculator, as we found the current tests were inadequate (our changes only triggered one fail of existing tests). 

During the process, we also discovered an error in the implementation of the square-root function used by the current curation algorithm for unsigned 128 bit integers, but we’re removing use of this square-root function in the new curation calculation, as part of our removal of the convergent-linear curve code (this is the code that weakened small votes).

The new curation reward algorithm works as follows: 
* first day (24 hours) linear rewards (equal weight to all voters in that window)
* second window (24 hours to 72 hours/3 days) with reward weight/2
* remaining votes in 3rd window with reward weight/8

Under the new algorithm, anyone voting with the first 24 hours of the post receives the same proportional rewards. In other words, for any given voting strength, the voter will get the same percentage return-on-investment as any other voter during that period. 

Voters voting during the second and third window receive a smaller proportional curation reward (and voters who voted during the first 24 hour period receive a little more reward when voters vote during the 2nd or 3rd window). Note that if no one votes during the first window, then 2nd window voters will receive the same amount of curation as if they had voted during the first window.

The basic idea behind the new algorithm is to encourage voters to find good content, but to put them on an equal footing with voting bots. Under the current algorithm that we’re replacing, voting bots have an advantage because there’s a short window in time to cast a vote for optimal curation rewards.

Note that author rewards are not affected by this change: this change only affects how curation rewards are distributed among voters.

### Hive to HBD conversion operation

The only code we’re still working on in hived for hardfork 25 is the new operation that allows users to convert liquid Hive to HBD. We’re still researching some issues associated with the existing code that computes the median price for Hive, but we expect to have the conversion code completed and tested this week.

### Hardfork code freeze in middle of this month

We expect to do a code freeze on 4/15 (middle of this month) so that witnesses can launch a testnet and begin evaluating and testing the code changes for hardfork 25. 

### Testnet to operate for at least one month

Barring any problems, we expect the testnet to operate for at least one month, then we’ll begin final prep for HF25. 

This will allow time for Hive API libraries and frontend web sites to make changes to provide notifications related to vote expiration and to enable the use of the new Hive→HBD conversion operation and the recurrent payments and rc delegation functionality implemented by @howo. But strictly speaking, most of such frontend functionality can be implemented after the hardfork is executed without causing any problems, so the primary reason for this time interval is to allow for testing and evaluation of the performance of the new algorithms and features.

# Modular hivemind (application framework for 2nd layer apps)

## Syncing modular hivemind from SQL account history plugin

We were able to successfully sync a hivemind instance from the data injected by the SQL account history plugin (with the syncing taking place as the SQL data was injected by the plugin), but we encountered a problem at the end when some of the indexes were being recreated by hivemind as hivemind exited full sync mode and entered live sync mode. We’re investigating this issue now and we expect a fix in the next couple of days.

## Performance measurements for hivemind sync with SQL account history plugin

Despite the issue when exiting full sync mode, we were able to collect some useful performance measurements. 

On the regular hivemind sync version, where we first do a hived replay to fill hivemind’s database, and where we then do a hivemind sync where indexes and foreign keys are dropped automatically and rebuilt at the end), the hivemind sync process took 50983s (hivemind sync) + 4047s (index creation) + 1998s (foreign key creation) = 57028s

On the modified version of hivemind sync, where indexes are created before the sync begins, the hivemind sync took 67947s (regular version was 10918s faster).

Despite the increased time for the modified version (10918s/3600s = 3.03 hours), this allows for an overall decrease  in the time to fully sync the hivemind node using the SQL account history plugin, because it means that the hivemind sync can be started while the hived node is being replayed to fill hivemind’s database. 

In the “regular method”, the total time would be  hived sync (~8 hours) + hivemind full sync time (15.84 hours) = 23.84 hours. With the modified method, it looks like we can get this time down to just hivemind modified sync time (18.87 hours). 

Note that all these times should ultimate be compared with the existing time to do a hivemind sync without the SQL account history plugin (~90+ hours). So it seems possible we could be looking at a 4x or better speedup in the time to do a full hivemind sync of a new node with the SQL account history plugin, if I haven’t messed up any where in my assumptions (I didn’t want to delay this report any longer, so it’s not been “peer-reviewed”).

# Hivemind (social media middle-ware)

## Significantly reduced memory usage by hivemind process

We fixed an issue in hivemind where a dictionary was used as a cache for post ids, and this dictionary was progressively consuming more memory as the blockchain grew in size. We spotted this issue during some our performance testing of hivemind syncing using the data provided by the new SQL account history plugin (but the problem exists for all existing hivemind implementations).

Unfortunately, we haven’t had a chance to measure the exact memory savings for the fix yet, as we were focused on other tasks, but I should have those numbers for our next report.

## Testing hivemind syncing on a low-end server

We’ve setup a low end computer (8GB of RAM and only a conventional hard disk drive, no SSD drive) to see what the minimum requirements are for a full hivemind node are, and to see if we can lower those requirements. In our tests, the hivemind process did manage to finish the full sync process, but it hit some problems during creation of indexes, so we’ll be digging into this issue further in the upcoming week.

## Testing performance of hivemind with Postgres 13

Currently postgres version 10 is the recommended version of the database for use with hivemind, but we did some tests this week to check if hivemind was compatible with the latest version of postgres (version 13) and to measure the relative performance. 

It’s all good news: no code changes were required to support postgres 13, and as an extra bonus, we saw a 5% speedup in full sync time in our test. We didn’t make any comprehensive tests yet of API response time related to SQL query speed, but signs are good that we can only expect performance improvements and no regressions.

## Miscellaneous hivemind bug fixes and documentation

We fixed a couple of small bugs reported by users and frontend devs, such as a pagination issue with a community-related API call and an issue with community name validation:  https://gitlab.syncad.com/hive/hivemind/-/merge_requests/488
https://gitlab.syncad.com/hive/hivemind/-/merge_requests/489

And we have an open merge request for the code to generate openapi documentation for the various hivemind API methods: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/486

# Another progress update soon

I’ll probably be putting out another progress update early next week, after we have more performance numbers. I kept delaying this one hoping to include those numbers, but we were caught up in too many tasks and small issues spoiled a bunch of our measurement attempts, and then the Easter holiday hit.

[EDIT] Several people have misinterpreted the function of the weights in the new algorithm, and this has led to a misapprehension about curation rewards for late voters. The weights are used to allocate the rewards between the curators. So if there are few strong voters in the first period and most in a later period, the late voters will receive roughly the same rewards as if they had voted in the early period. 

Total post reward amount (author + curation rewards) will be calculated based on total rshares with the new algorithm, not the weights. In pretty much every case, this new algorithm is designed to be MORE favorable to late voters than the current algorithm. So if this leads to people only voting in the first 24 hours, it's only due to misinformation. We'll be presenting more data later to explain how the new algorithm distributes curation rewards.&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@blocktrades&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/8th-update-of-2021-on-blocktrades-work-on-hive-software&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-blocktrades-8th-update-of-2021-on-blocktrades-work-on-hive-software').html();
      const outputElem = $('#content-blocktrades-8th-update-of-2021-on-blocktrades-work-on-hive-software');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-blocktrades-8th-update-of-2021-on-blocktrades-work-on-hive-software {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-blocktrades-8th-update-of-2021-on-blocktrades-work-on-hive-software code {
    background: white;
  }
  #content-blocktrades-8th-update-of-2021-on-blocktrades-work-on-hive-software a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-blocktrades-8th-update-of-2021-on-blocktrades-work-on-hive-software a:hover {
    border-bottom: 0;
  }
  #content-blocktrades-8th-update-of-2021-on-blocktrades-work-on-hive-software h1 {
    font-size: 2.2em;
  }
  #content-blocktrades-8th-update-of-2021-on-blocktrades-work-on-hive-software h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-blocktrades-8th-update-of-2021-on-blocktrades-work-on-hive-software header small {
    color: #999;
    font-size: 50%;
  }
  #content-blocktrades-8th-update-of-2021-on-blocktrades-work-on-hive-software img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-139531/@blocktrades/8th-update-of-2021-on-blocktrades-work-on-hive-software&quot;&gt;8th update of 2021 on BlockTrades work on Hive software&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@blocktrades&quot;&gt;@blocktrades&lt;/a&gt;
&lt;/p&gt;</content><author><name>blocktrades</name></author><category term="news" /><category term="core" /><category term="development" /><summary type="html">Below is a list of some Hive-related programming issues worked on by BlockTrades team during the past few weeks: # Hived work (blockchain node software) ## Code cleanup and investigation of support for Ubuntu 20 Separate from our hardfork 25 changes, we’ve been doing some general code cleanup to make the code more maintainable, and we also started a task to get the code to compile cleanly under Ubuntu 20 without requiring “fiddling” with the build process. ## HF25 changes (these are described in detail in our Hive roadmap post) ### Expiration of old governance votes We’ve completed and written tests for all changes related to handling expiration of governance votes (votes for witnesses and Hive Fund proposals). ### Curation rewards calculation changes We completed analysis and implementation of voting window curation changes for HF25. We’re also writing some tests for the curation calculator, as we found the current tests were inadequate (our changes only triggered one fail of existing tests). During the process, we also discovered an error in the implementation of the square-root function used by the current curation algorithm for unsigned 128 bit integers, but we’re removing use of this square-root function in the new curation calculation, as part of our removal of the convergent-linear curve code (this is the code that weakened small votes). The new curation reward algorithm works as follows: * first day (24 hours) linear rewards (equal weight to all voters in that window) * second window (24 hours to 72 hours/3 days) with reward weight/2 * remaining votes in 3rd window with reward weight/8 Under the new algorithm, anyone voting with the first 24 hours of the post receives the same proportional rewards. In other words, for any given voting strength, the voter will get the same percentage return-on-investment as any other voter during that period. Voters voting during the second and third window receive a smaller proportional curation reward (and voters who voted during the first 24 hour period receive a little more reward when voters vote during the 2nd or 3rd window). Note that if no one votes during the first window, then 2nd window voters will receive the same amount of curation as if they had voted during the first window. The basic idea behind the new algorithm is to encourage voters to find good content, but to put them on an equal footing with voting bots. Under the current algorithm that we’re replacing, voting bots have an advantage because there’s a short window in time to cast a vote for optimal curation rewards. Note that author rewards are not affected by this change: this change only affects how curation rewards are distributed among voters. ### Hive to HBD conversion operation The only code we’re still working on in hived for hardfork 25 is the new operation that allows users to convert liquid Hive to HBD. We’re still researching some issues associated with the existing code that computes the median price for Hive, but we expect to have the conversion code completed and tested this week. ### Hardfork code freeze in middle of this month We expect to do a code freeze on 4/15 (middle of this month) so that witnesses can launch a testnet and begin evaluating and testing the code changes for hardfork 25. ### Testnet to operate for at least one month Barring any problems, we expect the testnet to operate for at least one month, then we’ll begin final prep for HF25. This will allow time for Hive API libraries and frontend web sites to make changes to provide notifications related to vote expiration and to enable the use of the new Hive→HBD conversion operation and the recurrent payments and rc delegation functionality implemented by @howo. But strictly speaking, most of such frontend functionality can be implemented after the hardfork is executed without causing any problems, so the primary reason for this time interval is to allow for testing and evaluation of the performance of the new algorithms and features. # Modular hivemind (application framework for 2nd layer apps) ## Syncing modular hivemind from SQL account history plugin We were able to successfully sync a hivemind instance from the data injected by the SQL account history plugin (with the syncing taking place as the SQL data was injected by the plugin), but we encountered a problem at the end when some of the indexes were being recreated by hivemind as hivemind exited full sync mode and entered live sync mode. We’re investigating this issue now and we expect a fix in the next couple of days. ## Performance measurements for hivemind sync with SQL account history plugin Despite the issue when exiting full sync mode, we were able to collect some useful performance measurements. On the regular hivemind sync version, where we first do a hived replay to fill hivemind’s database, and where we then do a hivemind sync where indexes and foreign keys are dropped automatically and rebuilt at the end), the hivemind sync process took 50983s (hivemind sync) + 4047s (index creation) + 1998s (foreign key creation) = 57028s On the modified version of hivemind sync, where indexes are created before the sync begins, the hivemind sync took 67947s (regular version was 10918s faster). Despite the increased time for the modified version (10918s/3600s = 3.03 hours), this allows for an overall decrease in the time to fully sync the hivemind node using the SQL account history plugin, because it means that the hivemind sync can be started while the hived node is being replayed to fill hivemind’s database. In the “regular method”, the total time would be hived sync (~8 hours) + hivemind full sync time (15.84 hours) = 23.84 hours. With the modified method, it looks like we can get this time down to just hivemind modified sync time (18.87 hours). Note that all these times should ultimate be compared with the existing time to do a hivemind sync without the SQL account history plugin (~90+ hours). So it seems possible we could be looking at a 4x or better speedup in the time to do a full hivemind sync of a new node with the SQL account history plugin, if I haven’t messed up any where in my assumptions (I didn’t want to delay this report any longer, so it’s not been “peer-reviewed”). # Hivemind (social media middle-ware) ## Significantly reduced memory usage by hivemind process We fixed an issue in hivemind where a dictionary was used as a cache for post ids, and this dictionary was progressively consuming more memory as the blockchain grew in size. We spotted this issue during some our performance testing of hivemind syncing using the data provided by the new SQL account history plugin (but the problem exists for all existing hivemind implementations). Unfortunately, we haven’t had a chance to measure the exact memory savings for the fix yet, as we were focused on other tasks, but I should have those numbers for our next report. ## Testing hivemind syncing on a low-end server We’ve setup a low end computer (8GB of RAM and only a conventional hard disk drive, no SSD drive) to see what the minimum requirements are for a full hivemind node are, and to see if we can lower those requirements. In our tests, the hivemind process did manage to finish the full sync process, but it hit some problems during creation of indexes, so we’ll be digging into this issue further in the upcoming week. ## Testing performance of hivemind with Postgres 13 Currently postgres version 10 is the recommended version of the database for use with hivemind, but we did some tests this week to check if hivemind was compatible with the latest version of postgres (version 13) and to measure the relative performance. It’s all good news: no code changes were required to support postgres 13, and as an extra bonus, we saw a 5% speedup in full sync time in our test. We didn’t make any comprehensive tests yet of API response time related to SQL query speed, but signs are good that we can only expect performance improvements and no regressions. ## Miscellaneous hivemind bug fixes and documentation We fixed a couple of small bugs reported by users and frontend devs, such as a pagination issue with a community-related API call and an issue with community name validation: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/488 https://gitlab.syncad.com/hive/hivemind/-/merge_requests/489 And we have an open merge request for the code to generate openapi documentation for the various hivemind API methods: https://gitlab.syncad.com/hive/hivemind/-/merge_requests/486 # Another progress update soon I’ll probably be putting out another progress update early next week, after we have more performance numbers. I kept delaying this one hoping to include those numbers, but we were caught up in too many tasks and small issues spoiled a bunch of our measurement attempts, and then the Easter holiday hit. [EDIT] Several people have misinterpreted the function of the weights in the new algorithm, and this has led to a misapprehension about curation rewards for late voters. The weights are used to allocate the rewards between the curators. So if there are few strong voters in the first period and most in a later period, the late voters will receive roughly the same rewards as if they had voted in the early period. Total post reward amount (author + curation rewards) will be calculated based on total rshares with the new algorithm, not the weights. In pretty much every case, this new algorithm is designed to be MORE favorable to late voters than the current algorithm. So if this leads to people only voting in the first 24 hours, it's only due to misinformation. We'll be presenting more data later to explain how the new algorithm distributes curation rewards. See: 8th update of 2021 on BlockTrades work on Hive software by @blocktrades</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://hivedocs.info/assets/images/favicon.png" /><media:content medium="image" url="https://hivedocs.info/assets/images/favicon.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Making a Decentralized Game on Hive - Part 4</title><link href="https://hivedocs.info/howto/nodejs/2021/04/01/making-a-decentralized-game-on-hive-part-4.html" rel="alternate" type="text/html" title="Making a Decentralized Game on Hive - Part 4" /><published>2021-04-01T10:09:48-07:00</published><updated>2021-04-01T10:09:48-07:00</updated><id>https://hivedocs.info/howto/nodejs/2021/04/01/making-a-decentralized-game-on-hive-part-4</id><content type="html" xml:base="https://hivedocs.info/howto/nodejs/2021/04/01/making-a-decentralized-game-on-hive-part-4.html">&lt;div id=&quot;content-mahdiyari-making-a-decentralized-game-on-hive-part-4&quot;&gt;&lt;center&gt;![coding-pixabay.jpg](https://images.hive.blog/DQmbqyPpfU2dpwYkn9GVJdMmJbfukkvZZ8Bwqk7epyswP9w/macbook-2617705_1280.jpg)&lt;/center&gt;
In the [previous part](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-3), we made a back-end that is streaming blocks and detects 3 methods in custom_json. Create a game, request to join a game, and accept the request. We also set up a MySQL server with 3 tables for the methods.

&lt;sub&gt;You can find the links to the other parts at the end of the post.&lt;/sub&gt;


### API
Let's start by implementing the API for retrieving the games list. Our API is public so it doesn't require user authentication. The API will just return the data synced from the blockchain.
`api/games.js`:
```
const mysql = require('../helpers/mysql')
const express = require('express')
const router = express.Router()

// Return all games on route /games
router.get('/games', async (req, res) =&amp;gt; {
  try {
    // Get games data from Database
    const games = await mysql.query(
      'SELECT `game_id`, `player1`, `player2`, `starting_player`, `status`, `winner` FROM `games`'
    )
    // Check for expected result
    if (!games || !Array.isArray(games) || games.length &amp;lt; 1) {
      // WE return id: 1 for success and id: 0 for errors
      return res.json({
        id: 1,
        games: []
      })
    }
    // We return `games` as we receive from MySQL but it's not a good practice
    // specially when you have critical data in the database
    // You can return data one by one like `games: [{game_id: games.game_id, ...}]`
    return res.json({
      id: 1,
      games
    })
  } catch (e) {
    // Return error for unexpected errors like connection drops
    res.json({
      id: 0,
      error: 'Unexpected error.'
    })
  }
})

module.exports = router
```
The comments are in the code itself for better understanding.
Note: We use `try{} catch{}` wherever we can. It is always good to handle errors.

We can test our API at this point to detect possible errors in the code.
Include the following code in `api/server.js` just above the `port` and `host` constants.
```
const games = require('./games')
app.use(games)
```

Run `node api/server.js`. We can see the console.log: `Application started on 127.0.0.1:2021`
Let's open `127.0.0.1:2021/games` in the browser.

&lt;center&gt;![image.png](https://images.hive.blog/DQmbTKVAbtUB6nDH8HWuvku8NuiZv3jovu94jtEMAEU1vSX/image.png)&lt;/center&gt;
The API works as expected.

But it's not done yet. This API returns ALL the games without a specific order. We should implement pagination and define an order for our list.

Updated code `api/games.js`:
```
const mysql = require('../helpers/mysql')
const express = require('express')
const router = express.Router()

router.get('/games/:page', async (req, res) =&amp;gt; {
  try {
    if (isNaN(req.params.page)) {
      res.json({
        id: 0,
        error: 'Expected number.'
      })
    }
    const page = Math.floor(req.params.page)
    if (page &amp;lt; 1) {
      res.json({
        id: 0,
        error: 'Expected &amp;gt; 0'
      })
    }
    const offset = (page - 1) * 10
    const games = await mysql.query(
      'SELECT `game_id`, `player1`, `player2`, `starting_player`, `status`, `winner` FROM `games`' +
        ' ORDER BY `id` DESC LIMIT 10 OFFSET ?',
      [offset]
    )
    if (!games || !Array.isArray(games) || games.length &amp;lt; 1) {
      return res.json({
        id: 1,
        games: []
      })
    }
    return res.json({
      id: 1,
      games
    })
  } catch (e) {
    res.json({
      id: 0,
      error: 'Unexpected error.'
    })
  }
})

module.exports = router
```
We used `id` to order our list and get the newly created games first. Each page returns up to 10 games. We can try `127.0.0.1:2021/games/1` for testing.
***
Let's set another API for requests. The code is almost similar but we return only requests for the specific game_id.
`api/requests.js`:
```
const mysql = require('../helpers/mysql')
const express = require('express')
const router = express.Router()

router.get('/requests/:id', async (req, res) =&amp;gt; {
  try {
    if (!req.params.id) {
      res.json({
        id: 0,
        error: 'Expected game_id.'
      })
    }
    // We are passing user input into the database
    // You should be careful in such cases
    // We use ? for parameters which escapes the characters
    const requests = await mysql.query(
      'SELECT `player`, `status` FROM `requests` WHERE `game_id`= ?',
      [req.params.id]
    )
    if (!requests || !Array.isArray(requests) || requests.length &amp;lt; 1) {
      return res.json({
        id: 1,
        requests: []
      })
    }
    return res.json({
      id: 1,
      requests
    })
  } catch (e) {
    res.json({
      id: 0,
      error: 'Unexpected error.'
    })
  }
})

module.exports = router
```
Note: `:id` in the above router represents a variable named id. So for example `http://127.0.0.1:2021/requests/mygameidhere` in this request, the `id` variable is `mygameidhere` which is accessible by `req.params.id`.
***
A similar code for the `moves` table. There wasn't a better name in my mind for this table.
`api/moves.js`:
```
const mysql = require('../helpers/mysql')
const express = require('express')
const router = express.Router()

router.get('/moves/:id', async (req, res) =&amp;gt; {
  try {
    if (!req.params.id) {
      res.json({
        id: 0,
        error: 'Expected game_id.'
      })
    }
    const moves = await mysql.query(
      'SELECT `player`, `col`, `row` FROM `moves` WHERE `game_id`= ?',
      [req.params.id]
    )
    if (!moves || !Array.isArray(moves) || moves.length &amp;lt; 1) {
      return res.json({
        id: 1,
        moves: []
      })
    }
    return res.json({
      id: 1,
      moves
    })
  } catch (e) {
    res.json({
      id: 0,
      error: 'Unexpected error.'
    })
  }
})

module.exports = router
```
Now our 3 APIs are ready to be implemented on the front-end.
***
Here is the updated `api/server.js` after including the APIs:
```
const express = require('express')
const bodyParser = require('body-parser')
const hpp = require('hpp')
const helmet = require('helmet')
const app = express()

// more info: www.npmjs.com/package/hpp
app.use(hpp())
app.use(helmet())

// support json encoded bodies and encoded bodies
app.use(bodyParser.json())
app.use(bodyParser.urlencoded({ extended: true }))

app.use(function (req, res, next) {
  res.header(
    'Access-Control-Allow-Origin',
    'http://localhost https://tic-tac-toe.mahdiyari.info/'
  )
  res.header('Access-Control-Allow-Credentials', true)
  res.header(
    'Access-Control-Allow-Headers',
    'Origin, X-Requested-With, Content-Type, Accept, access_key'
  )
  next()
})

// APIs
const games = require('./games')
const requests = require('./requests')
const moves = require('./moves')

app.use(games)
app.use(requests)
app.use(moves)

const port = process.env.PORT || 2021
const host = process.env.HOST || '127.0.0.1'
app.listen(port, host, () =&amp;gt; {
  console.log(`Application started on ${host}:${port}`)
})
```
***
### Front-end
I think using pure HTML is a mistake and I would prefer something like Angular for the web applications but that comes with its own learning process which can make this tutorial complex. So my recommendation is to learn something like Angular or Vue and live a happy life. Anyway, coding time.

I'm not going to drop `index.html` here. It doesn't need much explanation and it's long. You can see it on the [GitLab repository](https://gitlab.com/mahdiyari/decentralized-game-on-hive/-/blob/master/front-end/index.html). I will just add some references here used in `app.js`.

The table for listing the games and buttons for pagination.
`index.html`:
```
&lt;div class=&quot;card-body&quot;&gt;
  &lt;h5 class=&quot;card-title&quot; style=&quot;float: left;&quot;&gt;Games list&lt;/h5&gt;
  &lt;span style=&quot;float: right;&quot;&gt;Auto updating every 5s&lt;/span&gt;
  &lt;table class=&quot;table table-striped&quot;&gt;
    &lt;thead&gt;
      &lt;tr&gt;
        &lt;th&gt;#&lt;/th&gt;
        &lt;th&gt;Game ID&lt;/th&gt;
        &lt;th&gt;Player 1&lt;/th&gt;
        &lt;th&gt;Player 2&lt;/th&gt;
        &lt;th&gt;Starting Player&lt;/th&gt;
        &lt;th&gt;Status&lt;/th&gt;
        &lt;th&gt;Winner&lt;/th&gt;
        &lt;th&gt;Action&lt;/th&gt;
      &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody id=&quot;games-table-body&quot;&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
  &lt;nav aria-label=&quot;Page navigation example&quot;&gt;
    &lt;ul class=&quot;pagination justify-content-center&quot;&gt;
      &lt;li class=&quot;page-item disabled&quot; id=&quot;prev-btn&quot;&gt;
        &lt;a class=&quot;page-link&quot; onclick=&quot;prevGamesPage()&quot;&gt;&amp;laquo;&lt;/a&gt;
      &lt;/li&gt;
      &lt;li class=&quot;page-item disabled&quot;&gt;
        &lt;a class=&quot;page-link&quot; id=&quot;page-number&quot; tabindex=&quot;-1&quot;&gt; 1 &lt;/a&gt;
      &lt;/li&gt;
      &lt;li class=&quot;page-item&quot; id=&quot;next-btn&quot;&gt;
        &lt;a class=&quot;page-link&quot; onclick=&quot;nextGamesPage()&quot;&gt;&amp;raquo;&lt;/a&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;
```
***
We have to fill the table above. So let's implement some basic functions.
`js/app.js`:
```
const baseAPI = 'http://127.0.0.1:2021'
const APICall = async (api) =&amp;gt; {
  return (await fetch(baseAPI + api)).json()
}
```
For ease of use, we define a function for `GET` calls using `fetch` and a variable for our API address.
***
```
const getGames = async (page = 1) =&amp;gt; {
  const games = await APICall('/games/' + page)
  return games.games
}
```
This function basically gets the games from the API per page.
***
```
const fillGamesTable = (data) =&amp;gt; {
  const tbody = document.getElementById('games-table-body')
  let temp = ''
  for (let i = 0; i &amp;lt; data.length; i++) {
    temp += `&lt;tr&gt;
    &lt;td&gt;${(gamesPage - 1) * 10 + i + 1}&lt;/td&gt;
    &lt;td&gt;${data[i].game_id}&lt;/td&gt;
    &lt;td&gt;${data[i].player1}&lt;/td&gt;
    &lt;td&gt;${data[i].player2}&lt;/td&gt;
    &lt;td&gt;${data[i].starting_player}&lt;/td&gt;
    &lt;td&gt;${data[i].status}&lt;/td&gt;
    &lt;td&gt;${data[i].winner}&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;`
  }
  if (data.length &amp;lt; 1) {
    temp = 'No games.'
  }
  tbody.innerHTML = temp
}
```
`fillGamesTable` takes the result from `getGames` function and fills the HTML table with data using a `for` loop.
***
```
let gamesPage = 1
const loadTheGames = async () =&amp;gt; {
  const games = await getGames(gamesPage)
  fillGamesTable(games)
  if (games.length &amp;lt; 10) {
    document.getElementById('next-btn').className = 'page-item disabled'
  } else {
    document.getElementById('next-btn').className = 'page-item'
  }
  if (gamesPage === 1) {
    document.getElementById('prev-btn').className = 'page-item disabled'
  } else {
    document.getElementById('prev-btn').className = 'page-item'
  }
  document.getElementById('page-number').innerHTML = ` ${gamesPage} `
}
loadTheGames()
setInterval(() =&amp;gt; loadTheGames(), 5000)
```
With this function, we call the two previously defined functions to do their job and update the pagination buttons and the page number every time we update the table data. Also, every 5 seconds, it gets new data from API and updates the table with new data so users don't have to reload the page for new data.
***
```
const nextGamesPage = () =&amp;gt; {
  gamesPage++
  loadTheGames()
}

const prevGamesPage = () =&amp;gt; {
  gamesPage--
  loadTheGames()
}
```
And two functions for changing pages. Simple as that.
***
The final result with dummy data looks like this on the browser:
&lt;center&gt;![Capture.PNG](https://images.hive.blog/DQmcYZC1vixajRW4Ui5dHiSfTy5MYqEYZhXy2bd2ituz4Ar/Capture.PNG)&lt;/center&gt;
***
That's it for this part. I'm really happy with the results we are getting. I didn't plan anything beforehand and I'm coding as I'm writing the posts.

Today we made 3 API calls and created the basic front-end which for now only shows the list of games that are submitted to the Hive blockchain. In the next part, we will implement the methods for creating and joining the games on the client side. We also probably need to create a game page where actual gaming happens.

Thanks for reading. Make sure to follow me and share the post. Upvote if you like and leave a comment.
***
[GitLab](https://gitlab.com/mahdiyari/decentralized-game-on-hive)
[Part 1](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-tic-tac-toe-part-1)
[Part 2](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-2)
[Part 3](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-3)

[Next part &amp;gt;&amp;gt;](https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-5)
***
**Vote for my witness:**
- https://wallet.hive.blog/~witnesses
- https://peakd.com/witnesses
- https://ecency.com/witnesses&lt;/div&gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;

&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@mahdiyari&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/making-a-decentralized-game-on-hive-part-4&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-mahdiyari-making-a-decentralized-game-on-hive-part-4').html();
      const outputElem = $('#content-mahdiyari-making-a-decentralized-game-on-hive-part-4');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;

&lt;style&gt;
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-4 {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-4 code {
    background: white;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-4 a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-4 a:hover {
    border-bottom: 0;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-4 h1 {
    font-size: 2.2em;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-4 h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-4 header small {
    color: #999;
    font-size: 50%;
  }
  #content-mahdiyari-making-a-decentralized-game-on-hive-part-4 img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;

&lt;p&gt;
  See: &lt;a href=&quot;https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-4&quot;&gt;Making a Decentralized Game on Hive - Part 4&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@mahdiyari&quot;&gt;@mahdiyari&lt;/a&gt;
&lt;/p&gt;</content><author><name>mahdiyari</name></author><category term="howto" /><category term="nodejs" /><summary type="html">![coding-pixabay.jpg](https://images.hive.blog/DQmbqyPpfU2dpwYkn9GVJdMmJbfukkvZZ8Bwqk7epyswP9w/macbook-2617705_1280.jpg) In the [previous part](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-3), we made a back-end that is streaming blocks and detects 3 methods in custom_json. Create a game, request to join a game, and accept the request. We also set up a MySQL server with 3 tables for the methods. You can find the links to the other parts at the end of the post. ### API Let's start by implementing the API for retrieving the games list. Our API is public so it doesn't require user authentication. The API will just return the data synced from the blockchain. `api/games.js`: ``` const mysql = require('../helpers/mysql') const express = require('express') const router = express.Router() // Return all games on route /games router.get('/games', async (req, res) =&amp;gt; { try { // Get games data from Database const games = await mysql.query( 'SELECT `game_id`, `player1`, `player2`, `starting_player`, `status`, `winner` FROM `games`' ) // Check for expected result if (!games || !Array.isArray(games) || games.length &amp;lt; 1) { // WE return id: 1 for success and id: 0 for errors return res.json({ id: 1, games: [] }) } // We return `games` as we receive from MySQL but it's not a good practice // specially when you have critical data in the database // You can return data one by one like `games: [{game_id: games.game_id, ...}]` return res.json({ id: 1, games }) } catch (e) { // Return error for unexpected errors like connection drops res.json({ id: 0, error: 'Unexpected error.' }) } }) module.exports = router ``` The comments are in the code itself for better understanding. Note: We use `try{} catch{}` wherever we can. It is always good to handle errors. We can test our API at this point to detect possible errors in the code. Include the following code in `api/server.js` just above the `port` and `host` constants. ``` const games = require('./games') app.use(games) ``` Run `node api/server.js`. We can see the console.log: `Application started on 127.0.0.1:2021` Let's open `127.0.0.1:2021/games` in the browser. ![image.png](https://images.hive.blog/DQmbTKVAbtUB6nDH8HWuvku8NuiZv3jovu94jtEMAEU1vSX/image.png) The API works as expected. But it's not done yet. This API returns ALL the games without a specific order. We should implement pagination and define an order for our list. Updated code `api/games.js`: ``` const mysql = require('../helpers/mysql') const express = require('express') const router = express.Router() router.get('/games/:page', async (req, res) =&amp;gt; { try { if (isNaN(req.params.page)) { res.json({ id: 0, error: 'Expected number.' }) } const page = Math.floor(req.params.page) if (page &amp;lt; 1) { res.json({ id: 0, error: 'Expected &amp;gt; 0' }) } const offset = (page - 1) * 10 const games = await mysql.query( 'SELECT `game_id`, `player1`, `player2`, `starting_player`, `status`, `winner` FROM `games`' + ' ORDER BY `id` DESC LIMIT 10 OFFSET ?', [offset] ) if (!games || !Array.isArray(games) || games.length &amp;lt; 1) { return res.json({ id: 1, games: [] }) } return res.json({ id: 1, games }) } catch (e) { res.json({ id: 0, error: 'Unexpected error.' }) } }) module.exports = router ``` We used `id` to order our list and get the newly created games first. Each page returns up to 10 games. We can try `127.0.0.1:2021/games/1` for testing. *** Let's set another API for requests. The code is almost similar but we return only requests for the specific game_id. `api/requests.js`: ``` const mysql = require('../helpers/mysql') const express = require('express') const router = express.Router() router.get('/requests/:id', async (req, res) =&amp;gt; { try { if (!req.params.id) { res.json({ id: 0, error: 'Expected game_id.' }) } // We are passing user input into the database // You should be careful in such cases // We use ? for parameters which escapes the characters const requests = await mysql.query( 'SELECT `player`, `status` FROM `requests` WHERE `game_id`= ?', [req.params.id] ) if (!requests || !Array.isArray(requests) || requests.length &amp;lt; 1) { return res.json({ id: 1, requests: [] }) } return res.json({ id: 1, requests }) } catch (e) { res.json({ id: 0, error: 'Unexpected error.' }) } }) module.exports = router ``` Note: `:id` in the above router represents a variable named id. So for example `http://127.0.0.1:2021/requests/mygameidhere` in this request, the `id` variable is `mygameidhere` which is accessible by `req.params.id`. *** A similar code for the `moves` table. There wasn't a better name in my mind for this table. `api/moves.js`: ``` const mysql = require('../helpers/mysql') const express = require('express') const router = express.Router() router.get('/moves/:id', async (req, res) =&amp;gt; { try { if (!req.params.id) { res.json({ id: 0, error: 'Expected game_id.' }) } const moves = await mysql.query( 'SELECT `player`, `col`, `row` FROM `moves` WHERE `game_id`= ?', [req.params.id] ) if (!moves || !Array.isArray(moves) || moves.length &amp;lt; 1) { return res.json({ id: 1, moves: [] }) } return res.json({ id: 1, moves }) } catch (e) { res.json({ id: 0, error: 'Unexpected error.' }) } }) module.exports = router ``` Now our 3 APIs are ready to be implemented on the front-end. *** Here is the updated `api/server.js` after including the APIs: ``` const express = require('express') const bodyParser = require('body-parser') const hpp = require('hpp') const helmet = require('helmet') const app = express() // more info: www.npmjs.com/package/hpp app.use(hpp()) app.use(helmet()) // support json encoded bodies and encoded bodies app.use(bodyParser.json()) app.use(bodyParser.urlencoded({ extended: true })) app.use(function (req, res, next) { res.header( 'Access-Control-Allow-Origin', 'http://localhost https://tic-tac-toe.mahdiyari.info/' ) res.header('Access-Control-Allow-Credentials', true) res.header( 'Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept, access_key' ) next() }) // APIs const games = require('./games') const requests = require('./requests') const moves = require('./moves') app.use(games) app.use(requests) app.use(moves) const port = process.env.PORT || 2021 const host = process.env.HOST || '127.0.0.1' app.listen(port, host, () =&amp;gt; { console.log(`Application started on ${host}:${port}`) }) ``` *** ### Front-end I think using pure HTML is a mistake and I would prefer something like Angular for the web applications but that comes with its own learning process which can make this tutorial complex. So my recommendation is to learn something like Angular or Vue and live a happy life. Anyway, coding time. I'm not going to drop `index.html` here. It doesn't need much explanation and it's long. You can see it on the [GitLab repository](https://gitlab.com/mahdiyari/decentralized-game-on-hive/-/blob/master/front-end/index.html). I will just add some references here used in `app.js`. The table for listing the games and buttons for pagination. `index.html`: ``` Games list Auto updating every 5s # Game ID Player 1 Player 2 Starting Player Status Winner Action &amp;laquo; 1 &amp;raquo; ``` *** We have to fill the table above. So let's implement some basic functions. `js/app.js`: ``` const baseAPI = 'http://127.0.0.1:2021' const APICall = async (api) =&amp;gt; { return (await fetch(baseAPI + api)).json() } ``` For ease of use, we define a function for `GET` calls using `fetch` and a variable for our API address. *** ``` const getGames = async (page = 1) =&amp;gt; { const games = await APICall('/games/' + page) return games.games } ``` This function basically gets the games from the API per page. *** ``` const fillGamesTable = (data) =&amp;gt; { const tbody = document.getElementById('games-table-body') let temp = '' for (let i = 0; i &amp;lt; data.length; i++) { temp += ` ${(gamesPage - 1) * 10 + i + 1} ${data[i].game_id} ${data[i].player1} ${data[i].player2} ${data[i].starting_player} ${data[i].status} ${data[i].winner} ` } if (data.length &amp;lt; 1) { temp = 'No games.' } tbody.innerHTML = temp } ``` `fillGamesTable` takes the result from `getGames` function and fills the HTML table with data using a `for` loop. *** ``` let gamesPage = 1 const loadTheGames = async () =&amp;gt; { const games = await getGames(gamesPage) fillGamesTable(games) if (games.length &amp;lt; 10) { document.getElementById('next-btn').className = 'page-item disabled' } else { document.getElementById('next-btn').className = 'page-item' } if (gamesPage === 1) { document.getElementById('prev-btn').className = 'page-item disabled' } else { document.getElementById('prev-btn').className = 'page-item' } document.getElementById('page-number').innerHTML = ` ${gamesPage} ` } loadTheGames() setInterval(() =&amp;gt; loadTheGames(), 5000) ``` With this function, we call the two previously defined functions to do their job and update the pagination buttons and the page number every time we update the table data. Also, every 5 seconds, it gets new data from API and updates the table with new data so users don't have to reload the page for new data. *** ``` const nextGamesPage = () =&amp;gt; { gamesPage++ loadTheGames() } const prevGamesPage = () =&amp;gt; { gamesPage-- loadTheGames() } ``` And two functions for changing pages. Simple as that. *** The final result with dummy data looks like this on the browser: ![Capture.PNG](https://images.hive.blog/DQmcYZC1vixajRW4Ui5dHiSfTy5MYqEYZhXy2bd2ituz4Ar/Capture.PNG) *** That's it for this part. I'm really happy with the results we are getting. I didn't plan anything beforehand and I'm coding as I'm writing the posts. Today we made 3 API calls and created the basic front-end which for now only shows the list of games that are submitted to the Hive blockchain. In the next part, we will implement the methods for creating and joining the games on the client side. We also probably need to create a game page where actual gaming happens. Thanks for reading. Make sure to follow me and share the post. Upvote if you like and leave a comment. *** [GitLab](https://gitlab.com/mahdiyari/decentralized-game-on-hive) [Part 1](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-tic-tac-toe-part-1) [Part 2](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-2) [Part 3](https://hive.blog/hive-139531/@mahdiyari/making-a-decentralized-game-on-hive-part-3) [Next part &amp;gt;&amp;gt;](https://hive.blog/hive-169321/@mahdiyari/making-a-decentralized-game-on-hive-part-5) *** **Vote for my witness:** - https://wallet.hive.blog/~witnesses - https://peakd.com/witnesses - https://ecency.com/witnesses See: Making a Decentralized Game on Hive - Part 4 by @mahdiyari</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://images.hive.blog/DQmbqyPpfU2dpwYkn9GVJdMmJbfukkvZZ8Bwqk7epyswP9w/macbook-2617705_1280.jpg" /><media:content medium="image" url="https://images.hive.blog/DQmbqyPpfU2dpwYkn9GVJdMmJbfukkvZZ8Bwqk7epyswP9w/macbook-2617705_1280.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Wanna help test RC delegations ? Here’s all you need to know</title><link href="https://hivedocs.info/howto/contribute/qa/2021/04/01/wanna-help-test-rc-delegations-heres-all-you-need-to-know.html" rel="alternate" type="text/html" title="Wanna help test RC delegations ? Here’s all you need to know" /><published>2021-04-01T05:47:18-07:00</published><updated>2021-04-01T05:47:18-07:00</updated><id>https://hivedocs.info/howto/contribute/qa/2021/04/01/wanna-help-test-rc-delegations-heres-all-you-need-to-know</id><content type="html" xml:base="https://hivedocs.info/howto/contribute/qa/2021/04/01/wanna-help-test-rc-delegations-heres-all-you-need-to-know.html">&lt;div id=&quot;content-howo-wanna-help-test-rc-delegations-heres-all-you-need-to-know&quot;&gt;Hello,


![social_hive_city.jpg](https://files.peakd.com/file/peakd-hive/howo/23tkhtbrgHEVtkgv17tzktjCoVTGzkbSPxxv2tqiF57xYvgh8XouRqfeV68p7cVTKfipk.jpg)


some users asked me how they can help testing rc delegations so I set to write a guide

disclaimer: this assumes that you are very technical and have a good understanding of how hive works.

## rc delegations

### Pools

Each account got an RC pool in his account, anyone can delegate to any account pool, that RC won't be usable by the account, it's just a pool he can delegate RC from. (he can delegate to himself if he wishes).

### RC slots

There is a notion of delegation slots, each account got 3 slots from which they can receive delegations. meaning they can receive rc from at most from 3 pools, also, each slot can only receive from a specific pool. If you are not &quot;whitelisted&quot; you can't delegate to an user.

For new accounts the slots will be set like this by default:
Slot 1 is set to the account creator of the account, and both the account and the account creator can change that slot
Slot 2 is set to the recovery account or not set, the account and the recovery partner for the account can change that slot
Slot 3 is not set, and only the account can change that slot.

Most of the use cases for rc delegations are linked to account creation, games or other operation intensive applications could have a button to &quot;ask for rc&quot; that would make the user set a slot to the game and then the app would delegate to it.

It's worth noting that if you change your slot, you lose your previous delegation on that slot.

### Oversubscription

Pool work on an oversubscription model:

Let's say Alice delegates 100 RC to an RC Pool.
That pool can then delegates 30 RC to Bob, Carol, Dave, and Eugene.
There is a total of 120 RC delegated, but only 100 RC in the pool.

Is that a problem? No.The implementation allows each of the out delegations to use up to the delegation's worth of RC, but that is charged to the pool.

If Bob uses all 30 RC and no one else does, Bob will no longer have access to RC from the pool until his regenerates, even though to pool still has 70 RC available. However, if Bob, Carol, and Dave all use 30 RC, then Eugene will only be able to use 10 RC before he cannot access any more.

Although he has RC still available from the delegation, because the pool ran out of RC, Eugene does not have any to use.

This is useful for this use case: multiple large stakeholder delegating to one account creation pool making many small delegations to new users. Users will consume their RC, but because not all users are retained, this can be significantly over subscribed.
Another real life example:

```
Alice delegates 50 rc to her pool
Bob changes it slot 3 to Alice
Alice delegates 30 RC from it's pool to Bob (Bob can now use the RC)
Alice tries to delegate to Eve, but since she didn't set a slot to Alice, Alice cannot delegate RC to it
```

That's it ! Feel free to comment if you have questions
this doc may give you some more info: https://gitlab.syncad.com/hive/hive/-/blob/feature/rc_delegation_rebase/doc/devs/delegation_pools.md

Now onto the actual testing.

# compiling hive

if you are on ubuntu 20 see this other guide first: https://peakd.com/hive/@howo/how-to-build-hive-on-ubuntu-20-04

first install all of the dependencies :

```
apt-get install -y \
        autoconf \
        automake \
        autotools-dev \
        build-essential \
        cmake \
        doxygen \
        git \
        libboost-all-dev \
        libyajl-dev \
        libreadline-dev \
        libssl-dev \
        libtool \
        liblz4-tool \
        ncurses-dev \
        python3 \
        python3-dev \
        python3-jinja2 \
        python3-pip \
        libgflags-dev \
        libsnappy-dev \
        zlib1g-dev \
        libbz2-dev \
        liblz4-dev \
        libzstd-dev
```

then build hive on the rc delegations branch:

```
git clone git@gitlab.syncad.com:hive/hive.git
cd hive
git checkout feature/rc_delegation_rebase
git submodule update --init --recursive
mkdir build
cd build

cmake -DENABLE_COVERAGE_TESTING=ON -DBUILD_HIVE_TESTNET=ON -DLOW_MEMORY_NODE=ON ..

make -j$(nproc) hived cli_wallet
```

if you got an error while doing the git clone try with this url:

`https://gitlab.syncad.com/hive/hive.git`

# running it

Run the node a few seconds and then exit hived like so

`./programs/steemd/hived -d testnet/`

this will create a testnet directory with the default config file.

open the config.ini file

`nano testnethf24/config.ini`

replace the config.ini with this one:

```
# Appender definition json: {&quot;appender&quot;, &quot;stream&quot;, &quot;file&quot;} Can only specify a file OR a stream
log-appender = {&quot;appender&quot;:&quot;stderr&quot;,&quot;stream&quot;:&quot;std_error&quot;} {&quot;appender&quot;:&quot;p2p&quot;,&quot;file&quot;:&quot;logs/p2p/p2p.log&quot;}

# log-console-appender = 

# log-file-appender = 

# Logger definition json: {&quot;name&quot;, &quot;level&quot;, &quot;appender&quot;}
log-logger = {&quot;name&quot;:&quot;default&quot;,&quot;level&quot;:&quot;info&quot;,&quot;appender&quot;:&quot;stderr&quot;} {&quot;name&quot;:&quot;p2p&quot;,&quot;level&quot;:&quot;warn&quot;,&quot;appender&quot;:&quot;p2p&quot;}

# Whether to print backtrace on SIGSEGV
backtrace = yes

# Plugin(s) to enable, may be specified multiple times
plugin = witness account_by_key account_by_key_api condenser_api 

# Defines a range of accounts to track as a json pair [&quot;from&quot;,&quot;to&quot;] [from,to] Can be specified multiple times.
# account-history-track-account-range = 

# Defines a range of accounts to track as a json pair [&quot;from&quot;,&quot;to&quot;] [from,to] Can be specified multiple times. Deprecated in favor of account-history-track-account-range.
# track-account-range = 

# Defines a list of operations which will be explicitly logged.
# account-history-whitelist-ops = 

# Defines a list of operations which will be explicitly logged. Deprecated in favor of account-history-whitelist-ops.
# history-whitelist-ops = 

# Defines a list of operations which will be explicitly ignored.
# account-history-blacklist-ops = 

# Defines a list of operations which will be explicitly ignored. Deprecated in favor of account-history-blacklist-ops.
# history-blacklist-ops = 

# Disables automatic account history trimming
history-disable-pruning = 0

# The location of the rocksdb database for account history. By default it is $DATA_DIR/blockchain/account-history-rocksdb-storage
account-history-rocksdb-path = &quot;blockchain/account-history-rocksdb-storage&quot;

# Defines a range of accounts to track as a json pair [&quot;from&quot;,&quot;to&quot;] [from,to] Can be specified multiple times.
# account-history-rocksdb-track-account-range = 

# Defines a list of operations which will be explicitly logged.
# account-history-rocksdb-whitelist-ops = 

# Defines a list of operations which will be explicitly ignored.
# account-history-rocksdb-blacklist-ops = 

# Where to export data (NONE to discard)
block-data-export-file = NONE

# How often to print out block_log_info (default 1 day)
block-log-info-print-interval-seconds = 86400

# Whether to defer printing until block is irreversible
block-log-info-print-irreversible = 1

# Where to print (filename or special sink ILOG, STDOUT, STDERR)
block-log-info-print-file = ILOG

# Maximum numbers of proposals/votes which can be removed in the same cycle
sps-remove-threshold = 200

# the location of the chain shared memory files (absolute path or relative to application data dir)
shared-file-dir = &quot;blockchain&quot;

# Size of the shared memory file. Default: 54G. If running a full node, increase this value to 200G.
shared-file-size = 54G

# A 2 precision percentage (0-10000) that defines the threshold for when to autoscale the shared memory file. Setting this to 0 disables autoscaling. Recommended value for consensus node is 9500 (95%). Full node is 9900 (99%)
shared-file-full-threshold = 0

# A 2 precision percentage (0-10000) that defines how quickly to scale the shared memory file. When autoscaling occurs the file's size will be increased by this percent. Setting this to 0 disables autoscaling. Recommended value is between 1000-2000 (10-20%)
shared-file-scale-rate = 0

# Pairs of [BLOCK_NUM,BLOCK_ID] that should be enforced as checkpoints.
# checkpoint = 

# flush shared memory changes to disk every N blocks
# flush-state-interval = 

# Database edits to apply on startup (may specify multiple times)
# debug-node-edit-script = 

# Database edits to apply on startup (may specify multiple times). Deprecated in favor of debug-node-edit-script.
# edit-script = 

# Set the maximum size of cached feed for an account
follow-max-feed-size = 500

# Block time (in epoch seconds) when to start calculating feeds
follow-start-feeds = 0

# json-rpc log directory name.
# log-json-rpc = 

# Track market history by grouping orders into buckets of equal size measured in seconds specified as a JSON array of numbers
market-history-bucket-size = [15,60,300,3600,86400]

# How far back in time to track history for each bucket size, measured in the number of buckets (default: 5760)
market-history-buckets-per-size = 5760

# The local IP address and port to listen for incoming connections.
# p2p-endpoint = 

# Maxmimum number of incoming connections on P2P endpoint.
# p2p-max-connections = 

# The IP address and port of a remote peer to sync with. Deprecated in favor of p2p-seed-node.
# seed-node = 

# The IP address and port of a remote peer to sync with.
# p2p-seed-node = 

# P2P network parameters. (Default: {&quot;listen_endpoint&quot;:&quot;0.0.0.0:0&quot;,&quot;accept_incoming_connections&quot;:true,&quot;wait_if_endpoint_is_busy&quot;:true,&quot;private_key&quot;:&quot;0000000000000000000000000000000000000000000000000000000000000000&quot;,&quot;desired_number_of_connections&quot;:20,&quot;maximum_number_of_connections&quot;:200,&quot;peer_connection_retry_timeout&quot;:30,&quot;peer_inactivity_timeout&quot;:5,&quot;peer_advertising_disabled&quot;:false,&quot;maximum_number_of_blocks_to_handle_at_one_time&quot;:200,&quot;maximum_number_of_sync_blocks_to_prefetch&quot;:2000,&quot;maximum_blocks_per_peer_during_syncing&quot;:200,&quot;active_ignored_request_timeout_microseconds&quot;:6000000} )
# p2p-parameters = 

# Skip rejecting transactions when account has insufficient RCs. This is not recommended.
rc-skip-reject-not-enough-rc = 0

# Generate historical resource credits
rc-compute-historical-rc = 0

# Start calculating RCs at a specific block
rc-start-at-block = 0

# Ignore RC calculations for the whitelist
# rc-account-whitelist = 

# Endpoint to send statsd messages to.
# statsd-endpoint = 

# Size to batch statsd messages.
statsd-batchsize = 1

# Whitelist of statistics to capture.
# statsd-whitelist = 

# Blacklist of statistics to capture.
# statsd-blacklist = 

# Block time (in epoch seconds) when to start calculating promoted content. Should be 1 week prior to current time.
tags-start-promoted = 0

# Skip updating tags on startup. Can safely be skipped when starting a previously running node. Should not be skipped when reindexing.
tags-skip-startup-update = 0

# Defines the number of blocks from the head block that transaction statuses will be tracked.
transaction-status-block-depth = 64000

# Defines the block number the transaction status plugin will begin tracking.
transaction-status-track-after-block = 0

# Local http endpoint for webserver requests.
# webserver-http-endpoint = 

# Local unix http endpoint for webserver requests.
# webserver-unix-endpoint = 

# Local websocket endpoint for webserver requests.
# webserver-ws-endpoint = 

# Local http and websocket endpoint for webserver requests. Deprecated in favor of webserver-http-endpoint and webserver-ws-endpoint
# rpc-endpoint = 

# Number of threads used to handle queries. Default: 32.
webserver-thread-pool-size = 32

# Enable block production, even if the chain is stale.
enable-stale-production = 1

# Percent of witnesses (0-99) that must be participating in order to produce blocks
required-participation = 0

# name of witness controlled by this node (e.g. initwitness )
witness = &quot;initminer&quot;

# WIF PRIVATE KEY to be used by one or more witnesses or miners
private-key = 5JNHfZYKGaomSFvd4NUdQ9qMcEAC43kujbfjueTHpVapX1Kzq2n

# Skip enforcing bandwidth restrictions. Default is true in favor of rc_plugin.
witness-skip-enforce-bandwidth = 1

# Local http endpoint for webserver requests.
webserver-http-endpoint = 127.0.0.1:8090

# Local websocket endpoint for webserver requests.
webserver-ws-endpoint =127.0.0.1:8091

plugin = webserver p2p json_rpc witness account_by_key reputation market_history

plugin = database_api account_by_key_api network_broadcast_api reputation_api market_history_api condenser_api block_api rc_api account_history account_history_api
```

then run hived again
`./programs/steemd/hived -d testnet/`

# Testing rc delegations 

I mostly test using the cli_wallet for real world tests, you can also look at hive-js that has support for the new operations (see this old half made script, ask me questions if you really want to use hive-js and not cli_wallet: https://github.com/drov0/hf23-testing/blob/master/rc_pools.js )

to run the cli_wallet locally:

`./programs/cli_wallet/cli_wallet --server-rpc-endpoint=&quot;ws://127.0.0.1:8091&quot;`

here's a simple &quot;happy path&quot; setup to give you an idea:

```
# set a password
set_password p
# unlock the wallet
unlock p
# import initminer's key 
import_key 5JNHfZYKGaomSFvd4NUdQ9qMcEAC43kujbfjueTHpVapX1Kzq2n
# account who will get the rc
create_account &quot;initminer&quot; &quot;howo&quot; &quot;&quot; true
# pool account 
create_account &quot;initminer&quot; &quot;pool&quot; &quot;&quot; true
# transfer some funds to test rc usage
transfer  initminer howo &quot;2500.000 TESTS&quot; &quot;&quot; true
# doesn't work because howo has no rc
transfer howo initminer &quot;1.000 TESTS&quot; &quot;&quot; true
# set slot 0 to point to pool signing using initminer
set_slot_delegator &quot;pool&quot; &quot;howo&quot; 0 &quot;initminer&quot; true
# delegate 100 rc to the pool account's rc pool from initminer
delegate_to_pool initminer pool {&quot;symbol&quot;:&quot;VESTS&quot;,&quot;amount&quot;: &quot;100&quot;, &quot;precision&quot;: 6, &quot;nai&quot;: &quot;@@000000037&quot;} true
# delegate 10 tests so that the pool account can delegate some rcs (delegating to the pool of an account doesn't make it available to the account)
transfer_to_vesting &quot;initminer&quot; &quot;pool&quot; &quot;10.000 TESTS&quot; true
# delegate 100 rc from the pool to howo
delegate_drc_from_pool pool howo {&quot;decimals&quot;: 6, &quot;nai&quot;: &quot;@@000000037&quot;} 100 true
# howo can now transfer
transfer howo initminer &quot;1.000 TESTS&quot; &quot;&quot; true
```

Some additional useful cli commands to see how things are going:

find_rc_accounts [&quot;account&quot;]:

gives you the state of your the rc account 

```
unlocked &amp;gt;&amp;gt;&amp;gt; find_rc_accounts [&quot;howo&quot;]
find_rc_accounts [&quot;howo&quot;]
[{
    &quot;account&quot;: &quot;howo&quot;,
    &quot;creator&quot;: &quot;initminer&quot;,
    &quot;rc_manabar&quot;: {
      &quot;current_mana&quot;: 356050,
      &quot;last_update_time&quot;: 1617274335
    },
    &quot;max_rc_creation_adjustment&quot;: {
      &quot;amount&quot;: &quot;0&quot;,
      &quot;precision&quot;: 6,
      &quot;nai&quot;: &quot;@@000000037&quot;
    },
    &quot;max_rc&quot;: 356054,
    &quot;vests_delegated_to_pools&quot;: {
      &quot;amount&quot;: &quot;0&quot;,
      &quot;precision&quot;: 6,
      &quot;nai&quot;: &quot;@@000000037&quot;
    },
    &quot;delegation_slots&quot;: [{
        &quot;rc_manabar&quot;: {
          &quot;current_mana&quot;: 96,
          &quot;last_update_time&quot;: 1617274335
        },
        &quot;max_mana&quot;: 100,
        &quot;delegator&quot;: &quot;pool&quot;
      },{
        &quot;rc_manabar&quot;: {
          &quot;current_mana&quot;: 0,
          &quot;last_update_time&quot;: 0
        },
        &quot;max_mana&quot;: 0,
        &quot;delegator&quot;: &quot;&quot;
      },{
        &quot;rc_manabar&quot;: {
          &quot;current_mana&quot;: 0,
          &quot;last_update_time&quot;: 0
        },
        &quot;max_mana&quot;: 0,
        &quot;delegator&quot;: &quot;&quot;
      }
    ],
    &quot;out_delegation_total&quot;: 0
  }
]
````


find_rc_delegation_pools [&quot;pool&quot;]

gets the status of a pool (how much rc is in it)
```
[{
    &quot;id&quot;: 0,
    &quot;account&quot;: &quot;pool&quot;,
    &quot;asset_symbol&quot;: {
      &quot;nai&quot;: &quot;@@000000037&quot;,
      &quot;decimals&quot;: 6
    },
    &quot;rc_pool_manabar&quot;: {
      &quot;current_mana&quot;: 100,
      &quot;last_update_time&quot;: 1617278439
    },
    &quot;max_rc&quot;: 100
  }
]
```

Here's a dump of all the commands and their parameters:
```
delegate_drc_from_pool(account_name_type from_pool, account_name_type to_account, asset_symbol_type asset_symbol, int64_t drc_max_mana, bool broadcast)
delegate_to_pool(account_name_type from_account, account_name_type to_pool, asset amount, bool broadcast)
set_slot_delegator(account_name_type from_pool, account_name_type to_account, uint8_t to_slot, account_name_type signer, bool broadcast)


find_rc_accounts(vector&lt;account_name_type&gt; accounts)
find_rc_delegation_pools(vector&lt;account_name_type&gt; accounts)
find_rc_delegations(account_name_type account) 
list_rc_accounts(account_name_type account, uint32_t limit, rc::sort_order_type order)
list_rc_delegation_pools(account_name_type account, uint32_t limit, rc::sort_order_type order)
list_rc_delegations(vector&lt;account_name_type&gt; account, uint32_t limit, rc::sort_order_type order)    
```

for list the sort orders are:

```
by_name
by_edge (edge is both an account and a pool)
by_pool
```

Finally if you want to reset your testnet, just delete the contents the blockchain dir and rerun hived:
`rm -rf testnet/blockchain/*`

Here's a few things you can test:

- lots of users delegating to a single pool (like 10k accounts) 
- one pool delegating to many users
- trying to break it by using very large or negative numbers 
- use your imagination !

please do ask questions if you have any I'd gladly reply to them.

# Support what I'm doing 

If you like what I'm doing, please consider voting on my new proposal:
https://peakd.com/proposals/167
[hivesigner](https://hivesigner.com/import?redirect=%2Fsign%2Fupdate-proposal-votes%3Fproposal_ids%3D%255B167%255D%26approve%3Dtrue&amp;amp;authority=active)&amp;lt;/div&amp;gt;
&lt;script crossorigin=&quot;anonymous&quot; integrity=&quot;sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=&quot; src=&quot;https://code.jquery.com/jquery-3.5.1.slim.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://unpkg.com/steem-content-renderer&quot;&gt;&lt;/script&gt;
&lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js&quot;&gt;&lt;/script&gt; --&gt;
&lt;script&gt;
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: &quot;https://hive.blog/&quot;,
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: &quot;&quot;,
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) =&gt; url,
        usertagUrlFn: (account) =&gt; &quot;/@howo&quot;,
        hashtagUrlFn: (hashtag) =&gt; &quot;/wanna-help-test-rc-delegations-heres-all-you-need-to-know&quot;,
        isLinkSafeFn: (url) =&gt; true,
      });
      
      const inputElem = $('#content-howo-wanna-help-test-rc-delegations-heres-all-you-need-to-know').html();
      const outputElem = $('#content-howo-wanna-help-test-rc-delegations-heres-all-you-need-to-know');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
&lt;/script&gt;
&lt;style&gt;
  #content-howo-wanna-help-test-rc-delegations-heres-all-you-need-to-know {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-howo-wanna-help-test-rc-delegations-heres-all-you-need-to-know code {
    background: white;
  }
  #content-howo-wanna-help-test-rc-delegations-heres-all-you-need-to-know a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-howo-wanna-help-test-rc-delegations-heres-all-you-need-to-know a:hover {
    border-bottom: 0;
  }
  #content-howo-wanna-help-test-rc-delegations-heres-all-you-need-to-know h1 {
    font-size: 2.2em;
  }
  #content-howo-wanna-help-test-rc-delegations-heres-all-you-need-to-know h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-howo-wanna-help-test-rc-delegations-heres-all-you-need-to-know header small {
    color: #999;
    font-size: 50%;
  }
  #content-howo-wanna-help-test-rc-delegations-heres-all-you-need-to-know img {
    max-width: 100%;
  }
&lt;/style&gt;

&lt;hr /&gt;
&lt;p&gt;
  See: &lt;a href=&quot;https://peakd.com/test/@howo/wanna-help-test-rc-delegations-heres-all-you-need-to-know&quot;&gt;Wanna help test RC delegations ? Here's all you need to know&lt;/a&gt;
  by
  &lt;a href=&quot;https://hive.blog/@howo&quot;&gt;@howo&lt;/a&gt;
&lt;/p&gt;

&lt;/account_name_type&gt;&lt;/account_name_type&gt;&lt;/account_name_type&gt;&lt;/div&gt;</content><author><name>howo</name></author><category term="howto" /><category term="contribute" /><category term="qa" /><summary type="html">Hello, ![social_hive_city.jpg](https://files.peakd.com/file/peakd-hive/howo/23tkhtbrgHEVtkgv17tzktjCoVTGzkbSPxxv2tqiF57xYvgh8XouRqfeV68p7cVTKfipk.jpg) some users asked me how they can help testing rc delegations so I set to write a guide disclaimer: this assumes that you are very technical and have a good understanding of how hive works. ## rc delegations ### Pools Each account got an RC pool in his account, anyone can delegate to any account pool, that RC won't be usable by the account, it's just a pool he can delegate RC from. (he can delegate to himself if he wishes). ### RC slots There is a notion of delegation slots, each account got 3 slots from which they can receive delegations. meaning they can receive rc from at most from 3 pools, also, each slot can only receive from a specific pool. If you are not &quot;whitelisted&quot; you can't delegate to an user. For new accounts the slots will be set like this by default: Slot 1 is set to the account creator of the account, and both the account and the account creator can change that slot Slot 2 is set to the recovery account or not set, the account and the recovery partner for the account can change that slot Slot 3 is not set, and only the account can change that slot. Most of the use cases for rc delegations are linked to account creation, games or other operation intensive applications could have a button to &quot;ask for rc&quot; that would make the user set a slot to the game and then the app would delegate to it. It's worth noting that if you change your slot, you lose your previous delegation on that slot. ### Oversubscription Pool work on an oversubscription model: Let's say Alice delegates 100 RC to an RC Pool. That pool can then delegates 30 RC to Bob, Carol, Dave, and Eugene. There is a total of 120 RC delegated, but only 100 RC in the pool. Is that a problem? No.The implementation allows each of the out delegations to use up to the delegation's worth of RC, but that is charged to the pool. If Bob uses all 30 RC and no one else does, Bob will no longer have access to RC from the pool until his regenerates, even though to pool still has 70 RC available. However, if Bob, Carol, and Dave all use 30 RC, then Eugene will only be able to use 10 RC before he cannot access any more. Although he has RC still available from the delegation, because the pool ran out of RC, Eugene does not have any to use. This is useful for this use case: multiple large stakeholder delegating to one account creation pool making many small delegations to new users. Users will consume their RC, but because not all users are retained, this can be significantly over subscribed. Another real life example: ``` Alice delegates 50 rc to her pool Bob changes it slot 3 to Alice Alice delegates 30 RC from it's pool to Bob (Bob can now use the RC) Alice tries to delegate to Eve, but since she didn't set a slot to Alice, Alice cannot delegate RC to it ``` That's it ! Feel free to comment if you have questions this doc may give you some more info: https://gitlab.syncad.com/hive/hive/-/blob/feature/rc_delegation_rebase/doc/devs/delegation_pools.md Now onto the actual testing. # compiling hive if you are on ubuntu 20 see this other guide first: https://peakd.com/hive/@howo/how-to-build-hive-on-ubuntu-20-04 first install all of the dependencies : ``` apt-get install -y \ autoconf \ automake \ autotools-dev \ build-essential \ cmake \ doxygen \ git \ libboost-all-dev \ libyajl-dev \ libreadline-dev \ libssl-dev \ libtool \ liblz4-tool \ ncurses-dev \ python3 \ python3-dev \ python3-jinja2 \ python3-pip \ libgflags-dev \ libsnappy-dev \ zlib1g-dev \ libbz2-dev \ liblz4-dev \ libzstd-dev ``` then build hive on the rc delegations branch: ``` git clone git@gitlab.syncad.com:hive/hive.git cd hive git checkout feature/rc_delegation_rebase git submodule update --init --recursive mkdir build cd build cmake -DENABLE_COVERAGE_TESTING=ON -DBUILD_HIVE_TESTNET=ON -DLOW_MEMORY_NODE=ON .. make -j$(nproc) hived cli_wallet ``` if you got an error while doing the git clone try with this url: `https://gitlab.syncad.com/hive/hive.git` # running it Run the node a few seconds and then exit hived like so `./programs/steemd/hived -d testnet/` this will create a testnet directory with the default config file. open the config.ini file `nano testnethf24/config.ini` replace the config.ini with this one: ``` # Appender definition json: {&quot;appender&quot;, &quot;stream&quot;, &quot;file&quot;} Can only specify a file OR a stream log-appender = {&quot;appender&quot;:&quot;stderr&quot;,&quot;stream&quot;:&quot;std_error&quot;} {&quot;appender&quot;:&quot;p2p&quot;,&quot;file&quot;:&quot;logs/p2p/p2p.log&quot;} # log-console-appender = # log-file-appender = # Logger definition json: {&quot;name&quot;, &quot;level&quot;, &quot;appender&quot;} log-logger = {&quot;name&quot;:&quot;default&quot;,&quot;level&quot;:&quot;info&quot;,&quot;appender&quot;:&quot;stderr&quot;} {&quot;name&quot;:&quot;p2p&quot;,&quot;level&quot;:&quot;warn&quot;,&quot;appender&quot;:&quot;p2p&quot;} # Whether to print backtrace on SIGSEGV backtrace = yes # Plugin(s) to enable, may be specified multiple times plugin = witness account_by_key account_by_key_api condenser_api # Defines a range of accounts to track as a json pair [&quot;from&quot;,&quot;to&quot;] [from,to] Can be specified multiple times. # account-history-track-account-range = # Defines a range of accounts to track as a json pair [&quot;from&quot;,&quot;to&quot;] [from,to] Can be specified multiple times. Deprecated in favor of account-history-track-account-range. # track-account-range = # Defines a list of operations which will be explicitly logged. # account-history-whitelist-ops = # Defines a list of operations which will be explicitly logged. Deprecated in favor of account-history-whitelist-ops. # history-whitelist-ops = # Defines a list of operations which will be explicitly ignored. # account-history-blacklist-ops = # Defines a list of operations which will be explicitly ignored. Deprecated in favor of account-history-blacklist-ops. # history-blacklist-ops = # Disables automatic account history trimming history-disable-pruning = 0 # The location of the rocksdb database for account history. By default it is $DATA_DIR/blockchain/account-history-rocksdb-storage account-history-rocksdb-path = &quot;blockchain/account-history-rocksdb-storage&quot; # Defines a range of accounts to track as a json pair [&quot;from&quot;,&quot;to&quot;] [from,to] Can be specified multiple times. # account-history-rocksdb-track-account-range = # Defines a list of operations which will be explicitly logged. # account-history-rocksdb-whitelist-ops = # Defines a list of operations which will be explicitly ignored. # account-history-rocksdb-blacklist-ops = # Where to export data (NONE to discard) block-data-export-file = NONE # How often to print out block_log_info (default 1 day) block-log-info-print-interval-seconds = 86400 # Whether to defer printing until block is irreversible block-log-info-print-irreversible = 1 # Where to print (filename or special sink ILOG, STDOUT, STDERR) block-log-info-print-file = ILOG # Maximum numbers of proposals/votes which can be removed in the same cycle sps-remove-threshold = 200 # the location of the chain shared memory files (absolute path or relative to application data dir) shared-file-dir = &quot;blockchain&quot; # Size of the shared memory file. Default: 54G. If running a full node, increase this value to 200G. shared-file-size = 54G # A 2 precision percentage (0-10000) that defines the threshold for when to autoscale the shared memory file. Setting this to 0 disables autoscaling. Recommended value for consensus node is 9500 (95%). Full node is 9900 (99%) shared-file-full-threshold = 0 # A 2 precision percentage (0-10000) that defines how quickly to scale the shared memory file. When autoscaling occurs the file's size will be increased by this percent. Setting this to 0 disables autoscaling. Recommended value is between 1000-2000 (10-20%) shared-file-scale-rate = 0 # Pairs of [BLOCK_NUM,BLOCK_ID] that should be enforced as checkpoints. # checkpoint = # flush shared memory changes to disk every N blocks # flush-state-interval = # Database edits to apply on startup (may specify multiple times) # debug-node-edit-script = # Database edits to apply on startup (may specify multiple times). Deprecated in favor of debug-node-edit-script. # edit-script = # Set the maximum size of cached feed for an account follow-max-feed-size = 500 # Block time (in epoch seconds) when to start calculating feeds follow-start-feeds = 0 # json-rpc log directory name. # log-json-rpc = # Track market history by grouping orders into buckets of equal size measured in seconds specified as a JSON array of numbers market-history-bucket-size = [15,60,300,3600,86400] # How far back in time to track history for each bucket size, measured in the number of buckets (default: 5760) market-history-buckets-per-size = 5760 # The local IP address and port to listen for incoming connections. # p2p-endpoint = # Maxmimum number of incoming connections on P2P endpoint. # p2p-max-connections = # The IP address and port of a remote peer to sync with. Deprecated in favor of p2p-seed-node. # seed-node = # The IP address and port of a remote peer to sync with. # p2p-seed-node = # P2P network parameters. (Default: {&quot;listen_endpoint&quot;:&quot;0.0.0.0:0&quot;,&quot;accept_incoming_connections&quot;:true,&quot;wait_if_endpoint_is_busy&quot;:true,&quot;private_key&quot;:&quot;0000000000000000000000000000000000000000000000000000000000000000&quot;,&quot;desired_number_of_connections&quot;:20,&quot;maximum_number_of_connections&quot;:200,&quot;peer_connection_retry_timeout&quot;:30,&quot;peer_inactivity_timeout&quot;:5,&quot;peer_advertising_disabled&quot;:false,&quot;maximum_number_of_blocks_to_handle_at_one_time&quot;:200,&quot;maximum_number_of_sync_blocks_to_prefetch&quot;:2000,&quot;maximum_blocks_per_peer_during_syncing&quot;:200,&quot;active_ignored_request_timeout_microseconds&quot;:6000000} ) # p2p-parameters = # Skip rejecting transactions when account has insufficient RCs. This is not recommended. rc-skip-reject-not-enough-rc = 0 # Generate historical resource credits rc-compute-historical-rc = 0 # Start calculating RCs at a specific block rc-start-at-block = 0 # Ignore RC calculations for the whitelist # rc-account-whitelist = # Endpoint to send statsd messages to. # statsd-endpoint = # Size to batch statsd messages. statsd-batchsize = 1 # Whitelist of statistics to capture. # statsd-whitelist = # Blacklist of statistics to capture. # statsd-blacklist = # Block time (in epoch seconds) when to start calculating promoted content. Should be 1 week prior to current time. tags-start-promoted = 0 # Skip updating tags on startup. Can safely be skipped when starting a previously running node. Should not be skipped when reindexing. tags-skip-startup-update = 0 # Defines the number of blocks from the head block that transaction statuses will be tracked. transaction-status-block-depth = 64000 # Defines the block number the transaction status plugin will begin tracking. transaction-status-track-after-block = 0 # Local http endpoint for webserver requests. # webserver-http-endpoint = # Local unix http endpoint for webserver requests. # webserver-unix-endpoint = # Local websocket endpoint for webserver requests. # webserver-ws-endpoint = # Local http and websocket endpoint for webserver requests. Deprecated in favor of webserver-http-endpoint and webserver-ws-endpoint # rpc-endpoint = # Number of threads used to handle queries. Default: 32. webserver-thread-pool-size = 32 # Enable block production, even if the chain is stale. enable-stale-production = 1 # Percent of witnesses (0-99) that must be participating in order to produce blocks required-participation = 0 # name of witness controlled by this node (e.g. initwitness ) witness = &quot;initminer&quot; # WIF PRIVATE KEY to be used by one or more witnesses or miners private-key = 5JNHfZYKGaomSFvd4NUdQ9qMcEAC43kujbfjueTHpVapX1Kzq2n # Skip enforcing bandwidth restrictions. Default is true in favor of rc_plugin. witness-skip-enforce-bandwidth = 1 # Local http endpoint for webserver requests. webserver-http-endpoint = 127.0.0.1:8090 # Local websocket endpoint for webserver requests. webserver-ws-endpoint =127.0.0.1:8091 plugin = webserver p2p json_rpc witness account_by_key reputation market_history plugin = database_api account_by_key_api network_broadcast_api reputation_api market_history_api condenser_api block_api rc_api account_history account_history_api ``` then run hived again `./programs/steemd/hived -d testnet/` # Testing rc delegations I mostly test using the cli_wallet for real world tests, you can also look at hive-js that has support for the new operations (see this old half made script, ask me questions if you really want to use hive-js and not cli_wallet: https://github.com/drov0/hf23-testing/blob/master/rc_pools.js ) to run the cli_wallet locally: `./programs/cli_wallet/cli_wallet --server-rpc-endpoint=&quot;ws://127.0.0.1:8091&quot;` here's a simple &quot;happy path&quot; setup to give you an idea: ``` # set a password set_password p # unlock the wallet unlock p # import initminer's key import_key 5JNHfZYKGaomSFvd4NUdQ9qMcEAC43kujbfjueTHpVapX1Kzq2n # account who will get the rc create_account &quot;initminer&quot; &quot;howo&quot; &quot;&quot; true # pool account create_account &quot;initminer&quot; &quot;pool&quot; &quot;&quot; true # transfer some funds to test rc usage transfer initminer howo &quot;2500.000 TESTS&quot; &quot;&quot; true # doesn't work because howo has no rc transfer howo initminer &quot;1.000 TESTS&quot; &quot;&quot; true # set slot 0 to point to pool signing using initminer set_slot_delegator &quot;pool&quot; &quot;howo&quot; 0 &quot;initminer&quot; true # delegate 100 rc to the pool account's rc pool from initminer delegate_to_pool initminer pool {&quot;symbol&quot;:&quot;VESTS&quot;,&quot;amount&quot;: &quot;100&quot;, &quot;precision&quot;: 6, &quot;nai&quot;: &quot;@@000000037&quot;} true # delegate 10 tests so that the pool account can delegate some rcs (delegating to the pool of an account doesn't make it available to the account) transfer_to_vesting &quot;initminer&quot; &quot;pool&quot; &quot;10.000 TESTS&quot; true # delegate 100 rc from the pool to howo delegate_drc_from_pool pool howo {&quot;decimals&quot;: 6, &quot;nai&quot;: &quot;@@000000037&quot;} 100 true # howo can now transfer transfer howo initminer &quot;1.000 TESTS&quot; &quot;&quot; true ``` Some additional useful cli commands to see how things are going: find_rc_accounts [&quot;account&quot;]: gives you the state of your the rc account ``` unlocked &amp;gt;&amp;gt;&amp;gt; find_rc_accounts [&quot;howo&quot;] find_rc_accounts [&quot;howo&quot;] [{ &quot;account&quot;: &quot;howo&quot;, &quot;creator&quot;: &quot;initminer&quot;, &quot;rc_manabar&quot;: { &quot;current_mana&quot;: 356050, &quot;last_update_time&quot;: 1617274335 }, &quot;max_rc_creation_adjustment&quot;: { &quot;amount&quot;: &quot;0&quot;, &quot;precision&quot;: 6, &quot;nai&quot;: &quot;@@000000037&quot; }, &quot;max_rc&quot;: 356054, &quot;vests_delegated_to_pools&quot;: { &quot;amount&quot;: &quot;0&quot;, &quot;precision&quot;: 6, &quot;nai&quot;: &quot;@@000000037&quot; }, &quot;delegation_slots&quot;: [{ &quot;rc_manabar&quot;: { &quot;current_mana&quot;: 96, &quot;last_update_time&quot;: 1617274335 }, &quot;max_mana&quot;: 100, &quot;delegator&quot;: &quot;pool&quot; },{ &quot;rc_manabar&quot;: { &quot;current_mana&quot;: 0, &quot;last_update_time&quot;: 0 }, &quot;max_mana&quot;: 0, &quot;delegator&quot;: &quot;&quot; },{ &quot;rc_manabar&quot;: { &quot;current_mana&quot;: 0, &quot;last_update_time&quot;: 0 }, &quot;max_mana&quot;: 0, &quot;delegator&quot;: &quot;&quot; } ], &quot;out_delegation_total&quot;: 0 } ] ```` find_rc_delegation_pools [&quot;pool&quot;] gets the status of a pool (how much rc is in it) ``` [{ &quot;id&quot;: 0, &quot;account&quot;: &quot;pool&quot;, &quot;asset_symbol&quot;: { &quot;nai&quot;: &quot;@@000000037&quot;, &quot;decimals&quot;: 6 }, &quot;rc_pool_manabar&quot;: { &quot;current_mana&quot;: 100, &quot;last_update_time&quot;: 1617278439 }, &quot;max_rc&quot;: 100 } ] ``` Here's a dump of all the commands and their parameters: ``` delegate_drc_from_pool(account_name_type from_pool, account_name_type to_account, asset_symbol_type asset_symbol, int64_t drc_max_mana, bool broadcast) delegate_to_pool(account_name_type from_account, account_name_type to_pool, asset amount, bool broadcast) set_slot_delegator(account_name_type from_pool, account_name_type to_account, uint8_t to_slot, account_name_type signer, bool broadcast) find_rc_accounts(vector accounts) find_rc_delegation_pools(vector accounts) find_rc_delegations(account_name_type account) list_rc_accounts(account_name_type account, uint32_t limit, rc::sort_order_type order) list_rc_delegation_pools(account_name_type account, uint32_t limit, rc::sort_order_type order) list_rc_delegations(vector account, uint32_t limit, rc::sort_order_type order) ``` for list the sort orders are: ``` by_name by_edge (edge is both an account and a pool) by_pool ``` Finally if you want to reset your testnet, just delete the contents the blockchain dir and rerun hived: `rm -rf testnet/blockchain/*` Here's a few things you can test: - lots of users delegating to a single pool (like 10k accounts) - one pool delegating to many users - trying to break it by using very large or negative numbers - use your imagination ! please do ask questions if you have any I'd gladly reply to them. # Support what I'm doing If you like what I'm doing, please consider voting on my new proposal: https://peakd.com/proposals/167 [hivesigner](https://hivesigner.com/import?redirect=%2Fsign%2Fupdate-proposal-votes%3Fproposal_ids%3D%255B167%255D%26approve%3Dtrue&amp;amp;authority=active)&amp;lt;/div&amp;gt; See: Wanna help test RC delegations ? Here's all you need to know by @howo</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://files.peakd.com/file/peakd-hive/howo/23tkhtbrgHEVtkgv17tzktjCoVTGzkbSPxxv2tqiF57xYvgh8XouRqfeV68p7cVTKfipk.jpg" /><media:content medium="image" url="https://files.peakd.com/file/peakd-hive/howo/23tkhtbrgHEVtkgv17tzktjCoVTGzkbSPxxv2tqiF57xYvgh8XouRqfeV68p7cVTKfipk.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>