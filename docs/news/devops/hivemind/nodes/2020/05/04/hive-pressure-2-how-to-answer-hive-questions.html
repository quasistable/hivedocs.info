<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:image" content="/assets/images/sticker.png" /><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Hive Pressure 2: How to Answer Hive Questions? | Hive Chain Documentation</title>
<meta name="generator" content="Jekyll v4.2.1" />
<meta property="og:title" content="Hive Pressure 2: How to Answer Hive Questions?" />
<meta name="author" content="gtg" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="First, you need to learn how to ask good questions, and here are some of the resources that will help you to do so: https://developers.hive.io/apidefinitions/ https://hive.hivesigner.com/ (Kudos to @inertia and @good-karma) This set of API calls is far from perfect, but for now it has to be enough for general purpose API nodes. https://www.youtube.com/watch?v=vlW9lDE3DuI # The big, the slow, and the ugly. Back in the days, we used to run a so-called “full node”, that is a single ~~`steemd`~~ (yeah, we haven’t renamed the binary yet) node that was built with `LOW_MEMORY_NODE=OFF` and `CLEAR_VOTES=OFF` and configured with all the plugins you can get. It required a lot of RAM, it replayed for ages, and it was a huge pain to keep it running. Our code is great for running blockchain. It’s not equally efficient when it has to answer complex questions. # Current architecture The idea is to move the workload requiring complex queries out of our blockchain nodes. ``` +----------+ | &lt;-----------------+ @ @@@@@@ ,@@@@@% | Hivemind | | @@@@ (@@@@@* @@@@@@ +-------+ | &lt;-------+ | %@@@@@@ @@@@@@ %@@@@@, | | +-----^----+ | | @@@@@@@@@@ @@@@@@ @@@@@@ | redis | | | | ,@@@@@@@@@@@@ @@@@@@ @@@@@@ | &lt;--+ | +----v-----+ | @@@@@@@@@@@@@@@&amp; @@@@@@ @@@@@@ +-------+ | +-v-+ | | | @@@@@@@@@@@@@@@@@@ .@@@@@% @@@@@@ | | &lt;-----&gt; AH node | | @@@@@@@@@@@@@@@@@@@@@( .@@@@@% +-------+ +--&gt; j | | | | @@@@@@@@@@@@@@@@@@@@ @@@@@@ &lt;-------&gt; | | u | +----------+ | *@@@@@@@@@@@@@@@@ @@@@@@ @@@@@@. &lt;-------&gt; nginx &lt;-----&gt; s | | @@@@@@@@@@@@@@ &amp;@@@@@. @@@@@@ &lt;-------&gt; | | s | +----------+ | #@@@@@@@@@@ @@@@@@ #@@@@@/ +-------+ | i | | | | @@@@@@@@ /@@@@@/ @@@@@@ | &lt;-----&gt; FAT node &lt;---+ @@@@@( @@@@@@ .@@@@@&amp; +---+ | | @@ @@@@@&amp; @@@@@@ +----------+ ``` Sorry, lack of GIMP skills ## Hivemind For this purpose I use Hivemind (hats off to @roadscape) backed by PostgreSQL. &gt; Hive is a &quot;consensus interpretation&quot; layer for the Hive blockchain, maintaining the state of social features such as post feeds, follows, and communities. Written in Python, it synchronizes an SQL database with chain state, providing developers with a more flexible/extensible alternative to the raw hived API. ## FAT node Also, instead of a single `hived` node with all the plugins, I chose to run two nodes, one of them is a “fat node” (`LOW_MEMORY_NODE=OFF` and `CLEAR_VOTES=OFF`) on a MIRA-enabled instance to feed the Hivemind. Please note that I have NOT included `market_history` in my configuration, simply because it doesn’t require a “fat node”, but Hivemind requires it, so make sure that you have it somewhere. ## AH node Account history node is the other node I use in my setup. It serves not only account history, but it’s definitely the heaviest plugin here, hence the name. I’m not using MIRA here, because I prefer the pre-MIRA implementation of the account history plugin and MIRA had some issues with it. Also, it’s way too slow for replay. ## Jussi Instead of one service, I now have three specialized ones, I need to route incoming calls to them. So the `get_account_history` goes to the AH node, while the `get_followers` goes to Hivemind. That’s what jussi does, but it also caches things. ## Redis Jussi uses Redis as in-memory data cache. This can very effectively take load off the nodes. Even though most of the entries quickly expire, it’s enough to effectively answer common questions such as “what’s in the head block?” ![headblock.jpg](https://images.hive.blog/DQmdb8PSfpBkD2dm8cJtLZJNvCYAe2aYLy5Rr9MCLQxHLoN/headblock.jpg) 8 dApps asking for the latest block will result in 1 call to the node and 7 cache hits from Redis. ## Nginx That’s the world facing component - here you can have your SSL termination, rate limiting, load balancing, and all other fancy stuff related to serving your clients. # Resources Now when you know all the components, let&#39;s take a look at what is required to run them all and (in the darkness) bind them. ## Small stuff There are no specific needs here. The more traffic you expect, the more resources you will need, but they can run on any reasonable server on instance: - Nginx needs what nginx usually needs - a bunch of cores and some RAM. - Jussi is no different than nginx when it comes to resources. - Redis needs what redis usually needs - a few GB of RAM to hold the data. ## Big stuff - the AH node, which is non-MIRA in my setup, requires plenty of RAM for the `shared_memory.bin` file to either hold it on tmpfs or buffer/cache it, especially during replay. A machine with 32GB RAM will work, but I would rather suggest using a 64GB RAM machine these days. Of course, low latency storage such as SSD or NVMe is a must. You need 600GB of it. - the FAT node in my setup is running MIRA, so it’s not that memory hungry, but the more RAM you have, the more effective it can be. A machine with 16GB RAM might work, but I would go with 32GB or 64GB for it. Don’t even try without a very fast SSD or NVMe. You need 400GB of it. - Hivemind itself is a simple script, but it needs PostgreSQL as a database backend, and for that you need all the things that PostgreSQL usually needs. It can run on pretty much everything, as long as you have enough space to fit the data, currently 300GB. Of course, faster storage and more RAM will result in much better performance. # From zero to hero Reference hardware configuration: ``` Intel(R) Xeon(R) E-2274G CPU @ 4.00GHz 64GB RAM, ECC, 2666MT/s 2x NVMe 960GB (SAMSUNG PM983) ``` When you are starting from scratch, it’s best to get a recent `block_log` I’m providing one at https://gtg.openhive.network/get/blockchain/ How fast you can get it depends on your network and load on my server. The average downloading speed is around 30MB/s, so you should be able to get it in less than 3 hours. ![replay-speed.png](https://images.hive.blog/DQmRTxHALWD8Nszhg7cYkqu4tQHCLotEYMK7USDF2xthbAH/replay-speed.png) ![replay-times.png](https://images.hive.blog/DQmeYsSaz9PTyt6wamQU76Z6Mz7gJGce8aHxmj78Q58DLuo/replay-times.png) |Node type|Replay Time| |---------|-------| |AH Node |15 hours 42 minutes| |Fat Node |48 hours 53 minutes| |Hivemind |85 hours 50 minutes| Roughly you need 4 days and 9 hours to have it synced to the latest head block. ![4days9hours.jpg](https://images.hive.blog/DQmTQXoQYYFenMLrvLRZzuHZQdZ6wStc394jKTnGF8bya1s/4days9hours.jpg) A lot can be improved at the backend, and we are working on that. To be developer-friendly, we also need to improve the set of available API calls, finally get rid of the deprecated ones such as `get_state`, and move away from the all in one wrapper `condenser_api`. But that&#39;s a different story for a different occasion. ![Hive_Queen](https://images.hive.blog/DQmSJUo4g9AmoVFoAbs6gzMw6coVURUQKg7URtBSfkEj5oJ/Hive_free-file.png) See: Hive Pressure 2: How to Answer Hive Questions? by @gtg" />
<meta property="og:description" content="First, you need to learn how to ask good questions, and here are some of the resources that will help you to do so: https://developers.hive.io/apidefinitions/ https://hive.hivesigner.com/ (Kudos to @inertia and @good-karma) This set of API calls is far from perfect, but for now it has to be enough for general purpose API nodes. https://www.youtube.com/watch?v=vlW9lDE3DuI # The big, the slow, and the ugly. Back in the days, we used to run a so-called “full node”, that is a single ~~`steemd`~~ (yeah, we haven’t renamed the binary yet) node that was built with `LOW_MEMORY_NODE=OFF` and `CLEAR_VOTES=OFF` and configured with all the plugins you can get. It required a lot of RAM, it replayed for ages, and it was a huge pain to keep it running. Our code is great for running blockchain. It’s not equally efficient when it has to answer complex questions. # Current architecture The idea is to move the workload requiring complex queries out of our blockchain nodes. ``` +----------+ | &lt;-----------------+ @ @@@@@@ ,@@@@@% | Hivemind | | @@@@ (@@@@@* @@@@@@ +-------+ | &lt;-------+ | %@@@@@@ @@@@@@ %@@@@@, | | +-----^----+ | | @@@@@@@@@@ @@@@@@ @@@@@@ | redis | | | | ,@@@@@@@@@@@@ @@@@@@ @@@@@@ | &lt;--+ | +----v-----+ | @@@@@@@@@@@@@@@&amp; @@@@@@ @@@@@@ +-------+ | +-v-+ | | | @@@@@@@@@@@@@@@@@@ .@@@@@% @@@@@@ | | &lt;-----&gt; AH node | | @@@@@@@@@@@@@@@@@@@@@( .@@@@@% +-------+ +--&gt; j | | | | @@@@@@@@@@@@@@@@@@@@ @@@@@@ &lt;-------&gt; | | u | +----------+ | *@@@@@@@@@@@@@@@@ @@@@@@ @@@@@@. &lt;-------&gt; nginx &lt;-----&gt; s | | @@@@@@@@@@@@@@ &amp;@@@@@. @@@@@@ &lt;-------&gt; | | s | +----------+ | #@@@@@@@@@@ @@@@@@ #@@@@@/ +-------+ | i | | | | @@@@@@@@ /@@@@@/ @@@@@@ | &lt;-----&gt; FAT node &lt;---+ @@@@@( @@@@@@ .@@@@@&amp; +---+ | | @@ @@@@@&amp; @@@@@@ +----------+ ``` Sorry, lack of GIMP skills ## Hivemind For this purpose I use Hivemind (hats off to @roadscape) backed by PostgreSQL. &gt; Hive is a &quot;consensus interpretation&quot; layer for the Hive blockchain, maintaining the state of social features such as post feeds, follows, and communities. Written in Python, it synchronizes an SQL database with chain state, providing developers with a more flexible/extensible alternative to the raw hived API. ## FAT node Also, instead of a single `hived` node with all the plugins, I chose to run two nodes, one of them is a “fat node” (`LOW_MEMORY_NODE=OFF` and `CLEAR_VOTES=OFF`) on a MIRA-enabled instance to feed the Hivemind. Please note that I have NOT included `market_history` in my configuration, simply because it doesn’t require a “fat node”, but Hivemind requires it, so make sure that you have it somewhere. ## AH node Account history node is the other node I use in my setup. It serves not only account history, but it’s definitely the heaviest plugin here, hence the name. I’m not using MIRA here, because I prefer the pre-MIRA implementation of the account history plugin and MIRA had some issues with it. Also, it’s way too slow for replay. ## Jussi Instead of one service, I now have three specialized ones, I need to route incoming calls to them. So the `get_account_history` goes to the AH node, while the `get_followers` goes to Hivemind. That’s what jussi does, but it also caches things. ## Redis Jussi uses Redis as in-memory data cache. This can very effectively take load off the nodes. Even though most of the entries quickly expire, it’s enough to effectively answer common questions such as “what’s in the head block?” ![headblock.jpg](https://images.hive.blog/DQmdb8PSfpBkD2dm8cJtLZJNvCYAe2aYLy5Rr9MCLQxHLoN/headblock.jpg) 8 dApps asking for the latest block will result in 1 call to the node and 7 cache hits from Redis. ## Nginx That’s the world facing component - here you can have your SSL termination, rate limiting, load balancing, and all other fancy stuff related to serving your clients. # Resources Now when you know all the components, let&#39;s take a look at what is required to run them all and (in the darkness) bind them. ## Small stuff There are no specific needs here. The more traffic you expect, the more resources you will need, but they can run on any reasonable server on instance: - Nginx needs what nginx usually needs - a bunch of cores and some RAM. - Jussi is no different than nginx when it comes to resources. - Redis needs what redis usually needs - a few GB of RAM to hold the data. ## Big stuff - the AH node, which is non-MIRA in my setup, requires plenty of RAM for the `shared_memory.bin` file to either hold it on tmpfs or buffer/cache it, especially during replay. A machine with 32GB RAM will work, but I would rather suggest using a 64GB RAM machine these days. Of course, low latency storage such as SSD or NVMe is a must. You need 600GB of it. - the FAT node in my setup is running MIRA, so it’s not that memory hungry, but the more RAM you have, the more effective it can be. A machine with 16GB RAM might work, but I would go with 32GB or 64GB for it. Don’t even try without a very fast SSD or NVMe. You need 400GB of it. - Hivemind itself is a simple script, but it needs PostgreSQL as a database backend, and for that you need all the things that PostgreSQL usually needs. It can run on pretty much everything, as long as you have enough space to fit the data, currently 300GB. Of course, faster storage and more RAM will result in much better performance. # From zero to hero Reference hardware configuration: ``` Intel(R) Xeon(R) E-2274G CPU @ 4.00GHz 64GB RAM, ECC, 2666MT/s 2x NVMe 960GB (SAMSUNG PM983) ``` When you are starting from scratch, it’s best to get a recent `block_log` I’m providing one at https://gtg.openhive.network/get/blockchain/ How fast you can get it depends on your network and load on my server. The average downloading speed is around 30MB/s, so you should be able to get it in less than 3 hours. ![replay-speed.png](https://images.hive.blog/DQmRTxHALWD8Nszhg7cYkqu4tQHCLotEYMK7USDF2xthbAH/replay-speed.png) ![replay-times.png](https://images.hive.blog/DQmeYsSaz9PTyt6wamQU76Z6Mz7gJGce8aHxmj78Q58DLuo/replay-times.png) |Node type|Replay Time| |---------|-------| |AH Node |15 hours 42 minutes| |Fat Node |48 hours 53 minutes| |Hivemind |85 hours 50 minutes| Roughly you need 4 days and 9 hours to have it synced to the latest head block. ![4days9hours.jpg](https://images.hive.blog/DQmTQXoQYYFenMLrvLRZzuHZQdZ6wStc394jKTnGF8bya1s/4days9hours.jpg) A lot can be improved at the backend, and we are working on that. To be developer-friendly, we also need to improve the set of available API calls, finally get rid of the deprecated ones such as `get_state`, and move away from the all in one wrapper `condenser_api`. But that&#39;s a different story for a different occasion. ![Hive_Queen](https://images.hive.blog/DQmSJUo4g9AmoVFoAbs6gzMw6coVURUQKg7URtBSfkEj5oJ/Hive_free-file.png) See: Hive Pressure 2: How to Answer Hive Questions? by @gtg" />
<link rel="canonical" href="https://hive.blog/hive-160391/@gtg/hive-pressure-2-how-to-answer-hive-questions" />
<meta property="og:url" content="https://hive.blog/hive-160391/@gtg/hive-pressure-2-how-to-answer-hive-questions" />
<meta property="og:site_name" content="Hive Chain Documentation" />
<meta property="og:image" content="https://images.hive.blog/DQmdb8PSfpBkD2dm8cJtLZJNvCYAe2aYLy5Rr9MCLQxHLoN/headblock.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-05-04T11:32:57-07:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://images.hive.blog/DQmdb8PSfpBkD2dm8cJtLZJNvCYAe2aYLy5Rr9MCLQxHLoN/headblock.jpg" />
<meta property="twitter:title" content="Hive Pressure 2: How to Answer Hive Questions?" />
<script type="application/ld+json">
{"description":"First, you need to learn how to ask good questions, and here are some of the resources that will help you to do so: https://developers.hive.io/apidefinitions/ https://hive.hivesigner.com/ (Kudos to @inertia and @good-karma) This set of API calls is far from perfect, but for now it has to be enough for general purpose API nodes. https://www.youtube.com/watch?v=vlW9lDE3DuI # The big, the slow, and the ugly. Back in the days, we used to run a so-called “full node”, that is a single ~~`steemd`~~ (yeah, we haven’t renamed the binary yet) node that was built with `LOW_MEMORY_NODE=OFF` and `CLEAR_VOTES=OFF` and configured with all the plugins you can get. It required a lot of RAM, it replayed for ages, and it was a huge pain to keep it running. Our code is great for running blockchain. It’s not equally efficient when it has to answer complex questions. # Current architecture The idea is to move the workload requiring complex queries out of our blockchain nodes. ``` +----------+ | &lt;-----------------+ @ @@@@@@ ,@@@@@% | Hivemind | | @@@@ (@@@@@* @@@@@@ +-------+ | &lt;-------+ | %@@@@@@ @@@@@@ %@@@@@, | | +-----^----+ | | @@@@@@@@@@ @@@@@@ @@@@@@ | redis | | | | ,@@@@@@@@@@@@ @@@@@@ @@@@@@ | &lt;--+ | +----v-----+ | @@@@@@@@@@@@@@@&amp; @@@@@@ @@@@@@ +-------+ | +-v-+ | | | @@@@@@@@@@@@@@@@@@ .@@@@@% @@@@@@ | | &lt;-----&gt; AH node | | @@@@@@@@@@@@@@@@@@@@@( .@@@@@% +-------+ +--&gt; j | | | | @@@@@@@@@@@@@@@@@@@@ @@@@@@ &lt;-------&gt; | | u | +----------+ | *@@@@@@@@@@@@@@@@ @@@@@@ @@@@@@. &lt;-------&gt; nginx &lt;-----&gt; s | | @@@@@@@@@@@@@@ &amp;@@@@@. @@@@@@ &lt;-------&gt; | | s | +----------+ | #@@@@@@@@@@ @@@@@@ #@@@@@/ +-------+ | i | | | | @@@@@@@@ /@@@@@/ @@@@@@ | &lt;-----&gt; FAT node &lt;---+ @@@@@( @@@@@@ .@@@@@&amp; +---+ | | @@ @@@@@&amp; @@@@@@ +----------+ ``` Sorry, lack of GIMP skills ## Hivemind For this purpose I use Hivemind (hats off to @roadscape) backed by PostgreSQL. &gt; Hive is a &quot;consensus interpretation&quot; layer for the Hive blockchain, maintaining the state of social features such as post feeds, follows, and communities. Written in Python, it synchronizes an SQL database with chain state, providing developers with a more flexible/extensible alternative to the raw hived API. ## FAT node Also, instead of a single `hived` node with all the plugins, I chose to run two nodes, one of them is a “fat node” (`LOW_MEMORY_NODE=OFF` and `CLEAR_VOTES=OFF`) on a MIRA-enabled instance to feed the Hivemind. Please note that I have NOT included `market_history` in my configuration, simply because it doesn’t require a “fat node”, but Hivemind requires it, so make sure that you have it somewhere. ## AH node Account history node is the other node I use in my setup. It serves not only account history, but it’s definitely the heaviest plugin here, hence the name. I’m not using MIRA here, because I prefer the pre-MIRA implementation of the account history plugin and MIRA had some issues with it. Also, it’s way too slow for replay. ## Jussi Instead of one service, I now have three specialized ones, I need to route incoming calls to them. So the `get_account_history` goes to the AH node, while the `get_followers` goes to Hivemind. That’s what jussi does, but it also caches things. ## Redis Jussi uses Redis as in-memory data cache. This can very effectively take load off the nodes. Even though most of the entries quickly expire, it’s enough to effectively answer common questions such as “what’s in the head block?” ![headblock.jpg](https://images.hive.blog/DQmdb8PSfpBkD2dm8cJtLZJNvCYAe2aYLy5Rr9MCLQxHLoN/headblock.jpg) 8 dApps asking for the latest block will result in 1 call to the node and 7 cache hits from Redis. ## Nginx That’s the world facing component - here you can have your SSL termination, rate limiting, load balancing, and all other fancy stuff related to serving your clients. # Resources Now when you know all the components, let&#39;s take a look at what is required to run them all and (in the darkness) bind them. ## Small stuff There are no specific needs here. The more traffic you expect, the more resources you will need, but they can run on any reasonable server on instance: - Nginx needs what nginx usually needs - a bunch of cores and some RAM. - Jussi is no different than nginx when it comes to resources. - Redis needs what redis usually needs - a few GB of RAM to hold the data. ## Big stuff - the AH node, which is non-MIRA in my setup, requires plenty of RAM for the `shared_memory.bin` file to either hold it on tmpfs or buffer/cache it, especially during replay. A machine with 32GB RAM will work, but I would rather suggest using a 64GB RAM machine these days. Of course, low latency storage such as SSD or NVMe is a must. You need 600GB of it. - the FAT node in my setup is running MIRA, so it’s not that memory hungry, but the more RAM you have, the more effective it can be. A machine with 16GB RAM might work, but I would go with 32GB or 64GB for it. Don’t even try without a very fast SSD or NVMe. You need 400GB of it. - Hivemind itself is a simple script, but it needs PostgreSQL as a database backend, and for that you need all the things that PostgreSQL usually needs. It can run on pretty much everything, as long as you have enough space to fit the data, currently 300GB. Of course, faster storage and more RAM will result in much better performance. # From zero to hero Reference hardware configuration: ``` Intel(R) Xeon(R) E-2274G CPU @ 4.00GHz 64GB RAM, ECC, 2666MT/s 2x NVMe 960GB (SAMSUNG PM983) ``` When you are starting from scratch, it’s best to get a recent `block_log` I’m providing one at https://gtg.openhive.network/get/blockchain/ How fast you can get it depends on your network and load on my server. The average downloading speed is around 30MB/s, so you should be able to get it in less than 3 hours. ![replay-speed.png](https://images.hive.blog/DQmRTxHALWD8Nszhg7cYkqu4tQHCLotEYMK7USDF2xthbAH/replay-speed.png) ![replay-times.png](https://images.hive.blog/DQmeYsSaz9PTyt6wamQU76Z6Mz7gJGce8aHxmj78Q58DLuo/replay-times.png) |Node type|Replay Time| |---------|-------| |AH Node |15 hours 42 minutes| |Fat Node |48 hours 53 minutes| |Hivemind |85 hours 50 minutes| Roughly you need 4 days and 9 hours to have it synced to the latest head block. ![4days9hours.jpg](https://images.hive.blog/DQmTQXoQYYFenMLrvLRZzuHZQdZ6wStc394jKTnGF8bya1s/4days9hours.jpg) A lot can be improved at the backend, and we are working on that. To be developer-friendly, we also need to improve the set of available API calls, finally get rid of the deprecated ones such as `get_state`, and move away from the all in one wrapper `condenser_api`. But that&#39;s a different story for a different occasion. ![Hive_Queen](https://images.hive.blog/DQmSJUo4g9AmoVFoAbs6gzMw6coVURUQKg7URtBSfkEj5oJ/Hive_free-file.png) See: Hive Pressure 2: How to Answer Hive Questions? by @gtg","image":"https://images.hive.blog/DQmdb8PSfpBkD2dm8cJtLZJNvCYAe2aYLy5Rr9MCLQxHLoN/headblock.jpg","headline":"Hive Pressure 2: How to Answer Hive Questions?","dateModified":"2020-05-04T11:32:57-07:00","datePublished":"2020-05-04T11:32:57-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://hive.blog/hive-160391/@gtg/hive-pressure-2-how-to-answer-hive-questions"},"url":"https://hive.blog/hive-160391/@gtg/hive-pressure-2-how-to-answer-hive-questions","author":{"@type":"Person","name":"gtg"},"@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://hivedocs.info/feed.xml" title="Hive Chain Documentation" /><script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-161692811-1', 'auto');
  ga('send', 'pageview');
}
</script>
  
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
  
  <!-- jQuery Modal -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-modal/0.9.1/jquery.modal.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery-modal/0.9.1/jquery.modal.min.css" />
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/turbolinks/5.2.0/turbolinks.js" integrity="sha256-iM4Yzi/zLj/IshPWMC1IluRxTtRjMqjPGd97TZ9yYpU=" crossorigin="anonymous"></script>
  <script src='https://unpkg.com/steem-content-renderer'></script>
  <script>
    (function () {
      if (Turbolinks.supported) {
        Turbolinks.setProgressBarDelay(500);
      }
    })();
  </script>
  <script src="/assets/javascript/universal-bridge-against-phishing.js"></script>
  <script src="/assets/javascript/lazysizes.min.js" async=""></script>
  <link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Cousine|Inconsolata" rel="stylesheet">
  <link rel="shortcut icon" type="image/png" href="/assets/images/favicon.png">
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Hive Chain Documentation</a>

      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/news/">News</a><a class="page-link" href="/howto/">How To</a><a class="page-link" href="/links/">Useful Links</a><a class="page-link" href="/authors/">Authors</a><!-- HTML elements for search -->
          <input type="text" id="search-input" placeholder="Search" />
          
          <ul id="results-container"></ul>

          <script src="/assets/javascript/search.js"></script>
          <script>
            var sjs = SimpleJekyllSearch({
              searchInput: document.getElementById('search-input'),
              resultsContainer: document.getElementById('results-container'),
              json: '/search.json'
            })
          </script>
          <!-- <form style="float: right;" class="form-inline" method="get" action="http://www.google.com/search">
            <input type="hidden" name="sitesearch" value="hivedocs.info" />
            <input type="text" name="q" maxlength="255" placeholder="Search" />
          </form> -->
          
          <!-- <a href="#" onclick="try { $('#authors-container').slideToggle(); } catch { document.getElementById('authors-container').style.display = 'block'; }; return false;">Authors &#187;</a>
          <a href="#" onclick="try { $('#topics-container').slideToggle(); } catch { document.getElementById('topics-container').style.display = 'block'; }; return false;">Topics &#187;</a> -->
          
          <a href="#topics-container" rel="modal:open">Topics &#187;</a>
          
          <div id="topics-container" class="modal">
            <h3>Topics</h3>
            <ul><li><a class="page-link" href="/account-recovery/"><nobr>Account Recovery</nobr></a></li><li><a class="page-link" href="/core-development/"><nobr>Core Development</nobr></a></li><li><a class="page-link" href="/dapps/"><nobr>Dapps</nobr></a></li><li><a class="page-link" href="/docker/"><nobr>Docker</nobr></a></li><li><a class="page-link" href="/hardfork/"><nobr>Hardfork</nobr></a></li><li><a class="page-link" href="/hivemind/"><nobr>Hivemind</nobr></a></li><li><a class="page-link" href="/javascript/"><nobr>Javascript</nobr></a></li><li><a class="page-link" href="/multisig/"><nobr>Multisig</nobr></a></li><li><a class="page-link" href="/python/"><nobr>Python</nobr></a></li><li><a class="page-link" href="/ruby/"><nobr>Ruby</nobr></a></li><li><a class="page-link" href="/testnet/"><nobr>Testnet</nobr></a></li><li><a class="page-link" href="/tools/"><nobr>Tools</nobr></a></li><li><a class="page-link" href="/witness/"><nobr>Witness</nobr></a></li></ul>
          </div>
        </div>
      </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <div class="pull-right well">
      <img src="https://images.hive.blog/u/gtg/avatar" width="128" height="128" class="lazyload" />
    </div>
    
    <h1 class="post-title p-name" itemprop="name headline">Hive Pressure 2: How to Answer Hive Questions?</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2020-05-04T11:32:57-07:00" itemprop="datePublished">May 4, 2020
      </time>• <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">
          <a href="/authors/#author-gtg">gtg</a>
        </span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <div id="content-gtg-hive-pressure-2-how-to-answer-hive-questions">First, you need to learn how to ask good questions, and here are some of the resources that will help you to do so:
https://developers.hive.io/apidefinitions/
https://hive.hivesigner.com/
(Kudos to @inertia and @good-karma)

This set of API calls is far from perfect, but for now it has to be enough for general purpose API nodes.

<center>https://www.youtube.com/watch?v=vlW9lDE3DuI</center>

# The big, the slow, and the ugly.
Back in the days, we used to run a so-called “full node”, that is a single ~~`steemd`~~ (yeah, we haven’t renamed the binary yet) node that was built with `LOW_MEMORY_NODE=OFF` and `CLEAR_VOTES=OFF` and configured with all the plugins you can get.
It required a lot of RAM, it replayed for ages, and it was a huge pain to keep it running.
Our code is great for running blockchain. It’s not equally efficient when it has to answer complex questions.

# Current architecture
The idea is to move the workload requiring complex queries out of our blockchain nodes.

```
                  +----------+                                                                
                  |          &lt;-----------------+             @     @@@@@@    ,@@@@@%          
                  | Hivemind |                 |            @@@@    (@@@@@*    @@@@@@         
        +-------+ |          &lt;-------+         |          %@@@@@@     @@@@@@    %@@@@@,       
        |       | +-----^----+       |         |         @@@@@@@@@@    @@@@@@     @@@@@@      
        | redis |       |            |         |       ,@@@@@@@@@@@@     @@@@@@    @@@@@@     
        |       &lt;--+    |       +----v-----+   |      @@@@@@@@@@@@@@@&amp;    @@@@@@     @@@@@@   
        +-------+  |  +-v-+     |          |   |     @@@@@@@@@@@@@@@@@@    .@@@@@%    @@@@@@  
                   |  |   &lt;-----&gt; AH node  |   |   @@@@@@@@@@@@@@@@@@@@@(              .@@@@@%
        +-------+  +--&gt; j |     |          |   |    @@@@@@@@@@@@@@@@@@@@               @@@@@@ 
&lt;-------&gt;       |     | u |     +----------+   |     *@@@@@@@@@@@@@@@@     @@@@@@    @@@@@@.  
&lt;-------&gt; nginx &lt;-----&gt; s |                    |       @@@@@@@@@@@@@@    &amp;@@@@@.    @@@@@@    
&lt;-------&gt;       |     | s |     +----------+   |        #@@@@@@@@@@     @@@@@@    #@@@@@/     
        +-------+     | i |     |          |   |          @@@@@@@@    /@@@@@/    @@@@@@       
                      |   &lt;-----&gt; FAT node &lt;---+           @@@@@(    @@@@@@    .@@@@@&amp;        
                      +---+     |          |                 @@     @@@@@&amp;    @@@@@@          
                                +----------+                                                  
```
<sup>Sorry, lack of GIMP skills</sup>

## Hivemind
For this purpose I use Hivemind (hats off to @roadscape) backed by PostgreSQL.
&gt; Hive is a "consensus interpretation" layer for the Hive blockchain, maintaining the state of social features such as post feeds, follows, and communities. Written in Python, it synchronizes an SQL database with chain state, providing developers with a more flexible/extensible alternative to the raw hived API.

## FAT node
Also, instead of a single `hived` node with all the plugins, I chose to run two nodes, one of them is a “fat node” (`LOW_MEMORY_NODE=OFF` and `CLEAR_VOTES=OFF`) on a MIRA-enabled instance to feed the Hivemind.

Please note that I have NOT included `market_history` in my configuration, simply because it doesn’t require a “fat node”, but Hivemind requires it, so make sure that you have it somewhere.

## AH node
Account history node is the other node I use in my setup. It serves not only account history, but it’s definitely the heaviest plugin here, hence the name.
I’m not using MIRA here, because I prefer the pre-MIRA implementation of the account history plugin and MIRA had some issues with it. Also, it’s way too slow for replay.

## Jussi
Instead of one service, I now have three specialized ones, I need to route incoming calls to them.
So the `get_account_history` goes to the AH node, while the `get_followers` goes to Hivemind.
That’s what jussi does, but it also caches things.

## Redis
Jussi uses Redis as in-memory data cache. This can very effectively take load off the nodes. Even though most of the entries quickly expire, it’s enough to effectively answer common questions such as “what’s in the head block?”

<center>![headblock.jpg](https://images.hive.blog/DQmdb8PSfpBkD2dm8cJtLZJNvCYAe2aYLy5Rr9MCLQxHLoN/headblock.jpg)</center>

8 dApps asking for the latest block will result in 1 call to the node and 7 cache hits from Redis.

## Nginx
That’s the world facing component - here you can have your SSL termination, rate limiting, load balancing, and all other fancy stuff related to serving your clients.

# Resources
Now when you know all the components, let's take a look at what is required to run them all and (in the darkness) bind them.

## Small stuff
There are no specific needs here. The more traffic you expect, the more resources you will need, but they can run on any reasonable server on instance:

- Nginx needs what nginx usually needs - a bunch of cores and some RAM.
- Jussi is no different than nginx when it comes to resources.
- Redis needs what redis usually needs - a few GB of RAM to hold the data.

## Big stuff

- the AH node, which is non-MIRA in my setup, requires plenty of RAM for the `shared_memory.bin` file to either hold it on tmpfs or buffer/cache it, especially during replay. A machine with 32GB RAM will work, but I would rather suggest using a 64GB RAM machine these days. Of course, low latency storage such as SSD or NVMe is a must. You need 600GB of it.

- the FAT node in my setup is running MIRA, so it’s not that memory hungry, but the more RAM you have, the more effective it can be. A machine with 16GB RAM might work, but I would go with 32GB or 64GB for it. Don’t even try without a very fast SSD or NVMe. You need 400GB of it.

- Hivemind itself is a simple script, but it needs PostgreSQL as a database backend, and for that you need all the things that PostgreSQL usually needs. It can run on pretty much everything, as long as you have enough space to fit the data, currently 300GB. Of course, faster storage and more RAM will result in much better performance.

# From zero to hero
Reference hardware configuration:
```
Intel(R) Xeon(R) E-2274G CPU @ 4.00GHz
64GB RAM, ECC, 2666MT/s
2x NVMe 960GB (SAMSUNG PM983)
```
When you are starting from scratch, it’s best to get a recent `block_log`
I’m providing one at https://gtg.openhive.network/get/blockchain/
How fast you can get it depends on your network and load on my server. The average downloading speed is around 30MB/s, so you should be able to get it in less than 3 hours.


<center>![replay-speed.png](https://images.hive.blog/DQmRTxHALWD8Nszhg7cYkqu4tQHCLotEYMK7USDF2xthbAH/replay-speed.png)</center>

<center>![replay-times.png](https://images.hive.blog/DQmeYsSaz9PTyt6wamQU76Z6Mz7gJGce8aHxmj78Q58DLuo/replay-times.png)</center>

|Node type|Replay Time|
|---------|-------|
|AH Node |15 hours 42 minutes|
|Fat Node |48 hours 53 minutes|
|Hivemind |85 hours 50 minutes|

Roughly you need 4 days and 9 hours to have it synced to the latest head block.


<center>![4days9hours.jpg](https://images.hive.blog/DQmTQXoQYYFenMLrvLRZzuHZQdZ6wStc394jKTnGF8bya1s/4days9hours.jpg)</center>


A lot can be improved at the backend, and we are working on that. To be developer-friendly, we also need to improve the set of available API calls, finally get rid of the deprecated ones such as `get_state`, and move away from the all in one wrapper `condenser_api`. But that's a different story for a different occasion.

<center>![Hive_Queen](https://images.hive.blog/DQmSJUo4g9AmoVFoAbs6gzMw6coVURUQKg7URtBSfkEj5oJ/Hive_free-file.png)</center></div>
<script crossorigin="anonymous" integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>

<script src="https://unpkg.com/steem-content-renderer"></script>

<!-- <script src="https://cdn.jsdelivr.net/npm/hive-content-renderer/dist/hive-content-renderer.min.js"></script> -->
<script>
  $(document).ready(function() {
    try {
      const renderer = new SteemContentRenderer.DefaultRenderer({
      // const renderer = new HiveContentRenderer({
        baseUrl: "https://hive.blog/",
        breaks: true,
        skipSanitization: false,
        allowInsecureScriptTags: false,
        addNofollowToLinks: true,
        doNotShowImages: false,
        ipfsPrefix: "",
        assetsWidth: 640,
        assetsHeight: 480,
        imageProxyFn: (url) => url,
        usertagUrlFn: (account) => "/@gtg",
        hashtagUrlFn: (hashtag) => "/hive-pressure-2-how-to-answer-hive-questions",
        isLinkSafeFn: (url) => true,
      });
      
      const inputElem = $('#content-gtg-hive-pressure-2-how-to-answer-hive-questions').html();
      const outputElem = $('#content-gtg-hive-pressure-2-how-to-answer-hive-questions');
      const output = renderer.render(inputElem);
      
      outputElem.html(output);
    } catch(e) {
      console.log(e);
    }
  });
</script>

<style>
  #content-gtg-hive-pressure-2-how-to-answer-hive-questions {
    padding: 0 3rem;
    color: #444444;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.8;
    text-shadow: 0 1px 0 #ffffff;
    padding: 0.5rem;
  }
  #content-gtg-hive-pressure-2-how-to-answer-hive-questions code {
    background: white;
  }
  #content-gtg-hive-pressure-2-how-to-answer-hive-questions a {
    border-bottom: 1px solid #444444; color: #444444; text-decoration: none;
  }
  #content-gtg-hive-pressure-2-how-to-answer-hive-questions a:hover {
    border-bottom: 0;
  }
  #content-gtg-hive-pressure-2-how-to-answer-hive-questions h1 {
    font-size: 2.2em;
  }
  #content-gtg-hive-pressure-2-how-to-answer-hive-questions h2, h3, h4, h5 {
    margin-bottom: 0;
  }
  #content-gtg-hive-pressure-2-how-to-answer-hive-questions header small {
    color: #999;
    font-size: 50%;
  }
  #content-gtg-hive-pressure-2-how-to-answer-hive-questions img {
    max-width: 100%;
  }
</style>

<hr />

<p>
  See: <a href="https://hive.blog/hive-160391/@gtg/hive-pressure-2-how-to-answer-hive-questions">Hive Pressure 2: How to Answer Hive Questions?</a>
  by
  <a href="https://hive.blog/@gtg">@gtg</a>
</p>


  </div><a class="u-url" href="/news/devops/hivemind/nodes/2020/05/04/hive-pressure-2-how-to-answer-hive-questions.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading"><a rel="author" href="/">Hive Chain Documentation</a></h2>
    
    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">site curated by: @inertia</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Your resource for various levels of Hive Documentation.</p>
      </div>
    </div>
  </div>

</footer>
</body>

</html>
